INFO:     127.0.0.1:53726 - "GET /v1/models HTTP/1.1" 200 OK
INFO:     127.0.0.1:53730 - "GET /health HTTP/1.1" 200 OK
INFO:     127.0.0.1:53736 - "GET /v1/models HTTP/1.1" 200 OK
INFO:     127.0.0.1:53740 - "GET /v1/models HTTP/1.1" 200 OK
INFO:     127.0.0.1:53742 - "GET /v1/models HTTP/1.1" 200 OK
INFO:     127.0.0.1:53756 - "GET /v1/models HTTP/1.1" 200 OK
INFO:     127.0.0.1:53758 - "GET /v1/models HTTP/1.1" 200 OK
INFO:     127.0.0.1:53760 - "GET /v1/models HTTP/1.1" 200 OK
INFO:     127.0.0.1:53763 - "GET /v1/models HTTP/1.1" 200 OK
INFO:     127.0.0.1:53765 - "GET /v1/models HTTP/1.1" 200 OK
INFO:     127.0.0.1:53767 - "GET /v1/models HTTP/1.1" 200 OK
INFO:     127.0.0.1:53768 - "GET /v1/models HTTP/1.1" 200 OK
INFO:     127.0.0.1:53770 - "GET /v1/models HTTP/1.1" 200 OK
INFO:     127.0.0.1:53771 - "GET /v1/models HTTP/1.1" 200 OK
INFO:     127.0.0.1:53787 - "GET /v1/models HTTP/1.1" 200 OK
INFO:     127.0.0.1:53790 - "GET /v1/models HTTP/1.1" 200 OK
INFO:     127.0.0.1:53805 - "GET /v1/models HTTP/1.1" 200 OK
INFO:     127.0.0.1:53813 - "GET /v1/models HTTP/1.1" 200 OK
INFO:     127.0.0.1:53816 - "GET /v1/models HTTP/1.1" 200 OK
INFO:     127.0.0.1:53819 - "GET /v1/models HTTP/1.1" 200 OK
INFO:     127.0.0.1:53822 - "POST /v1/chat/completions HTTP/1.1" 200 OK
Initialized litellm callbacks, Async Success Callbacks: [<litellm.proxy.hooks.model_max_budget_limiter._PROXY_VirtualKeyModelMaxBudgetLimiter object at 0x120d623c0>]
ASYNC kwargs[caching]: False; litellm.cache: None; kwargs.get('cache'): None
Final returned optional params: {'stream': True, 'tools': []}
_is_function_call: False
makes async anthropic streaming POST request
INFO:     127.0.0.1:53831 - "GET /v1/models HTTP/1.1" 200 OK
INFO:     127.0.0.1:53833 - "GET /v1/models HTTP/1.1" 200 OK
INFO:     127.0.0.1:53834 - "GET /v1/models HTTP/1.1" 200 OK
INFO:     127.0.0.1:53836 - "GET /v1/models HTTP/1.1" 200 OK
INFO:     127.0.0.1:53837 - "GET /v1/models HTTP/1.1" 200 OK
INFO:     127.0.0.1:53848 - "POST /v1/chat/completions HTTP/1.1" 200 OK
Initialized litellm callbacks, Async Success Callbacks: [<litellm.proxy.hooks.model_max_budget_limiter._PROXY_VirtualKeyModelMaxBudgetLimiter object at 0x120d623c0>]
ASYNC kwargs[caching]: False; litellm.cache: None; kwargs.get('cache'): None
Final returned optional params: {'stream': True, 'tools': []}
_is_function_call: False
makes async anthropic streaming POST request
INFO:     127.0.0.1:53849 - "POST /v1/chat/completions HTTP/1.1" 200 OK
Initialized litellm callbacks, Async Success Callbacks: [<litellm.proxy.hooks.model_max_budget_limiter._PROXY_VirtualKeyModelMaxBudgetLimiter object at 0x120d623c0>]
ASYNC kwargs[caching]: False; litellm.cache: None; kwargs.get('cache'): None
INFO:     127.0.0.1:53850 - "POST /v1/chat/completions HTTP/1.1" 200 OK
Final returned optional params: {'stream': True, 'tools': []}
_is_function_call: False
makes async anthropic streaming POST request
Initialized litellm callbacks, Async Success Callbacks: [<litellm.proxy.hooks.model_max_budget_limiter._PROXY_VirtualKeyModelMaxBudgetLimiter object at 0x120d623c0>]
ASYNC kwargs[caching]: False; litellm.cache: None; kwargs.get('cache'): None
Final returned optional params: {'stream': True, 'tools': []}
_is_function_call: False
makes async anthropic streaming POST request
INFO:     127.0.0.1:53851 - "POST /v1/chat/completions HTTP/1.1" 200 OK
Initialized litellm callbacks, Async Success Callbacks: [<litellm.proxy.hooks.model_max_budget_limiter._PROXY_VirtualKeyModelMaxBudgetLimiter object at 0x120d623c0>]
ASYNC kwargs[caching]: False; litellm.cache: None; kwargs.get('cache'): None
Final returned optional params: {'stream': True, 'tools': []}
_is_function_call: False
makes async anthropic streaming POST request
INFO:     127.0.0.1:53853 - "POST /v1/chat/completions HTTP/1.1" 200 OK
Initialized litellm callbacks, Async Success Callbacks: [<litellm.proxy.hooks.model_max_budget_limiter._PROXY_VirtualKeyModelMaxBudgetLimiter object at 0x120d623c0>]
ASYNC kwargs[caching]: False; litellm.cache: None; kwargs.get('cache'): None
Final returned optional params: {'stream': True, 'tools': []}
_is_function_call: False
makes async anthropic streaming POST request
model_response finish reason 3: None; response_obj={'text': '', 'is_finished': False, 'finish_reason': '', 'usage': None, 'index': 0, 'tool_use': None}
model_response.choices[0].delta: Delta(provider_specific_fields=None, content=None, role=None, function_call=None, tool_calls=None, audio=None); completion_obj: {'content': ''}
self.sent_first_chunk: False
completion_obj: {'content': ''}, model_response.choices[0]: StreamingChoices(finish_reason=None, index=0, delta=Delta(provider_specific_fields=None, content=None, role=None, function_call=None, tool_calls=None, audio=None), logprobs=None), response_obj: {'text': '', 'is_finished': False, 'finish_reason': '', 'usage': None, 'index': 0, 'tool_use': None}

Raw OpenAI Chunk
ModelResponseStream(id='chatcmpl-21fc6157-48cd-4533-a959-1748f66e48cc', created=1762144783, model=None, object='chat.completion.chunk', system_fingerprint=None, choices=[StreamingChoices(finish_reason=None, index=0, delta=Delta(provider_specific_fields=None, content='', role=None, function_call=None, tool_calls=None, audio=None), logprobs=None)], provider_specific_fields=None, usage=Usage(completion_tokens=1, prompt_tokens=1493, total_tokens=1494, completion_tokens_details=None, prompt_tokens_details=PromptTokensDetailsWrapper(audio_tokens=None, cached_tokens=0, text_tokens=None, image_tokens=None, cache_creation_tokens=0, cache_creation_token_details=CacheCreationTokenDetails(ephemeral_5m_input_tokens=0, ephemeral_1h_input_tokens=0)), cache_creation_input_tokens=0, cache_read_input_tokens=0))

model_response finish reason 3: None; response_obj={'text': '', 'is_finished': False, 'finish_reason': None, 'logprobs': None, 'original_chunk': ModelResponseStream(id='chatcmpl-21fc6157-48cd-4533-a959-1748f66e48cc', created=1762144783, model=None, object='chat.completion.chunk', system_fingerprint=None, choices=[StreamingChoices(finish_reason=None, index=0, delta=Delta(provider_specific_fields=None, content='', role=None, function_call=None, tool_calls=None, audio=None), logprobs=None)], provider_specific_fields=None, usage=Usage(completion_tokens=1, prompt_tokens=1493, total_tokens=1494, completion_tokens_details=None, prompt_tokens_details=PromptTokensDetailsWrapper(audio_tokens=None, cached_tokens=0, text_tokens=None, image_tokens=None, cache_creation_tokens=0, cache_creation_token_details=CacheCreationTokenDetails(ephemeral_5m_input_tokens=0, ephemeral_1h_input_tokens=0)), cache_creation_input_tokens=0, cache_read_input_tokens=0)), 'usage': Usage(completion_tokens=1, prompt_tokens=1493, total_tokens=1494, completion_tokens_details=None, prompt_tokens_details=PromptTokensDetailsWrapper(audio_tokens=None, cached_tokens=0, text_tokens=None, image_tokens=None, cache_creation_tokens=0, cache_creation_token_details=CacheCreationTokenDetails(ephemeral_5m_input_tokens=0, ephemeral_1h_input_tokens=0)), cache_creation_input_tokens=0, cache_read_input_tokens=0)}
original delta: {'provider_specific_fields': None, 'content': '', 'role': None, 'function_call': None, 'tool_calls': None, 'audio': None}
new delta: Delta(provider_specific_fields=None, content='', role=None, function_call=None, tool_calls=None, audio=None)
model_response.choices[0].delta: Delta(provider_specific_fields=None, content='', role=None, function_call=None, tool_calls=None, audio=None); completion_obj: {'content': ''}
self.sent_first_chunk: False
completion_obj: {'content': ''}, model_response.choices[0]: StreamingChoices(finish_reason=None, index=0, delta=Delta(provider_specific_fields=None, content='', role=None, function_call=None, tool_calls=None, audio=None), logprobs=None), response_obj: {'text': '', 'is_finished': False, 'finish_reason': None, 'logprobs': None, 'original_chunk': ModelResponseStream(id='chatcmpl-21fc6157-48cd-4533-a959-1748f66e48cc', created=1762144783, model=None, object='chat.completion.chunk', system_fingerprint=None, choices=[StreamingChoices(finish_reason=None, index=0, delta=Delta(provider_specific_fields=None, content='', role=None, function_call=None, tool_calls=None, audio=None), logprobs=None)], provider_specific_fields=None, usage=Usage(completion_tokens=1, prompt_tokens=1493, total_tokens=1494, completion_tokens_details=None, prompt_tokens_details=PromptTokensDetailsWrapper(audio_tokens=None, cached_tokens=0, text_tokens=None, image_tokens=None, cache_creation_tokens=0, cache_creation_token_details=CacheCreationTokenDetails(ephemeral_5m_input_tokens=0, ephemeral_1h_input_tokens=0)), cache_creation_input_tokens=0, cache_read_input_tokens=0)), 'usage': Usage(completion_tokens=1, prompt_tokens=1493, total_tokens=1494, completion_tokens_details=None, prompt_tokens_details=PromptTokensDetailsWrapper(audio_tokens=None, cached_tokens=0, text_tokens=None, image_tokens=None, cache_creation_tokens=0, cache_creation_token_details=CacheCreationTokenDetails(ephemeral_5m_input_tokens=0, ephemeral_1h_input_tokens=0)), cache_creation_input_tokens=0, cache_read_input_tokens=0)}
model_response finish reason 3: None; response_obj={'text': '', 'is_finished': False, 'finish_reason': '', 'usage': None, 'index': 0, 'tool_use': None}
model_response.choices[0].delta: Delta(provider_specific_fields=None, content=None, role=None, function_call=None, tool_calls=None, audio=None); completion_obj: {'content': ''}
self.sent_first_chunk: False
completion_obj: {'content': ''}, model_response.choices[0]: StreamingChoices(finish_reason=None, index=0, delta=Delta(provider_specific_fields=None, content=None, role=None, function_call=None, tool_calls=None, audio=None), logprobs=None), response_obj: {'text': '', 'is_finished': False, 'finish_reason': '', 'usage': None, 'index': 0, 'tool_use': None}
model_response finish reason 3: None; response_obj={'text': '', 'is_finished': False, 'finish_reason': '', 'usage': None, 'index': 0, 'tool_use': None}
model_response.choices[0].delta: Delta(provider_specific_fields=None, content=None, role=None, function_call=None, tool_calls=None, audio=None); completion_obj: {'content': ''}
self.sent_first_chunk: False
completion_obj: {'content': ''}, model_response.choices[0]: StreamingChoices(finish_reason=None, index=0, delta=Delta(provider_specific_fields=None, content=None, role=None, function_call=None, tool_calls=None, audio=None), logprobs=None), response_obj: {'text': '', 'is_finished': False, 'finish_reason': '', 'usage': None, 'index': 0, 'tool_use': None}

Raw OpenAI Chunk
ModelResponseStream(id='chatcmpl-21fc6157-48cd-4533-a959-1748f66e48cc', created=1762144783, model=None, object='chat.completion.chunk', system_fingerprint=None, choices=[StreamingChoices(finish_reason=None, index=0, delta=Delta(provider_specific_fields=None, content='', role=None, function_call=None, tool_calls=None, audio=None), logprobs=None)], provider_specific_fields=None, usage=None)

model_response finish reason 3: None; response_obj={'text': '', 'is_finished': False, 'finish_reason': None, 'logprobs': None, 'original_chunk': ModelResponseStream(id='chatcmpl-21fc6157-48cd-4533-a959-1748f66e48cc', created=1762144783, model=None, object='chat.completion.chunk', system_fingerprint=None, choices=[StreamingChoices(finish_reason=None, index=0, delta=Delta(provider_specific_fields=None, content='', role=None, function_call=None, tool_calls=None, audio=None), logprobs=None)], provider_specific_fields=None, usage=None), 'usage': None}
original delta: {'provider_specific_fields': None, 'content': '', 'role': None, 'function_call': None, 'tool_calls': None, 'audio': None}
new delta: Delta(provider_specific_fields=None, content='', role=None, function_call=None, tool_calls=None, audio=None)
model_response.choices[0].delta: Delta(provider_specific_fields=None, content='', role=None, function_call=None, tool_calls=None, audio=None); completion_obj: {'content': ''}
self.sent_first_chunk: False
completion_obj: {'content': ''}, model_response.choices[0]: StreamingChoices(finish_reason=None, index=0, delta=Delta(provider_specific_fields=None, content='', role=None, function_call=None, tool_calls=None, audio=None), logprobs=None), response_obj: {'text': '', 'is_finished': False, 'finish_reason': None, 'logprobs': None, 'original_chunk': ModelResponseStream(id='chatcmpl-21fc6157-48cd-4533-a959-1748f66e48cc', created=1762144783, model=None, object='chat.completion.chunk', system_fingerprint=None, choices=[StreamingChoices(finish_reason=None, index=0, delta=Delta(provider_specific_fields=None, content='', role=None, function_call=None, tool_calls=None, audio=None), logprobs=None)], provider_specific_fields=None, usage=None), 'usage': None}
model_response finish reason 3: None; response_obj={'text': '', 'is_finished': False, 'finish_reason': '', 'usage': None, 'index': 0, 'tool_use': None}
model_response.choices[0].delta: Delta(provider_specific_fields=None, content=None, role=None, function_call=None, tool_calls=None, audio=None); completion_obj: {'content': ''}
self.sent_first_chunk: False
completion_obj: {'content': ''}, model_response.choices[0]: StreamingChoices(finish_reason=None, index=0, delta=Delta(provider_specific_fields=None, content=None, role=None, function_call=None, tool_calls=None, audio=None), logprobs=None), response_obj: {'text': '', 'is_finished': False, 'finish_reason': '', 'usage': None, 'index': 0, 'tool_use': None}
model_response finish reason 3: None; response_obj={'text': '', 'is_finished': False, 'finish_reason': '', 'usage': None, 'index': 0, 'tool_use': None}
model_response.choices[0].delta: Delta(provider_specific_fields=None, content=None, role=None, function_call=None, tool_calls=None, audio=None); completion_obj: {'content': ''}
self.sent_first_chunk: False
completion_obj: {'content': ''}, model_response.choices[0]: StreamingChoices(finish_reason=None, index=0, delta=Delta(provider_specific_fields=None, content=None, role=None, function_call=None, tool_calls=None, audio=None), logprobs=None), response_obj: {'text': '', 'is_finished': False, 'finish_reason': '', 'usage': None, 'index': 0, 'tool_use': None}

Raw OpenAI Chunk
ModelResponseStream(id='chatcmpl-21fc6157-48cd-4533-a959-1748f66e48cc', created=1762144783, model=None, object='chat.completion.chunk', system_fingerprint=None, choices=[StreamingChoices(finish_reason=None, index=0, delta=Delta(provider_specific_fields=None, content='No', role=None, function_call=None, tool_calls=None, audio=None), logprobs=None)], provider_specific_fields=None, usage=None)

model_response finish reason 3: None; response_obj={'text': 'No', 'is_finished': False, 'finish_reason': None, 'logprobs': None, 'original_chunk': ModelResponseStream(id='chatcmpl-21fc6157-48cd-4533-a959-1748f66e48cc', created=1762144783, model=None, object='chat.completion.chunk', system_fingerprint=None, choices=[StreamingChoices(finish_reason=None, index=0, delta=Delta(provider_specific_fields=None, content='No', role=None, function_call=None, tool_calls=None, audio=None), logprobs=None)], provider_specific_fields=None, usage=None), 'usage': None}
original delta: {'provider_specific_fields': None, 'content': 'No', 'role': None, 'function_call': None, 'tool_calls': None, 'audio': None}
new delta: Delta(provider_specific_fields=None, content='No', role=None, function_call=None, tool_calls=None, audio=None)
model_response.choices[0].delta: Delta(provider_specific_fields=None, content='No', role=None, function_call=None, tool_calls=None, audio=None); completion_obj: {'content': 'No'}
self.sent_first_chunk: False
completion_obj: {'content': 'No'}, model_response.choices[0]: StreamingChoices(finish_reason=None, index=0, delta=Delta(provider_specific_fields=None, content='No', role=None, function_call=None, tool_calls=None, audio=None), logprobs=None), response_obj: {'text': 'No', 'is_finished': False, 'finish_reason': None, 'logprobs': None, 'original_chunk': ModelResponseStream(id='chatcmpl-21fc6157-48cd-4533-a959-1748f66e48cc', created=1762144783, model=None, object='chat.completion.chunk', system_fingerprint=None, choices=[StreamingChoices(finish_reason=None, index=0, delta=Delta(provider_specific_fields=None, content='No', role=None, function_call=None, tool_calls=None, audio=None), logprobs=None)], provider_specific_fields=None, usage=None), 'usage': None}
choice_json: {'index': 0, 'delta': {'provider_specific_fields': None, 'content': 'No', 'role': None, 'function_call': None, 'tool_calls': None, 'audio': None}, 'logprobs': None}
choices in streaming: [StreamingChoices(finish_reason=None, index=0, delta=Delta(provider_specific_fields=None, content='No', role=None, function_call=None, tool_calls=None, audio=None), logprobs=None)]
final returned processed chunk: ModelResponseStream(id='chatcmpl-21fc6157-48cd-4533-a959-1748f66e48cc', created=1762144783, model='claude-sonnet-4-5-20250929', object='chat.completion.chunk', system_fingerprint=None, choices=[StreamingChoices(finish_reason=None, index=0, delta=Delta(provider_specific_fields=None, content='No', role='assistant', function_call=None, tool_calls=None, audio=None), logprobs=None)], provider_specific_fields=None, citations=None)
model_response finish reason 3: None; response_obj={'text': '', 'is_finished': False, 'finish_reason': '', 'usage': None, 'index': 0, 'tool_use': None}
model_response.choices[0].delta: Delta(provider_specific_fields=None, content=None, role=None, function_call=None, tool_calls=None, audio=None); completion_obj: {'content': ''}
self.sent_first_chunk: True
completion_obj: {'content': ''}, model_response.choices[0]: StreamingChoices(finish_reason=None, index=0, delta=Delta(provider_specific_fields=None, content=None, role=None, function_call=None, tool_calls=None, audio=None), logprobs=None), response_obj: {'text': '', 'is_finished': False, 'finish_reason': '', 'usage': None, 'index': 0, 'tool_use': None}
model_response finish reason 3: None; response_obj={'text': '', 'is_finished': False, 'finish_reason': '', 'usage': None, 'index': 0, 'tool_use': None}
model_response.choices[0].delta: Delta(provider_specific_fields=None, content=None, role=None, function_call=None, tool_calls=None, audio=None); completion_obj: {'content': ''}
self.sent_first_chunk: False
completion_obj: {'content': ''}, model_response.choices[0]: StreamingChoices(finish_reason=None, index=0, delta=Delta(provider_specific_fields=None, content=None, role=None, function_call=None, tool_calls=None, audio=None), logprobs=None), response_obj: {'text': '', 'is_finished': False, 'finish_reason': '', 'usage': None, 'index': 0, 'tool_use': None}

Raw OpenAI Chunk
ModelResponseStream(id='chatcmpl-8013da75-3435-4199-b8cb-c12edc98d5c7', created=1762144783, model=None, object='chat.completion.chunk', system_fingerprint=None, choices=[StreamingChoices(finish_reason=None, index=0, delta=Delta(provider_specific_fields=None, content='', role=None, function_call=None, tool_calls=None, audio=None), logprobs=None)], provider_specific_fields=None, usage=Usage(completion_tokens=2, prompt_tokens=1321, total_tokens=1323, completion_tokens_details=None, prompt_tokens_details=PromptTokensDetailsWrapper(audio_tokens=None, cached_tokens=0, text_tokens=None, image_tokens=None, cache_creation_tokens=0, cache_creation_token_details=CacheCreationTokenDetails(ephemeral_5m_input_tokens=0, ephemeral_1h_input_tokens=0)), cache_creation_input_tokens=0, cache_read_input_tokens=0))

model_response finish reason 3: None; response_obj={'text': '', 'is_finished': False, 'finish_reason': None, 'logprobs': None, 'original_chunk': ModelResponseStream(id='chatcmpl-8013da75-3435-4199-b8cb-c12edc98d5c7', created=1762144783, model=None, object='chat.completion.chunk', system_fingerprint=None, choices=[StreamingChoices(finish_reason=None, index=0, delta=Delta(provider_specific_fields=None, content='', role=None, function_call=None, tool_calls=None, audio=None), logprobs=None)], provider_specific_fields=None, usage=Usage(completion_tokens=2, prompt_tokens=1321, total_tokens=1323, completion_tokens_details=None, prompt_tokens_details=PromptTokensDetailsWrapper(audio_tokens=None, cached_tokens=0, text_tokens=None, image_tokens=None, cache_creation_tokens=0, cache_creation_token_details=CacheCreationTokenDetails(ephemeral_5m_input_tokens=0, ephemeral_1h_input_tokens=0)), cache_creation_input_tokens=0, cache_read_input_tokens=0)), 'usage': Usage(completion_tokens=2, prompt_tokens=1321, total_tokens=1323, completion_tokens_details=None, prompt_tokens_details=PromptTokensDetailsWrapper(audio_tokens=None, cached_tokens=0, text_tokens=None, image_tokens=None, cache_creation_tokens=0, cache_creation_token_details=CacheCreationTokenDetails(ephemeral_5m_input_tokens=0, ephemeral_1h_input_tokens=0)), cache_creation_input_tokens=0, cache_read_input_tokens=0)}
original delta: {'provider_specific_fields': None, 'content': '', 'role': None, 'function_call': None, 'tool_calls': None, 'audio': None}
new delta: Delta(provider_specific_fields=None, content='', role=None, function_call=None, tool_calls=None, audio=None)
model_response.choices[0].delta: Delta(provider_specific_fields=None, content='', role=None, function_call=None, tool_calls=None, audio=None); completion_obj: {'content': ''}
self.sent_first_chunk: False
completion_obj: {'content': ''}, model_response.choices[0]: StreamingChoices(finish_reason=None, index=0, delta=Delta(provider_specific_fields=None, content='', role=None, function_call=None, tool_calls=None, audio=None), logprobs=None), response_obj: {'text': '', 'is_finished': False, 'finish_reason': None, 'logprobs': None, 'original_chunk': ModelResponseStream(id='chatcmpl-8013da75-3435-4199-b8cb-c12edc98d5c7', created=1762144783, model=None, object='chat.completion.chunk', system_fingerprint=None, choices=[StreamingChoices(finish_reason=None, index=0, delta=Delta(provider_specific_fields=None, content='', role=None, function_call=None, tool_calls=None, audio=None), logprobs=None)], provider_specific_fields=None, usage=Usage(completion_tokens=2, prompt_tokens=1321, total_tokens=1323, completion_tokens_details=None, prompt_tokens_details=PromptTokensDetailsWrapper(audio_tokens=None, cached_tokens=0, text_tokens=None, image_tokens=None, cache_creation_tokens=0, cache_creation_token_details=CacheCreationTokenDetails(ephemeral_5m_input_tokens=0, ephemeral_1h_input_tokens=0)), cache_creation_input_tokens=0, cache_read_input_tokens=0)), 'usage': Usage(completion_tokens=2, prompt_tokens=1321, total_tokens=1323, completion_tokens_details=None, prompt_tokens_details=PromptTokensDetailsWrapper(audio_tokens=None, cached_tokens=0, text_tokens=None, image_tokens=None, cache_creation_tokens=0, cache_creation_token_details=CacheCreationTokenDetails(ephemeral_5m_input_tokens=0, ephemeral_1h_input_tokens=0)), cache_creation_input_tokens=0, cache_read_input_tokens=0)}
model_response finish reason 3: None; response_obj={'text': '', 'is_finished': False, 'finish_reason': '', 'usage': None, 'index': 0, 'tool_use': None}
model_response.choices[0].delta: Delta(provider_specific_fields=None, content=None, role=None, function_call=None, tool_calls=None, audio=None); completion_obj: {'content': ''}
self.sent_first_chunk: False
completion_obj: {'content': ''}, model_response.choices[0]: StreamingChoices(finish_reason=None, index=0, delta=Delta(provider_specific_fields=None, content=None, role=None, function_call=None, tool_calls=None, audio=None), logprobs=None), response_obj: {'text': '', 'is_finished': False, 'finish_reason': '', 'usage': None, 'index': 0, 'tool_use': None}
model_response finish reason 3: None; response_obj={'text': '', 'is_finished': False, 'finish_reason': '', 'usage': None, 'index': 0, 'tool_use': None}
model_response.choices[0].delta: Delta(provider_specific_fields=None, content=None, role=None, function_call=None, tool_calls=None, audio=None); completion_obj: {'content': ''}
self.sent_first_chunk: False
completion_obj: {'content': ''}, model_response.choices[0]: StreamingChoices(finish_reason=None, index=0, delta=Delta(provider_specific_fields=None, content=None, role=None, function_call=None, tool_calls=None, audio=None), logprobs=None), response_obj: {'text': '', 'is_finished': False, 'finish_reason': '', 'usage': None, 'index': 0, 'tool_use': None}

Raw OpenAI Chunk
ModelResponseStream(id='chatcmpl-8013da75-3435-4199-b8cb-c12edc98d5c7', created=1762144783, model=None, object='chat.completion.chunk', system_fingerprint=None, choices=[StreamingChoices(finish_reason=None, index=0, delta=Delta(provider_specific_fields=None, content='', role=None, function_call=None, tool_calls=None, audio=None), logprobs=None)], provider_specific_fields=None, usage=None)

model_response finish reason 3: None; response_obj={'text': '', 'is_finished': False, 'finish_reason': None, 'logprobs': None, 'original_chunk': ModelResponseStream(id='chatcmpl-8013da75-3435-4199-b8cb-c12edc98d5c7', created=1762144783, model=None, object='chat.completion.chunk', system_fingerprint=None, choices=[StreamingChoices(finish_reason=None, index=0, delta=Delta(provider_specific_fields=None, content='', role=None, function_call=None, tool_calls=None, audio=None), logprobs=None)], provider_specific_fields=None, usage=None), 'usage': None}
original delta: {'provider_specific_fields': None, 'content': '', 'role': None, 'function_call': None, 'tool_calls': None, 'audio': None}
new delta: Delta(provider_specific_fields=None, content='', role=None, function_call=None, tool_calls=None, audio=None)
model_response.choices[0].delta: Delta(provider_specific_fields=None, content='', role=None, function_call=None, tool_calls=None, audio=None); completion_obj: {'content': ''}
self.sent_first_chunk: False
completion_obj: {'content': ''}, model_response.choices[0]: StreamingChoices(finish_reason=None, index=0, delta=Delta(provider_specific_fields=None, content='', role=None, function_call=None, tool_calls=None, audio=None), logprobs=None), response_obj: {'text': '', 'is_finished': False, 'finish_reason': None, 'logprobs': None, 'original_chunk': ModelResponseStream(id='chatcmpl-8013da75-3435-4199-b8cb-c12edc98d5c7', created=1762144783, model=None, object='chat.completion.chunk', system_fingerprint=None, choices=[StreamingChoices(finish_reason=None, index=0, delta=Delta(provider_specific_fields=None, content='', role=None, function_call=None, tool_calls=None, audio=None), logprobs=None)], provider_specific_fields=None, usage=None), 'usage': None}
model_response finish reason 3: None; response_obj={'text': '', 'is_finished': False, 'finish_reason': '', 'usage': None, 'index': 0, 'tool_use': None}
model_response.choices[0].delta: Delta(provider_specific_fields=None, content=None, role=None, function_call=None, tool_calls=None, audio=None); completion_obj: {'content': ''}
self.sent_first_chunk: False
completion_obj: {'content': ''}, model_response.choices[0]: StreamingChoices(finish_reason=None, index=0, delta=Delta(provider_specific_fields=None, content=None, role=None, function_call=None, tool_calls=None, audio=None), logprobs=None), response_obj: {'text': '', 'is_finished': False, 'finish_reason': '', 'usage': None, 'index': 0, 'tool_use': None}
model_response finish reason 3: None; response_obj={'text': '', 'is_finished': False, 'finish_reason': '', 'usage': None, 'index': 0, 'tool_use': None}
model_response.choices[0].delta: Delta(provider_specific_fields=None, content=None, role=None, function_call=None, tool_calls=None, audio=None); completion_obj: {'content': ''}
self.sent_first_chunk: False
completion_obj: {'content': ''}, model_response.choices[0]: StreamingChoices(finish_reason=None, index=0, delta=Delta(provider_specific_fields=None, content=None, role=None, function_call=None, tool_calls=None, audio=None), logprobs=None), response_obj: {'text': '', 'is_finished': False, 'finish_reason': '', 'usage': None, 'index': 0, 'tool_use': None}

Raw OpenAI Chunk
ModelResponseStream(id='chatcmpl-8013da75-3435-4199-b8cb-c12edc98d5c7', created=1762144783, model=None, object='chat.completion.chunk', system_fingerprint=None, choices=[StreamingChoices(finish_reason=None, index=0, delta=Delta(provider_specific_fields=None, content='No', role=None, function_call=None, tool_calls=None, audio=None), logprobs=None)], provider_specific_fields=None, usage=None)

model_response finish reason 3: None; response_obj={'text': 'No', 'is_finished': False, 'finish_reason': None, 'logprobs': None, 'original_chunk': ModelResponseStream(id='chatcmpl-8013da75-3435-4199-b8cb-c12edc98d5c7', created=1762144783, model=None, object='chat.completion.chunk', system_fingerprint=None, choices=[StreamingChoices(finish_reason=None, index=0, delta=Delta(provider_specific_fields=None, content='No', role=None, function_call=None, tool_calls=None, audio=None), logprobs=None)], provider_specific_fields=None, usage=None), 'usage': None}
original delta: {'provider_specific_fields': None, 'content': 'No', 'role': None, 'function_call': None, 'tool_calls': None, 'audio': None}
new delta: Delta(provider_specific_fields=None, content='No', role=None, function_call=None, tool_calls=None, audio=None)
model_response.choices[0].delta: Delta(provider_specific_fields=None, content='No', role=None, function_call=None, tool_calls=None, audio=None); completion_obj: {'content': 'No'}
self.sent_first_chunk: False
completion_obj: {'content': 'No'}, model_response.choices[0]: StreamingChoices(finish_reason=None, index=0, delta=Delta(provider_specific_fields=None, content='No', role=None, function_call=None, tool_calls=None, audio=None), logprobs=None), response_obj: {'text': 'No', 'is_finished': False, 'finish_reason': None, 'logprobs': None, 'original_chunk': ModelResponseStream(id='chatcmpl-8013da75-3435-4199-b8cb-c12edc98d5c7', created=1762144783, model=None, object='chat.completion.chunk', system_fingerprint=None, choices=[StreamingChoices(finish_reason=None, index=0, delta=Delta(provider_specific_fields=None, content='No', role=None, function_call=None, tool_calls=None, audio=None), logprobs=None)], provider_specific_fields=None, usage=None), 'usage': None}
choice_json: {'index': 0, 'delta': {'provider_specific_fields': None, 'content': 'No', 'role': None, 'function_call': None, 'tool_calls': None, 'audio': None}, 'logprobs': None}
choices in streaming: [StreamingChoices(finish_reason=None, index=0, delta=Delta(provider_specific_fields=None, content='No', role=None, function_call=None, tool_calls=None, audio=None), logprobs=None)]
final returned processed chunk: ModelResponseStream(id='chatcmpl-8013da75-3435-4199-b8cb-c12edc98d5c7', created=1762144783, model='claude-sonnet-4-5-20250929', object='chat.completion.chunk', system_fingerprint=None, choices=[StreamingChoices(finish_reason=None, index=0, delta=Delta(provider_specific_fields=None, content='No', role='assistant', function_call=None, tool_calls=None, audio=None), logprobs=None)], provider_specific_fields=None, citations=None)
model_response finish reason 3: None; response_obj={'text': '', 'is_finished': False, 'finish_reason': '', 'usage': None, 'index': 0, 'tool_use': None}
model_response.choices[0].delta: Delta(provider_specific_fields=None, content=None, role=None, function_call=None, tool_calls=None, audio=None); completion_obj: {'content': ''}
self.sent_first_chunk: True
completion_obj: {'content': ''}, model_response.choices[0]: StreamingChoices(finish_reason=None, index=0, delta=Delta(provider_specific_fields=None, content=None, role=None, function_call=None, tool_calls=None, audio=None), logprobs=None), response_obj: {'text': '', 'is_finished': False, 'finish_reason': '', 'usage': None, 'index': 0, 'tool_use': None}
model_response finish reason 3: None; response_obj={'text': '', 'is_finished': False, 'finish_reason': '', 'usage': None, 'index': 0, 'tool_use': None}
model_response.choices[0].delta: Delta(provider_specific_fields=None, content=None, role=None, function_call=None, tool_calls=None, audio=None); completion_obj: {'content': ''}
self.sent_first_chunk: False
completion_obj: {'content': ''}, model_response.choices[0]: StreamingChoices(finish_reason=None, index=0, delta=Delta(provider_specific_fields=None, content=None, role=None, function_call=None, tool_calls=None, audio=None), logprobs=None), response_obj: {'text': '', 'is_finished': False, 'finish_reason': '', 'usage': None, 'index': 0, 'tool_use': None}

Raw OpenAI Chunk
ModelResponseStream(id='chatcmpl-24e35af5-25b0-4416-9f29-279db90a0879', created=1762144783, model=None, object='chat.completion.chunk', system_fingerprint=None, choices=[StreamingChoices(finish_reason=None, index=0, delta=Delta(provider_specific_fields=None, content='', role=None, function_call=None, tool_calls=None, audio=None), logprobs=None)], provider_specific_fields=None, usage=Usage(completion_tokens=1, prompt_tokens=204, total_tokens=205, completion_tokens_details=None, prompt_tokens_details=PromptTokensDetailsWrapper(audio_tokens=None, cached_tokens=0, text_tokens=None, image_tokens=None, cache_creation_tokens=0, cache_creation_token_details=CacheCreationTokenDetails(ephemeral_5m_input_tokens=0, ephemeral_1h_input_tokens=0)), cache_creation_input_tokens=0, cache_read_input_tokens=0))

model_response finish reason 3: None; response_obj={'text': '', 'is_finished': False, 'finish_reason': None, 'logprobs': None, 'original_chunk': ModelResponseStream(id='chatcmpl-24e35af5-25b0-4416-9f29-279db90a0879', created=1762144783, model=None, object='chat.completion.chunk', system_fingerprint=None, choices=[StreamingChoices(finish_reason=None, index=0, delta=Delta(provider_specific_fields=None, content='', role=None, function_call=None, tool_calls=None, audio=None), logprobs=None)], provider_specific_fields=None, usage=Usage(completion_tokens=1, prompt_tokens=204, total_tokens=205, completion_tokens_details=None, prompt_tokens_details=PromptTokensDetailsWrapper(audio_tokens=None, cached_tokens=0, text_tokens=None, image_tokens=None, cache_creation_tokens=0, cache_creation_token_details=CacheCreationTokenDetails(ephemeral_5m_input_tokens=0, ephemeral_1h_input_tokens=0)), cache_creation_input_tokens=0, cache_read_input_tokens=0)), 'usage': Usage(completion_tokens=1, prompt_tokens=204, total_tokens=205, completion_tokens_details=None, prompt_tokens_details=PromptTokensDetailsWrapper(audio_tokens=None, cached_tokens=0, text_tokens=None, image_tokens=None, cache_creation_tokens=0, cache_creation_token_details=CacheCreationTokenDetails(ephemeral_5m_input_tokens=0, ephemeral_1h_input_tokens=0)), cache_creation_input_tokens=0, cache_read_input_tokens=0)}
original delta: {'provider_specific_fields': None, 'content': '', 'role': None, 'function_call': None, 'tool_calls': None, 'audio': None}
new delta: Delta(provider_specific_fields=None, content='', role=None, function_call=None, tool_calls=None, audio=None)
model_response.choices[0].delta: Delta(provider_specific_fields=None, content='', role=None, function_call=None, tool_calls=None, audio=None); completion_obj: {'content': ''}
self.sent_first_chunk: False
completion_obj: {'content': ''}, model_response.choices[0]: StreamingChoices(finish_reason=None, index=0, delta=Delta(provider_specific_fields=None, content='', role=None, function_call=None, tool_calls=None, audio=None), logprobs=None), response_obj: {'text': '', 'is_finished': False, 'finish_reason': None, 'logprobs': None, 'original_chunk': ModelResponseStream(id='chatcmpl-24e35af5-25b0-4416-9f29-279db90a0879', created=1762144783, model=None, object='chat.completion.chunk', system_fingerprint=None, choices=[StreamingChoices(finish_reason=None, index=0, delta=Delta(provider_specific_fields=None, content='', role=None, function_call=None, tool_calls=None, audio=None), logprobs=None)], provider_specific_fields=None, usage=Usage(completion_tokens=1, prompt_tokens=204, total_tokens=205, completion_tokens_details=None, prompt_tokens_details=PromptTokensDetailsWrapper(audio_tokens=None, cached_tokens=0, text_tokens=None, image_tokens=None, cache_creation_tokens=0, cache_creation_token_details=CacheCreationTokenDetails(ephemeral_5m_input_tokens=0, ephemeral_1h_input_tokens=0)), cache_creation_input_tokens=0, cache_read_input_tokens=0)), 'usage': Usage(completion_tokens=1, prompt_tokens=204, total_tokens=205, completion_tokens_details=None, prompt_tokens_details=PromptTokensDetailsWrapper(audio_tokens=None, cached_tokens=0, text_tokens=None, image_tokens=None, cache_creation_tokens=0, cache_creation_token_details=CacheCreationTokenDetails(ephemeral_5m_input_tokens=0, ephemeral_1h_input_tokens=0)), cache_creation_input_tokens=0, cache_read_input_tokens=0)}
model_response finish reason 3: None; response_obj={'text': '', 'is_finished': False, 'finish_reason': '', 'usage': None, 'index': 0, 'tool_use': None}
model_response.choices[0].delta: Delta(provider_specific_fields=None, content=None, role=None, function_call=None, tool_calls=None, audio=None); completion_obj: {'content': ''}
self.sent_first_chunk: False
completion_obj: {'content': ''}, model_response.choices[0]: StreamingChoices(finish_reason=None, index=0, delta=Delta(provider_specific_fields=None, content=None, role=None, function_call=None, tool_calls=None, audio=None), logprobs=None), response_obj: {'text': '', 'is_finished': False, 'finish_reason': '', 'usage': None, 'index': 0, 'tool_use': None}
model_response finish reason 3: None; response_obj={'text': '', 'is_finished': False, 'finish_reason': '', 'usage': None, 'index': 0, 'tool_use': None}
model_response.choices[0].delta: Delta(provider_specific_fields=None, content=None, role=None, function_call=None, tool_calls=None, audio=None); completion_obj: {'content': ''}
self.sent_first_chunk: False
completion_obj: {'content': ''}, model_response.choices[0]: StreamingChoices(finish_reason=None, index=0, delta=Delta(provider_specific_fields=None, content=None, role=None, function_call=None, tool_calls=None, audio=None), logprobs=None), response_obj: {'text': '', 'is_finished': False, 'finish_reason': '', 'usage': None, 'index': 0, 'tool_use': None}

Raw OpenAI Chunk
ModelResponseStream(id='chatcmpl-24e35af5-25b0-4416-9f29-279db90a0879', created=1762144783, model=None, object='chat.completion.chunk', system_fingerprint=None, choices=[StreamingChoices(finish_reason=None, index=0, delta=Delta(provider_specific_fields=None, content='', role=None, function_call=None, tool_calls=None, audio=None), logprobs=None)], provider_specific_fields=None, usage=None)

model_response finish reason 3: None; response_obj={'text': '', 'is_finished': False, 'finish_reason': None, 'logprobs': None, 'original_chunk': ModelResponseStream(id='chatcmpl-24e35af5-25b0-4416-9f29-279db90a0879', created=1762144783, model=None, object='chat.completion.chunk', system_fingerprint=None, choices=[StreamingChoices(finish_reason=None, index=0, delta=Delta(provider_specific_fields=None, content='', role=None, function_call=None, tool_calls=None, audio=None), logprobs=None)], provider_specific_fields=None, usage=None), 'usage': None}
original delta: {'provider_specific_fields': None, 'content': '', 'role': None, 'function_call': None, 'tool_calls': None, 'audio': None}
new delta: Delta(provider_specific_fields=None, content='', role=None, function_call=None, tool_calls=None, audio=None)
model_response.choices[0].delta: Delta(provider_specific_fields=None, content='', role=None, function_call=None, tool_calls=None, audio=None); completion_obj: {'content': ''}
self.sent_first_chunk: False
completion_obj: {'content': ''}, model_response.choices[0]: StreamingChoices(finish_reason=None, index=0, delta=Delta(provider_specific_fields=None, content='', role=None, function_call=None, tool_calls=None, audio=None), logprobs=None), response_obj: {'text': '', 'is_finished': False, 'finish_reason': None, 'logprobs': None, 'original_chunk': ModelResponseStream(id='chatcmpl-24e35af5-25b0-4416-9f29-279db90a0879', created=1762144783, model=None, object='chat.completion.chunk', system_fingerprint=None, choices=[StreamingChoices(finish_reason=None, index=0, delta=Delta(provider_specific_fields=None, content='', role=None, function_call=None, tool_calls=None, audio=None), logprobs=None)], provider_specific_fields=None, usage=None), 'usage': None}
model_response finish reason 3: None; response_obj={'text': '', 'is_finished': False, 'finish_reason': '', 'usage': None, 'index': 0, 'tool_use': None}
model_response.choices[0].delta: Delta(provider_specific_fields=None, content=None, role=None, function_call=None, tool_calls=None, audio=None); completion_obj: {'content': ''}
self.sent_first_chunk: False
completion_obj: {'content': ''}, model_response.choices[0]: StreamingChoices(finish_reason=None, index=0, delta=Delta(provider_specific_fields=None, content=None, role=None, function_call=None, tool_calls=None, audio=None), logprobs=None), response_obj: {'text': '', 'is_finished': False, 'finish_reason': '', 'usage': None, 'index': 0, 'tool_use': None}
model_response finish reason 3: None; response_obj={'text': '', 'is_finished': False, 'finish_reason': '', 'usage': None, 'index': 0, 'tool_use': None}
model_response.choices[0].delta: Delta(provider_specific_fields=None, content=None, role=None, function_call=None, tool_calls=None, audio=None); completion_obj: {'content': ''}
self.sent_first_chunk: False
completion_obj: {'content': ''}, model_response.choices[0]: StreamingChoices(finish_reason=None, index=0, delta=Delta(provider_specific_fields=None, content=None, role=None, function_call=None, tool_calls=None, audio=None), logprobs=None), response_obj: {'text': '', 'is_finished': False, 'finish_reason': '', 'usage': None, 'index': 0, 'tool_use': None}

Raw OpenAI Chunk
ModelResponseStream(id='chatcmpl-24e35af5-25b0-4416-9f29-279db90a0879', created=1762144783, model=None, object='chat.completion.chunk', system_fingerprint=None, choices=[StreamingChoices(finish_reason=None, index=0, delta=Delta(provider_specific_fields=None, content='conversation', role=None, function_call=None, tool_calls=None, audio=None), logprobs=None)], provider_specific_fields=None, usage=None)

model_response finish reason 3: None; response_obj={'text': 'conversation', 'is_finished': False, 'finish_reason': None, 'logprobs': None, 'original_chunk': ModelResponseStream(id='chatcmpl-24e35af5-25b0-4416-9f29-279db90a0879', created=1762144783, model=None, object='chat.completion.chunk', system_fingerprint=None, choices=[StreamingChoices(finish_reason=None, index=0, delta=Delta(provider_specific_fields=None, content='conversation', role=None, function_call=None, tool_calls=None, audio=None), logprobs=None)], provider_specific_fields=None, usage=None), 'usage': None}
original delta: {'provider_specific_fields': None, 'content': 'conversation', 'role': None, 'function_call': None, 'tool_calls': None, 'audio': None}
new delta: Delta(provider_specific_fields=None, content='conversation', role=None, function_call=None, tool_calls=None, audio=None)
model_response.choices[0].delta: Delta(provider_specific_fields=None, content='conversation', role=None, function_call=None, tool_calls=None, audio=None); completion_obj: {'content': 'conversation'}
self.sent_first_chunk: False
completion_obj: {'content': 'conversation'}, model_response.choices[0]: StreamingChoices(finish_reason=None, index=0, delta=Delta(provider_specific_fields=None, content='conversation', role=None, function_call=None, tool_calls=None, audio=None), logprobs=None), response_obj: {'text': 'conversation', 'is_finished': False, 'finish_reason': None, 'logprobs': None, 'original_chunk': ModelResponseStream(id='chatcmpl-24e35af5-25b0-4416-9f29-279db90a0879', created=1762144783, model=None, object='chat.completion.chunk', system_fingerprint=None, choices=[StreamingChoices(finish_reason=None, index=0, delta=Delta(provider_specific_fields=None, content='conversation', role=None, function_call=None, tool_calls=None, audio=None), logprobs=None)], provider_specific_fields=None, usage=None), 'usage': None}
choice_json: {'index': 0, 'delta': {'provider_specific_fields': None, 'content': 'conversation', 'role': None, 'function_call': None, 'tool_calls': None, 'audio': None}, 'logprobs': None}
choices in streaming: [StreamingChoices(finish_reason=None, index=0, delta=Delta(provider_specific_fields=None, content='conversation', role=None, function_call=None, tool_calls=None, audio=None), logprobs=None)]
final returned processed chunk: ModelResponseStream(id='chatcmpl-24e35af5-25b0-4416-9f29-279db90a0879', created=1762144783, model='claude-sonnet-4-5-20250929', object='chat.completion.chunk', system_fingerprint=None, choices=[StreamingChoices(finish_reason=None, index=0, delta=Delta(provider_specific_fields=None, content='conversation', role='assistant', function_call=None, tool_calls=None, audio=None), logprobs=None)], provider_specific_fields=None, citations=None)
model_response finish reason 3: None; response_obj={'text': '', 'is_finished': False, 'finish_reason': '', 'usage': None, 'index': 0, 'tool_use': None}
model_response.choices[0].delta: Delta(provider_specific_fields=None, content=None, role=None, function_call=None, tool_calls=None, audio=None); completion_obj: {'content': ''}
self.sent_first_chunk: True
completion_obj: {'content': ''}, model_response.choices[0]: StreamingChoices(finish_reason=None, index=0, delta=Delta(provider_specific_fields=None, content=None, role=None, function_call=None, tool_calls=None, audio=None), logprobs=None), response_obj: {'text': '', 'is_finished': False, 'finish_reason': '', 'usage': None, 'index': 0, 'tool_use': None}
model_response finish reason 3: None; response_obj={'text': '', 'is_finished': False, 'finish_reason': '', 'usage': None, 'index': 0, 'tool_use': None}
model_response.choices[0].delta: Delta(provider_specific_fields=None, content=None, role=None, function_call=None, tool_calls=None, audio=None); completion_obj: {'content': ''}
self.sent_first_chunk: True
completion_obj: {'content': ''}, model_response.choices[0]: StreamingChoices(finish_reason=None, index=0, delta=Delta(provider_specific_fields=None, content=None, role=None, function_call=None, tool_calls=None, audio=None), logprobs=None), response_obj: {'text': '', 'is_finished': False, 'finish_reason': '', 'usage': None, 'index': 0, 'tool_use': None}

Raw OpenAI Chunk
ModelResponseStream(id='chatcmpl-8013da75-3435-4199-b8cb-c12edc98d5c7', created=1762144783, model=None, object='chat.completion.chunk', system_fingerprint=None, choices=[StreamingChoices(finish_reason=None, index=0, delta=Delta(provider_specific_fields=None, content='', role=None, function_call=None, tool_calls=None, audio=None), logprobs=None)], provider_specific_fields=None, usage=None)

model_response finish reason 3: None; response_obj={'text': '', 'is_finished': False, 'finish_reason': None, 'logprobs': None, 'original_chunk': ModelResponseStream(id='chatcmpl-8013da75-3435-4199-b8cb-c12edc98d5c7', created=1762144783, model=None, object='chat.completion.chunk', system_fingerprint=None, choices=[StreamingChoices(finish_reason=None, index=0, delta=Delta(provider_specific_fields=None, content='', role=None, function_call=None, tool_calls=None, audio=None), logprobs=None)], provider_specific_fields=None, usage=None), 'usage': None}
original delta: {'provider_specific_fields': None, 'content': '', 'role': None, 'function_call': None, 'tool_calls': None, 'audio': None}
new delta: Delta(provider_specific_fields=None, content='', role=None, function_call=None, tool_calls=None, audio=None)
model_response.choices[0].delta: Delta(provider_specific_fields=None, content='', role=None, function_call=None, tool_calls=None, audio=None); completion_obj: {'content': ''}
self.sent_first_chunk: True
completion_obj: {'content': ''}, model_response.choices[0]: StreamingChoices(finish_reason=None, index=0, delta=Delta(provider_specific_fields=None, content='', role=None, function_call=None, tool_calls=None, audio=None), logprobs=None), response_obj: {'text': '', 'is_finished': False, 'finish_reason': None, 'logprobs': None, 'original_chunk': ModelResponseStream(id='chatcmpl-8013da75-3435-4199-b8cb-c12edc98d5c7', created=1762144783, model=None, object='chat.completion.chunk', system_fingerprint=None, choices=[StreamingChoices(finish_reason=None, index=0, delta=Delta(provider_specific_fields=None, content='', role=None, function_call=None, tool_calls=None, audio=None), logprobs=None)], provider_specific_fields=None, usage=None), 'usage': None}
model_response finish reason 3: None; response_obj={'text': '', 'is_finished': False, 'finish_reason': '', 'usage': None, 'index': 0, 'tool_use': None}
model_response.choices[0].delta: Delta(provider_specific_fields=None, content=None, role=None, function_call=None, tool_calls=None, audio=None); completion_obj: {'content': ''}
self.sent_first_chunk: True
completion_obj: {'content': ''}, model_response.choices[0]: StreamingChoices(finish_reason=None, index=0, delta=Delta(provider_specific_fields=None, content=None, role=None, function_call=None, tool_calls=None, audio=None), logprobs=None), response_obj: {'text': '', 'is_finished': False, 'finish_reason': '', 'usage': None, 'index': 0, 'tool_use': None}
model_response finish reason 3: None; response_obj={'text': '', 'is_finished': False, 'finish_reason': '', 'usage': None, 'index': 0, 'tool_use': None}
model_response.choices[0].delta: Delta(provider_specific_fields=None, content=None, role=None, function_call=None, tool_calls=None, audio=None); completion_obj: {'content': ''}
self.sent_first_chunk: True
completion_obj: {'content': ''}, model_response.choices[0]: StreamingChoices(finish_reason=None, index=0, delta=Delta(provider_specific_fields=None, content=None, role=None, function_call=None, tool_calls=None, audio=None), logprobs=None), response_obj: {'text': '', 'is_finished': False, 'finish_reason': '', 'usage': None, 'index': 0, 'tool_use': None}

Raw OpenAI Chunk
ModelResponseStream(id='chatcmpl-8013da75-3435-4199-b8cb-c12edc98d5c7', created=1762144783, model=None, object='chat.completion.chunk', system_fingerprint=None, choices=[StreamingChoices(finish_reason='stop', index=0, delta=Delta(provider_specific_fields=None, content='', role=None, function_call=None, tool_calls=None, audio=None), logprobs=None)], provider_specific_fields=None, usage=Usage(completion_tokens=4, prompt_tokens=1321, total_tokens=1325, completion_tokens_details=None, prompt_tokens_details=PromptTokensDetailsWrapper(audio_tokens=None, cached_tokens=0, text_tokens=None, image_tokens=None, cache_creation_tokens=0), cache_creation_input_tokens=0, cache_read_input_tokens=0))

model_response finish reason 3: stop; response_obj={'text': '', 'is_finished': True, 'finish_reason': 'stop', 'logprobs': None, 'original_chunk': ModelResponseStream(id='chatcmpl-8013da75-3435-4199-b8cb-c12edc98d5c7', created=1762144783, model=None, object='chat.completion.chunk', system_fingerprint=None, choices=[StreamingChoices(finish_reason='stop', index=0, delta=Delta(provider_specific_fields=None, content='', role=None, function_call=None, tool_calls=None, audio=None), logprobs=None)], provider_specific_fields=None, usage=Usage(completion_tokens=4, prompt_tokens=1321, total_tokens=1325, completion_tokens_details=None, prompt_tokens_details=PromptTokensDetailsWrapper(audio_tokens=None, cached_tokens=0, text_tokens=None, image_tokens=None, cache_creation_tokens=0), cache_creation_input_tokens=0, cache_read_input_tokens=0)), 'usage': Usage(completion_tokens=4, prompt_tokens=1321, total_tokens=1325, completion_tokens_details=None, prompt_tokens_details=PromptTokensDetailsWrapper(audio_tokens=None, cached_tokens=0, text_tokens=None, image_tokens=None, cache_creation_tokens=0), cache_creation_input_tokens=0, cache_read_input_tokens=0)}
original delta: {'provider_specific_fields': None, 'content': '', 'role': None, 'function_call': None, 'tool_calls': None, 'audio': None}
new delta: Delta(provider_specific_fields=None, content='', role=None, function_call=None, tool_calls=None, audio=None)
model_response.choices[0].delta: Delta(provider_specific_fields=None, content='', role=None, function_call=None, tool_calls=None, audio=None); completion_obj: {'content': ''}
self.sent_first_chunk: True
completion_obj: {'content': ''}, model_response.choices[0]: StreamingChoices(finish_reason=None, index=0, delta=Delta(provider_specific_fields=None, content='', role=None, function_call=None, tool_calls=None, audio=None), logprobs=None), response_obj: {'text': '', 'is_finished': True, 'finish_reason': 'stop', 'logprobs': None, 'original_chunk': ModelResponseStream(id='chatcmpl-8013da75-3435-4199-b8cb-c12edc98d5c7', created=1762144783, model=None, object='chat.completion.chunk', system_fingerprint=None, choices=[StreamingChoices(finish_reason='stop', index=0, delta=Delta(provider_specific_fields=None, content='', role=None, function_call=None, tool_calls=None, audio=None), logprobs=None)], provider_specific_fields=None, usage=Usage(completion_tokens=4, prompt_tokens=1321, total_tokens=1325, completion_tokens_details=None, prompt_tokens_details=PromptTokensDetailsWrapper(audio_tokens=None, cached_tokens=0, text_tokens=None, image_tokens=None, cache_creation_tokens=0), cache_creation_input_tokens=0, cache_read_input_tokens=0)), 'usage': Usage(completion_tokens=4, prompt_tokens=1321, total_tokens=1325, completion_tokens_details=None, prompt_tokens_details=PromptTokensDetailsWrapper(audio_tokens=None, cached_tokens=0, text_tokens=None, image_tokens=None, cache_creation_tokens=0), cache_creation_input_tokens=0, cache_read_input_tokens=0)}
final returned processed chunk: ModelResponseStream(id='chatcmpl-8013da75-3435-4199-b8cb-c12edc98d5c7', created=1762144783, model='claude-sonnet-4-5-20250929', object='chat.completion.chunk', system_fingerprint=None, choices=[StreamingChoices(finish_reason='stop', index=0, delta=Delta(provider_specific_fields=None, content=None, role=None, function_call=None, tool_calls=None, audio=None), logprobs=None)], provider_specific_fields=None)
INFO:     127.0.0.1:53861 - "GET /v1/models HTTP/1.1" 200 OK
model_response finish reason 3: None; response_obj={'text': '', 'is_finished': False, 'finish_reason': '', 'usage': None, 'index': 0, 'tool_use': None}
model_response.choices[0].delta: Delta(provider_specific_fields=None, content=None, role=None, function_call=None, tool_calls=None, audio=None); completion_obj: {'content': ''}
self.sent_first_chunk: False
completion_obj: {'content': ''}, model_response.choices[0]: StreamingChoices(finish_reason=None, index=0, delta=Delta(provider_specific_fields=None, content=None, role=None, function_call=None, tool_calls=None, audio=None), logprobs=None), response_obj: {'text': '', 'is_finished': False, 'finish_reason': '', 'usage': None, 'index': 0, 'tool_use': None}

Raw OpenAI Chunk
ModelResponseStream(id='chatcmpl-95690960-2e48-477d-9a30-4775f49b09e7', created=1762144783, model=None, object='chat.completion.chunk', system_fingerprint=None, choices=[StreamingChoices(finish_reason=None, index=0, delta=Delta(provider_specific_fields=None, content='', role=None, function_call=None, tool_calls=None, audio=None), logprobs=None)], provider_specific_fields=None, usage=Usage(completion_tokens=1, prompt_tokens=1371, total_tokens=1372, completion_tokens_details=None, prompt_tokens_details=PromptTokensDetailsWrapper(audio_tokens=None, cached_tokens=0, text_tokens=None, image_tokens=None, cache_creation_tokens=0, cache_creation_token_details=CacheCreationTokenDetails(ephemeral_5m_input_tokens=0, ephemeral_1h_input_tokens=0)), cache_creation_input_tokens=0, cache_read_input_tokens=0))

model_response finish reason 3: None; response_obj={'text': '', 'is_finished': False, 'finish_reason': None, 'logprobs': None, 'original_chunk': ModelResponseStream(id='chatcmpl-95690960-2e48-477d-9a30-4775f49b09e7', created=1762144783, model=None, object='chat.completion.chunk', system_fingerprint=None, choices=[StreamingChoices(finish_reason=None, index=0, delta=Delta(provider_specific_fields=None, content='', role=None, function_call=None, tool_calls=None, audio=None), logprobs=None)], provider_specific_fields=None, usage=Usage(completion_tokens=1, prompt_tokens=1371, total_tokens=1372, completion_tokens_details=None, prompt_tokens_details=PromptTokensDetailsWrapper(audio_tokens=None, cached_tokens=0, text_tokens=None, image_tokens=None, cache_creation_tokens=0, cache_creation_token_details=CacheCreationTokenDetails(ephemeral_5m_input_tokens=0, ephemeral_1h_input_tokens=0)), cache_creation_input_tokens=0, cache_read_input_tokens=0)), 'usage': Usage(completion_tokens=1, prompt_tokens=1371, total_tokens=1372, completion_tokens_details=None, prompt_tokens_details=PromptTokensDetailsWrapper(audio_tokens=None, cached_tokens=0, text_tokens=None, image_tokens=None, cache_creation_tokens=0, cache_creation_token_details=CacheCreationTokenDetails(ephemeral_5m_input_tokens=0, ephemeral_1h_input_tokens=0)), cache_creation_input_tokens=0, cache_read_input_tokens=0)}
original delta: {'provider_specific_fields': None, 'content': '', 'role': None, 'function_call': None, 'tool_calls': None, 'audio': None}
new delta: Delta(provider_specific_fields=None, content='', role=None, function_call=None, tool_calls=None, audio=None)
model_response.choices[0].delta: Delta(provider_specific_fields=None, content='', role=None, function_call=None, tool_calls=None, audio=None); completion_obj: {'content': ''}
self.sent_first_chunk: False
completion_obj: {'content': ''}, model_response.choices[0]: StreamingChoices(finish_reason=None, index=0, delta=Delta(provider_specific_fields=None, content='', role=None, function_call=None, tool_calls=None, audio=None), logprobs=None), response_obj: {'text': '', 'is_finished': False, 'finish_reason': None, 'logprobs': None, 'original_chunk': ModelResponseStream(id='chatcmpl-95690960-2e48-477d-9a30-4775f49b09e7', created=1762144783, model=None, object='chat.completion.chunk', system_fingerprint=None, choices=[StreamingChoices(finish_reason=None, index=0, delta=Delta(provider_specific_fields=None, content='', role=None, function_call=None, tool_calls=None, audio=None), logprobs=None)], provider_specific_fields=None, usage=Usage(completion_tokens=1, prompt_tokens=1371, total_tokens=1372, completion_tokens_details=None, prompt_tokens_details=PromptTokensDetailsWrapper(audio_tokens=None, cached_tokens=0, text_tokens=None, image_tokens=None, cache_creation_tokens=0, cache_creation_token_details=CacheCreationTokenDetails(ephemeral_5m_input_tokens=0, ephemeral_1h_input_tokens=0)), cache_creation_input_tokens=0, cache_read_input_tokens=0)), 'usage': Usage(completion_tokens=1, prompt_tokens=1371, total_tokens=1372, completion_tokens_details=None, prompt_tokens_details=PromptTokensDetailsWrapper(audio_tokens=None, cached_tokens=0, text_tokens=None, image_tokens=None, cache_creation_tokens=0, cache_creation_token_details=CacheCreationTokenDetails(ephemeral_5m_input_tokens=0, ephemeral_1h_input_tokens=0)), cache_creation_input_tokens=0, cache_read_input_tokens=0)}
model_response finish reason 3: None; response_obj={'text': '', 'is_finished': False, 'finish_reason': '', 'usage': None, 'index': 0, 'tool_use': None}
model_response.choices[0].delta: Delta(provider_specific_fields=None, content=None, role=None, function_call=None, tool_calls=None, audio=None); completion_obj: {'content': ''}
self.sent_first_chunk: False
completion_obj: {'content': ''}, model_response.choices[0]: StreamingChoices(finish_reason=None, index=0, delta=Delta(provider_specific_fields=None, content=None, role=None, function_call=None, tool_calls=None, audio=None), logprobs=None), response_obj: {'text': '', 'is_finished': False, 'finish_reason': '', 'usage': None, 'index': 0, 'tool_use': None}
model_response finish reason 3: None; response_obj={'text': '', 'is_finished': False, 'finish_reason': '', 'usage': None, 'index': 0, 'tool_use': None}
model_response.choices[0].delta: Delta(provider_specific_fields=None, content=None, role=None, function_call=None, tool_calls=None, audio=None); completion_obj: {'content': ''}
self.sent_first_chunk: False
completion_obj: {'content': ''}, model_response.choices[0]: StreamingChoices(finish_reason=None, index=0, delta=Delta(provider_specific_fields=None, content=None, role=None, function_call=None, tool_calls=None, audio=None), logprobs=None), response_obj: {'text': '', 'is_finished': False, 'finish_reason': '', 'usage': None, 'index': 0, 'tool_use': None}

Raw OpenAI Chunk
ModelResponseStream(id='chatcmpl-95690960-2e48-477d-9a30-4775f49b09e7', created=1762144783, model=None, object='chat.completion.chunk', system_fingerprint=None, choices=[StreamingChoices(finish_reason=None, index=0, delta=Delta(provider_specific_fields=None, content='', role=None, function_call=None, tool_calls=None, audio=None), logprobs=None)], provider_specific_fields=None, usage=None)

model_response finish reason 3: None; response_obj={'text': '', 'is_finished': False, 'finish_reason': None, 'logprobs': None, 'original_chunk': ModelResponseStream(id='chatcmpl-95690960-2e48-477d-9a30-4775f49b09e7', created=1762144783, model=None, object='chat.completion.chunk', system_fingerprint=None, choices=[StreamingChoices(finish_reason=None, index=0, delta=Delta(provider_specific_fields=None, content='', role=None, function_call=None, tool_calls=None, audio=None), logprobs=None)], provider_specific_fields=None, usage=None), 'usage': None}
original delta: {'provider_specific_fields': None, 'content': '', 'role': None, 'function_call': None, 'tool_calls': None, 'audio': None}
new delta: Delta(provider_specific_fields=None, content='', role=None, function_call=None, tool_calls=None, audio=None)
model_response.choices[0].delta: Delta(provider_specific_fields=None, content='', role=None, function_call=None, tool_calls=None, audio=None); completion_obj: {'content': ''}
self.sent_first_chunk: False
completion_obj: {'content': ''}, model_response.choices[0]: StreamingChoices(finish_reason=None, index=0, delta=Delta(provider_specific_fields=None, content='', role=None, function_call=None, tool_calls=None, audio=None), logprobs=None), response_obj: {'text': '', 'is_finished': False, 'finish_reason': None, 'logprobs': None, 'original_chunk': ModelResponseStream(id='chatcmpl-95690960-2e48-477d-9a30-4775f49b09e7', created=1762144783, model=None, object='chat.completion.chunk', system_fingerprint=None, choices=[StreamingChoices(finish_reason=None, index=0, delta=Delta(provider_specific_fields=None, content='', role=None, function_call=None, tool_calls=None, audio=None), logprobs=None)], provider_specific_fields=None, usage=None), 'usage': None}
model_response finish reason 3: None; response_obj={'text': '', 'is_finished': False, 'finish_reason': '', 'usage': None, 'index': 0, 'tool_use': None}
model_response.choices[0].delta: Delta(provider_specific_fields=None, content=None, role=None, function_call=None, tool_calls=None, audio=None); completion_obj: {'content': ''}
self.sent_first_chunk: False
completion_obj: {'content': ''}, model_response.choices[0]: StreamingChoices(finish_reason=None, index=0, delta=Delta(provider_specific_fields=None, content=None, role=None, function_call=None, tool_calls=None, audio=None), logprobs=None), response_obj: {'text': '', 'is_finished': False, 'finish_reason': '', 'usage': None, 'index': 0, 'tool_use': None}
model_response finish reason 3: None; response_obj={'text': '', 'is_finished': False, 'finish_reason': '', 'usage': None, 'index': 0, 'tool_use': None}
model_response.choices[0].delta: Delta(provider_specific_fields=None, content=None, role=None, function_call=None, tool_calls=None, audio=None); completion_obj: {'content': ''}
self.sent_first_chunk: False
completion_obj: {'content': ''}, model_response.choices[0]: StreamingChoices(finish_reason=None, index=0, delta=Delta(provider_specific_fields=None, content=None, role=None, function_call=None, tool_calls=None, audio=None), logprobs=None), response_obj: {'text': '', 'is_finished': False, 'finish_reason': '', 'usage': None, 'index': 0, 'tool_use': None}

Raw OpenAI Chunk
ModelResponseStream(id='chatcmpl-95690960-2e48-477d-9a30-4775f49b09e7', created=1762144783, model=None, object='chat.completion.chunk', system_fingerprint=None, choices=[StreamingChoices(finish_reason=None, index=0, delta=Delta(provider_specific_fields=None, content='Yes', role=None, function_call=None, tool_calls=None, audio=None), logprobs=None)], provider_specific_fields=None, usage=None)

model_response finish reason 3: None; response_obj={'text': 'Yes', 'is_finished': False, 'finish_reason': None, 'logprobs': None, 'original_chunk': ModelResponseStream(id='chatcmpl-95690960-2e48-477d-9a30-4775f49b09e7', created=1762144783, model=None, object='chat.completion.chunk', system_fingerprint=None, choices=[StreamingChoices(finish_reason=None, index=0, delta=Delta(provider_specific_fields=None, content='Yes', role=None, function_call=None, tool_calls=None, audio=None), logprobs=None)], provider_specific_fields=None, usage=None), 'usage': None}
original delta: {'provider_specific_fields': None, 'content': 'Yes', 'role': None, 'function_call': None, 'tool_calls': None, 'audio': None}
new delta: Delta(provider_specific_fields=None, content='Yes', role=None, function_call=None, tool_calls=None, audio=None)
model_response.choices[0].delta: Delta(provider_specific_fields=None, content='Yes', role=None, function_call=None, tool_calls=None, audio=None); completion_obj: {'content': 'Yes'}
self.sent_first_chunk: False
completion_obj: {'content': 'Yes'}, model_response.choices[0]: StreamingChoices(finish_reason=None, index=0, delta=Delta(provider_specific_fields=None, content='Yes', role=None, function_call=None, tool_calls=None, audio=None), logprobs=None), response_obj: {'text': 'Yes', 'is_finished': False, 'finish_reason': None, 'logprobs': None, 'original_chunk': ModelResponseStream(id='chatcmpl-95690960-2e48-477d-9a30-4775f49b09e7', created=1762144783, model=None, object='chat.completion.chunk', system_fingerprint=None, choices=[StreamingChoices(finish_reason=None, index=0, delta=Delta(provider_specific_fields=None, content='Yes', role=None, function_call=None, tool_calls=None, audio=None), logprobs=None)], provider_specific_fields=None, usage=None), 'usage': None}
choice_json: {'index': 0, 'delta': {'provider_specific_fields': None, 'content': 'Yes', 'role': None, 'function_call': None, 'tool_calls': None, 'audio': None}, 'logprobs': None}
choices in streaming: [StreamingChoices(finish_reason=None, index=0, delta=Delta(provider_specific_fields=None, content='Yes', role=None, function_call=None, tool_calls=None, audio=None), logprobs=None)]
final returned processed chunk: ModelResponseStream(id='chatcmpl-95690960-2e48-477d-9a30-4775f49b09e7', created=1762144783, model='claude-sonnet-4-5-20250929', object='chat.completion.chunk', system_fingerprint=None, choices=[StreamingChoices(finish_reason=None, index=0, delta=Delta(provider_specific_fields=None, content='Yes', role='assistant', function_call=None, tool_calls=None, audio=None), logprobs=None)], provider_specific_fields=None, citations=None)
model_response finish reason 3: None; response_obj={'text': '', 'is_finished': False, 'finish_reason': '', 'usage': None, 'index': 0, 'tool_use': None}
model_response.choices[0].delta: Delta(provider_specific_fields=None, content=None, role=None, function_call=None, tool_calls=None, audio=None); completion_obj: {'content': ''}
self.sent_first_chunk: True
completion_obj: {'content': ''}, model_response.choices[0]: StreamingChoices(finish_reason=None, index=0, delta=Delta(provider_specific_fields=None, content=None, role=None, function_call=None, tool_calls=None, audio=None), logprobs=None), response_obj: {'text': '', 'is_finished': False, 'finish_reason': '', 'usage': None, 'index': 0, 'tool_use': None}
INFO:     127.0.0.1:53864 - "POST /v1/chat/completions HTTP/1.1" 200 OK
Initialized litellm callbacks, Async Success Callbacks: [<litellm.proxy.hooks.model_max_budget_limiter._PROXY_VirtualKeyModelMaxBudgetLimiter object at 0x120d623c0>]
ASYNC kwargs[caching]: False; litellm.cache: None; kwargs.get('cache'): None
Final returned optional params: {'stream': True, 'tools': []}
_is_function_call: False
makes async anthropic streaming POST request
model_response finish reason 3: None; response_obj={'text': '', 'is_finished': False, 'finish_reason': '', 'usage': None, 'index': 0, 'tool_use': None}
model_response.choices[0].delta: Delta(provider_specific_fields=None, content=None, role=None, function_call=None, tool_calls=None, audio=None); completion_obj: {'content': ''}
self.sent_first_chunk: True
completion_obj: {'content': ''}, model_response.choices[0]: StreamingChoices(finish_reason=None, index=0, delta=Delta(provider_specific_fields=None, content=None, role=None, function_call=None, tool_calls=None, audio=None), logprobs=None), response_obj: {'text': '', 'is_finished': False, 'finish_reason': '', 'usage': None, 'index': 0, 'tool_use': None}

Raw OpenAI Chunk
ModelResponseStream(id='chatcmpl-24e35af5-25b0-4416-9f29-279db90a0879', created=1762144783, model=None, object='chat.completion.chunk', system_fingerprint=None, choices=[StreamingChoices(finish_reason=None, index=0, delta=Delta(provider_specific_fields=None, content=' history', role=None, function_call=None, tool_calls=None, audio=None), logprobs=None)], provider_specific_fields=None, usage=None)

model_response finish reason 3: None; response_obj={'text': ' history', 'is_finished': False, 'finish_reason': None, 'logprobs': None, 'original_chunk': ModelResponseStream(id='chatcmpl-24e35af5-25b0-4416-9f29-279db90a0879', created=1762144783, model=None, object='chat.completion.chunk', system_fingerprint=None, choices=[StreamingChoices(finish_reason=None, index=0, delta=Delta(provider_specific_fields=None, content=' history', role=None, function_call=None, tool_calls=None, audio=None), logprobs=None)], provider_specific_fields=None, usage=None), 'usage': None}
original delta: {'provider_specific_fields': None, 'content': ' history', 'role': None, 'function_call': None, 'tool_calls': None, 'audio': None}
new delta: Delta(provider_specific_fields=None, content=' history', role=None, function_call=None, tool_calls=None, audio=None)
model_response.choices[0].delta: Delta(provider_specific_fields=None, content=' history', role=None, function_call=None, tool_calls=None, audio=None); completion_obj: {'content': ' history'}
self.sent_first_chunk: True
completion_obj: {'content': ' history'}, model_response.choices[0]: StreamingChoices(finish_reason=None, index=0, delta=Delta(provider_specific_fields=None, content=' history', role=None, function_call=None, tool_calls=None, audio=None), logprobs=None), response_obj: {'text': ' history', 'is_finished': False, 'finish_reason': None, 'logprobs': None, 'original_chunk': ModelResponseStream(id='chatcmpl-24e35af5-25b0-4416-9f29-279db90a0879', created=1762144783, model=None, object='chat.completion.chunk', system_fingerprint=None, choices=[StreamingChoices(finish_reason=None, index=0, delta=Delta(provider_specific_fields=None, content=' history', role=None, function_call=None, tool_calls=None, audio=None), logprobs=None)], provider_specific_fields=None, usage=None), 'usage': None}
choice_json: {'index': 0, 'delta': {'provider_specific_fields': None, 'content': ' history', 'role': None, 'function_call': None, 'tool_calls': None, 'audio': None}, 'logprobs': None}
choices in streaming: [StreamingChoices(finish_reason=None, index=0, delta=Delta(provider_specific_fields=None, content=' history', role=None, function_call=None, tool_calls=None, audio=None), logprobs=None)]
final returned processed chunk: ModelResponseStream(id='chatcmpl-24e35af5-25b0-4416-9f29-279db90a0879', created=1762144783, model='claude-sonnet-4-5-20250929', object='chat.completion.chunk', system_fingerprint=None, choices=[StreamingChoices(finish_reason=None, index=0, delta=Delta(provider_specific_fields=None, content=' history', role=None, function_call=None, tool_calls=None, audio=None), logprobs=None)], provider_specific_fields=None, citations=None)
model_response finish reason 3: None; response_obj={'text': '', 'is_finished': False, 'finish_reason': '', 'usage': None, 'index': 0, 'tool_use': None}
model_response.choices[0].delta: Delta(provider_specific_fields=None, content=None, role=None, function_call=None, tool_calls=None, audio=None); completion_obj: {'content': ''}
self.sent_first_chunk: True
completion_obj: {'content': ''}, model_response.choices[0]: StreamingChoices(finish_reason=None, index=0, delta=Delta(provider_specific_fields=None, content=None, role=None, function_call=None, tool_calls=None, audio=None), logprobs=None), response_obj: {'text': '', 'is_finished': False, 'finish_reason': '', 'usage': None, 'index': 0, 'tool_use': None}
model_response finish reason 3: None; response_obj={'text': '', 'is_finished': False, 'finish_reason': '', 'usage': None, 'index': 0, 'tool_use': None}
model_response.choices[0].delta: Delta(provider_specific_fields=None, content=None, role=None, function_call=None, tool_calls=None, audio=None); completion_obj: {'content': ''}
self.sent_first_chunk: False
completion_obj: {'content': ''}, model_response.choices[0]: StreamingChoices(finish_reason=None, index=0, delta=Delta(provider_specific_fields=None, content=None, role=None, function_call=None, tool_calls=None, audio=None), logprobs=None), response_obj: {'text': '', 'is_finished': False, 'finish_reason': '', 'usage': None, 'index': 0, 'tool_use': None}

Raw OpenAI Chunk
ModelResponseStream(id='chatcmpl-dad69e75-0227-4ca2-b397-a0b3e9ce29d0', created=1762144783, model=None, object='chat.completion.chunk', system_fingerprint=None, choices=[StreamingChoices(finish_reason=None, index=0, delta=Delta(provider_specific_fields=None, content='', role=None, function_call=None, tool_calls=None, audio=None), logprobs=None)], provider_specific_fields=None, usage=Usage(completion_tokens=1, prompt_tokens=1388, total_tokens=1389, completion_tokens_details=None, prompt_tokens_details=PromptTokensDetailsWrapper(audio_tokens=None, cached_tokens=0, text_tokens=None, image_tokens=None, cache_creation_tokens=0, cache_creation_token_details=CacheCreationTokenDetails(ephemeral_5m_input_tokens=0, ephemeral_1h_input_tokens=0)), cache_creation_input_tokens=0, cache_read_input_tokens=0))

model_response finish reason 3: None; response_obj={'text': '', 'is_finished': False, 'finish_reason': None, 'logprobs': None, 'original_chunk': ModelResponseStream(id='chatcmpl-dad69e75-0227-4ca2-b397-a0b3e9ce29d0', created=1762144783, model=None, object='chat.completion.chunk', system_fingerprint=None, choices=[StreamingChoices(finish_reason=None, index=0, delta=Delta(provider_specific_fields=None, content='', role=None, function_call=None, tool_calls=None, audio=None), logprobs=None)], provider_specific_fields=None, usage=Usage(completion_tokens=1, prompt_tokens=1388, total_tokens=1389, completion_tokens_details=None, prompt_tokens_details=PromptTokensDetailsWrapper(audio_tokens=None, cached_tokens=0, text_tokens=None, image_tokens=None, cache_creation_tokens=0, cache_creation_token_details=CacheCreationTokenDetails(ephemeral_5m_input_tokens=0, ephemeral_1h_input_tokens=0)), cache_creation_input_tokens=0, cache_read_input_tokens=0)), 'usage': Usage(completion_tokens=1, prompt_tokens=1388, total_tokens=1389, completion_tokens_details=None, prompt_tokens_details=PromptTokensDetailsWrapper(audio_tokens=None, cached_tokens=0, text_tokens=None, image_tokens=None, cache_creation_tokens=0, cache_creation_token_details=CacheCreationTokenDetails(ephemeral_5m_input_tokens=0, ephemeral_1h_input_tokens=0)), cache_creation_input_tokens=0, cache_read_input_tokens=0)}
original delta: {'provider_specific_fields': None, 'content': '', 'role': None, 'function_call': None, 'tool_calls': None, 'audio': None}
new delta: Delta(provider_specific_fields=None, content='', role=None, function_call=None, tool_calls=None, audio=None)
model_response.choices[0].delta: Delta(provider_specific_fields=None, content='', role=None, function_call=None, tool_calls=None, audio=None); completion_obj: {'content': ''}
self.sent_first_chunk: False
completion_obj: {'content': ''}, model_response.choices[0]: StreamingChoices(finish_reason=None, index=0, delta=Delta(provider_specific_fields=None, content='', role=None, function_call=None, tool_calls=None, audio=None), logprobs=None), response_obj: {'text': '', 'is_finished': False, 'finish_reason': None, 'logprobs': None, 'original_chunk': ModelResponseStream(id='chatcmpl-dad69e75-0227-4ca2-b397-a0b3e9ce29d0', created=1762144783, model=None, object='chat.completion.chunk', system_fingerprint=None, choices=[StreamingChoices(finish_reason=None, index=0, delta=Delta(provider_specific_fields=None, content='', role=None, function_call=None, tool_calls=None, audio=None), logprobs=None)], provider_specific_fields=None, usage=Usage(completion_tokens=1, prompt_tokens=1388, total_tokens=1389, completion_tokens_details=None, prompt_tokens_details=PromptTokensDetailsWrapper(audio_tokens=None, cached_tokens=0, text_tokens=None, image_tokens=None, cache_creation_tokens=0, cache_creation_token_details=CacheCreationTokenDetails(ephemeral_5m_input_tokens=0, ephemeral_1h_input_tokens=0)), cache_creation_input_tokens=0, cache_read_input_tokens=0)), 'usage': Usage(completion_tokens=1, prompt_tokens=1388, total_tokens=1389, completion_tokens_details=None, prompt_tokens_details=PromptTokensDetailsWrapper(audio_tokens=None, cached_tokens=0, text_tokens=None, image_tokens=None, cache_creation_tokens=0, cache_creation_token_details=CacheCreationTokenDetails(ephemeral_5m_input_tokens=0, ephemeral_1h_input_tokens=0)), cache_creation_input_tokens=0, cache_read_input_tokens=0)}
model_response finish reason 3: None; response_obj={'text': '', 'is_finished': False, 'finish_reason': '', 'usage': None, 'index': 0, 'tool_use': None}
model_response.choices[0].delta: Delta(provider_specific_fields=None, content=None, role=None, function_call=None, tool_calls=None, audio=None); completion_obj: {'content': ''}
self.sent_first_chunk: False
completion_obj: {'content': ''}, model_response.choices[0]: StreamingChoices(finish_reason=None, index=0, delta=Delta(provider_specific_fields=None, content=None, role=None, function_call=None, tool_calls=None, audio=None), logprobs=None), response_obj: {'text': '', 'is_finished': False, 'finish_reason': '', 'usage': None, 'index': 0, 'tool_use': None}
model_response finish reason 3: None; response_obj={'text': '', 'is_finished': False, 'finish_reason': '', 'usage': None, 'index': 0, 'tool_use': None}
model_response.choices[0].delta: Delta(provider_specific_fields=None, content=None, role=None, function_call=None, tool_calls=None, audio=None); completion_obj: {'content': ''}
self.sent_first_chunk: False
completion_obj: {'content': ''}, model_response.choices[0]: StreamingChoices(finish_reason=None, index=0, delta=Delta(provider_specific_fields=None, content=None, role=None, function_call=None, tool_calls=None, audio=None), logprobs=None), response_obj: {'text': '', 'is_finished': False, 'finish_reason': '', 'usage': None, 'index': 0, 'tool_use': None}

Raw OpenAI Chunk
ModelResponseStream(id='chatcmpl-dad69e75-0227-4ca2-b397-a0b3e9ce29d0', created=1762144783, model=None, object='chat.completion.chunk', system_fingerprint=None, choices=[StreamingChoices(finish_reason=None, index=0, delta=Delta(provider_specific_fields=None, content='', role=None, function_call=None, tool_calls=None, audio=None), logprobs=None)], provider_specific_fields=None, usage=None)

model_response finish reason 3: None; response_obj={'text': '', 'is_finished': False, 'finish_reason': None, 'logprobs': None, 'original_chunk': ModelResponseStream(id='chatcmpl-dad69e75-0227-4ca2-b397-a0b3e9ce29d0', created=1762144783, model=None, object='chat.completion.chunk', system_fingerprint=None, choices=[StreamingChoices(finish_reason=None, index=0, delta=Delta(provider_specific_fields=None, content='', role=None, function_call=None, tool_calls=None, audio=None), logprobs=None)], provider_specific_fields=None, usage=None), 'usage': None}
original delta: {'provider_specific_fields': None, 'content': '', 'role': None, 'function_call': None, 'tool_calls': None, 'audio': None}
new delta: Delta(provider_specific_fields=None, content='', role=None, function_call=None, tool_calls=None, audio=None)
model_response.choices[0].delta: Delta(provider_specific_fields=None, content='', role=None, function_call=None, tool_calls=None, audio=None); completion_obj: {'content': ''}
self.sent_first_chunk: False
completion_obj: {'content': ''}, model_response.choices[0]: StreamingChoices(finish_reason=None, index=0, delta=Delta(provider_specific_fields=None, content='', role=None, function_call=None, tool_calls=None, audio=None), logprobs=None), response_obj: {'text': '', 'is_finished': False, 'finish_reason': None, 'logprobs': None, 'original_chunk': ModelResponseStream(id='chatcmpl-dad69e75-0227-4ca2-b397-a0b3e9ce29d0', created=1762144783, model=None, object='chat.completion.chunk', system_fingerprint=None, choices=[StreamingChoices(finish_reason=None, index=0, delta=Delta(provider_specific_fields=None, content='', role=None, function_call=None, tool_calls=None, audio=None), logprobs=None)], provider_specific_fields=None, usage=None), 'usage': None}
model_response finish reason 3: None; response_obj={'text': '', 'is_finished': False, 'finish_reason': '', 'usage': None, 'index': 0, 'tool_use': None}
model_response.choices[0].delta: Delta(provider_specific_fields=None, content=None, role=None, function_call=None, tool_calls=None, audio=None); completion_obj: {'content': ''}
self.sent_first_chunk: False
completion_obj: {'content': ''}, model_response.choices[0]: StreamingChoices(finish_reason=None, index=0, delta=Delta(provider_specific_fields=None, content=None, role=None, function_call=None, tool_calls=None, audio=None), logprobs=None), response_obj: {'text': '', 'is_finished': False, 'finish_reason': '', 'usage': None, 'index': 0, 'tool_use': None}
model_response finish reason 3: None; response_obj={'text': '', 'is_finished': False, 'finish_reason': '', 'usage': None, 'index': 0, 'tool_use': None}
model_response.choices[0].delta: Delta(provider_specific_fields=None, content=None, role=None, function_call=None, tool_calls=None, audio=None); completion_obj: {'content': ''}
self.sent_first_chunk: False
completion_obj: {'content': ''}, model_response.choices[0]: StreamingChoices(finish_reason=None, index=0, delta=Delta(provider_specific_fields=None, content=None, role=None, function_call=None, tool_calls=None, audio=None), logprobs=None), response_obj: {'text': '', 'is_finished': False, 'finish_reason': '', 'usage': None, 'index': 0, 'tool_use': None}

Raw OpenAI Chunk
ModelResponseStream(id='chatcmpl-dad69e75-0227-4ca2-b397-a0b3e9ce29d0', created=1762144783, model=None, object='chat.completion.chunk', system_fingerprint=None, choices=[StreamingChoices(finish_reason=None, index=0, delta=Delta(provider_specific_fields=None, content='No', role=None, function_call=None, tool_calls=None, audio=None), logprobs=None)], provider_specific_fields=None, usage=None)

model_response finish reason 3: None; response_obj={'text': 'No', 'is_finished': False, 'finish_reason': None, 'logprobs': None, 'original_chunk': ModelResponseStream(id='chatcmpl-dad69e75-0227-4ca2-b397-a0b3e9ce29d0', created=1762144783, model=None, object='chat.completion.chunk', system_fingerprint=None, choices=[StreamingChoices(finish_reason=None, index=0, delta=Delta(provider_specific_fields=None, content='No', role=None, function_call=None, tool_calls=None, audio=None), logprobs=None)], provider_specific_fields=None, usage=None), 'usage': None}
original delta: {'provider_specific_fields': None, 'content': 'No', 'role': None, 'function_call': None, 'tool_calls': None, 'audio': None}
new delta: Delta(provider_specific_fields=None, content='No', role=None, function_call=None, tool_calls=None, audio=None)
model_response.choices[0].delta: Delta(provider_specific_fields=None, content='No', role=None, function_call=None, tool_calls=None, audio=None); completion_obj: {'content': 'No'}
self.sent_first_chunk: False
completion_obj: {'content': 'No'}, model_response.choices[0]: StreamingChoices(finish_reason=None, index=0, delta=Delta(provider_specific_fields=None, content='No', role=None, function_call=None, tool_calls=None, audio=None), logprobs=None), response_obj: {'text': 'No', 'is_finished': False, 'finish_reason': None, 'logprobs': None, 'original_chunk': ModelResponseStream(id='chatcmpl-dad69e75-0227-4ca2-b397-a0b3e9ce29d0', created=1762144783, model=None, object='chat.completion.chunk', system_fingerprint=None, choices=[StreamingChoices(finish_reason=None, index=0, delta=Delta(provider_specific_fields=None, content='No', role=None, function_call=None, tool_calls=None, audio=None), logprobs=None)], provider_specific_fields=None, usage=None), 'usage': None}
choice_json: {'index': 0, 'delta': {'provider_specific_fields': None, 'content': 'No', 'role': None, 'function_call': None, 'tool_calls': None, 'audio': None}, 'logprobs': None}
choices in streaming: [StreamingChoices(finish_reason=None, index=0, delta=Delta(provider_specific_fields=None, content='No', role=None, function_call=None, tool_calls=None, audio=None), logprobs=None)]
final returned processed chunk: ModelResponseStream(id='chatcmpl-dad69e75-0227-4ca2-b397-a0b3e9ce29d0', created=1762144783, model='claude-sonnet-4-5-20250929', object='chat.completion.chunk', system_fingerprint=None, choices=[StreamingChoices(finish_reason=None, index=0, delta=Delta(provider_specific_fields=None, content='No', role='assistant', function_call=None, tool_calls=None, audio=None), logprobs=None)], provider_specific_fields=None, citations=None)
model_response finish reason 3: None; response_obj={'text': '', 'is_finished': False, 'finish_reason': '', 'usage': None, 'index': 0, 'tool_use': None}
model_response.choices[0].delta: Delta(provider_specific_fields=None, content=None, role=None, function_call=None, tool_calls=None, audio=None); completion_obj: {'content': ''}
self.sent_first_chunk: True
completion_obj: {'content': ''}, model_response.choices[0]: StreamingChoices(finish_reason=None, index=0, delta=Delta(provider_specific_fields=None, content=None, role=None, function_call=None, tool_calls=None, audio=None), logprobs=None), response_obj: {'text': '', 'is_finished': False, 'finish_reason': '', 'usage': None, 'index': 0, 'tool_use': None}
model_response finish reason 3: None; response_obj={'text': '', 'is_finished': False, 'finish_reason': '', 'usage': None, 'index': 0, 'tool_use': None}
model_response.choices[0].delta: Delta(provider_specific_fields=None, content=None, role=None, function_call=None, tool_calls=None, audio=None); completion_obj: {'content': ''}
self.sent_first_chunk: False
completion_obj: {'content': ''}, model_response.choices[0]: StreamingChoices(finish_reason=None, index=0, delta=Delta(provider_specific_fields=None, content=None, role=None, function_call=None, tool_calls=None, audio=None), logprobs=None), response_obj: {'text': '', 'is_finished': False, 'finish_reason': '', 'usage': None, 'index': 0, 'tool_use': None}

Raw OpenAI Chunk
ModelResponseStream(id='chatcmpl-a160984c-b23d-415a-a685-4ffd2e75b8c3', created=1762144783, model=None, object='chat.completion.chunk', system_fingerprint=None, choices=[StreamingChoices(finish_reason=None, index=0, delta=Delta(provider_specific_fields=None, content='', role=None, function_call=None, tool_calls=None, audio=None), logprobs=None)], provider_specific_fields=None, usage=Usage(completion_tokens=1, prompt_tokens=204, total_tokens=205, completion_tokens_details=None, prompt_tokens_details=PromptTokensDetailsWrapper(audio_tokens=None, cached_tokens=0, text_tokens=None, image_tokens=None, cache_creation_tokens=0, cache_creation_token_details=CacheCreationTokenDetails(ephemeral_5m_input_tokens=0, ephemeral_1h_input_tokens=0)), cache_creation_input_tokens=0, cache_read_input_tokens=0))

model_response finish reason 3: None; response_obj={'text': '', 'is_finished': False, 'finish_reason': None, 'logprobs': None, 'original_chunk': ModelResponseStream(id='chatcmpl-a160984c-b23d-415a-a685-4ffd2e75b8c3', created=1762144783, model=None, object='chat.completion.chunk', system_fingerprint=None, choices=[StreamingChoices(finish_reason=None, index=0, delta=Delta(provider_specific_fields=None, content='', role=None, function_call=None, tool_calls=None, audio=None), logprobs=None)], provider_specific_fields=None, usage=Usage(completion_tokens=1, prompt_tokens=204, total_tokens=205, completion_tokens_details=None, prompt_tokens_details=PromptTokensDetailsWrapper(audio_tokens=None, cached_tokens=0, text_tokens=None, image_tokens=None, cache_creation_tokens=0, cache_creation_token_details=CacheCreationTokenDetails(ephemeral_5m_input_tokens=0, ephemeral_1h_input_tokens=0)), cache_creation_input_tokens=0, cache_read_input_tokens=0)), 'usage': Usage(completion_tokens=1, prompt_tokens=204, total_tokens=205, completion_tokens_details=None, prompt_tokens_details=PromptTokensDetailsWrapper(audio_tokens=None, cached_tokens=0, text_tokens=None, image_tokens=None, cache_creation_tokens=0, cache_creation_token_details=CacheCreationTokenDetails(ephemeral_5m_input_tokens=0, ephemeral_1h_input_tokens=0)), cache_creation_input_tokens=0, cache_read_input_tokens=0)}
original delta: {'provider_specific_fields': None, 'content': '', 'role': None, 'function_call': None, 'tool_calls': None, 'audio': None}
new delta: Delta(provider_specific_fields=None, content='', role=None, function_call=None, tool_calls=None, audio=None)
model_response.choices[0].delta: Delta(provider_specific_fields=None, content='', role=None, function_call=None, tool_calls=None, audio=None); completion_obj: {'content': ''}
self.sent_first_chunk: False
completion_obj: {'content': ''}, model_response.choices[0]: StreamingChoices(finish_reason=None, index=0, delta=Delta(provider_specific_fields=None, content='', role=None, function_call=None, tool_calls=None, audio=None), logprobs=None), response_obj: {'text': '', 'is_finished': False, 'finish_reason': None, 'logprobs': None, 'original_chunk': ModelResponseStream(id='chatcmpl-a160984c-b23d-415a-a685-4ffd2e75b8c3', created=1762144783, model=None, object='chat.completion.chunk', system_fingerprint=None, choices=[StreamingChoices(finish_reason=None, index=0, delta=Delta(provider_specific_fields=None, content='', role=None, function_call=None, tool_calls=None, audio=None), logprobs=None)], provider_specific_fields=None, usage=Usage(completion_tokens=1, prompt_tokens=204, total_tokens=205, completion_tokens_details=None, prompt_tokens_details=PromptTokensDetailsWrapper(audio_tokens=None, cached_tokens=0, text_tokens=None, image_tokens=None, cache_creation_tokens=0, cache_creation_token_details=CacheCreationTokenDetails(ephemeral_5m_input_tokens=0, ephemeral_1h_input_tokens=0)), cache_creation_input_tokens=0, cache_read_input_tokens=0)), 'usage': Usage(completion_tokens=1, prompt_tokens=204, total_tokens=205, completion_tokens_details=None, prompt_tokens_details=PromptTokensDetailsWrapper(audio_tokens=None, cached_tokens=0, text_tokens=None, image_tokens=None, cache_creation_tokens=0, cache_creation_token_details=CacheCreationTokenDetails(ephemeral_5m_input_tokens=0, ephemeral_1h_input_tokens=0)), cache_creation_input_tokens=0, cache_read_input_tokens=0)}
model_response finish reason 3: None; response_obj={'text': '', 'is_finished': False, 'finish_reason': '', 'usage': None, 'index': 0, 'tool_use': None}
model_response.choices[0].delta: Delta(provider_specific_fields=None, content=None, role=None, function_call=None, tool_calls=None, audio=None); completion_obj: {'content': ''}
self.sent_first_chunk: False
completion_obj: {'content': ''}, model_response.choices[0]: StreamingChoices(finish_reason=None, index=0, delta=Delta(provider_specific_fields=None, content=None, role=None, function_call=None, tool_calls=None, audio=None), logprobs=None), response_obj: {'text': '', 'is_finished': False, 'finish_reason': '', 'usage': None, 'index': 0, 'tool_use': None}
model_response finish reason 3: None; response_obj={'text': '', 'is_finished': False, 'finish_reason': '', 'usage': None, 'index': 0, 'tool_use': None}
model_response.choices[0].delta: Delta(provider_specific_fields=None, content=None, role=None, function_call=None, tool_calls=None, audio=None); completion_obj: {'content': ''}
self.sent_first_chunk: False
completion_obj: {'content': ''}, model_response.choices[0]: StreamingChoices(finish_reason=None, index=0, delta=Delta(provider_specific_fields=None, content=None, role=None, function_call=None, tool_calls=None, audio=None), logprobs=None), response_obj: {'text': '', 'is_finished': False, 'finish_reason': '', 'usage': None, 'index': 0, 'tool_use': None}

Raw OpenAI Chunk
ModelResponseStream(id='chatcmpl-a160984c-b23d-415a-a685-4ffd2e75b8c3', created=1762144783, model=None, object='chat.completion.chunk', system_fingerprint=None, choices=[StreamingChoices(finish_reason=None, index=0, delta=Delta(provider_specific_fields=None, content='', role=None, function_call=None, tool_calls=None, audio=None), logprobs=None)], provider_specific_fields=None, usage=None)

model_response finish reason 3: None; response_obj={'text': '', 'is_finished': False, 'finish_reason': None, 'logprobs': None, 'original_chunk': ModelResponseStream(id='chatcmpl-a160984c-b23d-415a-a685-4ffd2e75b8c3', created=1762144783, model=None, object='chat.completion.chunk', system_fingerprint=None, choices=[StreamingChoices(finish_reason=None, index=0, delta=Delta(provider_specific_fields=None, content='', role=None, function_call=None, tool_calls=None, audio=None), logprobs=None)], provider_specific_fields=None, usage=None), 'usage': None}
original delta: {'provider_specific_fields': None, 'content': '', 'role': None, 'function_call': None, 'tool_calls': None, 'audio': None}
new delta: Delta(provider_specific_fields=None, content='', role=None, function_call=None, tool_calls=None, audio=None)
model_response.choices[0].delta: Delta(provider_specific_fields=None, content='', role=None, function_call=None, tool_calls=None, audio=None); completion_obj: {'content': ''}
self.sent_first_chunk: False
completion_obj: {'content': ''}, model_response.choices[0]: StreamingChoices(finish_reason=None, index=0, delta=Delta(provider_specific_fields=None, content='', role=None, function_call=None, tool_calls=None, audio=None), logprobs=None), response_obj: {'text': '', 'is_finished': False, 'finish_reason': None, 'logprobs': None, 'original_chunk': ModelResponseStream(id='chatcmpl-a160984c-b23d-415a-a685-4ffd2e75b8c3', created=1762144783, model=None, object='chat.completion.chunk', system_fingerprint=None, choices=[StreamingChoices(finish_reason=None, index=0, delta=Delta(provider_specific_fields=None, content='', role=None, function_call=None, tool_calls=None, audio=None), logprobs=None)], provider_specific_fields=None, usage=None), 'usage': None}
model_response finish reason 3: None; response_obj={'text': '', 'is_finished': False, 'finish_reason': '', 'usage': None, 'index': 0, 'tool_use': None}
model_response.choices[0].delta: Delta(provider_specific_fields=None, content=None, role=None, function_call=None, tool_calls=None, audio=None); completion_obj: {'content': ''}
self.sent_first_chunk: False
completion_obj: {'content': ''}, model_response.choices[0]: StreamingChoices(finish_reason=None, index=0, delta=Delta(provider_specific_fields=None, content=None, role=None, function_call=None, tool_calls=None, audio=None), logprobs=None), response_obj: {'text': '', 'is_finished': False, 'finish_reason': '', 'usage': None, 'index': 0, 'tool_use': None}
model_response finish reason 3: None; response_obj={'text': '', 'is_finished': False, 'finish_reason': '', 'usage': None, 'index': 0, 'tool_use': None}
model_response.choices[0].delta: Delta(provider_specific_fields=None, content=None, role=None, function_call=None, tool_calls=None, audio=None); completion_obj: {'content': ''}
self.sent_first_chunk: False
completion_obj: {'content': ''}, model_response.choices[0]: StreamingChoices(finish_reason=None, index=0, delta=Delta(provider_specific_fields=None, content=None, role=None, function_call=None, tool_calls=None, audio=None), logprobs=None), response_obj: {'text': '', 'is_finished': False, 'finish_reason': '', 'usage': None, 'index': 0, 'tool_use': None}

Raw OpenAI Chunk
ModelResponseStream(id='chatcmpl-a160984c-b23d-415a-a685-4ffd2e75b8c3', created=1762144783, model=None, object='chat.completion.chunk', system_fingerprint=None, choices=[StreamingChoices(finish_reason=None, index=0, delta=Delta(provider_specific_fields=None, content='No', role=None, function_call=None, tool_calls=None, audio=None), logprobs=None)], provider_specific_fields=None, usage=None)

model_response finish reason 3: None; response_obj={'text': 'No', 'is_finished': False, 'finish_reason': None, 'logprobs': None, 'original_chunk': ModelResponseStream(id='chatcmpl-a160984c-b23d-415a-a685-4ffd2e75b8c3', created=1762144783, model=None, object='chat.completion.chunk', system_fingerprint=None, choices=[StreamingChoices(finish_reason=None, index=0, delta=Delta(provider_specific_fields=None, content='No', role=None, function_call=None, tool_calls=None, audio=None), logprobs=None)], provider_specific_fields=None, usage=None), 'usage': None}
original delta: {'provider_specific_fields': None, 'content': 'No', 'role': None, 'function_call': None, 'tool_calls': None, 'audio': None}
new delta: Delta(provider_specific_fields=None, content='No', role=None, function_call=None, tool_calls=None, audio=None)
model_response.choices[0].delta: Delta(provider_specific_fields=None, content='No', role=None, function_call=None, tool_calls=None, audio=None); completion_obj: {'content': 'No'}
self.sent_first_chunk: False
completion_obj: {'content': 'No'}, model_response.choices[0]: StreamingChoices(finish_reason=None, index=0, delta=Delta(provider_specific_fields=None, content='No', role=None, function_call=None, tool_calls=None, audio=None), logprobs=None), response_obj: {'text': 'No', 'is_finished': False, 'finish_reason': None, 'logprobs': None, 'original_chunk': ModelResponseStream(id='chatcmpl-a160984c-b23d-415a-a685-4ffd2e75b8c3', created=1762144783, model=None, object='chat.completion.chunk', system_fingerprint=None, choices=[StreamingChoices(finish_reason=None, index=0, delta=Delta(provider_specific_fields=None, content='No', role=None, function_call=None, tool_calls=None, audio=None), logprobs=None)], provider_specific_fields=None, usage=None), 'usage': None}
choice_json: {'index': 0, 'delta': {'provider_specific_fields': None, 'content': 'No', 'role': None, 'function_call': None, 'tool_calls': None, 'audio': None}, 'logprobs': None}
choices in streaming: [StreamingChoices(finish_reason=None, index=0, delta=Delta(provider_specific_fields=None, content='No', role=None, function_call=None, tool_calls=None, audio=None), logprobs=None)]
final returned processed chunk: ModelResponseStream(id='chatcmpl-a160984c-b23d-415a-a685-4ffd2e75b8c3', created=1762144783, model='claude-sonnet-4-5-20250929', object='chat.completion.chunk', system_fingerprint=None, choices=[StreamingChoices(finish_reason=None, index=0, delta=Delta(provider_specific_fields=None, content='No', role='assistant', function_call=None, tool_calls=None, audio=None), logprobs=None)], provider_specific_fields=None, citations=None)
model_response finish reason 3: None; response_obj={'text': '', 'is_finished': False, 'finish_reason': '', 'usage': None, 'index': 0, 'tool_use': None}
model_response.choices[0].delta: Delta(provider_specific_fields=None, content=None, role=None, function_call=None, tool_calls=None, audio=None); completion_obj: {'content': ''}
self.sent_first_chunk: True
completion_obj: {'content': ''}, model_response.choices[0]: StreamingChoices(finish_reason=None, index=0, delta=Delta(provider_specific_fields=None, content=None, role=None, function_call=None, tool_calls=None, audio=None), logprobs=None), response_obj: {'text': '', 'is_finished': False, 'finish_reason': '', 'usage': None, 'index': 0, 'tool_use': None}
model_response finish reason 3: None; response_obj={'text': '', 'is_finished': False, 'finish_reason': '', 'usage': None, 'index': 0, 'tool_use': None}
model_response.choices[0].delta: Delta(provider_specific_fields=None, content=None, role=None, function_call=None, tool_calls=None, audio=None); completion_obj: {'content': ''}
self.sent_first_chunk: True
completion_obj: {'content': ''}, model_response.choices[0]: StreamingChoices(finish_reason=None, index=0, delta=Delta(provider_specific_fields=None, content=None, role=None, function_call=None, tool_calls=None, audio=None), logprobs=None), response_obj: {'text': '', 'is_finished': False, 'finish_reason': '', 'usage': None, 'index': 0, 'tool_use': None}

Raw OpenAI Chunk
ModelResponseStream(id='chatcmpl-24e35af5-25b0-4416-9f29-279db90a0879', created=1762144783, model=None, object='chat.completion.chunk', system_fingerprint=None, choices=[StreamingChoices(finish_reason=None, index=0, delta=Delta(provider_specific_fields=None, content='', role=None, function_call=None, tool_calls=None, audio=None), logprobs=None)], provider_specific_fields=None, usage=None)

model_response finish reason 3: None; response_obj={'text': '', 'is_finished': False, 'finish_reason': None, 'logprobs': None, 'original_chunk': ModelResponseStream(id='chatcmpl-24e35af5-25b0-4416-9f29-279db90a0879', created=1762144783, model=None, object='chat.completion.chunk', system_fingerprint=None, choices=[StreamingChoices(finish_reason=None, index=0, delta=Delta(provider_specific_fields=None, content='', role=None, function_call=None, tool_calls=None, audio=None), logprobs=None)], provider_specific_fields=None, usage=None), 'usage': None}
original delta: {'provider_specific_fields': None, 'content': '', 'role': None, 'function_call': None, 'tool_calls': None, 'audio': None}
new delta: Delta(provider_specific_fields=None, content='', role=None, function_call=None, tool_calls=None, audio=None)
model_response.choices[0].delta: Delta(provider_specific_fields=None, content='', role=None, function_call=None, tool_calls=None, audio=None); completion_obj: {'content': ''}
self.sent_first_chunk: True
completion_obj: {'content': ''}, model_response.choices[0]: StreamingChoices(finish_reason=None, index=0, delta=Delta(provider_specific_fields=None, content='', role=None, function_call=None, tool_calls=None, audio=None), logprobs=None), response_obj: {'text': '', 'is_finished': False, 'finish_reason': None, 'logprobs': None, 'original_chunk': ModelResponseStream(id='chatcmpl-24e35af5-25b0-4416-9f29-279db90a0879', created=1762144783, model=None, object='chat.completion.chunk', system_fingerprint=None, choices=[StreamingChoices(finish_reason=None, index=0, delta=Delta(provider_specific_fields=None, content='', role=None, function_call=None, tool_calls=None, audio=None), logprobs=None)], provider_specific_fields=None, usage=None), 'usage': None}
model_response finish reason 3: None; response_obj={'text': '', 'is_finished': False, 'finish_reason': '', 'usage': None, 'index': 0, 'tool_use': None}
model_response.choices[0].delta: Delta(provider_specific_fields=None, content=None, role=None, function_call=None, tool_calls=None, audio=None); completion_obj: {'content': ''}
self.sent_first_chunk: True
completion_obj: {'content': ''}, model_response.choices[0]: StreamingChoices(finish_reason=None, index=0, delta=Delta(provider_specific_fields=None, content=None, role=None, function_call=None, tool_calls=None, audio=None), logprobs=None), response_obj: {'text': '', 'is_finished': False, 'finish_reason': '', 'usage': None, 'index': 0, 'tool_use': None}
model_response finish reason 3: None; response_obj={'text': '', 'is_finished': False, 'finish_reason': '', 'usage': None, 'index': 0, 'tool_use': None}
model_response.choices[0].delta: Delta(provider_specific_fields=None, content=None, role=None, function_call=None, tool_calls=None, audio=None); completion_obj: {'content': ''}
self.sent_first_chunk: True
completion_obj: {'content': ''}, model_response.choices[0]: StreamingChoices(finish_reason=None, index=0, delta=Delta(provider_specific_fields=None, content=None, role=None, function_call=None, tool_calls=None, audio=None), logprobs=None), response_obj: {'text': '', 'is_finished': False, 'finish_reason': '', 'usage': None, 'index': 0, 'tool_use': None}

Raw OpenAI Chunk
ModelResponseStream(id='chatcmpl-24e35af5-25b0-4416-9f29-279db90a0879', created=1762144783, model=None, object='chat.completion.chunk', system_fingerprint=None, choices=[StreamingChoices(finish_reason=None, index=0, delta=Delta(provider_specific_fields=None, content='\npast', role=None, function_call=None, tool_calls=None, audio=None), logprobs=None)], provider_specific_fields=None, usage=None)

model_response finish reason 3: None; response_obj={'text': '\npast', 'is_finished': False, 'finish_reason': None, 'logprobs': None, 'original_chunk': ModelResponseStream(id='chatcmpl-24e35af5-25b0-4416-9f29-279db90a0879', created=1762144783, model=None, object='chat.completion.chunk', system_fingerprint=None, choices=[StreamingChoices(finish_reason=None, index=0, delta=Delta(provider_specific_fields=None, content='\npast', role=None, function_call=None, tool_calls=None, audio=None), logprobs=None)], provider_specific_fields=None, usage=None), 'usage': None}
original delta: {'provider_specific_fields': None, 'content': '\npast', 'role': None, 'function_call': None, 'tool_calls': None, 'audio': None}
new delta: Delta(provider_specific_fields=None, content='\npast', role=None, function_call=None, tool_calls=None, audio=None)
model_response.choices[0].delta: Delta(provider_specific_fields=None, content='\npast', role=None, function_call=None, tool_calls=None, audio=None); completion_obj: {'content': '\npast'}
self.sent_first_chunk: True
completion_obj: {'content': '\npast'}, model_response.choices[0]: StreamingChoices(finish_reason=None, index=0, delta=Delta(provider_specific_fields=None, content='\npast', role=None, function_call=None, tool_calls=None, audio=None), logprobs=None), response_obj: {'text': '\npast', 'is_finished': False, 'finish_reason': None, 'logprobs': None, 'original_chunk': ModelResponseStream(id='chatcmpl-24e35af5-25b0-4416-9f29-279db90a0879', created=1762144783, model=None, object='chat.completion.chunk', system_fingerprint=None, choices=[StreamingChoices(finish_reason=None, index=0, delta=Delta(provider_specific_fields=None, content='\npast', role=None, function_call=None, tool_calls=None, audio=None), logprobs=None)], provider_specific_fields=None, usage=None), 'usage': None}
choice_json: {'index': 0, 'delta': {'provider_specific_fields': None, 'content': '\npast', 'role': None, 'function_call': None, 'tool_calls': None, 'audio': None}, 'logprobs': None}
choices in streaming: [StreamingChoices(finish_reason=None, index=0, delta=Delta(provider_specific_fields=None, content='\npast', role=None, function_call=None, tool_calls=None, audio=None), logprobs=None)]
final returned processed chunk: ModelResponseStream(id='chatcmpl-24e35af5-25b0-4416-9f29-279db90a0879', created=1762144783, model='claude-sonnet-4-5-20250929', object='chat.completion.chunk', system_fingerprint=None, choices=[StreamingChoices(finish_reason=None, index=0, delta=Delta(provider_specific_fields=None, content='\npast', role=None, function_call=None, tool_calls=None, audio=None), logprobs=None)], provider_specific_fields=None, citations=None)
model_response finish reason 3: None; response_obj={'text': '', 'is_finished': False, 'finish_reason': '', 'usage': None, 'index': 0, 'tool_use': None}
model_response.choices[0].delta: Delta(provider_specific_fields=None, content=None, role=None, function_call=None, tool_calls=None, audio=None); completion_obj: {'content': ''}
self.sent_first_chunk: True
completion_obj: {'content': ''}, model_response.choices[0]: StreamingChoices(finish_reason=None, index=0, delta=Delta(provider_specific_fields=None, content=None, role=None, function_call=None, tool_calls=None, audio=None), logprobs=None), response_obj: {'text': '', 'is_finished': False, 'finish_reason': '', 'usage': None, 'index': 0, 'tool_use': None}
model_response finish reason 3: None; response_obj={'text': '', 'is_finished': False, 'finish_reason': '', 'usage': None, 'index': 0, 'tool_use': None}
model_response.choices[0].delta: Delta(provider_specific_fields=None, content=None, role=None, function_call=None, tool_calls=None, audio=None); completion_obj: {'content': ''}
self.sent_first_chunk: True
completion_obj: {'content': ''}, model_response.choices[0]: StreamingChoices(finish_reason=None, index=0, delta=Delta(provider_specific_fields=None, content=None, role=None, function_call=None, tool_calls=None, audio=None), logprobs=None), response_obj: {'text': '', 'is_finished': False, 'finish_reason': '', 'usage': None, 'index': 0, 'tool_use': None}

Raw OpenAI Chunk
ModelResponseStream(id='chatcmpl-a160984c-b23d-415a-a685-4ffd2e75b8c3', created=1762144783, model=None, object='chat.completion.chunk', system_fingerprint=None, choices=[StreamingChoices(finish_reason=None, index=0, delta=Delta(provider_specific_fields=None, content='', role=None, function_call=None, tool_calls=None, audio=None), logprobs=None)], provider_specific_fields=None, usage=None)

model_response finish reason 3: None; response_obj={'text': '', 'is_finished': False, 'finish_reason': None, 'logprobs': None, 'original_chunk': ModelResponseStream(id='chatcmpl-a160984c-b23d-415a-a685-4ffd2e75b8c3', created=1762144783, model=None, object='chat.completion.chunk', system_fingerprint=None, choices=[StreamingChoices(finish_reason=None, index=0, delta=Delta(provider_specific_fields=None, content='', role=None, function_call=None, tool_calls=None, audio=None), logprobs=None)], provider_specific_fields=None, usage=None), 'usage': None}
original delta: {'provider_specific_fields': None, 'content': '', 'role': None, 'function_call': None, 'tool_calls': None, 'audio': None}
new delta: Delta(provider_specific_fields=None, content='', role=None, function_call=None, tool_calls=None, audio=None)
model_response.choices[0].delta: Delta(provider_specific_fields=None, content='', role=None, function_call=None, tool_calls=None, audio=None); completion_obj: {'content': ''}
self.sent_first_chunk: True
completion_obj: {'content': ''}, model_response.choices[0]: StreamingChoices(finish_reason=None, index=0, delta=Delta(provider_specific_fields=None, content='', role=None, function_call=None, tool_calls=None, audio=None), logprobs=None), response_obj: {'text': '', 'is_finished': False, 'finish_reason': None, 'logprobs': None, 'original_chunk': ModelResponseStream(id='chatcmpl-a160984c-b23d-415a-a685-4ffd2e75b8c3', created=1762144783, model=None, object='chat.completion.chunk', system_fingerprint=None, choices=[StreamingChoices(finish_reason=None, index=0, delta=Delta(provider_specific_fields=None, content='', role=None, function_call=None, tool_calls=None, audio=None), logprobs=None)], provider_specific_fields=None, usage=None), 'usage': None}
model_response finish reason 3: None; response_obj={'text': '', 'is_finished': False, 'finish_reason': '', 'usage': None, 'index': 0, 'tool_use': None}
model_response.choices[0].delta: Delta(provider_specific_fields=None, content=None, role=None, function_call=None, tool_calls=None, audio=None); completion_obj: {'content': ''}
self.sent_first_chunk: True
completion_obj: {'content': ''}, model_response.choices[0]: StreamingChoices(finish_reason=None, index=0, delta=Delta(provider_specific_fields=None, content=None, role=None, function_call=None, tool_calls=None, audio=None), logprobs=None), response_obj: {'text': '', 'is_finished': False, 'finish_reason': '', 'usage': None, 'index': 0, 'tool_use': None}
model_response finish reason 3: None; response_obj={'text': '', 'is_finished': False, 'finish_reason': '', 'usage': None, 'index': 0, 'tool_use': None}
model_response.choices[0].delta: Delta(provider_specific_fields=None, content=None, role=None, function_call=None, tool_calls=None, audio=None); completion_obj: {'content': ''}
self.sent_first_chunk: True
completion_obj: {'content': ''}, model_response.choices[0]: StreamingChoices(finish_reason=None, index=0, delta=Delta(provider_specific_fields=None, content=None, role=None, function_call=None, tool_calls=None, audio=None), logprobs=None), response_obj: {'text': '', 'is_finished': False, 'finish_reason': '', 'usage': None, 'index': 0, 'tool_use': None}

Raw OpenAI Chunk
ModelResponseStream(id='chatcmpl-21fc6157-48cd-4533-a959-1748f66e48cc', created=1762144783, model=None, object='chat.completion.chunk', system_fingerprint=None, choices=[StreamingChoices(finish_reason=None, index=0, delta=Delta(provider_specific_fields=None, content='', role=None, function_call=None, tool_calls=None, audio=None), logprobs=None)], provider_specific_fields=None, usage=None)

model_response finish reason 3: None; response_obj={'text': '', 'is_finished': False, 'finish_reason': None, 'logprobs': None, 'original_chunk': ModelResponseStream(id='chatcmpl-21fc6157-48cd-4533-a959-1748f66e48cc', created=1762144783, model=None, object='chat.completion.chunk', system_fingerprint=None, choices=[StreamingChoices(finish_reason=None, index=0, delta=Delta(provider_specific_fields=None, content='', role=None, function_call=None, tool_calls=None, audio=None), logprobs=None)], provider_specific_fields=None, usage=None), 'usage': None}
original delta: {'provider_specific_fields': None, 'content': '', 'role': None, 'function_call': None, 'tool_calls': None, 'audio': None}
new delta: Delta(provider_specific_fields=None, content='', role=None, function_call=None, tool_calls=None, audio=None)
model_response.choices[0].delta: Delta(provider_specific_fields=None, content='', role=None, function_call=None, tool_calls=None, audio=None); completion_obj: {'content': ''}
self.sent_first_chunk: True
completion_obj: {'content': ''}, model_response.choices[0]: StreamingChoices(finish_reason=None, index=0, delta=Delta(provider_specific_fields=None, content='', role=None, function_call=None, tool_calls=None, audio=None), logprobs=None), response_obj: {'text': '', 'is_finished': False, 'finish_reason': None, 'logprobs': None, 'original_chunk': ModelResponseStream(id='chatcmpl-21fc6157-48cd-4533-a959-1748f66e48cc', created=1762144783, model=None, object='chat.completion.chunk', system_fingerprint=None, choices=[StreamingChoices(finish_reason=None, index=0, delta=Delta(provider_specific_fields=None, content='', role=None, function_call=None, tool_calls=None, audio=None), logprobs=None)], provider_specific_fields=None, usage=None), 'usage': None}
model_response finish reason 3: None; response_obj={'text': '', 'is_finished': False, 'finish_reason': '', 'usage': None, 'index': 0, 'tool_use': None}
model_response.choices[0].delta: Delta(provider_specific_fields=None, content=None, role=None, function_call=None, tool_calls=None, audio=None); completion_obj: {'content': ''}
self.sent_first_chunk: True
completion_obj: {'content': ''}, model_response.choices[0]: StreamingChoices(finish_reason=None, index=0, delta=Delta(provider_specific_fields=None, content=None, role=None, function_call=None, tool_calls=None, audio=None), logprobs=None), response_obj: {'text': '', 'is_finished': False, 'finish_reason': '', 'usage': None, 'index': 0, 'tool_use': None}
model_response finish reason 3: None; response_obj={'text': '', 'is_finished': False, 'finish_reason': '', 'usage': None, 'index': 0, 'tool_use': None}
model_response.choices[0].delta: Delta(provider_specific_fields=None, content=None, role=None, function_call=None, tool_calls=None, audio=None); completion_obj: {'content': ''}
self.sent_first_chunk: True
completion_obj: {'content': ''}, model_response.choices[0]: StreamingChoices(finish_reason=None, index=0, delta=Delta(provider_specific_fields=None, content=None, role=None, function_call=None, tool_calls=None, audio=None), logprobs=None), response_obj: {'text': '', 'is_finished': False, 'finish_reason': '', 'usage': None, 'index': 0, 'tool_use': None}

Raw OpenAI Chunk
ModelResponseStream(id='chatcmpl-a160984c-b23d-415a-a685-4ffd2e75b8c3', created=1762144783, model=None, object='chat.completion.chunk', system_fingerprint=None, choices=[StreamingChoices(finish_reason='stop', index=0, delta=Delta(provider_specific_fields=None, content='', role=None, function_call=None, tool_calls=None, audio=None), logprobs=None)], provider_specific_fields=None, usage=Usage(completion_tokens=4, prompt_tokens=204, total_tokens=208, completion_tokens_details=None, prompt_tokens_details=PromptTokensDetailsWrapper(audio_tokens=None, cached_tokens=0, text_tokens=None, image_tokens=None, cache_creation_tokens=0), cache_creation_input_tokens=0, cache_read_input_tokens=0))

model_response finish reason 3: stop; response_obj={'text': '', 'is_finished': True, 'finish_reason': 'stop', 'logprobs': None, 'original_chunk': ModelResponseStream(id='chatcmpl-a160984c-b23d-415a-a685-4ffd2e75b8c3', created=1762144783, model=None, object='chat.completion.chunk', system_fingerprint=None, choices=[StreamingChoices(finish_reason='stop', index=0, delta=Delta(provider_specific_fields=None, content='', role=None, function_call=None, tool_calls=None, audio=None), logprobs=None)], provider_specific_fields=None, usage=Usage(completion_tokens=4, prompt_tokens=204, total_tokens=208, completion_tokens_details=None, prompt_tokens_details=PromptTokensDetailsWrapper(audio_tokens=None, cached_tokens=0, text_tokens=None, image_tokens=None, cache_creation_tokens=0), cache_creation_input_tokens=0, cache_read_input_tokens=0)), 'usage': Usage(completion_tokens=4, prompt_tokens=204, total_tokens=208, completion_tokens_details=None, prompt_tokens_details=PromptTokensDetailsWrapper(audio_tokens=None, cached_tokens=0, text_tokens=None, image_tokens=None, cache_creation_tokens=0), cache_creation_input_tokens=0, cache_read_input_tokens=0)}
original delta: {'provider_specific_fields': None, 'content': '', 'role': None, 'function_call': None, 'tool_calls': None, 'audio': None}
new delta: Delta(provider_specific_fields=None, content='', role=None, function_call=None, tool_calls=None, audio=None)
model_response.choices[0].delta: Delta(provider_specific_fields=None, content='', role=None, function_call=None, tool_calls=None, audio=None); completion_obj: {'content': ''}
self.sent_first_chunk: True
completion_obj: {'content': ''}, model_response.choices[0]: StreamingChoices(finish_reason=None, index=0, delta=Delta(provider_specific_fields=None, content='', role=None, function_call=None, tool_calls=None, audio=None), logprobs=None), response_obj: {'text': '', 'is_finished': True, 'finish_reason': 'stop', 'logprobs': None, 'original_chunk': ModelResponseStream(id='chatcmpl-a160984c-b23d-415a-a685-4ffd2e75b8c3', created=1762144783, model=None, object='chat.completion.chunk', system_fingerprint=None, choices=[StreamingChoices(finish_reason='stop', index=0, delta=Delta(provider_specific_fields=None, content='', role=None, function_call=None, tool_calls=None, audio=None), logprobs=None)], provider_specific_fields=None, usage=Usage(completion_tokens=4, prompt_tokens=204, total_tokens=208, completion_tokens_details=None, prompt_tokens_details=PromptTokensDetailsWrapper(audio_tokens=None, cached_tokens=0, text_tokens=None, image_tokens=None, cache_creation_tokens=0), cache_creation_input_tokens=0, cache_read_input_tokens=0)), 'usage': Usage(completion_tokens=4, prompt_tokens=204, total_tokens=208, completion_tokens_details=None, prompt_tokens_details=PromptTokensDetailsWrapper(audio_tokens=None, cached_tokens=0, text_tokens=None, image_tokens=None, cache_creation_tokens=0), cache_creation_input_tokens=0, cache_read_input_tokens=0)}
final returned processed chunk: ModelResponseStream(id='chatcmpl-a160984c-b23d-415a-a685-4ffd2e75b8c3', created=1762144783, model='claude-sonnet-4-5-20250929', object='chat.completion.chunk', system_fingerprint=None, choices=[StreamingChoices(finish_reason='stop', index=0, delta=Delta(provider_specific_fields=None, content=None, role=None, function_call=None, tool_calls=None, audio=None), logprobs=None)], provider_specific_fields=None)
INFO:     127.0.0.1:53867 - "GET /v1/models HTTP/1.1" 200 OK
model_response finish reason 3: None; response_obj={'text': '', 'is_finished': False, 'finish_reason': '', 'usage': None, 'index': 0, 'tool_use': None}
model_response.choices[0].delta: Delta(provider_specific_fields=None, content=None, role=None, function_call=None, tool_calls=None, audio=None); completion_obj: {'content': ''}
self.sent_first_chunk: True
completion_obj: {'content': ''}, model_response.choices[0]: StreamingChoices(finish_reason=None, index=0, delta=Delta(provider_specific_fields=None, content=None, role=None, function_call=None, tool_calls=None, audio=None), logprobs=None), response_obj: {'text': '', 'is_finished': False, 'finish_reason': '', 'usage': None, 'index': 0, 'tool_use': None}

Raw OpenAI Chunk
ModelResponseStream(id='chatcmpl-21fc6157-48cd-4533-a959-1748f66e48cc', created=1762144783, model=None, object='chat.completion.chunk', system_fingerprint=None, choices=[StreamingChoices(finish_reason='stop', index=0, delta=Delta(provider_specific_fields=None, content='', role=None, function_call=None, tool_calls=None, audio=None), logprobs=None)], provider_specific_fields=None, usage=Usage(completion_tokens=4, prompt_tokens=1493, total_tokens=1497, completion_tokens_details=None, prompt_tokens_details=PromptTokensDetailsWrapper(audio_tokens=None, cached_tokens=0, text_tokens=None, image_tokens=None, cache_creation_tokens=0), cache_creation_input_tokens=0, cache_read_input_tokens=0))

model_response finish reason 3: stop; response_obj={'text': '', 'is_finished': True, 'finish_reason': 'stop', 'logprobs': None, 'original_chunk': ModelResponseStream(id='chatcmpl-21fc6157-48cd-4533-a959-1748f66e48cc', created=1762144783, model=None, object='chat.completion.chunk', system_fingerprint=None, choices=[StreamingChoices(finish_reason='stop', index=0, delta=Delta(provider_specific_fields=None, content='', role=None, function_call=None, tool_calls=None, audio=None), logprobs=None)], provider_specific_fields=None, usage=Usage(completion_tokens=4, prompt_tokens=1493, total_tokens=1497, completion_tokens_details=None, prompt_tokens_details=PromptTokensDetailsWrapper(audio_tokens=None, cached_tokens=0, text_tokens=None, image_tokens=None, cache_creation_tokens=0), cache_creation_input_tokens=0, cache_read_input_tokens=0)), 'usage': Usage(completion_tokens=4, prompt_tokens=1493, total_tokens=1497, completion_tokens_details=None, prompt_tokens_details=PromptTokensDetailsWrapper(audio_tokens=None, cached_tokens=0, text_tokens=None, image_tokens=None, cache_creation_tokens=0), cache_creation_input_tokens=0, cache_read_input_tokens=0)}
original delta: {'provider_specific_fields': None, 'content': '', 'role': None, 'function_call': None, 'tool_calls': None, 'audio': None}
new delta: Delta(provider_specific_fields=None, content='', role=None, function_call=None, tool_calls=None, audio=None)
model_response.choices[0].delta: Delta(provider_specific_fields=None, content='', role=None, function_call=None, tool_calls=None, audio=None); completion_obj: {'content': ''}
self.sent_first_chunk: True
completion_obj: {'content': ''}, model_response.choices[0]: StreamingChoices(finish_reason=None, index=0, delta=Delta(provider_specific_fields=None, content='', role=None, function_call=None, tool_calls=None, audio=None), logprobs=None), response_obj: {'text': '', 'is_finished': True, 'finish_reason': 'stop', 'logprobs': None, 'original_chunk': ModelResponseStream(id='chatcmpl-21fc6157-48cd-4533-a959-1748f66e48cc', created=1762144783, model=None, object='chat.completion.chunk', system_fingerprint=None, choices=[StreamingChoices(finish_reason='stop', index=0, delta=Delta(provider_specific_fields=None, content='', role=None, function_call=None, tool_calls=None, audio=None), logprobs=None)], provider_specific_fields=None, usage=Usage(completion_tokens=4, prompt_tokens=1493, total_tokens=1497, completion_tokens_details=None, prompt_tokens_details=PromptTokensDetailsWrapper(audio_tokens=None, cached_tokens=0, text_tokens=None, image_tokens=None, cache_creation_tokens=0), cache_creation_input_tokens=0, cache_read_input_tokens=0)), 'usage': Usage(completion_tokens=4, prompt_tokens=1493, total_tokens=1497, completion_tokens_details=None, prompt_tokens_details=PromptTokensDetailsWrapper(audio_tokens=None, cached_tokens=0, text_tokens=None, image_tokens=None, cache_creation_tokens=0), cache_creation_input_tokens=0, cache_read_input_tokens=0)}
final returned processed chunk: ModelResponseStream(id='chatcmpl-21fc6157-48cd-4533-a959-1748f66e48cc', created=1762144783, model='claude-sonnet-4-5-20250929', object='chat.completion.chunk', system_fingerprint=None, choices=[StreamingChoices(finish_reason='stop', index=0, delta=Delta(provider_specific_fields=None, content=None, role=None, function_call=None, tool_calls=None, audio=None), logprobs=None)], provider_specific_fields=None)
INFO:     127.0.0.1:53871 - "GET /v1/models HTTP/1.1" 200 OK
model_response finish reason 3: None; response_obj={'text': '', 'is_finished': False, 'finish_reason': '', 'usage': None, 'index': 0, 'tool_use': None}
model_response.choices[0].delta: Delta(provider_specific_fields=None, content=None, role=None, function_call=None, tool_calls=None, audio=None); completion_obj: {'content': ''}
self.sent_first_chunk: True
completion_obj: {'content': ''}, model_response.choices[0]: StreamingChoices(finish_reason=None, index=0, delta=Delta(provider_specific_fields=None, content=None, role=None, function_call=None, tool_calls=None, audio=None), logprobs=None), response_obj: {'text': '', 'is_finished': False, 'finish_reason': '', 'usage': None, 'index': 0, 'tool_use': None}

Raw OpenAI Chunk
ModelResponseStream(id='chatcmpl-24e35af5-25b0-4416-9f29-279db90a0879', created=1762144783, model=None, object='chat.completion.chunk', system_fingerprint=None, choices=[StreamingChoices(finish_reason=None, index=0, delta=Delta(provider_specific_fields=None, content=' conversations\nconversation', role=None, function_call=None, tool_calls=None, audio=None), logprobs=None)], provider_specific_fields=None, usage=None)

model_response finish reason 3: None; response_obj={'text': ' conversations\nconversation', 'is_finished': False, 'finish_reason': None, 'logprobs': None, 'original_chunk': ModelResponseStream(id='chatcmpl-24e35af5-25b0-4416-9f29-279db90a0879', created=1762144783, model=None, object='chat.completion.chunk', system_fingerprint=None, choices=[StreamingChoices(finish_reason=None, index=0, delta=Delta(provider_specific_fields=None, content=' conversations\nconversation', role=None, function_call=None, tool_calls=None, audio=None), logprobs=None)], provider_specific_fields=None, usage=None), 'usage': None}
original delta: {'provider_specific_fields': None, 'content': ' conversations\nconversation', 'role': None, 'function_call': None, 'tool_calls': None, 'audio': None}
new delta: Delta(provider_specific_fields=None, content=' conversations\nconversation', role=None, function_call=None, tool_calls=None, audio=None)
model_response.choices[0].delta: Delta(provider_specific_fields=None, content=' conversations\nconversation', role=None, function_call=None, tool_calls=None, audio=None); completion_obj: {'content': ' conversations\nconversation'}
self.sent_first_chunk: True
completion_obj: {'content': ' conversations\nconversation'}, model_response.choices[0]: StreamingChoices(finish_reason=None, index=0, delta=Delta(provider_specific_fields=None, content=' conversations\nconversation', role=None, function_call=None, tool_calls=None, audio=None), logprobs=None), response_obj: {'text': ' conversations\nconversation', 'is_finished': False, 'finish_reason': None, 'logprobs': None, 'original_chunk': ModelResponseStream(id='chatcmpl-24e35af5-25b0-4416-9f29-279db90a0879', created=1762144783, model=None, object='chat.completion.chunk', system_fingerprint=None, choices=[StreamingChoices(finish_reason=None, index=0, delta=Delta(provider_specific_fields=None, content=' conversations\nconversation', role=None, function_call=None, tool_calls=None, audio=None), logprobs=None)], provider_specific_fields=None, usage=None), 'usage': None}
choice_json: {'index': 0, 'delta': {'provider_specific_fields': None, 'content': ' conversations\nconversation', 'role': None, 'function_call': None, 'tool_calls': None, 'audio': None}, 'logprobs': None}
choices in streaming: [StreamingChoices(finish_reason=None, index=0, delta=Delta(provider_specific_fields=None, content=' conversations\nconversation', role=None, function_call=None, tool_calls=None, audio=None), logprobs=None)]
final returned processed chunk: ModelResponseStream(id='chatcmpl-24e35af5-25b0-4416-9f29-279db90a0879', created=1762144783, model='claude-sonnet-4-5-20250929', object='chat.completion.chunk', system_fingerprint=None, choices=[StreamingChoices(finish_reason=None, index=0, delta=Delta(provider_specific_fields=None, content=' conversations\nconversation', role=None, function_call=None, tool_calls=None, audio=None), logprobs=None)], provider_specific_fields=None, citations=None)
model_response finish reason 3: None; response_obj={'text': '', 'is_finished': False, 'finish_reason': '', 'usage': None, 'index': 0, 'tool_use': None}
model_response.choices[0].delta: Delta(provider_specific_fields=None, content=None, role=None, function_call=None, tool_calls=None, audio=None); completion_obj: {'content': ''}
self.sent_first_chunk: True
completion_obj: {'content': ''}, model_response.choices[0]: StreamingChoices(finish_reason=None, index=0, delta=Delta(provider_specific_fields=None, content=None, role=None, function_call=None, tool_calls=None, audio=None), logprobs=None), response_obj: {'text': '', 'is_finished': False, 'finish_reason': '', 'usage': None, 'index': 0, 'tool_use': None}
model_response finish reason 3: None; response_obj={'text': '', 'is_finished': False, 'finish_reason': '', 'usage': None, 'index': 0, 'tool_use': None}
model_response.choices[0].delta: Delta(provider_specific_fields=None, content=None, role=None, function_call=None, tool_calls=None, audio=None); completion_obj: {'content': ''}
self.sent_first_chunk: True
completion_obj: {'content': ''}, model_response.choices[0]: StreamingChoices(finish_reason=None, index=0, delta=Delta(provider_specific_fields=None, content=None, role=None, function_call=None, tool_calls=None, audio=None), logprobs=None), response_obj: {'text': '', 'is_finished': False, 'finish_reason': '', 'usage': None, 'index': 0, 'tool_use': None}

Raw OpenAI Chunk
ModelResponseStream(id='chatcmpl-24e35af5-25b0-4416-9f29-279db90a0879', created=1762144783, model=None, object='chat.completion.chunk', system_fingerprint=None, choices=[StreamingChoices(finish_reason=None, index=0, delta=Delta(provider_specific_fields=None, content=' storage', role=None, function_call=None, tool_calls=None, audio=None), logprobs=None)], provider_specific_fields=None, usage=None)

model_response finish reason 3: None; response_obj={'text': ' storage', 'is_finished': False, 'finish_reason': None, 'logprobs': None, 'original_chunk': ModelResponseStream(id='chatcmpl-24e35af5-25b0-4416-9f29-279db90a0879', created=1762144783, model=None, object='chat.completion.chunk', system_fingerprint=None, choices=[StreamingChoices(finish_reason=None, index=0, delta=Delta(provider_specific_fields=None, content=' storage', role=None, function_call=None, tool_calls=None, audio=None), logprobs=None)], provider_specific_fields=None, usage=None), 'usage': None}
original delta: {'provider_specific_fields': None, 'content': ' storage', 'role': None, 'function_call': None, 'tool_calls': None, 'audio': None}
new delta: Delta(provider_specific_fields=None, content=' storage', role=None, function_call=None, tool_calls=None, audio=None)
model_response.choices[0].delta: Delta(provider_specific_fields=None, content=' storage', role=None, function_call=None, tool_calls=None, audio=None); completion_obj: {'content': ' storage'}
self.sent_first_chunk: True
completion_obj: {'content': ' storage'}, model_response.choices[0]: StreamingChoices(finish_reason=None, index=0, delta=Delta(provider_specific_fields=None, content=' storage', role=None, function_call=None, tool_calls=None, audio=None), logprobs=None), response_obj: {'text': ' storage', 'is_finished': False, 'finish_reason': None, 'logprobs': None, 'original_chunk': ModelResponseStream(id='chatcmpl-24e35af5-25b0-4416-9f29-279db90a0879', created=1762144783, model=None, object='chat.completion.chunk', system_fingerprint=None, choices=[StreamingChoices(finish_reason=None, index=0, delta=Delta(provider_specific_fields=None, content=' storage', role=None, function_call=None, tool_calls=None, audio=None), logprobs=None)], provider_specific_fields=None, usage=None), 'usage': None}
choice_json: {'index': 0, 'delta': {'provider_specific_fields': None, 'content': ' storage', 'role': None, 'function_call': None, 'tool_calls': None, 'audio': None}, 'logprobs': None}
choices in streaming: [StreamingChoices(finish_reason=None, index=0, delta=Delta(provider_specific_fields=None, content=' storage', role=None, function_call=None, tool_calls=None, audio=None), logprobs=None)]
final returned processed chunk: ModelResponseStream(id='chatcmpl-24e35af5-25b0-4416-9f29-279db90a0879', created=1762144783, model='claude-sonnet-4-5-20250929', object='chat.completion.chunk', system_fingerprint=None, choices=[StreamingChoices(finish_reason=None, index=0, delta=Delta(provider_specific_fields=None, content=' storage', role=None, function_call=None, tool_calls=None, audio=None), logprobs=None)], provider_specific_fields=None, citations=None)
model_response finish reason 3: None; response_obj={'text': '', 'is_finished': False, 'finish_reason': '', 'usage': None, 'index': 0, 'tool_use': None}
model_response.choices[0].delta: Delta(provider_specific_fields=None, content=None, role=None, function_call=None, tool_calls=None, audio=None); completion_obj: {'content': ''}
self.sent_first_chunk: True
completion_obj: {'content': ''}, model_response.choices[0]: StreamingChoices(finish_reason=None, index=0, delta=Delta(provider_specific_fields=None, content=None, role=None, function_call=None, tool_calls=None, audio=None), logprobs=None), response_obj: {'text': '', 'is_finished': False, 'finish_reason': '', 'usage': None, 'index': 0, 'tool_use': None}
model_response finish reason 3: None; response_obj={'text': '', 'is_finished': False, 'finish_reason': '', 'usage': None, 'index': 0, 'tool_use': None}
model_response.choices[0].delta: Delta(provider_specific_fields=None, content=None, role=None, function_call=None, tool_calls=None, audio=None); completion_obj: {'content': ''}
self.sent_first_chunk: True
completion_obj: {'content': ''}, model_response.choices[0]: StreamingChoices(finish_reason=None, index=0, delta=Delta(provider_specific_fields=None, content=None, role=None, function_call=None, tool_calls=None, audio=None), logprobs=None), response_obj: {'text': '', 'is_finished': False, 'finish_reason': '', 'usage': None, 'index': 0, 'tool_use': None}

Raw OpenAI Chunk
ModelResponseStream(id='chatcmpl-95690960-2e48-477d-9a30-4775f49b09e7', created=1762144783, model=None, object='chat.completion.chunk', system_fingerprint=None, choices=[StreamingChoices(finish_reason=None, index=0, delta=Delta(provider_specific_fields=None, content='', role=None, function_call=None, tool_calls=None, audio=None), logprobs=None)], provider_specific_fields=None, usage=None)

model_response finish reason 3: None; response_obj={'text': '', 'is_finished': False, 'finish_reason': None, 'logprobs': None, 'original_chunk': ModelResponseStream(id='chatcmpl-95690960-2e48-477d-9a30-4775f49b09e7', created=1762144783, model=None, object='chat.completion.chunk', system_fingerprint=None, choices=[StreamingChoices(finish_reason=None, index=0, delta=Delta(provider_specific_fields=None, content='', role=None, function_call=None, tool_calls=None, audio=None), logprobs=None)], provider_specific_fields=None, usage=None), 'usage': None}
original delta: {'provider_specific_fields': None, 'content': '', 'role': None, 'function_call': None, 'tool_calls': None, 'audio': None}
new delta: Delta(provider_specific_fields=None, content='', role=None, function_call=None, tool_calls=None, audio=None)
model_response.choices[0].delta: Delta(provider_specific_fields=None, content='', role=None, function_call=None, tool_calls=None, audio=None); completion_obj: {'content': ''}
self.sent_first_chunk: True
completion_obj: {'content': ''}, model_response.choices[0]: StreamingChoices(finish_reason=None, index=0, delta=Delta(provider_specific_fields=None, content='', role=None, function_call=None, tool_calls=None, audio=None), logprobs=None), response_obj: {'text': '', 'is_finished': False, 'finish_reason': None, 'logprobs': None, 'original_chunk': ModelResponseStream(id='chatcmpl-95690960-2e48-477d-9a30-4775f49b09e7', created=1762144783, model=None, object='chat.completion.chunk', system_fingerprint=None, choices=[StreamingChoices(finish_reason=None, index=0, delta=Delta(provider_specific_fields=None, content='', role=None, function_call=None, tool_calls=None, audio=None), logprobs=None)], provider_specific_fields=None, usage=None), 'usage': None}
model_response finish reason 3: None; response_obj={'text': '', 'is_finished': False, 'finish_reason': '', 'usage': None, 'index': 0, 'tool_use': None}
model_response.choices[0].delta: Delta(provider_specific_fields=None, content=None, role=None, function_call=None, tool_calls=None, audio=None); completion_obj: {'content': ''}
self.sent_first_chunk: True
completion_obj: {'content': ''}, model_response.choices[0]: StreamingChoices(finish_reason=None, index=0, delta=Delta(provider_specific_fields=None, content=None, role=None, function_call=None, tool_calls=None, audio=None), logprobs=None), response_obj: {'text': '', 'is_finished': False, 'finish_reason': '', 'usage': None, 'index': 0, 'tool_use': None}
model_response finish reason 3: None; response_obj={'text': '', 'is_finished': False, 'finish_reason': '', 'usage': None, 'index': 0, 'tool_use': None}
model_response.choices[0].delta: Delta(provider_specific_fields=None, content=None, role=None, function_call=None, tool_calls=None, audio=None); completion_obj: {'content': ''}
self.sent_first_chunk: True
completion_obj: {'content': ''}, model_response.choices[0]: StreamingChoices(finish_reason=None, index=0, delta=Delta(provider_specific_fields=None, content=None, role=None, function_call=None, tool_calls=None, audio=None), logprobs=None), response_obj: {'text': '', 'is_finished': False, 'finish_reason': '', 'usage': None, 'index': 0, 'tool_use': None}

Raw OpenAI Chunk
ModelResponseStream(id='chatcmpl-dad69e75-0227-4ca2-b397-a0b3e9ce29d0', created=1762144783, model=None, object='chat.completion.chunk', system_fingerprint=None, choices=[StreamingChoices(finish_reason=None, index=0, delta=Delta(provider_specific_fields=None, content='', role=None, function_call=None, tool_calls=None, audio=None), logprobs=None)], provider_specific_fields=None, usage=None)

model_response finish reason 3: None; response_obj={'text': '', 'is_finished': False, 'finish_reason': None, 'logprobs': None, 'original_chunk': ModelResponseStream(id='chatcmpl-dad69e75-0227-4ca2-b397-a0b3e9ce29d0', created=1762144783, model=None, object='chat.completion.chunk', system_fingerprint=None, choices=[StreamingChoices(finish_reason=None, index=0, delta=Delta(provider_specific_fields=None, content='', role=None, function_call=None, tool_calls=None, audio=None), logprobs=None)], provider_specific_fields=None, usage=None), 'usage': None}
original delta: {'provider_specific_fields': None, 'content': '', 'role': None, 'function_call': None, 'tool_calls': None, 'audio': None}
new delta: Delta(provider_specific_fields=None, content='', role=None, function_call=None, tool_calls=None, audio=None)
model_response.choices[0].delta: Delta(provider_specific_fields=None, content='', role=None, function_call=None, tool_calls=None, audio=None); completion_obj: {'content': ''}
self.sent_first_chunk: True
completion_obj: {'content': ''}, model_response.choices[0]: StreamingChoices(finish_reason=None, index=0, delta=Delta(provider_specific_fields=None, content='', role=None, function_call=None, tool_calls=None, audio=None), logprobs=None), response_obj: {'text': '', 'is_finished': False, 'finish_reason': None, 'logprobs': None, 'original_chunk': ModelResponseStream(id='chatcmpl-dad69e75-0227-4ca2-b397-a0b3e9ce29d0', created=1762144783, model=None, object='chat.completion.chunk', system_fingerprint=None, choices=[StreamingChoices(finish_reason=None, index=0, delta=Delta(provider_specific_fields=None, content='', role=None, function_call=None, tool_calls=None, audio=None), logprobs=None)], provider_specific_fields=None, usage=None), 'usage': None}
model_response finish reason 3: None; response_obj={'text': '', 'is_finished': False, 'finish_reason': '', 'usage': None, 'index': 0, 'tool_use': None}
model_response.choices[0].delta: Delta(provider_specific_fields=None, content=None, role=None, function_call=None, tool_calls=None, audio=None); completion_obj: {'content': ''}
self.sent_first_chunk: True
completion_obj: {'content': ''}, model_response.choices[0]: StreamingChoices(finish_reason=None, index=0, delta=Delta(provider_specific_fields=None, content=None, role=None, function_call=None, tool_calls=None, audio=None), logprobs=None), response_obj: {'text': '', 'is_finished': False, 'finish_reason': '', 'usage': None, 'index': 0, 'tool_use': None}
model_response finish reason 3: None; response_obj={'text': '', 'is_finished': False, 'finish_reason': '', 'usage': None, 'index': 0, 'tool_use': None}
model_response.choices[0].delta: Delta(provider_specific_fields=None, content=None, role=None, function_call=None, tool_calls=None, audio=None); completion_obj: {'content': ''}
self.sent_first_chunk: True
completion_obj: {'content': ''}, model_response.choices[0]: StreamingChoices(finish_reason=None, index=0, delta=Delta(provider_specific_fields=None, content=None, role=None, function_call=None, tool_calls=None, audio=None), logprobs=None), response_obj: {'text': '', 'is_finished': False, 'finish_reason': '', 'usage': None, 'index': 0, 'tool_use': None}

Raw OpenAI Chunk
ModelResponseStream(id='chatcmpl-24e35af5-25b0-4416-9f29-279db90a0879', created=1762144783, model=None, object='chat.completion.chunk', system_fingerprint=None, choices=[StreamingChoices(finish_reason=None, index=0, delta=Delta(provider_specific_fields=None, content='\nconversation manager', role=None, function_call=None, tool_calls=None, audio=None), logprobs=None)], provider_specific_fields=None, usage=None)

model_response finish reason 3: None; response_obj={'text': '\nconversation manager', 'is_finished': False, 'finish_reason': None, 'logprobs': None, 'original_chunk': ModelResponseStream(id='chatcmpl-24e35af5-25b0-4416-9f29-279db90a0879', created=1762144783, model=None, object='chat.completion.chunk', system_fingerprint=None, choices=[StreamingChoices(finish_reason=None, index=0, delta=Delta(provider_specific_fields=None, content='\nconversation manager', role=None, function_call=None, tool_calls=None, audio=None), logprobs=None)], provider_specific_fields=None, usage=None), 'usage': None}
original delta: {'provider_specific_fields': None, 'content': '\nconversation manager', 'role': None, 'function_call': None, 'tool_calls': None, 'audio': None}
new delta: Delta(provider_specific_fields=None, content='\nconversation manager', role=None, function_call=None, tool_calls=None, audio=None)
model_response.choices[0].delta: Delta(provider_specific_fields=None, content='\nconversation manager', role=None, function_call=None, tool_calls=None, audio=None); completion_obj: {'content': '\nconversation manager'}
self.sent_first_chunk: True
completion_obj: {'content': '\nconversation manager'}, model_response.choices[0]: StreamingChoices(finish_reason=None, index=0, delta=Delta(provider_specific_fields=None, content='\nconversation manager', role=None, function_call=None, tool_calls=None, audio=None), logprobs=None), response_obj: {'text': '\nconversation manager', 'is_finished': False, 'finish_reason': None, 'logprobs': None, 'original_chunk': ModelResponseStream(id='chatcmpl-24e35af5-25b0-4416-9f29-279db90a0879', created=1762144783, model=None, object='chat.completion.chunk', system_fingerprint=None, choices=[StreamingChoices(finish_reason=None, index=0, delta=Delta(provider_specific_fields=None, content='\nconversation manager', role=None, function_call=None, tool_calls=None, audio=None), logprobs=None)], provider_specific_fields=None, usage=None), 'usage': None}
choice_json: {'index': 0, 'delta': {'provider_specific_fields': None, 'content': '\nconversation manager', 'role': None, 'function_call': None, 'tool_calls': None, 'audio': None}, 'logprobs': None}
choices in streaming: [StreamingChoices(finish_reason=None, index=0, delta=Delta(provider_specific_fields=None, content='\nconversation manager', role=None, function_call=None, tool_calls=None, audio=None), logprobs=None)]
final returned processed chunk: ModelResponseStream(id='chatcmpl-24e35af5-25b0-4416-9f29-279db90a0879', created=1762144783, model='claude-sonnet-4-5-20250929', object='chat.completion.chunk', system_fingerprint=None, choices=[StreamingChoices(finish_reason=None, index=0, delta=Delta(provider_specific_fields=None, content='\nconversation manager', role=None, function_call=None, tool_calls=None, audio=None), logprobs=None)], provider_specific_fields=None, citations=None)
model_response finish reason 3: None; response_obj={'text': '', 'is_finished': False, 'finish_reason': '', 'usage': None, 'index': 0, 'tool_use': None}
model_response.choices[0].delta: Delta(provider_specific_fields=None, content=None, role=None, function_call=None, tool_calls=None, audio=None); completion_obj: {'content': ''}
self.sent_first_chunk: True
completion_obj: {'content': ''}, model_response.choices[0]: StreamingChoices(finish_reason=None, index=0, delta=Delta(provider_specific_fields=None, content=None, role=None, function_call=None, tool_calls=None, audio=None), logprobs=None), response_obj: {'text': '', 'is_finished': False, 'finish_reason': '', 'usage': None, 'index': 0, 'tool_use': None}
model_response finish reason 3: None; response_obj={'text': '', 'is_finished': False, 'finish_reason': '', 'usage': None, 'index': 0, 'tool_use': None}
model_response.choices[0].delta: Delta(provider_specific_fields=None, content=None, role=None, function_call=None, tool_calls=None, audio=None); completion_obj: {'content': ''}
self.sent_first_chunk: True
completion_obj: {'content': ''}, model_response.choices[0]: StreamingChoices(finish_reason=None, index=0, delta=Delta(provider_specific_fields=None, content=None, role=None, function_call=None, tool_calls=None, audio=None), logprobs=None), response_obj: {'text': '', 'is_finished': False, 'finish_reason': '', 'usage': None, 'index': 0, 'tool_use': None}

Raw OpenAI Chunk
ModelResponseStream(id='chatcmpl-dad69e75-0227-4ca2-b397-a0b3e9ce29d0', created=1762144783, model=None, object='chat.completion.chunk', system_fingerprint=None, choices=[StreamingChoices(finish_reason='stop', index=0, delta=Delta(provider_specific_fields=None, content='', role=None, function_call=None, tool_calls=None, audio=None), logprobs=None)], provider_specific_fields=None, usage=Usage(completion_tokens=4, prompt_tokens=1388, total_tokens=1392, completion_tokens_details=None, prompt_tokens_details=PromptTokensDetailsWrapper(audio_tokens=None, cached_tokens=0, text_tokens=None, image_tokens=None, cache_creation_tokens=0), cache_creation_input_tokens=0, cache_read_input_tokens=0))

model_response finish reason 3: stop; response_obj={'text': '', 'is_finished': True, 'finish_reason': 'stop', 'logprobs': None, 'original_chunk': ModelResponseStream(id='chatcmpl-dad69e75-0227-4ca2-b397-a0b3e9ce29d0', created=1762144783, model=None, object='chat.completion.chunk', system_fingerprint=None, choices=[StreamingChoices(finish_reason='stop', index=0, delta=Delta(provider_specific_fields=None, content='', role=None, function_call=None, tool_calls=None, audio=None), logprobs=None)], provider_specific_fields=None, usage=Usage(completion_tokens=4, prompt_tokens=1388, total_tokens=1392, completion_tokens_details=None, prompt_tokens_details=PromptTokensDetailsWrapper(audio_tokens=None, cached_tokens=0, text_tokens=None, image_tokens=None, cache_creation_tokens=0), cache_creation_input_tokens=0, cache_read_input_tokens=0)), 'usage': Usage(completion_tokens=4, prompt_tokens=1388, total_tokens=1392, completion_tokens_details=None, prompt_tokens_details=PromptTokensDetailsWrapper(audio_tokens=None, cached_tokens=0, text_tokens=None, image_tokens=None, cache_creation_tokens=0), cache_creation_input_tokens=0, cache_read_input_tokens=0)}
original delta: {'provider_specific_fields': None, 'content': '', 'role': None, 'function_call': None, 'tool_calls': None, 'audio': None}
new delta: Delta(provider_specific_fields=None, content='', role=None, function_call=None, tool_calls=None, audio=None)
model_response.choices[0].delta: Delta(provider_specific_fields=None, content='', role=None, function_call=None, tool_calls=None, audio=None); completion_obj: {'content': ''}
self.sent_first_chunk: True
completion_obj: {'content': ''}, model_response.choices[0]: StreamingChoices(finish_reason=None, index=0, delta=Delta(provider_specific_fields=None, content='', role=None, function_call=None, tool_calls=None, audio=None), logprobs=None), response_obj: {'text': '', 'is_finished': True, 'finish_reason': 'stop', 'logprobs': None, 'original_chunk': ModelResponseStream(id='chatcmpl-dad69e75-0227-4ca2-b397-a0b3e9ce29d0', created=1762144783, model=None, object='chat.completion.chunk', system_fingerprint=None, choices=[StreamingChoices(finish_reason='stop', index=0, delta=Delta(provider_specific_fields=None, content='', role=None, function_call=None, tool_calls=None, audio=None), logprobs=None)], provider_specific_fields=None, usage=Usage(completion_tokens=4, prompt_tokens=1388, total_tokens=1392, completion_tokens_details=None, prompt_tokens_details=PromptTokensDetailsWrapper(audio_tokens=None, cached_tokens=0, text_tokens=None, image_tokens=None, cache_creation_tokens=0), cache_creation_input_tokens=0, cache_read_input_tokens=0)), 'usage': Usage(completion_tokens=4, prompt_tokens=1388, total_tokens=1392, completion_tokens_details=None, prompt_tokens_details=PromptTokensDetailsWrapper(audio_tokens=None, cached_tokens=0, text_tokens=None, image_tokens=None, cache_creation_tokens=0), cache_creation_input_tokens=0, cache_read_input_tokens=0)}
final returned processed chunk: ModelResponseStream(id='chatcmpl-dad69e75-0227-4ca2-b397-a0b3e9ce29d0', created=1762144783, model='claude-sonnet-4-5-20250929', object='chat.completion.chunk', system_fingerprint=None, choices=[StreamingChoices(finish_reason='stop', index=0, delta=Delta(provider_specific_fields=None, content=None, role=None, function_call=None, tool_calls=None, audio=None), logprobs=None)], provider_specific_fields=None)
model_response finish reason 3: None; response_obj={'text': '', 'is_finished': False, 'finish_reason': '', 'usage': None, 'index': 0, 'tool_use': None}
model_response.choices[0].delta: Delta(provider_specific_fields=None, content=None, role=None, function_call=None, tool_calls=None, audio=None); completion_obj: {'content': ''}
self.sent_first_chunk: True
completion_obj: {'content': ''}, model_response.choices[0]: StreamingChoices(finish_reason=None, index=0, delta=Delta(provider_specific_fields=None, content=None, role=None, function_call=None, tool_calls=None, audio=None), logprobs=None), response_obj: {'text': '', 'is_finished': False, 'finish_reason': '', 'usage': None, 'index': 0, 'tool_use': None}

Raw OpenAI Chunk
ModelResponseStream(id='chatcmpl-95690960-2e48-477d-9a30-4775f49b09e7', created=1762144783, model=None, object='chat.completion.chunk', system_fingerprint=None, choices=[StreamingChoices(finish_reason='stop', index=0, delta=Delta(provider_specific_fields=None, content='', role=None, function_call=None, tool_calls=None, audio=None), logprobs=None)], provider_specific_fields=None, usage=Usage(completion_tokens=4, prompt_tokens=1371, total_tokens=1375, completion_tokens_details=None, prompt_tokens_details=PromptTokensDetailsWrapper(audio_tokens=None, cached_tokens=0, text_tokens=None, image_tokens=None, cache_creation_tokens=0), cache_creation_input_tokens=0, cache_read_input_tokens=0))

model_response finish reason 3: stop; response_obj={'text': '', 'is_finished': True, 'finish_reason': 'stop', 'logprobs': None, 'original_chunk': ModelResponseStream(id='chatcmpl-95690960-2e48-477d-9a30-4775f49b09e7', created=1762144783, model=None, object='chat.completion.chunk', system_fingerprint=None, choices=[StreamingChoices(finish_reason='stop', index=0, delta=Delta(provider_specific_fields=None, content='', role=None, function_call=None, tool_calls=None, audio=None), logprobs=None)], provider_specific_fields=None, usage=Usage(completion_tokens=4, prompt_tokens=1371, total_tokens=1375, completion_tokens_details=None, prompt_tokens_details=PromptTokensDetailsWrapper(audio_tokens=None, cached_tokens=0, text_tokens=None, image_tokens=None, cache_creation_tokens=0), cache_creation_input_tokens=0, cache_read_input_tokens=0)), 'usage': Usage(completion_tokens=4, prompt_tokens=1371, total_tokens=1375, completion_tokens_details=None, prompt_tokens_details=PromptTokensDetailsWrapper(audio_tokens=None, cached_tokens=0, text_tokens=None, image_tokens=None, cache_creation_tokens=0), cache_creation_input_tokens=0, cache_read_input_tokens=0)}
original delta: {'provider_specific_fields': None, 'content': '', 'role': None, 'function_call': None, 'tool_calls': None, 'audio': None}
new delta: Delta(provider_specific_fields=None, content='', role=None, function_call=None, tool_calls=None, audio=None)
model_response.choices[0].delta: Delta(provider_specific_fields=None, content='', role=None, function_call=None, tool_calls=None, audio=None); completion_obj: {'content': ''}
self.sent_first_chunk: True
completion_obj: {'content': ''}, model_response.choices[0]: StreamingChoices(finish_reason=None, index=0, delta=Delta(provider_specific_fields=None, content='', role=None, function_call=None, tool_calls=None, audio=None), logprobs=None), response_obj: {'text': '', 'is_finished': True, 'finish_reason': 'stop', 'logprobs': None, 'original_chunk': ModelResponseStream(id='chatcmpl-95690960-2e48-477d-9a30-4775f49b09e7', created=1762144783, model=None, object='chat.completion.chunk', system_fingerprint=None, choices=[StreamingChoices(finish_reason='stop', index=0, delta=Delta(provider_specific_fields=None, content='', role=None, function_call=None, tool_calls=None, audio=None), logprobs=None)], provider_specific_fields=None, usage=Usage(completion_tokens=4, prompt_tokens=1371, total_tokens=1375, completion_tokens_details=None, prompt_tokens_details=PromptTokensDetailsWrapper(audio_tokens=None, cached_tokens=0, text_tokens=None, image_tokens=None, cache_creation_tokens=0), cache_creation_input_tokens=0, cache_read_input_tokens=0)), 'usage': Usage(completion_tokens=4, prompt_tokens=1371, total_tokens=1375, completion_tokens_details=None, prompt_tokens_details=PromptTokensDetailsWrapper(audio_tokens=None, cached_tokens=0, text_tokens=None, image_tokens=None, cache_creation_tokens=0), cache_creation_input_tokens=0, cache_read_input_tokens=0)}
final returned processed chunk: ModelResponseStream(id='chatcmpl-95690960-2e48-477d-9a30-4775f49b09e7', created=1762144783, model='claude-sonnet-4-5-20250929', object='chat.completion.chunk', system_fingerprint=None, choices=[StreamingChoices(finish_reason='stop', index=0, delta=Delta(provider_specific_fields=None, content=None, role=None, function_call=None, tool_calls=None, audio=None), logprobs=None)], provider_specific_fields=None)
model_response finish reason 3: None; response_obj={'text': '', 'is_finished': False, 'finish_reason': '', 'usage': None, 'index': 0, 'tool_use': None}
model_response.choices[0].delta: Delta(provider_specific_fields=None, content=None, role=None, function_call=None, tool_calls=None, audio=None); completion_obj: {'content': ''}
self.sent_first_chunk: True
completion_obj: {'content': ''}, model_response.choices[0]: StreamingChoices(finish_reason=None, index=0, delta=Delta(provider_specific_fields=None, content=None, role=None, function_call=None, tool_calls=None, audio=None), logprobs=None), response_obj: {'text': '', 'is_finished': False, 'finish_reason': '', 'usage': None, 'index': 0, 'tool_use': None}

Raw OpenAI Chunk
ModelResponseStream(id='chatcmpl-24e35af5-25b0-4416-9f29-279db90a0879', created=1762144783, model=None, object='chat.completion.chunk', system_fingerprint=None, choices=[StreamingChoices(finish_reason=None, index=0, delta=Delta(provider_specific_fields=None, content='\nchat', role=None, function_call=None, tool_calls=None, audio=None), logprobs=None)], provider_specific_fields=None, usage=None)

model_response finish reason 3: None; response_obj={'text': '\nchat', 'is_finished': False, 'finish_reason': None, 'logprobs': None, 'original_chunk': ModelResponseStream(id='chatcmpl-24e35af5-25b0-4416-9f29-279db90a0879', created=1762144783, model=None, object='chat.completion.chunk', system_fingerprint=None, choices=[StreamingChoices(finish_reason=None, index=0, delta=Delta(provider_specific_fields=None, content='\nchat', role=None, function_call=None, tool_calls=None, audio=None), logprobs=None)], provider_specific_fields=None, usage=None), 'usage': None}
original delta: {'provider_specific_fields': None, 'content': '\nchat', 'role': None, 'function_call': None, 'tool_calls': None, 'audio': None}
new delta: Delta(provider_specific_fields=None, content='\nchat', role=None, function_call=None, tool_calls=None, audio=None)
model_response.choices[0].delta: Delta(provider_specific_fields=None, content='\nchat', role=None, function_call=None, tool_calls=None, audio=None); completion_obj: {'content': '\nchat'}
self.sent_first_chunk: True
completion_obj: {'content': '\nchat'}, model_response.choices[0]: StreamingChoices(finish_reason=None, index=0, delta=Delta(provider_specific_fields=None, content='\nchat', role=None, function_call=None, tool_calls=None, audio=None), logprobs=None), response_obj: {'text': '\nchat', 'is_finished': False, 'finish_reason': None, 'logprobs': None, 'original_chunk': ModelResponseStream(id='chatcmpl-24e35af5-25b0-4416-9f29-279db90a0879', created=1762144783, model=None, object='chat.completion.chunk', system_fingerprint=None, choices=[StreamingChoices(finish_reason=None, index=0, delta=Delta(provider_specific_fields=None, content='\nchat', role=None, function_call=None, tool_calls=None, audio=None), logprobs=None)], provider_specific_fields=None, usage=None), 'usage': None}
choice_json: {'index': 0, 'delta': {'provider_specific_fields': None, 'content': '\nchat', 'role': None, 'function_call': None, 'tool_calls': None, 'audio': None}, 'logprobs': None}
choices in streaming: [StreamingChoices(finish_reason=None, index=0, delta=Delta(provider_specific_fields=None, content='\nchat', role=None, function_call=None, tool_calls=None, audio=None), logprobs=None)]
final returned processed chunk: ModelResponseStream(id='chatcmpl-24e35af5-25b0-4416-9f29-279db90a0879', created=1762144783, model='claude-sonnet-4-5-20250929', object='chat.completion.chunk', system_fingerprint=None, choices=[StreamingChoices(finish_reason=None, index=0, delta=Delta(provider_specific_fields=None, content='\nchat', role=None, function_call=None, tool_calls=None, audio=None), logprobs=None)], provider_specific_fields=None, citations=None)
model_response finish reason 3: None; response_obj={'text': '', 'is_finished': False, 'finish_reason': '', 'usage': None, 'index': 0, 'tool_use': None}
model_response.choices[0].delta: Delta(provider_specific_fields=None, content=None, role=None, function_call=None, tool_calls=None, audio=None); completion_obj: {'content': ''}
self.sent_first_chunk: True
completion_obj: {'content': ''}, model_response.choices[0]: StreamingChoices(finish_reason=None, index=0, delta=Delta(provider_specific_fields=None, content=None, role=None, function_call=None, tool_calls=None, audio=None), logprobs=None), response_obj: {'text': '', 'is_finished': False, 'finish_reason': '', 'usage': None, 'index': 0, 'tool_use': None}
model_response finish reason 3: None; response_obj={'text': '', 'is_finished': False, 'finish_reason': '', 'usage': None, 'index': 0, 'tool_use': None}
model_response.choices[0].delta: Delta(provider_specific_fields=None, content=None, role=None, function_call=None, tool_calls=None, audio=None); completion_obj: {'content': ''}
self.sent_first_chunk: True
completion_obj: {'content': ''}, model_response.choices[0]: StreamingChoices(finish_reason=None, index=0, delta=Delta(provider_specific_fields=None, content=None, role=None, function_call=None, tool_calls=None, audio=None), logprobs=None), response_obj: {'text': '', 'is_finished': False, 'finish_reason': '', 'usage': None, 'index': 0, 'tool_use': None}

Raw OpenAI Chunk
ModelResponseStream(id='chatcmpl-24e35af5-25b0-4416-9f29-279db90a0879', created=1762144783, model=None, object='chat.completion.chunk', system_fingerprint=None, choices=[StreamingChoices(finish_reason=None, index=0, delta=Delta(provider_specific_fields=None, content=' history\nmessage', role=None, function_call=None, tool_calls=None, audio=None), logprobs=None)], provider_specific_fields=None, usage=None)

model_response finish reason 3: None; response_obj={'text': ' history\nmessage', 'is_finished': False, 'finish_reason': None, 'logprobs': None, 'original_chunk': ModelResponseStream(id='chatcmpl-24e35af5-25b0-4416-9f29-279db90a0879', created=1762144783, model=None, object='chat.completion.chunk', system_fingerprint=None, choices=[StreamingChoices(finish_reason=None, index=0, delta=Delta(provider_specific_fields=None, content=' history\nmessage', role=None, function_call=None, tool_calls=None, audio=None), logprobs=None)], provider_specific_fields=None, usage=None), 'usage': None}
original delta: {'provider_specific_fields': None, 'content': ' history\nmessage', 'role': None, 'function_call': None, 'tool_calls': None, 'audio': None}
new delta: Delta(provider_specific_fields=None, content=' history\nmessage', role=None, function_call=None, tool_calls=None, audio=None)
model_response.choices[0].delta: Delta(provider_specific_fields=None, content=' history\nmessage', role=None, function_call=None, tool_calls=None, audio=None); completion_obj: {'content': ' history\nmessage'}
self.sent_first_chunk: True
completion_obj: {'content': ' history\nmessage'}, model_response.choices[0]: StreamingChoices(finish_reason=None, index=0, delta=Delta(provider_specific_fields=None, content=' history\nmessage', role=None, function_call=None, tool_calls=None, audio=None), logprobs=None), response_obj: {'text': ' history\nmessage', 'is_finished': False, 'finish_reason': None, 'logprobs': None, 'original_chunk': ModelResponseStream(id='chatcmpl-24e35af5-25b0-4416-9f29-279db90a0879', created=1762144783, model=None, object='chat.completion.chunk', system_fingerprint=None, choices=[StreamingChoices(finish_reason=None, index=0, delta=Delta(provider_specific_fields=None, content=' history\nmessage', role=None, function_call=None, tool_calls=None, audio=None), logprobs=None)], provider_specific_fields=None, usage=None), 'usage': None}
choice_json: {'index': 0, 'delta': {'provider_specific_fields': None, 'content': ' history\nmessage', 'role': None, 'function_call': None, 'tool_calls': None, 'audio': None}, 'logprobs': None}
choices in streaming: [StreamingChoices(finish_reason=None, index=0, delta=Delta(provider_specific_fields=None, content=' history\nmessage', role=None, function_call=None, tool_calls=None, audio=None), logprobs=None)]
final returned processed chunk: ModelResponseStream(id='chatcmpl-24e35af5-25b0-4416-9f29-279db90a0879', created=1762144783, model='claude-sonnet-4-5-20250929', object='chat.completion.chunk', system_fingerprint=None, choices=[StreamingChoices(finish_reason=None, index=0, delta=Delta(provider_specific_fields=None, content=' history\nmessage', role=None, function_call=None, tool_calls=None, audio=None), logprobs=None)], provider_specific_fields=None, citations=None)
model_response finish reason 3: None; response_obj={'text': '', 'is_finished': False, 'finish_reason': '', 'usage': None, 'index': 0, 'tool_use': None}
model_response.choices[0].delta: Delta(provider_specific_fields=None, content=None, role=None, function_call=None, tool_calls=None, audio=None); completion_obj: {'content': ''}
self.sent_first_chunk: True
completion_obj: {'content': ''}, model_response.choices[0]: StreamingChoices(finish_reason=None, index=0, delta=Delta(provider_specific_fields=None, content=None, role=None, function_call=None, tool_calls=None, audio=None), logprobs=None), response_obj: {'text': '', 'is_finished': False, 'finish_reason': '', 'usage': None, 'index': 0, 'tool_use': None}
model_response finish reason 3: None; response_obj={'text': '', 'is_finished': False, 'finish_reason': '', 'usage': None, 'index': 0, 'tool_use': None}
model_response.choices[0].delta: Delta(provider_specific_fields=None, content=None, role=None, function_call=None, tool_calls=None, audio=None); completion_obj: {'content': ''}
self.sent_first_chunk: True
completion_obj: {'content': ''}, model_response.choices[0]: StreamingChoices(finish_reason=None, index=0, delta=Delta(provider_specific_fields=None, content=None, role=None, function_call=None, tool_calls=None, audio=None), logprobs=None), response_obj: {'text': '', 'is_finished': False, 'finish_reason': '', 'usage': None, 'index': 0, 'tool_use': None}

Raw OpenAI Chunk
ModelResponseStream(id='chatcmpl-24e35af5-25b0-4416-9f29-279db90a0879', created=1762144783, model=None, object='chat.completion.chunk', system_fingerprint=None, choices=[StreamingChoices(finish_reason=None, index=0, delta=Delta(provider_specific_fields=None, content=' history\nuser', role=None, function_call=None, tool_calls=None, audio=None), logprobs=None)], provider_specific_fields=None, usage=None)

model_response finish reason 3: None; response_obj={'text': ' history\nuser', 'is_finished': False, 'finish_reason': None, 'logprobs': None, 'original_chunk': ModelResponseStream(id='chatcmpl-24e35af5-25b0-4416-9f29-279db90a0879', created=1762144783, model=None, object='chat.completion.chunk', system_fingerprint=None, choices=[StreamingChoices(finish_reason=None, index=0, delta=Delta(provider_specific_fields=None, content=' history\nuser', role=None, function_call=None, tool_calls=None, audio=None), logprobs=None)], provider_specific_fields=None, usage=None), 'usage': None}
original delta: {'provider_specific_fields': None, 'content': ' history\nuser', 'role': None, 'function_call': None, 'tool_calls': None, 'audio': None}
new delta: Delta(provider_specific_fields=None, content=' history\nuser', role=None, function_call=None, tool_calls=None, audio=None)
model_response.choices[0].delta: Delta(provider_specific_fields=None, content=' history\nuser', role=None, function_call=None, tool_calls=None, audio=None); completion_obj: {'content': ' history\nuser'}
self.sent_first_chunk: True
completion_obj: {'content': ' history\nuser'}, model_response.choices[0]: StreamingChoices(finish_reason=None, index=0, delta=Delta(provider_specific_fields=None, content=' history\nuser', role=None, function_call=None, tool_calls=None, audio=None), logprobs=None), response_obj: {'text': ' history\nuser', 'is_finished': False, 'finish_reason': None, 'logprobs': None, 'original_chunk': ModelResponseStream(id='chatcmpl-24e35af5-25b0-4416-9f29-279db90a0879', created=1762144783, model=None, object='chat.completion.chunk', system_fingerprint=None, choices=[StreamingChoices(finish_reason=None, index=0, delta=Delta(provider_specific_fields=None, content=' history\nuser', role=None, function_call=None, tool_calls=None, audio=None), logprobs=None)], provider_specific_fields=None, usage=None), 'usage': None}
choice_json: {'index': 0, 'delta': {'provider_specific_fields': None, 'content': ' history\nuser', 'role': None, 'function_call': None, 'tool_calls': None, 'audio': None}, 'logprobs': None}
choices in streaming: [StreamingChoices(finish_reason=None, index=0, delta=Delta(provider_specific_fields=None, content=' history\nuser', role=None, function_call=None, tool_calls=None, audio=None), logprobs=None)]
final returned processed chunk: ModelResponseStream(id='chatcmpl-24e35af5-25b0-4416-9f29-279db90a0879', created=1762144783, model='claude-sonnet-4-5-20250929', object='chat.completion.chunk', system_fingerprint=None, choices=[StreamingChoices(finish_reason=None, index=0, delta=Delta(provider_specific_fields=None, content=' history\nuser', role=None, function_call=None, tool_calls=None, audio=None), logprobs=None)], provider_specific_fields=None, citations=None)
model_response finish reason 3: None; response_obj={'text': '', 'is_finished': False, 'finish_reason': '', 'usage': None, 'index': 0, 'tool_use': None}
model_response.choices[0].delta: Delta(provider_specific_fields=None, content=None, role=None, function_call=None, tool_calls=None, audio=None); completion_obj: {'content': ''}
self.sent_first_chunk: True
completion_obj: {'content': ''}, model_response.choices[0]: StreamingChoices(finish_reason=None, index=0, delta=Delta(provider_specific_fields=None, content=None, role=None, function_call=None, tool_calls=None, audio=None), logprobs=None), response_obj: {'text': '', 'is_finished': False, 'finish_reason': '', 'usage': None, 'index': 0, 'tool_use': None}
model_response finish reason 3: None; response_obj={'text': '', 'is_finished': False, 'finish_reason': '', 'usage': None, 'index': 0, 'tool_use': None}
model_response.choices[0].delta: Delta(provider_specific_fields=None, content=None, role=None, function_call=None, tool_calls=None, audio=None); completion_obj: {'content': ''}
self.sent_first_chunk: True
completion_obj: {'content': ''}, model_response.choices[0]: StreamingChoices(finish_reason=None, index=0, delta=Delta(provider_specific_fields=None, content=None, role=None, function_call=None, tool_calls=None, audio=None), logprobs=None), response_obj: {'text': '', 'is_finished': False, 'finish_reason': '', 'usage': None, 'index': 0, 'tool_use': None}

Raw OpenAI Chunk
ModelResponseStream(id='chatcmpl-24e35af5-25b0-4416-9f29-279db90a0879', created=1762144783, model=None, object='chat.completion.chunk', system_fingerprint=None, choices=[StreamingChoices(finish_reason=None, index=0, delta=Delta(provider_specific_fields=None, content=' conversations', role=None, function_call=None, tool_calls=None, audio=None), logprobs=None)], provider_specific_fields=None, usage=None)

model_response finish reason 3: None; response_obj={'text': ' conversations', 'is_finished': False, 'finish_reason': None, 'logprobs': None, 'original_chunk': ModelResponseStream(id='chatcmpl-24e35af5-25b0-4416-9f29-279db90a0879', created=1762144783, model=None, object='chat.completion.chunk', system_fingerprint=None, choices=[StreamingChoices(finish_reason=None, index=0, delta=Delta(provider_specific_fields=None, content=' conversations', role=None, function_call=None, tool_calls=None, audio=None), logprobs=None)], provider_specific_fields=None, usage=None), 'usage': None}
original delta: {'provider_specific_fields': None, 'content': ' conversations', 'role': None, 'function_call': None, 'tool_calls': None, 'audio': None}
new delta: Delta(provider_specific_fields=None, content=' conversations', role=None, function_call=None, tool_calls=None, audio=None)
model_response.choices[0].delta: Delta(provider_specific_fields=None, content=' conversations', role=None, function_call=None, tool_calls=None, audio=None); completion_obj: {'content': ' conversations'}
self.sent_first_chunk: True
completion_obj: {'content': ' conversations'}, model_response.choices[0]: StreamingChoices(finish_reason=None, index=0, delta=Delta(provider_specific_fields=None, content=' conversations', role=None, function_call=None, tool_calls=None, audio=None), logprobs=None), response_obj: {'text': ' conversations', 'is_finished': False, 'finish_reason': None, 'logprobs': None, 'original_chunk': ModelResponseStream(id='chatcmpl-24e35af5-25b0-4416-9f29-279db90a0879', created=1762144783, model=None, object='chat.completion.chunk', system_fingerprint=None, choices=[StreamingChoices(finish_reason=None, index=0, delta=Delta(provider_specific_fields=None, content=' conversations', role=None, function_call=None, tool_calls=None, audio=None), logprobs=None)], provider_specific_fields=None, usage=None), 'usage': None}
choice_json: {'index': 0, 'delta': {'provider_specific_fields': None, 'content': ' conversations', 'role': None, 'function_call': None, 'tool_calls': None, 'audio': None}, 'logprobs': None}
choices in streaming: [StreamingChoices(finish_reason=None, index=0, delta=Delta(provider_specific_fields=None, content=' conversations', role=None, function_call=None, tool_calls=None, audio=None), logprobs=None)]
final returned processed chunk: ModelResponseStream(id='chatcmpl-24e35af5-25b0-4416-9f29-279db90a0879', created=1762144783, model='claude-sonnet-4-5-20250929', object='chat.completion.chunk', system_fingerprint=None, choices=[StreamingChoices(finish_reason=None, index=0, delta=Delta(provider_specific_fields=None, content=' conversations', role=None, function_call=None, tool_calls=None, audio=None), logprobs=None)], provider_specific_fields=None, citations=None)
model_response finish reason 3: None; response_obj={'text': '', 'is_finished': False, 'finish_reason': '', 'usage': None, 'index': 0, 'tool_use': None}
model_response.choices[0].delta: Delta(provider_specific_fields=None, content=None, role=None, function_call=None, tool_calls=None, audio=None); completion_obj: {'content': ''}
self.sent_first_chunk: True
completion_obj: {'content': ''}, model_response.choices[0]: StreamingChoices(finish_reason=None, index=0, delta=Delta(provider_specific_fields=None, content=None, role=None, function_call=None, tool_calls=None, audio=None), logprobs=None), response_obj: {'text': '', 'is_finished': False, 'finish_reason': '', 'usage': None, 'index': 0, 'tool_use': None}
model_response finish reason 3: None; response_obj={'text': '', 'is_finished': False, 'finish_reason': '', 'usage': None, 'index': 0, 'tool_use': None}
model_response.choices[0].delta: Delta(provider_specific_fields=None, content=None, role=None, function_call=None, tool_calls=None, audio=None); completion_obj: {'content': ''}
self.sent_first_chunk: True
completion_obj: {'content': ''}, model_response.choices[0]: StreamingChoices(finish_reason=None, index=0, delta=Delta(provider_specific_fields=None, content=None, role=None, function_call=None, tool_calls=None, audio=None), logprobs=None), response_obj: {'text': '', 'is_finished': False, 'finish_reason': '', 'usage': None, 'index': 0, 'tool_use': None}

Raw OpenAI Chunk
ModelResponseStream(id='chatcmpl-24e35af5-25b0-4416-9f29-279db90a0879', created=1762144783, model=None, object='chat.completion.chunk', system_fingerprint=None, choices=[StreamingChoices(finish_reason=None, index=0, delta=Delta(provider_specific_fields=None, content='\nconversation repository', role=None, function_call=None, tool_calls=None, audio=None), logprobs=None)], provider_specific_fields=None, usage=None)

model_response finish reason 3: None; response_obj={'text': '\nconversation repository', 'is_finished': False, 'finish_reason': None, 'logprobs': None, 'original_chunk': ModelResponseStream(id='chatcmpl-24e35af5-25b0-4416-9f29-279db90a0879', created=1762144783, model=None, object='chat.completion.chunk', system_fingerprint=None, choices=[StreamingChoices(finish_reason=None, index=0, delta=Delta(provider_specific_fields=None, content='\nconversation repository', role=None, function_call=None, tool_calls=None, audio=None), logprobs=None)], provider_specific_fields=None, usage=None), 'usage': None}
original delta: {'provider_specific_fields': None, 'content': '\nconversation repository', 'role': None, 'function_call': None, 'tool_calls': None, 'audio': None}
new delta: Delta(provider_specific_fields=None, content='\nconversation repository', role=None, function_call=None, tool_calls=None, audio=None)
model_response.choices[0].delta: Delta(provider_specific_fields=None, content='\nconversation repository', role=None, function_call=None, tool_calls=None, audio=None); completion_obj: {'content': '\nconversation repository'}
self.sent_first_chunk: True
completion_obj: {'content': '\nconversation repository'}, model_response.choices[0]: StreamingChoices(finish_reason=None, index=0, delta=Delta(provider_specific_fields=None, content='\nconversation repository', role=None, function_call=None, tool_calls=None, audio=None), logprobs=None), response_obj: {'text': '\nconversation repository', 'is_finished': False, 'finish_reason': None, 'logprobs': None, 'original_chunk': ModelResponseStream(id='chatcmpl-24e35af5-25b0-4416-9f29-279db90a0879', created=1762144783, model=None, object='chat.completion.chunk', system_fingerprint=None, choices=[StreamingChoices(finish_reason=None, index=0, delta=Delta(provider_specific_fields=None, content='\nconversation repository', role=None, function_call=None, tool_calls=None, audio=None), logprobs=None)], provider_specific_fields=None, usage=None), 'usage': None}
choice_json: {'index': 0, 'delta': {'provider_specific_fields': None, 'content': '\nconversation repository', 'role': None, 'function_call': None, 'tool_calls': None, 'audio': None}, 'logprobs': None}
choices in streaming: [StreamingChoices(finish_reason=None, index=0, delta=Delta(provider_specific_fields=None, content='\nconversation repository', role=None, function_call=None, tool_calls=None, audio=None), logprobs=None)]
final returned processed chunk: ModelResponseStream(id='chatcmpl-24e35af5-25b0-4416-9f29-279db90a0879', created=1762144783, model='claude-sonnet-4-5-20250929', object='chat.completion.chunk', system_fingerprint=None, choices=[StreamingChoices(finish_reason=None, index=0, delta=Delta(provider_specific_fields=None, content='\nconversation repository', role=None, function_call=None, tool_calls=None, audio=None), logprobs=None)], provider_specific_fields=None, citations=None)
model_response finish reason 3: None; response_obj={'text': '', 'is_finished': False, 'finish_reason': '', 'usage': None, 'index': 0, 'tool_use': None}
model_response.choices[0].delta: Delta(provider_specific_fields=None, content=None, role=None, function_call=None, tool_calls=None, audio=None); completion_obj: {'content': ''}
self.sent_first_chunk: True
completion_obj: {'content': ''}, model_response.choices[0]: StreamingChoices(finish_reason=None, index=0, delta=Delta(provider_specific_fields=None, content=None, role=None, function_call=None, tool_calls=None, audio=None), logprobs=None), response_obj: {'text': '', 'is_finished': False, 'finish_reason': '', 'usage': None, 'index': 0, 'tool_use': None}
model_response finish reason 3: None; response_obj={'text': '', 'is_finished': False, 'finish_reason': '', 'usage': None, 'index': 0, 'tool_use': None}
model_response.choices[0].delta: Delta(provider_specific_fields=None, content=None, role=None, function_call=None, tool_calls=None, audio=None); completion_obj: {'content': ''}
self.sent_first_chunk: True
completion_obj: {'content': ''}, model_response.choices[0]: StreamingChoices(finish_reason=None, index=0, delta=Delta(provider_specific_fields=None, content=None, role=None, function_call=None, tool_calls=None, audio=None), logprobs=None), response_obj: {'text': '', 'is_finished': False, 'finish_reason': '', 'usage': None, 'index': 0, 'tool_use': None}

Raw OpenAI Chunk
ModelResponseStream(id='chatcmpl-24e35af5-25b0-4416-9f29-279db90a0879', created=1762144784, model=None, object='chat.completion.chunk', system_fingerprint=None, choices=[StreamingChoices(finish_reason=None, index=0, delta=Delta(provider_specific_fields=None, content='\nconversation service', role=None, function_call=None, tool_calls=None, audio=None), logprobs=None)], provider_specific_fields=None, usage=None)

model_response finish reason 3: None; response_obj={'text': '\nconversation service', 'is_finished': False, 'finish_reason': None, 'logprobs': None, 'original_chunk': ModelResponseStream(id='chatcmpl-24e35af5-25b0-4416-9f29-279db90a0879', created=1762144784, model=None, object='chat.completion.chunk', system_fingerprint=None, choices=[StreamingChoices(finish_reason=None, index=0, delta=Delta(provider_specific_fields=None, content='\nconversation service', role=None, function_call=None, tool_calls=None, audio=None), logprobs=None)], provider_specific_fields=None, usage=None), 'usage': None}
original delta: {'provider_specific_fields': None, 'content': '\nconversation service', 'role': None, 'function_call': None, 'tool_calls': None, 'audio': None}
new delta: Delta(provider_specific_fields=None, content='\nconversation service', role=None, function_call=None, tool_calls=None, audio=None)
model_response.choices[0].delta: Delta(provider_specific_fields=None, content='\nconversation service', role=None, function_call=None, tool_calls=None, audio=None); completion_obj: {'content': '\nconversation service'}
self.sent_first_chunk: True
completion_obj: {'content': '\nconversation service'}, model_response.choices[0]: StreamingChoices(finish_reason=None, index=0, delta=Delta(provider_specific_fields=None, content='\nconversation service', role=None, function_call=None, tool_calls=None, audio=None), logprobs=None), response_obj: {'text': '\nconversation service', 'is_finished': False, 'finish_reason': None, 'logprobs': None, 'original_chunk': ModelResponseStream(id='chatcmpl-24e35af5-25b0-4416-9f29-279db90a0879', created=1762144784, model=None, object='chat.completion.chunk', system_fingerprint=None, choices=[StreamingChoices(finish_reason=None, index=0, delta=Delta(provider_specific_fields=None, content='\nconversation service', role=None, function_call=None, tool_calls=None, audio=None), logprobs=None)], provider_specific_fields=None, usage=None), 'usage': None}
choice_json: {'index': 0, 'delta': {'provider_specific_fields': None, 'content': '\nconversation service', 'role': None, 'function_call': None, 'tool_calls': None, 'audio': None}, 'logprobs': None}
choices in streaming: [StreamingChoices(finish_reason=None, index=0, delta=Delta(provider_specific_fields=None, content='\nconversation service', role=None, function_call=None, tool_calls=None, audio=None), logprobs=None)]
final returned processed chunk: ModelResponseStream(id='chatcmpl-24e35af5-25b0-4416-9f29-279db90a0879', created=1762144783, model='claude-sonnet-4-5-20250929', object='chat.completion.chunk', system_fingerprint=None, choices=[StreamingChoices(finish_reason=None, index=0, delta=Delta(provider_specific_fields=None, content='\nconversation service', role=None, function_call=None, tool_calls=None, audio=None), logprobs=None)], provider_specific_fields=None, citations=None)
model_response finish reason 3: None; response_obj={'text': '', 'is_finished': False, 'finish_reason': '', 'usage': None, 'index': 0, 'tool_use': None}
model_response.choices[0].delta: Delta(provider_specific_fields=None, content=None, role=None, function_call=None, tool_calls=None, audio=None); completion_obj: {'content': ''}
self.sent_first_chunk: True
completion_obj: {'content': ''}, model_response.choices[0]: StreamingChoices(finish_reason=None, index=0, delta=Delta(provider_specific_fields=None, content=None, role=None, function_call=None, tool_calls=None, audio=None), logprobs=None), response_obj: {'text': '', 'is_finished': False, 'finish_reason': '', 'usage': None, 'index': 0, 'tool_use': None}
model_response finish reason 3: None; response_obj={'text': '', 'is_finished': False, 'finish_reason': '', 'usage': None, 'index': 0, 'tool_use': None}
model_response.choices[0].delta: Delta(provider_specific_fields=None, content=None, role=None, function_call=None, tool_calls=None, audio=None); completion_obj: {'content': ''}
self.sent_first_chunk: True
completion_obj: {'content': ''}, model_response.choices[0]: StreamingChoices(finish_reason=None, index=0, delta=Delta(provider_specific_fields=None, content=None, role=None, function_call=None, tool_calls=None, audio=None), logprobs=None), response_obj: {'text': '', 'is_finished': False, 'finish_reason': '', 'usage': None, 'index': 0, 'tool_use': None}

Raw OpenAI Chunk
ModelResponseStream(id='chatcmpl-24e35af5-25b0-4416-9f29-279db90a0879', created=1762144784, model=None, object='chat.completion.chunk', system_fingerprint=None, choices=[StreamingChoices(finish_reason=None, index=0, delta=Delta(provider_specific_fields=None, content='\nsession', role=None, function_call=None, tool_calls=None, audio=None), logprobs=None)], provider_specific_fields=None, usage=None)

model_response finish reason 3: None; response_obj={'text': '\nsession', 'is_finished': False, 'finish_reason': None, 'logprobs': None, 'original_chunk': ModelResponseStream(id='chatcmpl-24e35af5-25b0-4416-9f29-279db90a0879', created=1762144784, model=None, object='chat.completion.chunk', system_fingerprint=None, choices=[StreamingChoices(finish_reason=None, index=0, delta=Delta(provider_specific_fields=None, content='\nsession', role=None, function_call=None, tool_calls=None, audio=None), logprobs=None)], provider_specific_fields=None, usage=None), 'usage': None}
original delta: {'provider_specific_fields': None, 'content': '\nsession', 'role': None, 'function_call': None, 'tool_calls': None, 'audio': None}
new delta: Delta(provider_specific_fields=None, content='\nsession', role=None, function_call=None, tool_calls=None, audio=None)
model_response.choices[0].delta: Delta(provider_specific_fields=None, content='\nsession', role=None, function_call=None, tool_calls=None, audio=None); completion_obj: {'content': '\nsession'}
self.sent_first_chunk: True
completion_obj: {'content': '\nsession'}, model_response.choices[0]: StreamingChoices(finish_reason=None, index=0, delta=Delta(provider_specific_fields=None, content='\nsession', role=None, function_call=None, tool_calls=None, audio=None), logprobs=None), response_obj: {'text': '\nsession', 'is_finished': False, 'finish_reason': None, 'logprobs': None, 'original_chunk': ModelResponseStream(id='chatcmpl-24e35af5-25b0-4416-9f29-279db90a0879', created=1762144784, model=None, object='chat.completion.chunk', system_fingerprint=None, choices=[StreamingChoices(finish_reason=None, index=0, delta=Delta(provider_specific_fields=None, content='\nsession', role=None, function_call=None, tool_calls=None, audio=None), logprobs=None)], provider_specific_fields=None, usage=None), 'usage': None}
choice_json: {'index': 0, 'delta': {'provider_specific_fields': None, 'content': '\nsession', 'role': None, 'function_call': None, 'tool_calls': None, 'audio': None}, 'logprobs': None}
choices in streaming: [StreamingChoices(finish_reason=None, index=0, delta=Delta(provider_specific_fields=None, content='\nsession', role=None, function_call=None, tool_calls=None, audio=None), logprobs=None)]
final returned processed chunk: ModelResponseStream(id='chatcmpl-24e35af5-25b0-4416-9f29-279db90a0879', created=1762144783, model='claude-sonnet-4-5-20250929', object='chat.completion.chunk', system_fingerprint=None, choices=[StreamingChoices(finish_reason=None, index=0, delta=Delta(provider_specific_fields=None, content='\nsession', role=None, function_call=None, tool_calls=None, audio=None), logprobs=None)], provider_specific_fields=None, citations=None)
model_response finish reason 3: None; response_obj={'text': '', 'is_finished': False, 'finish_reason': '', 'usage': None, 'index': 0, 'tool_use': None}
model_response.choices[0].delta: Delta(provider_specific_fields=None, content=None, role=None, function_call=None, tool_calls=None, audio=None); completion_obj: {'content': ''}
self.sent_first_chunk: True
completion_obj: {'content': ''}, model_response.choices[0]: StreamingChoices(finish_reason=None, index=0, delta=Delta(provider_specific_fields=None, content=None, role=None, function_call=None, tool_calls=None, audio=None), logprobs=None), response_obj: {'text': '', 'is_finished': False, 'finish_reason': '', 'usage': None, 'index': 0, 'tool_use': None}
model_response finish reason 3: None; response_obj={'text': '', 'is_finished': False, 'finish_reason': '', 'usage': None, 'index': 0, 'tool_use': None}
model_response.choices[0].delta: Delta(provider_specific_fields=None, content=None, role=None, function_call=None, tool_calls=None, audio=None); completion_obj: {'content': ''}
self.sent_first_chunk: True
completion_obj: {'content': ''}, model_response.choices[0]: StreamingChoices(finish_reason=None, index=0, delta=Delta(provider_specific_fields=None, content=None, role=None, function_call=None, tool_calls=None, audio=None), logprobs=None), response_obj: {'text': '', 'is_finished': False, 'finish_reason': '', 'usage': None, 'index': 0, 'tool_use': None}

Raw OpenAI Chunk
ModelResponseStream(id='chatcmpl-24e35af5-25b0-4416-9f29-279db90a0879', created=1762144784, model=None, object='chat.completion.chunk', system_fingerprint=None, choices=[StreamingChoices(finish_reason=None, index=0, delta=Delta(provider_specific_fields=None, content=' history\ndialogue', role=None, function_call=None, tool_calls=None, audio=None), logprobs=None)], provider_specific_fields=None, usage=None)

model_response finish reason 3: None; response_obj={'text': ' history\ndialogue', 'is_finished': False, 'finish_reason': None, 'logprobs': None, 'original_chunk': ModelResponseStream(id='chatcmpl-24e35af5-25b0-4416-9f29-279db90a0879', created=1762144784, model=None, object='chat.completion.chunk', system_fingerprint=None, choices=[StreamingChoices(finish_reason=None, index=0, delta=Delta(provider_specific_fields=None, content=' history\ndialogue', role=None, function_call=None, tool_calls=None, audio=None), logprobs=None)], provider_specific_fields=None, usage=None), 'usage': None}
original delta: {'provider_specific_fields': None, 'content': ' history\ndialogue', 'role': None, 'function_call': None, 'tool_calls': None, 'audio': None}
new delta: Delta(provider_specific_fields=None, content=' history\ndialogue', role=None, function_call=None, tool_calls=None, audio=None)
model_response.choices[0].delta: Delta(provider_specific_fields=None, content=' history\ndialogue', role=None, function_call=None, tool_calls=None, audio=None); completion_obj: {'content': ' history\ndialogue'}
self.sent_first_chunk: True
completion_obj: {'content': ' history\ndialogue'}, model_response.choices[0]: StreamingChoices(finish_reason=None, index=0, delta=Delta(provider_specific_fields=None, content=' history\ndialogue', role=None, function_call=None, tool_calls=None, audio=None), logprobs=None), response_obj: {'text': ' history\ndialogue', 'is_finished': False, 'finish_reason': None, 'logprobs': None, 'original_chunk': ModelResponseStream(id='chatcmpl-24e35af5-25b0-4416-9f29-279db90a0879', created=1762144784, model=None, object='chat.completion.chunk', system_fingerprint=None, choices=[StreamingChoices(finish_reason=None, index=0, delta=Delta(provider_specific_fields=None, content=' history\ndialogue', role=None, function_call=None, tool_calls=None, audio=None), logprobs=None)], provider_specific_fields=None, usage=None), 'usage': None}
choice_json: {'index': 0, 'delta': {'provider_specific_fields': None, 'content': ' history\ndialogue', 'role': None, 'function_call': None, 'tool_calls': None, 'audio': None}, 'logprobs': None}
choices in streaming: [StreamingChoices(finish_reason=None, index=0, delta=Delta(provider_specific_fields=None, content=' history\ndialogue', role=None, function_call=None, tool_calls=None, audio=None), logprobs=None)]
final returned processed chunk: ModelResponseStream(id='chatcmpl-24e35af5-25b0-4416-9f29-279db90a0879', created=1762144783, model='claude-sonnet-4-5-20250929', object='chat.completion.chunk', system_fingerprint=None, choices=[StreamingChoices(finish_reason=None, index=0, delta=Delta(provider_specific_fields=None, content=' history\ndialogue', role=None, function_call=None, tool_calls=None, audio=None), logprobs=None)], provider_specific_fields=None, citations=None)
model_response finish reason 3: None; response_obj={'text': '', 'is_finished': False, 'finish_reason': '', 'usage': None, 'index': 0, 'tool_use': None}
model_response.choices[0].delta: Delta(provider_specific_fields=None, content=None, role=None, function_call=None, tool_calls=None, audio=None); completion_obj: {'content': ''}
self.sent_first_chunk: True
completion_obj: {'content': ''}, model_response.choices[0]: StreamingChoices(finish_reason=None, index=0, delta=Delta(provider_specific_fields=None, content=None, role=None, function_call=None, tool_calls=None, audio=None), logprobs=None), response_obj: {'text': '', 'is_finished': False, 'finish_reason': '', 'usage': None, 'index': 0, 'tool_use': None}
model_response finish reason 3: None; response_obj={'text': '', 'is_finished': False, 'finish_reason': '', 'usage': None, 'index': 0, 'tool_use': None}
model_response.choices[0].delta: Delta(provider_specific_fields=None, content=None, role=None, function_call=None, tool_calls=None, audio=None); completion_obj: {'content': ''}
self.sent_first_chunk: True
completion_obj: {'content': ''}, model_response.choices[0]: StreamingChoices(finish_reason=None, index=0, delta=Delta(provider_specific_fields=None, content=None, role=None, function_call=None, tool_calls=None, audio=None), logprobs=None), response_obj: {'text': '', 'is_finished': False, 'finish_reason': '', 'usage': None, 'index': 0, 'tool_use': None}

Raw OpenAI Chunk
ModelResponseStream(id='chatcmpl-24e35af5-25b0-4416-9f29-279db90a0879', created=1762144784, model=None, object='chat.completion.chunk', system_fingerprint=None, choices=[StreamingChoices(finish_reason=None, index=0, delta=Delta(provider_specific_fields=None, content=' history', role=None, function_call=None, tool_calls=None, audio=None), logprobs=None)], provider_specific_fields=None, usage=None)

model_response finish reason 3: None; response_obj={'text': ' history', 'is_finished': False, 'finish_reason': None, 'logprobs': None, 'original_chunk': ModelResponseStream(id='chatcmpl-24e35af5-25b0-4416-9f29-279db90a0879', created=1762144784, model=None, object='chat.completion.chunk', system_fingerprint=None, choices=[StreamingChoices(finish_reason=None, index=0, delta=Delta(provider_specific_fields=None, content=' history', role=None, function_call=None, tool_calls=None, audio=None), logprobs=None)], provider_specific_fields=None, usage=None), 'usage': None}
original delta: {'provider_specific_fields': None, 'content': ' history', 'role': None, 'function_call': None, 'tool_calls': None, 'audio': None}
new delta: Delta(provider_specific_fields=None, content=' history', role=None, function_call=None, tool_calls=None, audio=None)
model_response.choices[0].delta: Delta(provider_specific_fields=None, content=' history', role=None, function_call=None, tool_calls=None, audio=None); completion_obj: {'content': ' history'}
self.sent_first_chunk: True
completion_obj: {'content': ' history'}, model_response.choices[0]: StreamingChoices(finish_reason=None, index=0, delta=Delta(provider_specific_fields=None, content=' history', role=None, function_call=None, tool_calls=None, audio=None), logprobs=None), response_obj: {'text': ' history', 'is_finished': False, 'finish_reason': None, 'logprobs': None, 'original_chunk': ModelResponseStream(id='chatcmpl-24e35af5-25b0-4416-9f29-279db90a0879', created=1762144784, model=None, object='chat.completion.chunk', system_fingerprint=None, choices=[StreamingChoices(finish_reason=None, index=0, delta=Delta(provider_specific_fields=None, content=' history', role=None, function_call=None, tool_calls=None, audio=None), logprobs=None)], provider_specific_fields=None, usage=None), 'usage': None}
choice_json: {'index': 0, 'delta': {'provider_specific_fields': None, 'content': ' history', 'role': None, 'function_call': None, 'tool_calls': None, 'audio': None}, 'logprobs': None}
choices in streaming: [StreamingChoices(finish_reason=None, index=0, delta=Delta(provider_specific_fields=None, content=' history', role=None, function_call=None, tool_calls=None, audio=None), logprobs=None)]
final returned processed chunk: ModelResponseStream(id='chatcmpl-24e35af5-25b0-4416-9f29-279db90a0879', created=1762144783, model='claude-sonnet-4-5-20250929', object='chat.completion.chunk', system_fingerprint=None, choices=[StreamingChoices(finish_reason=None, index=0, delta=Delta(provider_specific_fields=None, content=' history', role=None, function_call=None, tool_calls=None, audio=None), logprobs=None)], provider_specific_fields=None, citations=None)
model_response finish reason 3: None; response_obj={'text': '', 'is_finished': False, 'finish_reason': '', 'usage': None, 'index': 0, 'tool_use': None}
model_response.choices[0].delta: Delta(provider_specific_fields=None, content=None, role=None, function_call=None, tool_calls=None, audio=None); completion_obj: {'content': ''}
self.sent_first_chunk: True
completion_obj: {'content': ''}, model_response.choices[0]: StreamingChoices(finish_reason=None, index=0, delta=Delta(provider_specific_fields=None, content=None, role=None, function_call=None, tool_calls=None, audio=None), logprobs=None), response_obj: {'text': '', 'is_finished': False, 'finish_reason': '', 'usage': None, 'index': 0, 'tool_use': None}
model_response finish reason 3: None; response_obj={'text': '', 'is_finished': False, 'finish_reason': '', 'usage': None, 'index': 0, 'tool_use': None}
model_response.choices[0].delta: Delta(provider_specific_fields=None, content=None, role=None, function_call=None, tool_calls=None, audio=None); completion_obj: {'content': ''}
self.sent_first_chunk: True
completion_obj: {'content': ''}, model_response.choices[0]: StreamingChoices(finish_reason=None, index=0, delta=Delta(provider_specific_fields=None, content=None, role=None, function_call=None, tool_calls=None, audio=None), logprobs=None), response_obj: {'text': '', 'is_finished': False, 'finish_reason': '', 'usage': None, 'index': 0, 'tool_use': None}

Raw OpenAI Chunk
ModelResponseStream(id='chatcmpl-24e35af5-25b0-4416-9f29-279db90a0879', created=1762144784, model=None, object='chat.completion.chunk', system_fingerprint=None, choices=[StreamingChoices(finish_reason=None, index=0, delta=Delta(provider_specific_fields=None, content='', role=None, function_call=None, tool_calls=None, audio=None), logprobs=None)], provider_specific_fields=None, usage=None)

model_response finish reason 3: None; response_obj={'text': '', 'is_finished': False, 'finish_reason': None, 'logprobs': None, 'original_chunk': ModelResponseStream(id='chatcmpl-24e35af5-25b0-4416-9f29-279db90a0879', created=1762144784, model=None, object='chat.completion.chunk', system_fingerprint=None, choices=[StreamingChoices(finish_reason=None, index=0, delta=Delta(provider_specific_fields=None, content='', role=None, function_call=None, tool_calls=None, audio=None), logprobs=None)], provider_specific_fields=None, usage=None), 'usage': None}
original delta: {'provider_specific_fields': None, 'content': '', 'role': None, 'function_call': None, 'tool_calls': None, 'audio': None}
new delta: Delta(provider_specific_fields=None, content='', role=None, function_call=None, tool_calls=None, audio=None)
model_response.choices[0].delta: Delta(provider_specific_fields=None, content='', role=None, function_call=None, tool_calls=None, audio=None); completion_obj: {'content': ''}
self.sent_first_chunk: True
completion_obj: {'content': ''}, model_response.choices[0]: StreamingChoices(finish_reason=None, index=0, delta=Delta(provider_specific_fields=None, content='', role=None, function_call=None, tool_calls=None, audio=None), logprobs=None), response_obj: {'text': '', 'is_finished': False, 'finish_reason': None, 'logprobs': None, 'original_chunk': ModelResponseStream(id='chatcmpl-24e35af5-25b0-4416-9f29-279db90a0879', created=1762144784, model=None, object='chat.completion.chunk', system_fingerprint=None, choices=[StreamingChoices(finish_reason=None, index=0, delta=Delta(provider_specific_fields=None, content='', role=None, function_call=None, tool_calls=None, audio=None), logprobs=None)], provider_specific_fields=None, usage=None), 'usage': None}
model_response finish reason 3: None; response_obj={'text': '', 'is_finished': False, 'finish_reason': '', 'usage': None, 'index': 0, 'tool_use': None}
model_response.choices[0].delta: Delta(provider_specific_fields=None, content=None, role=None, function_call=None, tool_calls=None, audio=None); completion_obj: {'content': ''}
self.sent_first_chunk: True
completion_obj: {'content': ''}, model_response.choices[0]: StreamingChoices(finish_reason=None, index=0, delta=Delta(provider_specific_fields=None, content=None, role=None, function_call=None, tool_calls=None, audio=None), logprobs=None), response_obj: {'text': '', 'is_finished': False, 'finish_reason': '', 'usage': None, 'index': 0, 'tool_use': None}
model_response finish reason 3: None; response_obj={'text': '', 'is_finished': False, 'finish_reason': '', 'usage': None, 'index': 0, 'tool_use': None}
model_response.choices[0].delta: Delta(provider_specific_fields=None, content=None, role=None, function_call=None, tool_calls=None, audio=None); completion_obj: {'content': ''}
self.sent_first_chunk: True
completion_obj: {'content': ''}, model_response.choices[0]: StreamingChoices(finish_reason=None, index=0, delta=Delta(provider_specific_fields=None, content=None, role=None, function_call=None, tool_calls=None, audio=None), logprobs=None), response_obj: {'text': '', 'is_finished': False, 'finish_reason': '', 'usage': None, 'index': 0, 'tool_use': None}

Raw OpenAI Chunk
ModelResponseStream(id='chatcmpl-24e35af5-25b0-4416-9f29-279db90a0879', created=1762144784, model=None, object='chat.completion.chunk', system_fingerprint=None, choices=[StreamingChoices(finish_reason='stop', index=0, delta=Delta(provider_specific_fields=None, content='', role=None, function_call=None, tool_calls=None, audio=None), logprobs=None)], provider_specific_fields=None, usage=Usage(completion_tokens=35, prompt_tokens=204, total_tokens=239, completion_tokens_details=None, prompt_tokens_details=PromptTokensDetailsWrapper(audio_tokens=None, cached_tokens=0, text_tokens=None, image_tokens=None, cache_creation_tokens=0), cache_creation_input_tokens=0, cache_read_input_tokens=0))

model_response finish reason 3: stop; response_obj={'text': '', 'is_finished': True, 'finish_reason': 'stop', 'logprobs': None, 'original_chunk': ModelResponseStream(id='chatcmpl-24e35af5-25b0-4416-9f29-279db90a0879', created=1762144784, model=None, object='chat.completion.chunk', system_fingerprint=None, choices=[StreamingChoices(finish_reason='stop', index=0, delta=Delta(provider_specific_fields=None, content='', role=None, function_call=None, tool_calls=None, audio=None), logprobs=None)], provider_specific_fields=None, usage=Usage(completion_tokens=35, prompt_tokens=204, total_tokens=239, completion_tokens_details=None, prompt_tokens_details=PromptTokensDetailsWrapper(audio_tokens=None, cached_tokens=0, text_tokens=None, image_tokens=None, cache_creation_tokens=0), cache_creation_input_tokens=0, cache_read_input_tokens=0)), 'usage': Usage(completion_tokens=35, prompt_tokens=204, total_tokens=239, completion_tokens_details=None, prompt_tokens_details=PromptTokensDetailsWrapper(audio_tokens=None, cached_tokens=0, text_tokens=None, image_tokens=None, cache_creation_tokens=0), cache_creation_input_tokens=0, cache_read_input_tokens=0)}
original delta: {'provider_specific_fields': None, 'content': '', 'role': None, 'function_call': None, 'tool_calls': None, 'audio': None}
new delta: Delta(provider_specific_fields=None, content='', role=None, function_call=None, tool_calls=None, audio=None)
model_response.choices[0].delta: Delta(provider_specific_fields=None, content='', role=None, function_call=None, tool_calls=None, audio=None); completion_obj: {'content': ''}
self.sent_first_chunk: True
completion_obj: {'content': ''}, model_response.choices[0]: StreamingChoices(finish_reason=None, index=0, delta=Delta(provider_specific_fields=None, content='', role=None, function_call=None, tool_calls=None, audio=None), logprobs=None), response_obj: {'text': '', 'is_finished': True, 'finish_reason': 'stop', 'logprobs': None, 'original_chunk': ModelResponseStream(id='chatcmpl-24e35af5-25b0-4416-9f29-279db90a0879', created=1762144784, model=None, object='chat.completion.chunk', system_fingerprint=None, choices=[StreamingChoices(finish_reason='stop', index=0, delta=Delta(provider_specific_fields=None, content='', role=None, function_call=None, tool_calls=None, audio=None), logprobs=None)], provider_specific_fields=None, usage=Usage(completion_tokens=35, prompt_tokens=204, total_tokens=239, completion_tokens_details=None, prompt_tokens_details=PromptTokensDetailsWrapper(audio_tokens=None, cached_tokens=0, text_tokens=None, image_tokens=None, cache_creation_tokens=0), cache_creation_input_tokens=0, cache_read_input_tokens=0)), 'usage': Usage(completion_tokens=35, prompt_tokens=204, total_tokens=239, completion_tokens_details=None, prompt_tokens_details=PromptTokensDetailsWrapper(audio_tokens=None, cached_tokens=0, text_tokens=None, image_tokens=None, cache_creation_tokens=0), cache_creation_input_tokens=0, cache_read_input_tokens=0)}
final returned processed chunk: ModelResponseStream(id='chatcmpl-24e35af5-25b0-4416-9f29-279db90a0879', created=1762144783, model='claude-sonnet-4-5-20250929', object='chat.completion.chunk', system_fingerprint=None, choices=[StreamingChoices(finish_reason='stop', index=0, delta=Delta(provider_specific_fields=None, content=None, role=None, function_call=None, tool_calls=None, audio=None), logprobs=None)], provider_specific_fields=None)
INFO:     127.0.0.1:53885 - "GET /v1/models HTTP/1.1" 200 OK
INFO:     127.0.0.1:53887 - "GET /v1/models HTTP/1.1" 200 OK
INFO:     127.0.0.1:53888 - "GET /v1/models HTTP/1.1" 200 OK
INFO:     127.0.0.1:53890 - "GET /v1/models HTTP/1.1" 200 OK
INFO:     127.0.0.1:53891 - "GET /v1/models HTTP/1.1" 200 OK
INFO:     127.0.0.1:53900 - "POST /v1/chat/completions HTTP/1.1" 200 OK
Initialized litellm callbacks, Async Success Callbacks: [<litellm.proxy.hooks.model_max_budget_limiter._PROXY_VirtualKeyModelMaxBudgetLimiter object at 0x120d623c0>]
ASYNC kwargs[caching]: False; litellm.cache: None; kwargs.get('cache'): None
INFO:     127.0.0.1:53902 - "POST /v1/chat/completions HTTP/1.1" 200 OK
Final returned optional params: {'stream': True, 'tools': []}
_is_function_call: False
makes async anthropic streaming POST request
Initialized litellm callbacks, Async Success Callbacks: [<litellm.proxy.hooks.model_max_budget_limiter._PROXY_VirtualKeyModelMaxBudgetLimiter object at 0x120d623c0>]
ASYNC kwargs[caching]: False; litellm.cache: None; kwargs.get('cache'): None
Final returned optional params: {'stream': True, 'tools': []}
_is_function_call: False
makes async anthropic streaming POST request
INFO:     127.0.0.1:53903 - "POST /v1/chat/completions HTTP/1.1" 200 OK
Initialized litellm callbacks, Async Success Callbacks: [<litellm.proxy.hooks.model_max_budget_limiter._PROXY_VirtualKeyModelMaxBudgetLimiter object at 0x120d623c0>]
ASYNC kwargs[caching]: False; litellm.cache: None; kwargs.get('cache'): None
Final returned optional params: {'stream': True, 'tools': []}
_is_function_call: False
makes async anthropic streaming POST request
INFO:     127.0.0.1:53906 - "POST /v1/chat/completions HTTP/1.1" 200 OK
Initialized litellm callbacks, Async Success Callbacks: [<litellm.proxy.hooks.model_max_budget_limiter._PROXY_VirtualKeyModelMaxBudgetLimiter object at 0x120d623c0>]
ASYNC kwargs[caching]: False; litellm.cache: None; kwargs.get('cache'): None
Final returned optional params: {'stream': True, 'tools': []}
_is_function_call: False
makes async anthropic streaming POST request
model_response finish reason 3: None; response_obj={'text': '', 'is_finished': False, 'finish_reason': '', 'usage': None, 'index': 0, 'tool_use': None}
model_response.choices[0].delta: Delta(provider_specific_fields=None, content=None, role=None, function_call=None, tool_calls=None, audio=None); completion_obj: {'content': ''}
self.sent_first_chunk: False
completion_obj: {'content': ''}, model_response.choices[0]: StreamingChoices(finish_reason=None, index=0, delta=Delta(provider_specific_fields=None, content=None, role=None, function_call=None, tool_calls=None, audio=None), logprobs=None), response_obj: {'text': '', 'is_finished': False, 'finish_reason': '', 'usage': None, 'index': 0, 'tool_use': None}

Raw OpenAI Chunk
ModelResponseStream(id='chatcmpl-c7c0fb30-d40a-4374-9caa-21da3eccb7a6', created=1762144785, model=None, object='chat.completion.chunk', system_fingerprint=None, choices=[StreamingChoices(finish_reason=None, index=0, delta=Delta(provider_specific_fields=None, content='', role=None, function_call=None, tool_calls=None, audio=None), logprobs=None)], provider_specific_fields=None, usage=Usage(completion_tokens=1, prompt_tokens=1447, total_tokens=1448, completion_tokens_details=None, prompt_tokens_details=PromptTokensDetailsWrapper(audio_tokens=None, cached_tokens=0, text_tokens=None, image_tokens=None, cache_creation_tokens=0, cache_creation_token_details=CacheCreationTokenDetails(ephemeral_5m_input_tokens=0, ephemeral_1h_input_tokens=0)), cache_creation_input_tokens=0, cache_read_input_tokens=0))

model_response finish reason 3: None; response_obj={'text': '', 'is_finished': False, 'finish_reason': None, 'logprobs': None, 'original_chunk': ModelResponseStream(id='chatcmpl-c7c0fb30-d40a-4374-9caa-21da3eccb7a6', created=1762144785, model=None, object='chat.completion.chunk', system_fingerprint=None, choices=[StreamingChoices(finish_reason=None, index=0, delta=Delta(provider_specific_fields=None, content='', role=None, function_call=None, tool_calls=None, audio=None), logprobs=None)], provider_specific_fields=None, usage=Usage(completion_tokens=1, prompt_tokens=1447, total_tokens=1448, completion_tokens_details=None, prompt_tokens_details=PromptTokensDetailsWrapper(audio_tokens=None, cached_tokens=0, text_tokens=None, image_tokens=None, cache_creation_tokens=0, cache_creation_token_details=CacheCreationTokenDetails(ephemeral_5m_input_tokens=0, ephemeral_1h_input_tokens=0)), cache_creation_input_tokens=0, cache_read_input_tokens=0)), 'usage': Usage(completion_tokens=1, prompt_tokens=1447, total_tokens=1448, completion_tokens_details=None, prompt_tokens_details=PromptTokensDetailsWrapper(audio_tokens=None, cached_tokens=0, text_tokens=None, image_tokens=None, cache_creation_tokens=0, cache_creation_token_details=CacheCreationTokenDetails(ephemeral_5m_input_tokens=0, ephemeral_1h_input_tokens=0)), cache_creation_input_tokens=0, cache_read_input_tokens=0)}
original delta: {'provider_specific_fields': None, 'content': '', 'role': None, 'function_call': None, 'tool_calls': None, 'audio': None}
new delta: Delta(provider_specific_fields=None, content='', role=None, function_call=None, tool_calls=None, audio=None)
model_response.choices[0].delta: Delta(provider_specific_fields=None, content='', role=None, function_call=None, tool_calls=None, audio=None); completion_obj: {'content': ''}
self.sent_first_chunk: False
completion_obj: {'content': ''}, model_response.choices[0]: StreamingChoices(finish_reason=None, index=0, delta=Delta(provider_specific_fields=None, content='', role=None, function_call=None, tool_calls=None, audio=None), logprobs=None), response_obj: {'text': '', 'is_finished': False, 'finish_reason': None, 'logprobs': None, 'original_chunk': ModelResponseStream(id='chatcmpl-c7c0fb30-d40a-4374-9caa-21da3eccb7a6', created=1762144785, model=None, object='chat.completion.chunk', system_fingerprint=None, choices=[StreamingChoices(finish_reason=None, index=0, delta=Delta(provider_specific_fields=None, content='', role=None, function_call=None, tool_calls=None, audio=None), logprobs=None)], provider_specific_fields=None, usage=Usage(completion_tokens=1, prompt_tokens=1447, total_tokens=1448, completion_tokens_details=None, prompt_tokens_details=PromptTokensDetailsWrapper(audio_tokens=None, cached_tokens=0, text_tokens=None, image_tokens=None, cache_creation_tokens=0, cache_creation_token_details=CacheCreationTokenDetails(ephemeral_5m_input_tokens=0, ephemeral_1h_input_tokens=0)), cache_creation_input_tokens=0, cache_read_input_tokens=0)), 'usage': Usage(completion_tokens=1, prompt_tokens=1447, total_tokens=1448, completion_tokens_details=None, prompt_tokens_details=PromptTokensDetailsWrapper(audio_tokens=None, cached_tokens=0, text_tokens=None, image_tokens=None, cache_creation_tokens=0, cache_creation_token_details=CacheCreationTokenDetails(ephemeral_5m_input_tokens=0, ephemeral_1h_input_tokens=0)), cache_creation_input_tokens=0, cache_read_input_tokens=0)}
model_response finish reason 3: None; response_obj={'text': '', 'is_finished': False, 'finish_reason': '', 'usage': None, 'index': 0, 'tool_use': None}
model_response.choices[0].delta: Delta(provider_specific_fields=None, content=None, role=None, function_call=None, tool_calls=None, audio=None); completion_obj: {'content': ''}
self.sent_first_chunk: False
completion_obj: {'content': ''}, model_response.choices[0]: StreamingChoices(finish_reason=None, index=0, delta=Delta(provider_specific_fields=None, content=None, role=None, function_call=None, tool_calls=None, audio=None), logprobs=None), response_obj: {'text': '', 'is_finished': False, 'finish_reason': '', 'usage': None, 'index': 0, 'tool_use': None}
model_response finish reason 3: None; response_obj={'text': '', 'is_finished': False, 'finish_reason': '', 'usage': None, 'index': 0, 'tool_use': None}
model_response.choices[0].delta: Delta(provider_specific_fields=None, content=None, role=None, function_call=None, tool_calls=None, audio=None); completion_obj: {'content': ''}
self.sent_first_chunk: False
completion_obj: {'content': ''}, model_response.choices[0]: StreamingChoices(finish_reason=None, index=0, delta=Delta(provider_specific_fields=None, content=None, role=None, function_call=None, tool_calls=None, audio=None), logprobs=None), response_obj: {'text': '', 'is_finished': False, 'finish_reason': '', 'usage': None, 'index': 0, 'tool_use': None}

Raw OpenAI Chunk
ModelResponseStream(id='chatcmpl-c7c0fb30-d40a-4374-9caa-21da3eccb7a6', created=1762144785, model=None, object='chat.completion.chunk', system_fingerprint=None, choices=[StreamingChoices(finish_reason=None, index=0, delta=Delta(provider_specific_fields=None, content='', role=None, function_call=None, tool_calls=None, audio=None), logprobs=None)], provider_specific_fields=None, usage=None)

model_response finish reason 3: None; response_obj={'text': '', 'is_finished': False, 'finish_reason': None, 'logprobs': None, 'original_chunk': ModelResponseStream(id='chatcmpl-c7c0fb30-d40a-4374-9caa-21da3eccb7a6', created=1762144785, model=None, object='chat.completion.chunk', system_fingerprint=None, choices=[StreamingChoices(finish_reason=None, index=0, delta=Delta(provider_specific_fields=None, content='', role=None, function_call=None, tool_calls=None, audio=None), logprobs=None)], provider_specific_fields=None, usage=None), 'usage': None}
original delta: {'provider_specific_fields': None, 'content': '', 'role': None, 'function_call': None, 'tool_calls': None, 'audio': None}
new delta: Delta(provider_specific_fields=None, content='', role=None, function_call=None, tool_calls=None, audio=None)
model_response.choices[0].delta: Delta(provider_specific_fields=None, content='', role=None, function_call=None, tool_calls=None, audio=None); completion_obj: {'content': ''}
self.sent_first_chunk: False
completion_obj: {'content': ''}, model_response.choices[0]: StreamingChoices(finish_reason=None, index=0, delta=Delta(provider_specific_fields=None, content='', role=None, function_call=None, tool_calls=None, audio=None), logprobs=None), response_obj: {'text': '', 'is_finished': False, 'finish_reason': None, 'logprobs': None, 'original_chunk': ModelResponseStream(id='chatcmpl-c7c0fb30-d40a-4374-9caa-21da3eccb7a6', created=1762144785, model=None, object='chat.completion.chunk', system_fingerprint=None, choices=[StreamingChoices(finish_reason=None, index=0, delta=Delta(provider_specific_fields=None, content='', role=None, function_call=None, tool_calls=None, audio=None), logprobs=None)], provider_specific_fields=None, usage=None), 'usage': None}
model_response finish reason 3: None; response_obj={'text': '', 'is_finished': False, 'finish_reason': '', 'usage': None, 'index': 0, 'tool_use': None}
model_response.choices[0].delta: Delta(provider_specific_fields=None, content=None, role=None, function_call=None, tool_calls=None, audio=None); completion_obj: {'content': ''}
self.sent_first_chunk: False
completion_obj: {'content': ''}, model_response.choices[0]: StreamingChoices(finish_reason=None, index=0, delta=Delta(provider_specific_fields=None, content=None, role=None, function_call=None, tool_calls=None, audio=None), logprobs=None), response_obj: {'text': '', 'is_finished': False, 'finish_reason': '', 'usage': None, 'index': 0, 'tool_use': None}
model_response finish reason 3: None; response_obj={'text': '', 'is_finished': False, 'finish_reason': '', 'usage': None, 'index': 0, 'tool_use': None}
model_response.choices[0].delta: Delta(provider_specific_fields=None, content=None, role=None, function_call=None, tool_calls=None, audio=None); completion_obj: {'content': ''}
self.sent_first_chunk: False
completion_obj: {'content': ''}, model_response.choices[0]: StreamingChoices(finish_reason=None, index=0, delta=Delta(provider_specific_fields=None, content=None, role=None, function_call=None, tool_calls=None, audio=None), logprobs=None), response_obj: {'text': '', 'is_finished': False, 'finish_reason': '', 'usage': None, 'index': 0, 'tool_use': None}

Raw OpenAI Chunk
ModelResponseStream(id='chatcmpl-c7c0fb30-d40a-4374-9caa-21da3eccb7a6', created=1762144785, model=None, object='chat.completion.chunk', system_fingerprint=None, choices=[StreamingChoices(finish_reason=None, index=0, delta=Delta(provider_specific_fields=None, content='No', role=None, function_call=None, tool_calls=None, audio=None), logprobs=None)], provider_specific_fields=None, usage=None)

model_response finish reason 3: None; response_obj={'text': 'No', 'is_finished': False, 'finish_reason': None, 'logprobs': None, 'original_chunk': ModelResponseStream(id='chatcmpl-c7c0fb30-d40a-4374-9caa-21da3eccb7a6', created=1762144785, model=None, object='chat.completion.chunk', system_fingerprint=None, choices=[StreamingChoices(finish_reason=None, index=0, delta=Delta(provider_specific_fields=None, content='No', role=None, function_call=None, tool_calls=None, audio=None), logprobs=None)], provider_specific_fields=None, usage=None), 'usage': None}
original delta: {'provider_specific_fields': None, 'content': 'No', 'role': None, 'function_call': None, 'tool_calls': None, 'audio': None}
new delta: Delta(provider_specific_fields=None, content='No', role=None, function_call=None, tool_calls=None, audio=None)
model_response.choices[0].delta: Delta(provider_specific_fields=None, content='No', role=None, function_call=None, tool_calls=None, audio=None); completion_obj: {'content': 'No'}
self.sent_first_chunk: False
completion_obj: {'content': 'No'}, model_response.choices[0]: StreamingChoices(finish_reason=None, index=0, delta=Delta(provider_specific_fields=None, content='No', role=None, function_call=None, tool_calls=None, audio=None), logprobs=None), response_obj: {'text': 'No', 'is_finished': False, 'finish_reason': None, 'logprobs': None, 'original_chunk': ModelResponseStream(id='chatcmpl-c7c0fb30-d40a-4374-9caa-21da3eccb7a6', created=1762144785, model=None, object='chat.completion.chunk', system_fingerprint=None, choices=[StreamingChoices(finish_reason=None, index=0, delta=Delta(provider_specific_fields=None, content='No', role=None, function_call=None, tool_calls=None, audio=None), logprobs=None)], provider_specific_fields=None, usage=None), 'usage': None}
choice_json: {'index': 0, 'delta': {'provider_specific_fields': None, 'content': 'No', 'role': None, 'function_call': None, 'tool_calls': None, 'audio': None}, 'logprobs': None}
choices in streaming: [StreamingChoices(finish_reason=None, index=0, delta=Delta(provider_specific_fields=None, content='No', role=None, function_call=None, tool_calls=None, audio=None), logprobs=None)]
final returned processed chunk: ModelResponseStream(id='chatcmpl-c7c0fb30-d40a-4374-9caa-21da3eccb7a6', created=1762144785, model='claude-sonnet-4-5-20250929', object='chat.completion.chunk', system_fingerprint=None, choices=[StreamingChoices(finish_reason=None, index=0, delta=Delta(provider_specific_fields=None, content='No', role='assistant', function_call=None, tool_calls=None, audio=None), logprobs=None)], provider_specific_fields=None, citations=None)
model_response finish reason 3: None; response_obj={'text': '', 'is_finished': False, 'finish_reason': '', 'usage': None, 'index': 0, 'tool_use': None}
model_response.choices[0].delta: Delta(provider_specific_fields=None, content=None, role=None, function_call=None, tool_calls=None, audio=None); completion_obj: {'content': ''}
self.sent_first_chunk: True
completion_obj: {'content': ''}, model_response.choices[0]: StreamingChoices(finish_reason=None, index=0, delta=Delta(provider_specific_fields=None, content=None, role=None, function_call=None, tool_calls=None, audio=None), logprobs=None), response_obj: {'text': '', 'is_finished': False, 'finish_reason': '', 'usage': None, 'index': 0, 'tool_use': None}
model_response finish reason 3: None; response_obj={'text': '', 'is_finished': False, 'finish_reason': '', 'usage': None, 'index': 0, 'tool_use': None}
model_response.choices[0].delta: Delta(provider_specific_fields=None, content=None, role=None, function_call=None, tool_calls=None, audio=None); completion_obj: {'content': ''}
self.sent_first_chunk: True
completion_obj: {'content': ''}, model_response.choices[0]: StreamingChoices(finish_reason=None, index=0, delta=Delta(provider_specific_fields=None, content=None, role=None, function_call=None, tool_calls=None, audio=None), logprobs=None), response_obj: {'text': '', 'is_finished': False, 'finish_reason': '', 'usage': None, 'index': 0, 'tool_use': None}

Raw OpenAI Chunk
ModelResponseStream(id='chatcmpl-c7c0fb30-d40a-4374-9caa-21da3eccb7a6', created=1762144785, model=None, object='chat.completion.chunk', system_fingerprint=None, choices=[StreamingChoices(finish_reason=None, index=0, delta=Delta(provider_specific_fields=None, content='', role=None, function_call=None, tool_calls=None, audio=None), logprobs=None)], provider_specific_fields=None, usage=None)

model_response finish reason 3: None; response_obj={'text': '', 'is_finished': False, 'finish_reason': None, 'logprobs': None, 'original_chunk': ModelResponseStream(id='chatcmpl-c7c0fb30-d40a-4374-9caa-21da3eccb7a6', created=1762144785, model=None, object='chat.completion.chunk', system_fingerprint=None, choices=[StreamingChoices(finish_reason=None, index=0, delta=Delta(provider_specific_fields=None, content='', role=None, function_call=None, tool_calls=None, audio=None), logprobs=None)], provider_specific_fields=None, usage=None), 'usage': None}
original delta: {'provider_specific_fields': None, 'content': '', 'role': None, 'function_call': None, 'tool_calls': None, 'audio': None}
new delta: Delta(provider_specific_fields=None, content='', role=None, function_call=None, tool_calls=None, audio=None)
model_response.choices[0].delta: Delta(provider_specific_fields=None, content='', role=None, function_call=None, tool_calls=None, audio=None); completion_obj: {'content': ''}
self.sent_first_chunk: True
completion_obj: {'content': ''}, model_response.choices[0]: StreamingChoices(finish_reason=None, index=0, delta=Delta(provider_specific_fields=None, content='', role=None, function_call=None, tool_calls=None, audio=None), logprobs=None), response_obj: {'text': '', 'is_finished': False, 'finish_reason': None, 'logprobs': None, 'original_chunk': ModelResponseStream(id='chatcmpl-c7c0fb30-d40a-4374-9caa-21da3eccb7a6', created=1762144785, model=None, object='chat.completion.chunk', system_fingerprint=None, choices=[StreamingChoices(finish_reason=None, index=0, delta=Delta(provider_specific_fields=None, content='', role=None, function_call=None, tool_calls=None, audio=None), logprobs=None)], provider_specific_fields=None, usage=None), 'usage': None}
model_response finish reason 3: None; response_obj={'text': '', 'is_finished': False, 'finish_reason': '', 'usage': None, 'index': 0, 'tool_use': None}
model_response.choices[0].delta: Delta(provider_specific_fields=None, content=None, role=None, function_call=None, tool_calls=None, audio=None); completion_obj: {'content': ''}
self.sent_first_chunk: True
completion_obj: {'content': ''}, model_response.choices[0]: StreamingChoices(finish_reason=None, index=0, delta=Delta(provider_specific_fields=None, content=None, role=None, function_call=None, tool_calls=None, audio=None), logprobs=None), response_obj: {'text': '', 'is_finished': False, 'finish_reason': '', 'usage': None, 'index': 0, 'tool_use': None}
model_response finish reason 3: None; response_obj={'text': '', 'is_finished': False, 'finish_reason': '', 'usage': None, 'index': 0, 'tool_use': None}
model_response.choices[0].delta: Delta(provider_specific_fields=None, content=None, role=None, function_call=None, tool_calls=None, audio=None); completion_obj: {'content': ''}
self.sent_first_chunk: True
completion_obj: {'content': ''}, model_response.choices[0]: StreamingChoices(finish_reason=None, index=0, delta=Delta(provider_specific_fields=None, content=None, role=None, function_call=None, tool_calls=None, audio=None), logprobs=None), response_obj: {'text': '', 'is_finished': False, 'finish_reason': '', 'usage': None, 'index': 0, 'tool_use': None}

Raw OpenAI Chunk
ModelResponseStream(id='chatcmpl-c7c0fb30-d40a-4374-9caa-21da3eccb7a6', created=1762144785, model=None, object='chat.completion.chunk', system_fingerprint=None, choices=[StreamingChoices(finish_reason='stop', index=0, delta=Delta(provider_specific_fields=None, content='', role=None, function_call=None, tool_calls=None, audio=None), logprobs=None)], provider_specific_fields=None, usage=Usage(completion_tokens=4, prompt_tokens=1447, total_tokens=1451, completion_tokens_details=None, prompt_tokens_details=PromptTokensDetailsWrapper(audio_tokens=None, cached_tokens=0, text_tokens=None, image_tokens=None, cache_creation_tokens=0), cache_creation_input_tokens=0, cache_read_input_tokens=0))

model_response finish reason 3: stop; response_obj={'text': '', 'is_finished': True, 'finish_reason': 'stop', 'logprobs': None, 'original_chunk': ModelResponseStream(id='chatcmpl-c7c0fb30-d40a-4374-9caa-21da3eccb7a6', created=1762144785, model=None, object='chat.completion.chunk', system_fingerprint=None, choices=[StreamingChoices(finish_reason='stop', index=0, delta=Delta(provider_specific_fields=None, content='', role=None, function_call=None, tool_calls=None, audio=None), logprobs=None)], provider_specific_fields=None, usage=Usage(completion_tokens=4, prompt_tokens=1447, total_tokens=1451, completion_tokens_details=None, prompt_tokens_details=PromptTokensDetailsWrapper(audio_tokens=None, cached_tokens=0, text_tokens=None, image_tokens=None, cache_creation_tokens=0), cache_creation_input_tokens=0, cache_read_input_tokens=0)), 'usage': Usage(completion_tokens=4, prompt_tokens=1447, total_tokens=1451, completion_tokens_details=None, prompt_tokens_details=PromptTokensDetailsWrapper(audio_tokens=None, cached_tokens=0, text_tokens=None, image_tokens=None, cache_creation_tokens=0), cache_creation_input_tokens=0, cache_read_input_tokens=0)}
original delta: {'provider_specific_fields': None, 'content': '', 'role': None, 'function_call': None, 'tool_calls': None, 'audio': None}
new delta: Delta(provider_specific_fields=None, content='', role=None, function_call=None, tool_calls=None, audio=None)
model_response.choices[0].delta: Delta(provider_specific_fields=None, content='', role=None, function_call=None, tool_calls=None, audio=None); completion_obj: {'content': ''}
self.sent_first_chunk: True
completion_obj: {'content': ''}, model_response.choices[0]: StreamingChoices(finish_reason=None, index=0, delta=Delta(provider_specific_fields=None, content='', role=None, function_call=None, tool_calls=None, audio=None), logprobs=None), response_obj: {'text': '', 'is_finished': True, 'finish_reason': 'stop', 'logprobs': None, 'original_chunk': ModelResponseStream(id='chatcmpl-c7c0fb30-d40a-4374-9caa-21da3eccb7a6', created=1762144785, model=None, object='chat.completion.chunk', system_fingerprint=None, choices=[StreamingChoices(finish_reason='stop', index=0, delta=Delta(provider_specific_fields=None, content='', role=None, function_call=None, tool_calls=None, audio=None), logprobs=None)], provider_specific_fields=None, usage=Usage(completion_tokens=4, prompt_tokens=1447, total_tokens=1451, completion_tokens_details=None, prompt_tokens_details=PromptTokensDetailsWrapper(audio_tokens=None, cached_tokens=0, text_tokens=None, image_tokens=None, cache_creation_tokens=0), cache_creation_input_tokens=0, cache_read_input_tokens=0)), 'usage': Usage(completion_tokens=4, prompt_tokens=1447, total_tokens=1451, completion_tokens_details=None, prompt_tokens_details=PromptTokensDetailsWrapper(audio_tokens=None, cached_tokens=0, text_tokens=None, image_tokens=None, cache_creation_tokens=0), cache_creation_input_tokens=0, cache_read_input_tokens=0)}
final returned processed chunk: ModelResponseStream(id='chatcmpl-c7c0fb30-d40a-4374-9caa-21da3eccb7a6', created=1762144785, model='claude-sonnet-4-5-20250929', object='chat.completion.chunk', system_fingerprint=None, choices=[StreamingChoices(finish_reason='stop', index=0, delta=Delta(provider_specific_fields=None, content=None, role=None, function_call=None, tool_calls=None, audio=None), logprobs=None)], provider_specific_fields=None)
model_response finish reason 3: None; response_obj={'text': '', 'is_finished': False, 'finish_reason': '', 'usage': None, 'index': 0, 'tool_use': None}
model_response.choices[0].delta: Delta(provider_specific_fields=None, content=None, role=None, function_call=None, tool_calls=None, audio=None); completion_obj: {'content': ''}
self.sent_first_chunk: False
completion_obj: {'content': ''}, model_response.choices[0]: StreamingChoices(finish_reason=None, index=0, delta=Delta(provider_specific_fields=None, content=None, role=None, function_call=None, tool_calls=None, audio=None), logprobs=None), response_obj: {'text': '', 'is_finished': False, 'finish_reason': '', 'usage': None, 'index': 0, 'tool_use': None}

Raw OpenAI Chunk
ModelResponseStream(id='chatcmpl-74cff690-a131-477e-8b96-e680cb3d607a', created=1762144786, model=None, object='chat.completion.chunk', system_fingerprint=None, choices=[StreamingChoices(finish_reason=None, index=0, delta=Delta(provider_specific_fields=None, content='', role=None, function_call=None, tool_calls=None, audio=None), logprobs=None)], provider_specific_fields=None, usage=Usage(completion_tokens=4, prompt_tokens=680, total_tokens=684, completion_tokens_details=None, prompt_tokens_details=PromptTokensDetailsWrapper(audio_tokens=None, cached_tokens=0, text_tokens=None, image_tokens=None, cache_creation_tokens=0, cache_creation_token_details=CacheCreationTokenDetails(ephemeral_5m_input_tokens=0, ephemeral_1h_input_tokens=0)), cache_creation_input_tokens=0, cache_read_input_tokens=0))

model_response finish reason 3: None; response_obj={'text': '', 'is_finished': False, 'finish_reason': None, 'logprobs': None, 'original_chunk': ModelResponseStream(id='chatcmpl-74cff690-a131-477e-8b96-e680cb3d607a', created=1762144786, model=None, object='chat.completion.chunk', system_fingerprint=None, choices=[StreamingChoices(finish_reason=None, index=0, delta=Delta(provider_specific_fields=None, content='', role=None, function_call=None, tool_calls=None, audio=None), logprobs=None)], provider_specific_fields=None, usage=Usage(completion_tokens=4, prompt_tokens=680, total_tokens=684, completion_tokens_details=None, prompt_tokens_details=PromptTokensDetailsWrapper(audio_tokens=None, cached_tokens=0, text_tokens=None, image_tokens=None, cache_creation_tokens=0, cache_creation_token_details=CacheCreationTokenDetails(ephemeral_5m_input_tokens=0, ephemeral_1h_input_tokens=0)), cache_creation_input_tokens=0, cache_read_input_tokens=0)), 'usage': Usage(completion_tokens=4, prompt_tokens=680, total_tokens=684, completion_tokens_details=None, prompt_tokens_details=PromptTokensDetailsWrapper(audio_tokens=None, cached_tokens=0, text_tokens=None, image_tokens=None, cache_creation_tokens=0, cache_creation_token_details=CacheCreationTokenDetails(ephemeral_5m_input_tokens=0, ephemeral_1h_input_tokens=0)), cache_creation_input_tokens=0, cache_read_input_tokens=0)}
original delta: {'provider_specific_fields': None, 'content': '', 'role': None, 'function_call': None, 'tool_calls': None, 'audio': None}
new delta: Delta(provider_specific_fields=None, content='', role=None, function_call=None, tool_calls=None, audio=None)
model_response.choices[0].delta: Delta(provider_specific_fields=None, content='', role=None, function_call=None, tool_calls=None, audio=None); completion_obj: {'content': ''}
self.sent_first_chunk: False
completion_obj: {'content': ''}, model_response.choices[0]: StreamingChoices(finish_reason=None, index=0, delta=Delta(provider_specific_fields=None, content='', role=None, function_call=None, tool_calls=None, audio=None), logprobs=None), response_obj: {'text': '', 'is_finished': False, 'finish_reason': None, 'logprobs': None, 'original_chunk': ModelResponseStream(id='chatcmpl-74cff690-a131-477e-8b96-e680cb3d607a', created=1762144786, model=None, object='chat.completion.chunk', system_fingerprint=None, choices=[StreamingChoices(finish_reason=None, index=0, delta=Delta(provider_specific_fields=None, content='', role=None, function_call=None, tool_calls=None, audio=None), logprobs=None)], provider_specific_fields=None, usage=Usage(completion_tokens=4, prompt_tokens=680, total_tokens=684, completion_tokens_details=None, prompt_tokens_details=PromptTokensDetailsWrapper(audio_tokens=None, cached_tokens=0, text_tokens=None, image_tokens=None, cache_creation_tokens=0, cache_creation_token_details=CacheCreationTokenDetails(ephemeral_5m_input_tokens=0, ephemeral_1h_input_tokens=0)), cache_creation_input_tokens=0, cache_read_input_tokens=0)), 'usage': Usage(completion_tokens=4, prompt_tokens=680, total_tokens=684, completion_tokens_details=None, prompt_tokens_details=PromptTokensDetailsWrapper(audio_tokens=None, cached_tokens=0, text_tokens=None, image_tokens=None, cache_creation_tokens=0, cache_creation_token_details=CacheCreationTokenDetails(ephemeral_5m_input_tokens=0, ephemeral_1h_input_tokens=0)), cache_creation_input_tokens=0, cache_read_input_tokens=0)}
model_response finish reason 3: None; response_obj={'text': '', 'is_finished': False, 'finish_reason': '', 'usage': None, 'index': 0, 'tool_use': None}
model_response.choices[0].delta: Delta(provider_specific_fields=None, content=None, role=None, function_call=None, tool_calls=None, audio=None); completion_obj: {'content': ''}
self.sent_first_chunk: False
completion_obj: {'content': ''}, model_response.choices[0]: StreamingChoices(finish_reason=None, index=0, delta=Delta(provider_specific_fields=None, content=None, role=None, function_call=None, tool_calls=None, audio=None), logprobs=None), response_obj: {'text': '', 'is_finished': False, 'finish_reason': '', 'usage': None, 'index': 0, 'tool_use': None}
model_response finish reason 3: None; response_obj={'text': '', 'is_finished': False, 'finish_reason': '', 'usage': None, 'index': 0, 'tool_use': None}
model_response.choices[0].delta: Delta(provider_specific_fields=None, content=None, role=None, function_call=None, tool_calls=None, audio=None); completion_obj: {'content': ''}
self.sent_first_chunk: False
completion_obj: {'content': ''}, model_response.choices[0]: StreamingChoices(finish_reason=None, index=0, delta=Delta(provider_specific_fields=None, content=None, role=None, function_call=None, tool_calls=None, audio=None), logprobs=None), response_obj: {'text': '', 'is_finished': False, 'finish_reason': '', 'usage': None, 'index': 0, 'tool_use': None}

Raw OpenAI Chunk
ModelResponseStream(id='chatcmpl-74cff690-a131-477e-8b96-e680cb3d607a', created=1762144786, model=None, object='chat.completion.chunk', system_fingerprint=None, choices=[StreamingChoices(finish_reason=None, index=0, delta=Delta(provider_specific_fields=None, content='', role=None, function_call=None, tool_calls=None, audio=None), logprobs=None)], provider_specific_fields=None, usage=None)

model_response finish reason 3: None; response_obj={'text': '', 'is_finished': False, 'finish_reason': None, 'logprobs': None, 'original_chunk': ModelResponseStream(id='chatcmpl-74cff690-a131-477e-8b96-e680cb3d607a', created=1762144786, model=None, object='chat.completion.chunk', system_fingerprint=None, choices=[StreamingChoices(finish_reason=None, index=0, delta=Delta(provider_specific_fields=None, content='', role=None, function_call=None, tool_calls=None, audio=None), logprobs=None)], provider_specific_fields=None, usage=None), 'usage': None}
original delta: {'provider_specific_fields': None, 'content': '', 'role': None, 'function_call': None, 'tool_calls': None, 'audio': None}
new delta: Delta(provider_specific_fields=None, content='', role=None, function_call=None, tool_calls=None, audio=None)
model_response.choices[0].delta: Delta(provider_specific_fields=None, content='', role=None, function_call=None, tool_calls=None, audio=None); completion_obj: {'content': ''}
self.sent_first_chunk: False
completion_obj: {'content': ''}, model_response.choices[0]: StreamingChoices(finish_reason=None, index=0, delta=Delta(provider_specific_fields=None, content='', role=None, function_call=None, tool_calls=None, audio=None), logprobs=None), response_obj: {'text': '', 'is_finished': False, 'finish_reason': None, 'logprobs': None, 'original_chunk': ModelResponseStream(id='chatcmpl-74cff690-a131-477e-8b96-e680cb3d607a', created=1762144786, model=None, object='chat.completion.chunk', system_fingerprint=None, choices=[StreamingChoices(finish_reason=None, index=0, delta=Delta(provider_specific_fields=None, content='', role=None, function_call=None, tool_calls=None, audio=None), logprobs=None)], provider_specific_fields=None, usage=None), 'usage': None}
model_response finish reason 3: None; response_obj={'text': '', 'is_finished': False, 'finish_reason': '', 'usage': None, 'index': 0, 'tool_use': None}
model_response.choices[0].delta: Delta(provider_specific_fields=None, content=None, role=None, function_call=None, tool_calls=None, audio=None); completion_obj: {'content': ''}
self.sent_first_chunk: False
completion_obj: {'content': ''}, model_response.choices[0]: StreamingChoices(finish_reason=None, index=0, delta=Delta(provider_specific_fields=None, content=None, role=None, function_call=None, tool_calls=None, audio=None), logprobs=None), response_obj: {'text': '', 'is_finished': False, 'finish_reason': '', 'usage': None, 'index': 0, 'tool_use': None}
model_response finish reason 3: None; response_obj={'text': '', 'is_finished': False, 'finish_reason': '', 'usage': None, 'index': 0, 'tool_use': None}
model_response.choices[0].delta: Delta(provider_specific_fields=None, content=None, role=None, function_call=None, tool_calls=None, audio=None); completion_obj: {'content': ''}
self.sent_first_chunk: False
completion_obj: {'content': ''}, model_response.choices[0]: StreamingChoices(finish_reason=None, index=0, delta=Delta(provider_specific_fields=None, content=None, role=None, function_call=None, tool_calls=None, audio=None), logprobs=None), response_obj: {'text': '', 'is_finished': False, 'finish_reason': '', 'usage': None, 'index': 0, 'tool_use': None}

Raw OpenAI Chunk
ModelResponseStream(id='chatcmpl-74cff690-a131-477e-8b96-e680cb3d607a', created=1762144786, model=None, object='chat.completion.chunk', system_fingerprint=None, choices=[StreamingChoices(finish_reason=None, index=0, delta=Delta(provider_specific_fields=None, content='Yes', role=None, function_call=None, tool_calls=None, audio=None), logprobs=None)], provider_specific_fields=None, usage=None)

model_response finish reason 3: None; response_obj={'text': 'Yes', 'is_finished': False, 'finish_reason': None, 'logprobs': None, 'original_chunk': ModelResponseStream(id='chatcmpl-74cff690-a131-477e-8b96-e680cb3d607a', created=1762144786, model=None, object='chat.completion.chunk', system_fingerprint=None, choices=[StreamingChoices(finish_reason=None, index=0, delta=Delta(provider_specific_fields=None, content='Yes', role=None, function_call=None, tool_calls=None, audio=None), logprobs=None)], provider_specific_fields=None, usage=None), 'usage': None}
original delta: {'provider_specific_fields': None, 'content': 'Yes', 'role': None, 'function_call': None, 'tool_calls': None, 'audio': None}
new delta: Delta(provider_specific_fields=None, content='Yes', role=None, function_call=None, tool_calls=None, audio=None)
model_response.choices[0].delta: Delta(provider_specific_fields=None, content='Yes', role=None, function_call=None, tool_calls=None, audio=None); completion_obj: {'content': 'Yes'}
self.sent_first_chunk: False
completion_obj: {'content': 'Yes'}, model_response.choices[0]: StreamingChoices(finish_reason=None, index=0, delta=Delta(provider_specific_fields=None, content='Yes', role=None, function_call=None, tool_calls=None, audio=None), logprobs=None), response_obj: {'text': 'Yes', 'is_finished': False, 'finish_reason': None, 'logprobs': None, 'original_chunk': ModelResponseStream(id='chatcmpl-74cff690-a131-477e-8b96-e680cb3d607a', created=1762144786, model=None, object='chat.completion.chunk', system_fingerprint=None, choices=[StreamingChoices(finish_reason=None, index=0, delta=Delta(provider_specific_fields=None, content='Yes', role=None, function_call=None, tool_calls=None, audio=None), logprobs=None)], provider_specific_fields=None, usage=None), 'usage': None}
choice_json: {'index': 0, 'delta': {'provider_specific_fields': None, 'content': 'Yes', 'role': None, 'function_call': None, 'tool_calls': None, 'audio': None}, 'logprobs': None}
choices in streaming: [StreamingChoices(finish_reason=None, index=0, delta=Delta(provider_specific_fields=None, content='Yes', role=None, function_call=None, tool_calls=None, audio=None), logprobs=None)]
final returned processed chunk: ModelResponseStream(id='chatcmpl-74cff690-a131-477e-8b96-e680cb3d607a', created=1762144786, model='claude-sonnet-4-5-20250929', object='chat.completion.chunk', system_fingerprint=None, choices=[StreamingChoices(finish_reason=None, index=0, delta=Delta(provider_specific_fields=None, content='Yes', role='assistant', function_call=None, tool_calls=None, audio=None), logprobs=None)], provider_specific_fields=None, citations=None)
model_response finish reason 3: None; response_obj={'text': '', 'is_finished': False, 'finish_reason': '', 'usage': None, 'index': 0, 'tool_use': None}
model_response.choices[0].delta: Delta(provider_specific_fields=None, content=None, role=None, function_call=None, tool_calls=None, audio=None); completion_obj: {'content': ''}
self.sent_first_chunk: True
completion_obj: {'content': ''}, model_response.choices[0]: StreamingChoices(finish_reason=None, index=0, delta=Delta(provider_specific_fields=None, content=None, role=None, function_call=None, tool_calls=None, audio=None), logprobs=None), response_obj: {'text': '', 'is_finished': False, 'finish_reason': '', 'usage': None, 'index': 0, 'tool_use': None}
model_response finish reason 3: None; response_obj={'text': '', 'is_finished': False, 'finish_reason': '', 'usage': None, 'index': 0, 'tool_use': None}
model_response.choices[0].delta: Delta(provider_specific_fields=None, content=None, role=None, function_call=None, tool_calls=None, audio=None); completion_obj: {'content': ''}
self.sent_first_chunk: True
completion_obj: {'content': ''}, model_response.choices[0]: StreamingChoices(finish_reason=None, index=0, delta=Delta(provider_specific_fields=None, content=None, role=None, function_call=None, tool_calls=None, audio=None), logprobs=None), response_obj: {'text': '', 'is_finished': False, 'finish_reason': '', 'usage': None, 'index': 0, 'tool_use': None}

Raw OpenAI Chunk
ModelResponseStream(id='chatcmpl-74cff690-a131-477e-8b96-e680cb3d607a', created=1762144786, model=None, object='chat.completion.chunk', system_fingerprint=None, choices=[StreamingChoices(finish_reason=None, index=0, delta=Delta(provider_specific_fields=None, content='', role=None, function_call=None, tool_calls=None, audio=None), logprobs=None)], provider_specific_fields=None, usage=None)

model_response finish reason 3: None; response_obj={'text': '', 'is_finished': False, 'finish_reason': None, 'logprobs': None, 'original_chunk': ModelResponseStream(id='chatcmpl-74cff690-a131-477e-8b96-e680cb3d607a', created=1762144786, model=None, object='chat.completion.chunk', system_fingerprint=None, choices=[StreamingChoices(finish_reason=None, index=0, delta=Delta(provider_specific_fields=None, content='', role=None, function_call=None, tool_calls=None, audio=None), logprobs=None)], provider_specific_fields=None, usage=None), 'usage': None}
original delta: {'provider_specific_fields': None, 'content': '', 'role': None, 'function_call': None, 'tool_calls': None, 'audio': None}
new delta: Delta(provider_specific_fields=None, content='', role=None, function_call=None, tool_calls=None, audio=None)
model_response.choices[0].delta: Delta(provider_specific_fields=None, content='', role=None, function_call=None, tool_calls=None, audio=None); completion_obj: {'content': ''}
self.sent_first_chunk: True
completion_obj: {'content': ''}, model_response.choices[0]: StreamingChoices(finish_reason=None, index=0, delta=Delta(provider_specific_fields=None, content='', role=None, function_call=None, tool_calls=None, audio=None), logprobs=None), response_obj: {'text': '', 'is_finished': False, 'finish_reason': None, 'logprobs': None, 'original_chunk': ModelResponseStream(id='chatcmpl-74cff690-a131-477e-8b96-e680cb3d607a', created=1762144786, model=None, object='chat.completion.chunk', system_fingerprint=None, choices=[StreamingChoices(finish_reason=None, index=0, delta=Delta(provider_specific_fields=None, content='', role=None, function_call=None, tool_calls=None, audio=None), logprobs=None)], provider_specific_fields=None, usage=None), 'usage': None}
model_response finish reason 3: None; response_obj={'text': '', 'is_finished': False, 'finish_reason': '', 'usage': None, 'index': 0, 'tool_use': None}
model_response.choices[0].delta: Delta(provider_specific_fields=None, content=None, role=None, function_call=None, tool_calls=None, audio=None); completion_obj: {'content': ''}
self.sent_first_chunk: True
completion_obj: {'content': ''}, model_response.choices[0]: StreamingChoices(finish_reason=None, index=0, delta=Delta(provider_specific_fields=None, content=None, role=None, function_call=None, tool_calls=None, audio=None), logprobs=None), response_obj: {'text': '', 'is_finished': False, 'finish_reason': '', 'usage': None, 'index': 0, 'tool_use': None}
model_response finish reason 3: None; response_obj={'text': '', 'is_finished': False, 'finish_reason': '', 'usage': None, 'index': 0, 'tool_use': None}
model_response.choices[0].delta: Delta(provider_specific_fields=None, content=None, role=None, function_call=None, tool_calls=None, audio=None); completion_obj: {'content': ''}
self.sent_first_chunk: False
completion_obj: {'content': ''}, model_response.choices[0]: StreamingChoices(finish_reason=None, index=0, delta=Delta(provider_specific_fields=None, content=None, role=None, function_call=None, tool_calls=None, audio=None), logprobs=None), response_obj: {'text': '', 'is_finished': False, 'finish_reason': '', 'usage': None, 'index': 0, 'tool_use': None}

Raw OpenAI Chunk
ModelResponseStream(id='chatcmpl-e84a7236-69b1-4003-a764-ca4be92e3b2d', created=1762144786, model=None, object='chat.completion.chunk', system_fingerprint=None, choices=[StreamingChoices(finish_reason=None, index=0, delta=Delta(provider_specific_fields=None, content='', role=None, function_call=None, tool_calls=None, audio=None), logprobs=None)], provider_specific_fields=None, usage=Usage(completion_tokens=1, prompt_tokens=1193, total_tokens=1194, completion_tokens_details=None, prompt_tokens_details=PromptTokensDetailsWrapper(audio_tokens=None, cached_tokens=0, text_tokens=None, image_tokens=None, cache_creation_tokens=0, cache_creation_token_details=CacheCreationTokenDetails(ephemeral_5m_input_tokens=0, ephemeral_1h_input_tokens=0)), cache_creation_input_tokens=0, cache_read_input_tokens=0))

model_response finish reason 3: None; response_obj={'text': '', 'is_finished': False, 'finish_reason': None, 'logprobs': None, 'original_chunk': ModelResponseStream(id='chatcmpl-e84a7236-69b1-4003-a764-ca4be92e3b2d', created=1762144786, model=None, object='chat.completion.chunk', system_fingerprint=None, choices=[StreamingChoices(finish_reason=None, index=0, delta=Delta(provider_specific_fields=None, content='', role=None, function_call=None, tool_calls=None, audio=None), logprobs=None)], provider_specific_fields=None, usage=Usage(completion_tokens=1, prompt_tokens=1193, total_tokens=1194, completion_tokens_details=None, prompt_tokens_details=PromptTokensDetailsWrapper(audio_tokens=None, cached_tokens=0, text_tokens=None, image_tokens=None, cache_creation_tokens=0, cache_creation_token_details=CacheCreationTokenDetails(ephemeral_5m_input_tokens=0, ephemeral_1h_input_tokens=0)), cache_creation_input_tokens=0, cache_read_input_tokens=0)), 'usage': Usage(completion_tokens=1, prompt_tokens=1193, total_tokens=1194, completion_tokens_details=None, prompt_tokens_details=PromptTokensDetailsWrapper(audio_tokens=None, cached_tokens=0, text_tokens=None, image_tokens=None, cache_creation_tokens=0, cache_creation_token_details=CacheCreationTokenDetails(ephemeral_5m_input_tokens=0, ephemeral_1h_input_tokens=0)), cache_creation_input_tokens=0, cache_read_input_tokens=0)}
original delta: {'provider_specific_fields': None, 'content': '', 'role': None, 'function_call': None, 'tool_calls': None, 'audio': None}
new delta: Delta(provider_specific_fields=None, content='', role=None, function_call=None, tool_calls=None, audio=None)
model_response.choices[0].delta: Delta(provider_specific_fields=None, content='', role=None, function_call=None, tool_calls=None, audio=None); completion_obj: {'content': ''}
self.sent_first_chunk: False
completion_obj: {'content': ''}, model_response.choices[0]: StreamingChoices(finish_reason=None, index=0, delta=Delta(provider_specific_fields=None, content='', role=None, function_call=None, tool_calls=None, audio=None), logprobs=None), response_obj: {'text': '', 'is_finished': False, 'finish_reason': None, 'logprobs': None, 'original_chunk': ModelResponseStream(id='chatcmpl-e84a7236-69b1-4003-a764-ca4be92e3b2d', created=1762144786, model=None, object='chat.completion.chunk', system_fingerprint=None, choices=[StreamingChoices(finish_reason=None, index=0, delta=Delta(provider_specific_fields=None, content='', role=None, function_call=None, tool_calls=None, audio=None), logprobs=None)], provider_specific_fields=None, usage=Usage(completion_tokens=1, prompt_tokens=1193, total_tokens=1194, completion_tokens_details=None, prompt_tokens_details=PromptTokensDetailsWrapper(audio_tokens=None, cached_tokens=0, text_tokens=None, image_tokens=None, cache_creation_tokens=0, cache_creation_token_details=CacheCreationTokenDetails(ephemeral_5m_input_tokens=0, ephemeral_1h_input_tokens=0)), cache_creation_input_tokens=0, cache_read_input_tokens=0)), 'usage': Usage(completion_tokens=1, prompt_tokens=1193, total_tokens=1194, completion_tokens_details=None, prompt_tokens_details=PromptTokensDetailsWrapper(audio_tokens=None, cached_tokens=0, text_tokens=None, image_tokens=None, cache_creation_tokens=0, cache_creation_token_details=CacheCreationTokenDetails(ephemeral_5m_input_tokens=0, ephemeral_1h_input_tokens=0)), cache_creation_input_tokens=0, cache_read_input_tokens=0)}
model_response finish reason 3: None; response_obj={'text': '', 'is_finished': False, 'finish_reason': '', 'usage': None, 'index': 0, 'tool_use': None}
model_response.choices[0].delta: Delta(provider_specific_fields=None, content=None, role=None, function_call=None, tool_calls=None, audio=None); completion_obj: {'content': ''}
self.sent_first_chunk: False
completion_obj: {'content': ''}, model_response.choices[0]: StreamingChoices(finish_reason=None, index=0, delta=Delta(provider_specific_fields=None, content=None, role=None, function_call=None, tool_calls=None, audio=None), logprobs=None), response_obj: {'text': '', 'is_finished': False, 'finish_reason': '', 'usage': None, 'index': 0, 'tool_use': None}
model_response finish reason 3: None; response_obj={'text': '', 'is_finished': False, 'finish_reason': '', 'usage': None, 'index': 0, 'tool_use': None}
model_response.choices[0].delta: Delta(provider_specific_fields=None, content=None, role=None, function_call=None, tool_calls=None, audio=None); completion_obj: {'content': ''}
self.sent_first_chunk: False
completion_obj: {'content': ''}, model_response.choices[0]: StreamingChoices(finish_reason=None, index=0, delta=Delta(provider_specific_fields=None, content=None, role=None, function_call=None, tool_calls=None, audio=None), logprobs=None), response_obj: {'text': '', 'is_finished': False, 'finish_reason': '', 'usage': None, 'index': 0, 'tool_use': None}

Raw OpenAI Chunk
ModelResponseStream(id='chatcmpl-e84a7236-69b1-4003-a764-ca4be92e3b2d', created=1762144786, model=None, object='chat.completion.chunk', system_fingerprint=None, choices=[StreamingChoices(finish_reason=None, index=0, delta=Delta(provider_specific_fields=None, content='', role=None, function_call=None, tool_calls=None, audio=None), logprobs=None)], provider_specific_fields=None, usage=None)

model_response finish reason 3: None; response_obj={'text': '', 'is_finished': False, 'finish_reason': None, 'logprobs': None, 'original_chunk': ModelResponseStream(id='chatcmpl-e84a7236-69b1-4003-a764-ca4be92e3b2d', created=1762144786, model=None, object='chat.completion.chunk', system_fingerprint=None, choices=[StreamingChoices(finish_reason=None, index=0, delta=Delta(provider_specific_fields=None, content='', role=None, function_call=None, tool_calls=None, audio=None), logprobs=None)], provider_specific_fields=None, usage=None), 'usage': None}
original delta: {'provider_specific_fields': None, 'content': '', 'role': None, 'function_call': None, 'tool_calls': None, 'audio': None}
new delta: Delta(provider_specific_fields=None, content='', role=None, function_call=None, tool_calls=None, audio=None)
model_response.choices[0].delta: Delta(provider_specific_fields=None, content='', role=None, function_call=None, tool_calls=None, audio=None); completion_obj: {'content': ''}
self.sent_first_chunk: False
completion_obj: {'content': ''}, model_response.choices[0]: StreamingChoices(finish_reason=None, index=0, delta=Delta(provider_specific_fields=None, content='', role=None, function_call=None, tool_calls=None, audio=None), logprobs=None), response_obj: {'text': '', 'is_finished': False, 'finish_reason': None, 'logprobs': None, 'original_chunk': ModelResponseStream(id='chatcmpl-e84a7236-69b1-4003-a764-ca4be92e3b2d', created=1762144786, model=None, object='chat.completion.chunk', system_fingerprint=None, choices=[StreamingChoices(finish_reason=None, index=0, delta=Delta(provider_specific_fields=None, content='', role=None, function_call=None, tool_calls=None, audio=None), logprobs=None)], provider_specific_fields=None, usage=None), 'usage': None}
model_response finish reason 3: None; response_obj={'text': '', 'is_finished': False, 'finish_reason': '', 'usage': None, 'index': 0, 'tool_use': None}
model_response.choices[0].delta: Delta(provider_specific_fields=None, content=None, role=None, function_call=None, tool_calls=None, audio=None); completion_obj: {'content': ''}
self.sent_first_chunk: False
completion_obj: {'content': ''}, model_response.choices[0]: StreamingChoices(finish_reason=None, index=0, delta=Delta(provider_specific_fields=None, content=None, role=None, function_call=None, tool_calls=None, audio=None), logprobs=None), response_obj: {'text': '', 'is_finished': False, 'finish_reason': '', 'usage': None, 'index': 0, 'tool_use': None}
model_response finish reason 3: None; response_obj={'text': '', 'is_finished': False, 'finish_reason': '', 'usage': None, 'index': 0, 'tool_use': None}
model_response.choices[0].delta: Delta(provider_specific_fields=None, content=None, role=None, function_call=None, tool_calls=None, audio=None); completion_obj: {'content': ''}
self.sent_first_chunk: False
completion_obj: {'content': ''}, model_response.choices[0]: StreamingChoices(finish_reason=None, index=0, delta=Delta(provider_specific_fields=None, content=None, role=None, function_call=None, tool_calls=None, audio=None), logprobs=None), response_obj: {'text': '', 'is_finished': False, 'finish_reason': '', 'usage': None, 'index': 0, 'tool_use': None}

Raw OpenAI Chunk
ModelResponseStream(id='chatcmpl-e84a7236-69b1-4003-a764-ca4be92e3b2d', created=1762144786, model=None, object='chat.completion.chunk', system_fingerprint=None, choices=[StreamingChoices(finish_reason=None, index=0, delta=Delta(provider_specific_fields=None, content='No', role=None, function_call=None, tool_calls=None, audio=None), logprobs=None)], provider_specific_fields=None, usage=None)

model_response finish reason 3: None; response_obj={'text': 'No', 'is_finished': False, 'finish_reason': None, 'logprobs': None, 'original_chunk': ModelResponseStream(id='chatcmpl-e84a7236-69b1-4003-a764-ca4be92e3b2d', created=1762144786, model=None, object='chat.completion.chunk', system_fingerprint=None, choices=[StreamingChoices(finish_reason=None, index=0, delta=Delta(provider_specific_fields=None, content='No', role=None, function_call=None, tool_calls=None, audio=None), logprobs=None)], provider_specific_fields=None, usage=None), 'usage': None}
original delta: {'provider_specific_fields': None, 'content': 'No', 'role': None, 'function_call': None, 'tool_calls': None, 'audio': None}
new delta: Delta(provider_specific_fields=None, content='No', role=None, function_call=None, tool_calls=None, audio=None)
model_response.choices[0].delta: Delta(provider_specific_fields=None, content='No', role=None, function_call=None, tool_calls=None, audio=None); completion_obj: {'content': 'No'}
self.sent_first_chunk: False
completion_obj: {'content': 'No'}, model_response.choices[0]: StreamingChoices(finish_reason=None, index=0, delta=Delta(provider_specific_fields=None, content='No', role=None, function_call=None, tool_calls=None, audio=None), logprobs=None), response_obj: {'text': 'No', 'is_finished': False, 'finish_reason': None, 'logprobs': None, 'original_chunk': ModelResponseStream(id='chatcmpl-e84a7236-69b1-4003-a764-ca4be92e3b2d', created=1762144786, model=None, object='chat.completion.chunk', system_fingerprint=None, choices=[StreamingChoices(finish_reason=None, index=0, delta=Delta(provider_specific_fields=None, content='No', role=None, function_call=None, tool_calls=None, audio=None), logprobs=None)], provider_specific_fields=None, usage=None), 'usage': None}
choice_json: {'index': 0, 'delta': {'provider_specific_fields': None, 'content': 'No', 'role': None, 'function_call': None, 'tool_calls': None, 'audio': None}, 'logprobs': None}
choices in streaming: [StreamingChoices(finish_reason=None, index=0, delta=Delta(provider_specific_fields=None, content='No', role=None, function_call=None, tool_calls=None, audio=None), logprobs=None)]
final returned processed chunk: ModelResponseStream(id='chatcmpl-e84a7236-69b1-4003-a764-ca4be92e3b2d', created=1762144786, model='claude-sonnet-4-5-20250929', object='chat.completion.chunk', system_fingerprint=None, choices=[StreamingChoices(finish_reason=None, index=0, delta=Delta(provider_specific_fields=None, content='No', role='assistant', function_call=None, tool_calls=None, audio=None), logprobs=None)], provider_specific_fields=None, citations=None)
model_response finish reason 3: None; response_obj={'text': '', 'is_finished': False, 'finish_reason': '', 'usage': None, 'index': 0, 'tool_use': None}
model_response.choices[0].delta: Delta(provider_specific_fields=None, content=None, role=None, function_call=None, tool_calls=None, audio=None); completion_obj: {'content': ''}
self.sent_first_chunk: True
completion_obj: {'content': ''}, model_response.choices[0]: StreamingChoices(finish_reason=None, index=0, delta=Delta(provider_specific_fields=None, content=None, role=None, function_call=None, tool_calls=None, audio=None), logprobs=None), response_obj: {'text': '', 'is_finished': False, 'finish_reason': '', 'usage': None, 'index': 0, 'tool_use': None}
model_response finish reason 3: None; response_obj={'text': '', 'is_finished': False, 'finish_reason': '', 'usage': None, 'index': 0, 'tool_use': None}
model_response.choices[0].delta: Delta(provider_specific_fields=None, content=None, role=None, function_call=None, tool_calls=None, audio=None); completion_obj: {'content': ''}
self.sent_first_chunk: True
completion_obj: {'content': ''}, model_response.choices[0]: StreamingChoices(finish_reason=None, index=0, delta=Delta(provider_specific_fields=None, content=None, role=None, function_call=None, tool_calls=None, audio=None), logprobs=None), response_obj: {'text': '', 'is_finished': False, 'finish_reason': '', 'usage': None, 'index': 0, 'tool_use': None}

Raw OpenAI Chunk
ModelResponseStream(id='chatcmpl-74cff690-a131-477e-8b96-e680cb3d607a', created=1762144786, model=None, object='chat.completion.chunk', system_fingerprint=None, choices=[StreamingChoices(finish_reason='stop', index=0, delta=Delta(provider_specific_fields=None, content='', role=None, function_call=None, tool_calls=None, audio=None), logprobs=None)], provider_specific_fields=None, usage=Usage(completion_tokens=4, prompt_tokens=680, total_tokens=684, completion_tokens_details=None, prompt_tokens_details=PromptTokensDetailsWrapper(audio_tokens=None, cached_tokens=0, text_tokens=None, image_tokens=None, cache_creation_tokens=0), cache_creation_input_tokens=0, cache_read_input_tokens=0))

model_response finish reason 3: stop; response_obj={'text': '', 'is_finished': True, 'finish_reason': 'stop', 'logprobs': None, 'original_chunk': ModelResponseStream(id='chatcmpl-74cff690-a131-477e-8b96-e680cb3d607a', created=1762144786, model=None, object='chat.completion.chunk', system_fingerprint=None, choices=[StreamingChoices(finish_reason='stop', index=0, delta=Delta(provider_specific_fields=None, content='', role=None, function_call=None, tool_calls=None, audio=None), logprobs=None)], provider_specific_fields=None, usage=Usage(completion_tokens=4, prompt_tokens=680, total_tokens=684, completion_tokens_details=None, prompt_tokens_details=PromptTokensDetailsWrapper(audio_tokens=None, cached_tokens=0, text_tokens=None, image_tokens=None, cache_creation_tokens=0), cache_creation_input_tokens=0, cache_read_input_tokens=0)), 'usage': Usage(completion_tokens=4, prompt_tokens=680, total_tokens=684, completion_tokens_details=None, prompt_tokens_details=PromptTokensDetailsWrapper(audio_tokens=None, cached_tokens=0, text_tokens=None, image_tokens=None, cache_creation_tokens=0), cache_creation_input_tokens=0, cache_read_input_tokens=0)}
original delta: {'provider_specific_fields': None, 'content': '', 'role': None, 'function_call': None, 'tool_calls': None, 'audio': None}
new delta: Delta(provider_specific_fields=None, content='', role=None, function_call=None, tool_calls=None, audio=None)
model_response.choices[0].delta: Delta(provider_specific_fields=None, content='', role=None, function_call=None, tool_calls=None, audio=None); completion_obj: {'content': ''}
self.sent_first_chunk: True
completion_obj: {'content': ''}, model_response.choices[0]: StreamingChoices(finish_reason=None, index=0, delta=Delta(provider_specific_fields=None, content='', role=None, function_call=None, tool_calls=None, audio=None), logprobs=None), response_obj: {'text': '', 'is_finished': True, 'finish_reason': 'stop', 'logprobs': None, 'original_chunk': ModelResponseStream(id='chatcmpl-74cff690-a131-477e-8b96-e680cb3d607a', created=1762144786, model=None, object='chat.completion.chunk', system_fingerprint=None, choices=[StreamingChoices(finish_reason='stop', index=0, delta=Delta(provider_specific_fields=None, content='', role=None, function_call=None, tool_calls=None, audio=None), logprobs=None)], provider_specific_fields=None, usage=Usage(completion_tokens=4, prompt_tokens=680, total_tokens=684, completion_tokens_details=None, prompt_tokens_details=PromptTokensDetailsWrapper(audio_tokens=None, cached_tokens=0, text_tokens=None, image_tokens=None, cache_creation_tokens=0), cache_creation_input_tokens=0, cache_read_input_tokens=0)), 'usage': Usage(completion_tokens=4, prompt_tokens=680, total_tokens=684, completion_tokens_details=None, prompt_tokens_details=PromptTokensDetailsWrapper(audio_tokens=None, cached_tokens=0, text_tokens=None, image_tokens=None, cache_creation_tokens=0), cache_creation_input_tokens=0, cache_read_input_tokens=0)}
final returned processed chunk: ModelResponseStream(id='chatcmpl-74cff690-a131-477e-8b96-e680cb3d607a', created=1762144786, model='claude-sonnet-4-5-20250929', object='chat.completion.chunk', system_fingerprint=None, choices=[StreamingChoices(finish_reason='stop', index=0, delta=Delta(provider_specific_fields=None, content=None, role=None, function_call=None, tool_calls=None, audio=None), logprobs=None)], provider_specific_fields=None)
INFO:     127.0.0.1:53909 - "GET /v1/models HTTP/1.1" 200 OK
model_response finish reason 3: None; response_obj={'text': '', 'is_finished': False, 'finish_reason': '', 'usage': None, 'index': 0, 'tool_use': None}
model_response.choices[0].delta: Delta(provider_specific_fields=None, content=None, role=None, function_call=None, tool_calls=None, audio=None); completion_obj: {'content': ''}
self.sent_first_chunk: False
completion_obj: {'content': ''}, model_response.choices[0]: StreamingChoices(finish_reason=None, index=0, delta=Delta(provider_specific_fields=None, content=None, role=None, function_call=None, tool_calls=None, audio=None), logprobs=None), response_obj: {'text': '', 'is_finished': False, 'finish_reason': '', 'usage': None, 'index': 0, 'tool_use': None}

Raw OpenAI Chunk
ModelResponseStream(id='chatcmpl-a1b184e5-9f97-4d6f-b08a-2b67aecea87c', created=1762144786, model=None, object='chat.completion.chunk', system_fingerprint=None, choices=[StreamingChoices(finish_reason=None, index=0, delta=Delta(provider_specific_fields=None, content='', role=None, function_call=None, tool_calls=None, audio=None), logprobs=None)], provider_specific_fields=None, usage=Usage(completion_tokens=1, prompt_tokens=1288, total_tokens=1289, completion_tokens_details=None, prompt_tokens_details=PromptTokensDetailsWrapper(audio_tokens=None, cached_tokens=0, text_tokens=None, image_tokens=None, cache_creation_tokens=0, cache_creation_token_details=CacheCreationTokenDetails(ephemeral_5m_input_tokens=0, ephemeral_1h_input_tokens=0)), cache_creation_input_tokens=0, cache_read_input_tokens=0))

model_response finish reason 3: None; response_obj={'text': '', 'is_finished': False, 'finish_reason': None, 'logprobs': None, 'original_chunk': ModelResponseStream(id='chatcmpl-a1b184e5-9f97-4d6f-b08a-2b67aecea87c', created=1762144786, model=None, object='chat.completion.chunk', system_fingerprint=None, choices=[StreamingChoices(finish_reason=None, index=0, delta=Delta(provider_specific_fields=None, content='', role=None, function_call=None, tool_calls=None, audio=None), logprobs=None)], provider_specific_fields=None, usage=Usage(completion_tokens=1, prompt_tokens=1288, total_tokens=1289, completion_tokens_details=None, prompt_tokens_details=PromptTokensDetailsWrapper(audio_tokens=None, cached_tokens=0, text_tokens=None, image_tokens=None, cache_creation_tokens=0, cache_creation_token_details=CacheCreationTokenDetails(ephemeral_5m_input_tokens=0, ephemeral_1h_input_tokens=0)), cache_creation_input_tokens=0, cache_read_input_tokens=0)), 'usage': Usage(completion_tokens=1, prompt_tokens=1288, total_tokens=1289, completion_tokens_details=None, prompt_tokens_details=PromptTokensDetailsWrapper(audio_tokens=None, cached_tokens=0, text_tokens=None, image_tokens=None, cache_creation_tokens=0, cache_creation_token_details=CacheCreationTokenDetails(ephemeral_5m_input_tokens=0, ephemeral_1h_input_tokens=0)), cache_creation_input_tokens=0, cache_read_input_tokens=0)}
original delta: {'provider_specific_fields': None, 'content': '', 'role': None, 'function_call': None, 'tool_calls': None, 'audio': None}
new delta: Delta(provider_specific_fields=None, content='', role=None, function_call=None, tool_calls=None, audio=None)
model_response.choices[0].delta: Delta(provider_specific_fields=None, content='', role=None, function_call=None, tool_calls=None, audio=None); completion_obj: {'content': ''}
self.sent_first_chunk: False
completion_obj: {'content': ''}, model_response.choices[0]: StreamingChoices(finish_reason=None, index=0, delta=Delta(provider_specific_fields=None, content='', role=None, function_call=None, tool_calls=None, audio=None), logprobs=None), response_obj: {'text': '', 'is_finished': False, 'finish_reason': None, 'logprobs': None, 'original_chunk': ModelResponseStream(id='chatcmpl-a1b184e5-9f97-4d6f-b08a-2b67aecea87c', created=1762144786, model=None, object='chat.completion.chunk', system_fingerprint=None, choices=[StreamingChoices(finish_reason=None, index=0, delta=Delta(provider_specific_fields=None, content='', role=None, function_call=None, tool_calls=None, audio=None), logprobs=None)], provider_specific_fields=None, usage=Usage(completion_tokens=1, prompt_tokens=1288, total_tokens=1289, completion_tokens_details=None, prompt_tokens_details=PromptTokensDetailsWrapper(audio_tokens=None, cached_tokens=0, text_tokens=None, image_tokens=None, cache_creation_tokens=0, cache_creation_token_details=CacheCreationTokenDetails(ephemeral_5m_input_tokens=0, ephemeral_1h_input_tokens=0)), cache_creation_input_tokens=0, cache_read_input_tokens=0)), 'usage': Usage(completion_tokens=1, prompt_tokens=1288, total_tokens=1289, completion_tokens_details=None, prompt_tokens_details=PromptTokensDetailsWrapper(audio_tokens=None, cached_tokens=0, text_tokens=None, image_tokens=None, cache_creation_tokens=0, cache_creation_token_details=CacheCreationTokenDetails(ephemeral_5m_input_tokens=0, ephemeral_1h_input_tokens=0)), cache_creation_input_tokens=0, cache_read_input_tokens=0)}
model_response finish reason 3: None; response_obj={'text': '', 'is_finished': False, 'finish_reason': '', 'usage': None, 'index': 0, 'tool_use': None}
model_response.choices[0].delta: Delta(provider_specific_fields=None, content=None, role=None, function_call=None, tool_calls=None, audio=None); completion_obj: {'content': ''}
self.sent_first_chunk: False
completion_obj: {'content': ''}, model_response.choices[0]: StreamingChoices(finish_reason=None, index=0, delta=Delta(provider_specific_fields=None, content=None, role=None, function_call=None, tool_calls=None, audio=None), logprobs=None), response_obj: {'text': '', 'is_finished': False, 'finish_reason': '', 'usage': None, 'index': 0, 'tool_use': None}
model_response finish reason 3: None; response_obj={'text': '', 'is_finished': False, 'finish_reason': '', 'usage': None, 'index': 0, 'tool_use': None}
model_response.choices[0].delta: Delta(provider_specific_fields=None, content=None, role=None, function_call=None, tool_calls=None, audio=None); completion_obj: {'content': ''}
self.sent_first_chunk: False
completion_obj: {'content': ''}, model_response.choices[0]: StreamingChoices(finish_reason=None, index=0, delta=Delta(provider_specific_fields=None, content=None, role=None, function_call=None, tool_calls=None, audio=None), logprobs=None), response_obj: {'text': '', 'is_finished': False, 'finish_reason': '', 'usage': None, 'index': 0, 'tool_use': None}

Raw OpenAI Chunk
ModelResponseStream(id='chatcmpl-a1b184e5-9f97-4d6f-b08a-2b67aecea87c', created=1762144786, model=None, object='chat.completion.chunk', system_fingerprint=None, choices=[StreamingChoices(finish_reason=None, index=0, delta=Delta(provider_specific_fields=None, content='', role=None, function_call=None, tool_calls=None, audio=None), logprobs=None)], provider_specific_fields=None, usage=None)

model_response finish reason 3: None; response_obj={'text': '', 'is_finished': False, 'finish_reason': None, 'logprobs': None, 'original_chunk': ModelResponseStream(id='chatcmpl-a1b184e5-9f97-4d6f-b08a-2b67aecea87c', created=1762144786, model=None, object='chat.completion.chunk', system_fingerprint=None, choices=[StreamingChoices(finish_reason=None, index=0, delta=Delta(provider_specific_fields=None, content='', role=None, function_call=None, tool_calls=None, audio=None), logprobs=None)], provider_specific_fields=None, usage=None), 'usage': None}
original delta: {'provider_specific_fields': None, 'content': '', 'role': None, 'function_call': None, 'tool_calls': None, 'audio': None}
new delta: Delta(provider_specific_fields=None, content='', role=None, function_call=None, tool_calls=None, audio=None)
model_response.choices[0].delta: Delta(provider_specific_fields=None, content='', role=None, function_call=None, tool_calls=None, audio=None); completion_obj: {'content': ''}
self.sent_first_chunk: False
completion_obj: {'content': ''}, model_response.choices[0]: StreamingChoices(finish_reason=None, index=0, delta=Delta(provider_specific_fields=None, content='', role=None, function_call=None, tool_calls=None, audio=None), logprobs=None), response_obj: {'text': '', 'is_finished': False, 'finish_reason': None, 'logprobs': None, 'original_chunk': ModelResponseStream(id='chatcmpl-a1b184e5-9f97-4d6f-b08a-2b67aecea87c', created=1762144786, model=None, object='chat.completion.chunk', system_fingerprint=None, choices=[StreamingChoices(finish_reason=None, index=0, delta=Delta(provider_specific_fields=None, content='', role=None, function_call=None, tool_calls=None, audio=None), logprobs=None)], provider_specific_fields=None, usage=None), 'usage': None}
model_response finish reason 3: None; response_obj={'text': '', 'is_finished': False, 'finish_reason': '', 'usage': None, 'index': 0, 'tool_use': None}
model_response.choices[0].delta: Delta(provider_specific_fields=None, content=None, role=None, function_call=None, tool_calls=None, audio=None); completion_obj: {'content': ''}
self.sent_first_chunk: False
completion_obj: {'content': ''}, model_response.choices[0]: StreamingChoices(finish_reason=None, index=0, delta=Delta(provider_specific_fields=None, content=None, role=None, function_call=None, tool_calls=None, audio=None), logprobs=None), response_obj: {'text': '', 'is_finished': False, 'finish_reason': '', 'usage': None, 'index': 0, 'tool_use': None}
model_response finish reason 3: None; response_obj={'text': '', 'is_finished': False, 'finish_reason': '', 'usage': None, 'index': 0, 'tool_use': None}
model_response.choices[0].delta: Delta(provider_specific_fields=None, content=None, role=None, function_call=None, tool_calls=None, audio=None); completion_obj: {'content': ''}
self.sent_first_chunk: False
completion_obj: {'content': ''}, model_response.choices[0]: StreamingChoices(finish_reason=None, index=0, delta=Delta(provider_specific_fields=None, content=None, role=None, function_call=None, tool_calls=None, audio=None), logprobs=None), response_obj: {'text': '', 'is_finished': False, 'finish_reason': '', 'usage': None, 'index': 0, 'tool_use': None}

Raw OpenAI Chunk
ModelResponseStream(id='chatcmpl-a1b184e5-9f97-4d6f-b08a-2b67aecea87c', created=1762144786, model=None, object='chat.completion.chunk', system_fingerprint=None, choices=[StreamingChoices(finish_reason=None, index=0, delta=Delta(provider_specific_fields=None, content='No', role=None, function_call=None, tool_calls=None, audio=None), logprobs=None)], provider_specific_fields=None, usage=None)

model_response finish reason 3: None; response_obj={'text': 'No', 'is_finished': False, 'finish_reason': None, 'logprobs': None, 'original_chunk': ModelResponseStream(id='chatcmpl-a1b184e5-9f97-4d6f-b08a-2b67aecea87c', created=1762144786, model=None, object='chat.completion.chunk', system_fingerprint=None, choices=[StreamingChoices(finish_reason=None, index=0, delta=Delta(provider_specific_fields=None, content='No', role=None, function_call=None, tool_calls=None, audio=None), logprobs=None)], provider_specific_fields=None, usage=None), 'usage': None}
original delta: {'provider_specific_fields': None, 'content': 'No', 'role': None, 'function_call': None, 'tool_calls': None, 'audio': None}
new delta: Delta(provider_specific_fields=None, content='No', role=None, function_call=None, tool_calls=None, audio=None)
model_response.choices[0].delta: Delta(provider_specific_fields=None, content='No', role=None, function_call=None, tool_calls=None, audio=None); completion_obj: {'content': 'No'}
self.sent_first_chunk: False
completion_obj: {'content': 'No'}, model_response.choices[0]: StreamingChoices(finish_reason=None, index=0, delta=Delta(provider_specific_fields=None, content='No', role=None, function_call=None, tool_calls=None, audio=None), logprobs=None), response_obj: {'text': 'No', 'is_finished': False, 'finish_reason': None, 'logprobs': None, 'original_chunk': ModelResponseStream(id='chatcmpl-a1b184e5-9f97-4d6f-b08a-2b67aecea87c', created=1762144786, model=None, object='chat.completion.chunk', system_fingerprint=None, choices=[StreamingChoices(finish_reason=None, index=0, delta=Delta(provider_specific_fields=None, content='No', role=None, function_call=None, tool_calls=None, audio=None), logprobs=None)], provider_specific_fields=None, usage=None), 'usage': None}
choice_json: {'index': 0, 'delta': {'provider_specific_fields': None, 'content': 'No', 'role': None, 'function_call': None, 'tool_calls': None, 'audio': None}, 'logprobs': None}
choices in streaming: [StreamingChoices(finish_reason=None, index=0, delta=Delta(provider_specific_fields=None, content='No', role=None, function_call=None, tool_calls=None, audio=None), logprobs=None)]
final returned processed chunk: ModelResponseStream(id='chatcmpl-a1b184e5-9f97-4d6f-b08a-2b67aecea87c', created=1762144786, model='claude-sonnet-4-5-20250929', object='chat.completion.chunk', system_fingerprint=None, choices=[StreamingChoices(finish_reason=None, index=0, delta=Delta(provider_specific_fields=None, content='No', role='assistant', function_call=None, tool_calls=None, audio=None), logprobs=None)], provider_specific_fields=None, citations=None)
model_response finish reason 3: None; response_obj={'text': '', 'is_finished': False, 'finish_reason': '', 'usage': None, 'index': 0, 'tool_use': None}
model_response.choices[0].delta: Delta(provider_specific_fields=None, content=None, role=None, function_call=None, tool_calls=None, audio=None); completion_obj: {'content': ''}
self.sent_first_chunk: True
completion_obj: {'content': ''}, model_response.choices[0]: StreamingChoices(finish_reason=None, index=0, delta=Delta(provider_specific_fields=None, content=None, role=None, function_call=None, tool_calls=None, audio=None), logprobs=None), response_obj: {'text': '', 'is_finished': False, 'finish_reason': '', 'usage': None, 'index': 0, 'tool_use': None}
model_response finish reason 3: None; response_obj={'text': '', 'is_finished': False, 'finish_reason': '', 'usage': None, 'index': 0, 'tool_use': None}
model_response.choices[0].delta: Delta(provider_specific_fields=None, content=None, role=None, function_call=None, tool_calls=None, audio=None); completion_obj: {'content': ''}
self.sent_first_chunk: False
completion_obj: {'content': ''}, model_response.choices[0]: StreamingChoices(finish_reason=None, index=0, delta=Delta(provider_specific_fields=None, content=None, role=None, function_call=None, tool_calls=None, audio=None), logprobs=None), response_obj: {'text': '', 'is_finished': False, 'finish_reason': '', 'usage': None, 'index': 0, 'tool_use': None}

Raw OpenAI Chunk
ModelResponseStream(id='chatcmpl-15308067-3203-475b-8351-38598d6b85e6', created=1762144786, model=None, object='chat.completion.chunk', system_fingerprint=None, choices=[StreamingChoices(finish_reason=None, index=0, delta=Delta(provider_specific_fields=None, content='', role=None, function_call=None, tool_calls=None, audio=None), logprobs=None)], provider_specific_fields=None, usage=Usage(completion_tokens=2, prompt_tokens=341, total_tokens=343, completion_tokens_details=None, prompt_tokens_details=PromptTokensDetailsWrapper(audio_tokens=None, cached_tokens=0, text_tokens=None, image_tokens=None, cache_creation_tokens=0, cache_creation_token_details=CacheCreationTokenDetails(ephemeral_5m_input_tokens=0, ephemeral_1h_input_tokens=0)), cache_creation_input_tokens=0, cache_read_input_tokens=0))

model_response finish reason 3: None; response_obj={'text': '', 'is_finished': False, 'finish_reason': None, 'logprobs': None, 'original_chunk': ModelResponseStream(id='chatcmpl-15308067-3203-475b-8351-38598d6b85e6', created=1762144786, model=None, object='chat.completion.chunk', system_fingerprint=None, choices=[StreamingChoices(finish_reason=None, index=0, delta=Delta(provider_specific_fields=None, content='', role=None, function_call=None, tool_calls=None, audio=None), logprobs=None)], provider_specific_fields=None, usage=Usage(completion_tokens=2, prompt_tokens=341, total_tokens=343, completion_tokens_details=None, prompt_tokens_details=PromptTokensDetailsWrapper(audio_tokens=None, cached_tokens=0, text_tokens=None, image_tokens=None, cache_creation_tokens=0, cache_creation_token_details=CacheCreationTokenDetails(ephemeral_5m_input_tokens=0, ephemeral_1h_input_tokens=0)), cache_creation_input_tokens=0, cache_read_input_tokens=0)), 'usage': Usage(completion_tokens=2, prompt_tokens=341, total_tokens=343, completion_tokens_details=None, prompt_tokens_details=PromptTokensDetailsWrapper(audio_tokens=None, cached_tokens=0, text_tokens=None, image_tokens=None, cache_creation_tokens=0, cache_creation_token_details=CacheCreationTokenDetails(ephemeral_5m_input_tokens=0, ephemeral_1h_input_tokens=0)), cache_creation_input_tokens=0, cache_read_input_tokens=0)}
original delta: {'provider_specific_fields': None, 'content': '', 'role': None, 'function_call': None, 'tool_calls': None, 'audio': None}
new delta: Delta(provider_specific_fields=None, content='', role=None, function_call=None, tool_calls=None, audio=None)
model_response.choices[0].delta: Delta(provider_specific_fields=None, content='', role=None, function_call=None, tool_calls=None, audio=None); completion_obj: {'content': ''}
self.sent_first_chunk: False
completion_obj: {'content': ''}, model_response.choices[0]: StreamingChoices(finish_reason=None, index=0, delta=Delta(provider_specific_fields=None, content='', role=None, function_call=None, tool_calls=None, audio=None), logprobs=None), response_obj: {'text': '', 'is_finished': False, 'finish_reason': None, 'logprobs': None, 'original_chunk': ModelResponseStream(id='chatcmpl-15308067-3203-475b-8351-38598d6b85e6', created=1762144786, model=None, object='chat.completion.chunk', system_fingerprint=None, choices=[StreamingChoices(finish_reason=None, index=0, delta=Delta(provider_specific_fields=None, content='', role=None, function_call=None, tool_calls=None, audio=None), logprobs=None)], provider_specific_fields=None, usage=Usage(completion_tokens=2, prompt_tokens=341, total_tokens=343, completion_tokens_details=None, prompt_tokens_details=PromptTokensDetailsWrapper(audio_tokens=None, cached_tokens=0, text_tokens=None, image_tokens=None, cache_creation_tokens=0, cache_creation_token_details=CacheCreationTokenDetails(ephemeral_5m_input_tokens=0, ephemeral_1h_input_tokens=0)), cache_creation_input_tokens=0, cache_read_input_tokens=0)), 'usage': Usage(completion_tokens=2, prompt_tokens=341, total_tokens=343, completion_tokens_details=None, prompt_tokens_details=PromptTokensDetailsWrapper(audio_tokens=None, cached_tokens=0, text_tokens=None, image_tokens=None, cache_creation_tokens=0, cache_creation_token_details=CacheCreationTokenDetails(ephemeral_5m_input_tokens=0, ephemeral_1h_input_tokens=0)), cache_creation_input_tokens=0, cache_read_input_tokens=0)}
model_response finish reason 3: None; response_obj={'text': '', 'is_finished': False, 'finish_reason': '', 'usage': None, 'index': 0, 'tool_use': None}
model_response.choices[0].delta: Delta(provider_specific_fields=None, content=None, role=None, function_call=None, tool_calls=None, audio=None); completion_obj: {'content': ''}
self.sent_first_chunk: False
completion_obj: {'content': ''}, model_response.choices[0]: StreamingChoices(finish_reason=None, index=0, delta=Delta(provider_specific_fields=None, content=None, role=None, function_call=None, tool_calls=None, audio=None), logprobs=None), response_obj: {'text': '', 'is_finished': False, 'finish_reason': '', 'usage': None, 'index': 0, 'tool_use': None}
model_response finish reason 3: None; response_obj={'text': '', 'is_finished': False, 'finish_reason': '', 'usage': None, 'index': 0, 'tool_use': None}
model_response.choices[0].delta: Delta(provider_specific_fields=None, content=None, role=None, function_call=None, tool_calls=None, audio=None); completion_obj: {'content': ''}
self.sent_first_chunk: False
completion_obj: {'content': ''}, model_response.choices[0]: StreamingChoices(finish_reason=None, index=0, delta=Delta(provider_specific_fields=None, content=None, role=None, function_call=None, tool_calls=None, audio=None), logprobs=None), response_obj: {'text': '', 'is_finished': False, 'finish_reason': '', 'usage': None, 'index': 0, 'tool_use': None}

Raw OpenAI Chunk
ModelResponseStream(id='chatcmpl-15308067-3203-475b-8351-38598d6b85e6', created=1762144786, model=None, object='chat.completion.chunk', system_fingerprint=None, choices=[StreamingChoices(finish_reason=None, index=0, delta=Delta(provider_specific_fields=None, content='', role=None, function_call=None, tool_calls=None, audio=None), logprobs=None)], provider_specific_fields=None, usage=None)

model_response finish reason 3: None; response_obj={'text': '', 'is_finished': False, 'finish_reason': None, 'logprobs': None, 'original_chunk': ModelResponseStream(id='chatcmpl-15308067-3203-475b-8351-38598d6b85e6', created=1762144786, model=None, object='chat.completion.chunk', system_fingerprint=None, choices=[StreamingChoices(finish_reason=None, index=0, delta=Delta(provider_specific_fields=None, content='', role=None, function_call=None, tool_calls=None, audio=None), logprobs=None)], provider_specific_fields=None, usage=None), 'usage': None}
original delta: {'provider_specific_fields': None, 'content': '', 'role': None, 'function_call': None, 'tool_calls': None, 'audio': None}
new delta: Delta(provider_specific_fields=None, content='', role=None, function_call=None, tool_calls=None, audio=None)
model_response.choices[0].delta: Delta(provider_specific_fields=None, content='', role=None, function_call=None, tool_calls=None, audio=None); completion_obj: {'content': ''}
self.sent_first_chunk: False
completion_obj: {'content': ''}, model_response.choices[0]: StreamingChoices(finish_reason=None, index=0, delta=Delta(provider_specific_fields=None, content='', role=None, function_call=None, tool_calls=None, audio=None), logprobs=None), response_obj: {'text': '', 'is_finished': False, 'finish_reason': None, 'logprobs': None, 'original_chunk': ModelResponseStream(id='chatcmpl-15308067-3203-475b-8351-38598d6b85e6', created=1762144786, model=None, object='chat.completion.chunk', system_fingerprint=None, choices=[StreamingChoices(finish_reason=None, index=0, delta=Delta(provider_specific_fields=None, content='', role=None, function_call=None, tool_calls=None, audio=None), logprobs=None)], provider_specific_fields=None, usage=None), 'usage': None}
model_response finish reason 3: None; response_obj={'text': '', 'is_finished': False, 'finish_reason': '', 'usage': None, 'index': 0, 'tool_use': None}
model_response.choices[0].delta: Delta(provider_specific_fields=None, content=None, role=None, function_call=None, tool_calls=None, audio=None); completion_obj: {'content': ''}
self.sent_first_chunk: False
completion_obj: {'content': ''}, model_response.choices[0]: StreamingChoices(finish_reason=None, index=0, delta=Delta(provider_specific_fields=None, content=None, role=None, function_call=None, tool_calls=None, audio=None), logprobs=None), response_obj: {'text': '', 'is_finished': False, 'finish_reason': '', 'usage': None, 'index': 0, 'tool_use': None}
model_response finish reason 3: None; response_obj={'text': '', 'is_finished': False, 'finish_reason': '', 'usage': None, 'index': 0, 'tool_use': None}
model_response.choices[0].delta: Delta(provider_specific_fields=None, content=None, role=None, function_call=None, tool_calls=None, audio=None); completion_obj: {'content': ''}
self.sent_first_chunk: False
completion_obj: {'content': ''}, model_response.choices[0]: StreamingChoices(finish_reason=None, index=0, delta=Delta(provider_specific_fields=None, content=None, role=None, function_call=None, tool_calls=None, audio=None), logprobs=None), response_obj: {'text': '', 'is_finished': False, 'finish_reason': '', 'usage': None, 'index': 0, 'tool_use': None}

Raw OpenAI Chunk
ModelResponseStream(id='chatcmpl-15308067-3203-475b-8351-38598d6b85e6', created=1762144786, model=None, object='chat.completion.chunk', system_fingerprint=None, choices=[StreamingChoices(finish_reason=None, index=0, delta=Delta(provider_specific_fields=None, content='Yes', role=None, function_call=None, tool_calls=None, audio=None), logprobs=None)], provider_specific_fields=None, usage=None)

model_response finish reason 3: None; response_obj={'text': 'Yes', 'is_finished': False, 'finish_reason': None, 'logprobs': None, 'original_chunk': ModelResponseStream(id='chatcmpl-15308067-3203-475b-8351-38598d6b85e6', created=1762144786, model=None, object='chat.completion.chunk', system_fingerprint=None, choices=[StreamingChoices(finish_reason=None, index=0, delta=Delta(provider_specific_fields=None, content='Yes', role=None, function_call=None, tool_calls=None, audio=None), logprobs=None)], provider_specific_fields=None, usage=None), 'usage': None}
original delta: {'provider_specific_fields': None, 'content': 'Yes', 'role': None, 'function_call': None, 'tool_calls': None, 'audio': None}
new delta: Delta(provider_specific_fields=None, content='Yes', role=None, function_call=None, tool_calls=None, audio=None)
model_response.choices[0].delta: Delta(provider_specific_fields=None, content='Yes', role=None, function_call=None, tool_calls=None, audio=None); completion_obj: {'content': 'Yes'}
self.sent_first_chunk: False
completion_obj: {'content': 'Yes'}, model_response.choices[0]: StreamingChoices(finish_reason=None, index=0, delta=Delta(provider_specific_fields=None, content='Yes', role=None, function_call=None, tool_calls=None, audio=None), logprobs=None), response_obj: {'text': 'Yes', 'is_finished': False, 'finish_reason': None, 'logprobs': None, 'original_chunk': ModelResponseStream(id='chatcmpl-15308067-3203-475b-8351-38598d6b85e6', created=1762144786, model=None, object='chat.completion.chunk', system_fingerprint=None, choices=[StreamingChoices(finish_reason=None, index=0, delta=Delta(provider_specific_fields=None, content='Yes', role=None, function_call=None, tool_calls=None, audio=None), logprobs=None)], provider_specific_fields=None, usage=None), 'usage': None}
choice_json: {'index': 0, 'delta': {'provider_specific_fields': None, 'content': 'Yes', 'role': None, 'function_call': None, 'tool_calls': None, 'audio': None}, 'logprobs': None}
choices in streaming: [StreamingChoices(finish_reason=None, index=0, delta=Delta(provider_specific_fields=None, content='Yes', role=None, function_call=None, tool_calls=None, audio=None), logprobs=None)]
final returned processed chunk: ModelResponseStream(id='chatcmpl-15308067-3203-475b-8351-38598d6b85e6', created=1762144786, model='claude-sonnet-4-5-20250929', object='chat.completion.chunk', system_fingerprint=None, choices=[StreamingChoices(finish_reason=None, index=0, delta=Delta(provider_specific_fields=None, content='Yes', role='assistant', function_call=None, tool_calls=None, audio=None), logprobs=None)], provider_specific_fields=None, citations=None)
model_response finish reason 3: None; response_obj={'text': '', 'is_finished': False, 'finish_reason': '', 'usage': None, 'index': 0, 'tool_use': None}
model_response.choices[0].delta: Delta(provider_specific_fields=None, content=None, role=None, function_call=None, tool_calls=None, audio=None); completion_obj: {'content': ''}
self.sent_first_chunk: True
completion_obj: {'content': ''}, model_response.choices[0]: StreamingChoices(finish_reason=None, index=0, delta=Delta(provider_specific_fields=None, content=None, role=None, function_call=None, tool_calls=None, audio=None), logprobs=None), response_obj: {'text': '', 'is_finished': False, 'finish_reason': '', 'usage': None, 'index': 0, 'tool_use': None}
model_response finish reason 3: None; response_obj={'text': '', 'is_finished': False, 'finish_reason': '', 'usage': None, 'index': 0, 'tool_use': None}
model_response.choices[0].delta: Delta(provider_specific_fields=None, content=None, role=None, function_call=None, tool_calls=None, audio=None); completion_obj: {'content': ''}
self.sent_first_chunk: True
completion_obj: {'content': ''}, model_response.choices[0]: StreamingChoices(finish_reason=None, index=0, delta=Delta(provider_specific_fields=None, content=None, role=None, function_call=None, tool_calls=None, audio=None), logprobs=None), response_obj: {'text': '', 'is_finished': False, 'finish_reason': '', 'usage': None, 'index': 0, 'tool_use': None}

Raw OpenAI Chunk
ModelResponseStream(id='chatcmpl-15308067-3203-475b-8351-38598d6b85e6', created=1762144786, model=None, object='chat.completion.chunk', system_fingerprint=None, choices=[StreamingChoices(finish_reason=None, index=0, delta=Delta(provider_specific_fields=None, content='', role=None, function_call=None, tool_calls=None, audio=None), logprobs=None)], provider_specific_fields=None, usage=None)

model_response finish reason 3: None; response_obj={'text': '', 'is_finished': False, 'finish_reason': None, 'logprobs': None, 'original_chunk': ModelResponseStream(id='chatcmpl-15308067-3203-475b-8351-38598d6b85e6', created=1762144786, model=None, object='chat.completion.chunk', system_fingerprint=None, choices=[StreamingChoices(finish_reason=None, index=0, delta=Delta(provider_specific_fields=None, content='', role=None, function_call=None, tool_calls=None, audio=None), logprobs=None)], provider_specific_fields=None, usage=None), 'usage': None}
original delta: {'provider_specific_fields': None, 'content': '', 'role': None, 'function_call': None, 'tool_calls': None, 'audio': None}
new delta: Delta(provider_specific_fields=None, content='', role=None, function_call=None, tool_calls=None, audio=None)
model_response.choices[0].delta: Delta(provider_specific_fields=None, content='', role=None, function_call=None, tool_calls=None, audio=None); completion_obj: {'content': ''}
self.sent_first_chunk: True
completion_obj: {'content': ''}, model_response.choices[0]: StreamingChoices(finish_reason=None, index=0, delta=Delta(provider_specific_fields=None, content='', role=None, function_call=None, tool_calls=None, audio=None), logprobs=None), response_obj: {'text': '', 'is_finished': False, 'finish_reason': None, 'logprobs': None, 'original_chunk': ModelResponseStream(id='chatcmpl-15308067-3203-475b-8351-38598d6b85e6', created=1762144786, model=None, object='chat.completion.chunk', system_fingerprint=None, choices=[StreamingChoices(finish_reason=None, index=0, delta=Delta(provider_specific_fields=None, content='', role=None, function_call=None, tool_calls=None, audio=None), logprobs=None)], provider_specific_fields=None, usage=None), 'usage': None}
model_response finish reason 3: None; response_obj={'text': '', 'is_finished': False, 'finish_reason': '', 'usage': None, 'index': 0, 'tool_use': None}
model_response.choices[0].delta: Delta(provider_specific_fields=None, content=None, role=None, function_call=None, tool_calls=None, audio=None); completion_obj: {'content': ''}
self.sent_first_chunk: True
completion_obj: {'content': ''}, model_response.choices[0]: StreamingChoices(finish_reason=None, index=0, delta=Delta(provider_specific_fields=None, content=None, role=None, function_call=None, tool_calls=None, audio=None), logprobs=None), response_obj: {'text': '', 'is_finished': False, 'finish_reason': '', 'usage': None, 'index': 0, 'tool_use': None}
model_response finish reason 3: None; response_obj={'text': '', 'is_finished': False, 'finish_reason': '', 'usage': None, 'index': 0, 'tool_use': None}
model_response.choices[0].delta: Delta(provider_specific_fields=None, content=None, role=None, function_call=None, tool_calls=None, audio=None); completion_obj: {'content': ''}
self.sent_first_chunk: True
completion_obj: {'content': ''}, model_response.choices[0]: StreamingChoices(finish_reason=None, index=0, delta=Delta(provider_specific_fields=None, content=None, role=None, function_call=None, tool_calls=None, audio=None), logprobs=None), response_obj: {'text': '', 'is_finished': False, 'finish_reason': '', 'usage': None, 'index': 0, 'tool_use': None}

Raw OpenAI Chunk
ModelResponseStream(id='chatcmpl-e84a7236-69b1-4003-a764-ca4be92e3b2d', created=1762144786, model=None, object='chat.completion.chunk', system_fingerprint=None, choices=[StreamingChoices(finish_reason=None, index=0, delta=Delta(provider_specific_fields=None, content='', role=None, function_call=None, tool_calls=None, audio=None), logprobs=None)], provider_specific_fields=None, usage=None)

model_response finish reason 3: None; response_obj={'text': '', 'is_finished': False, 'finish_reason': None, 'logprobs': None, 'original_chunk': ModelResponseStream(id='chatcmpl-e84a7236-69b1-4003-a764-ca4be92e3b2d', created=1762144786, model=None, object='chat.completion.chunk', system_fingerprint=None, choices=[StreamingChoices(finish_reason=None, index=0, delta=Delta(provider_specific_fields=None, content='', role=None, function_call=None, tool_calls=None, audio=None), logprobs=None)], provider_specific_fields=None, usage=None), 'usage': None}
original delta: {'provider_specific_fields': None, 'content': '', 'role': None, 'function_call': None, 'tool_calls': None, 'audio': None}
new delta: Delta(provider_specific_fields=None, content='', role=None, function_call=None, tool_calls=None, audio=None)
model_response.choices[0].delta: Delta(provider_specific_fields=None, content='', role=None, function_call=None, tool_calls=None, audio=None); completion_obj: {'content': ''}
self.sent_first_chunk: True
completion_obj: {'content': ''}, model_response.choices[0]: StreamingChoices(finish_reason=None, index=0, delta=Delta(provider_specific_fields=None, content='', role=None, function_call=None, tool_calls=None, audio=None), logprobs=None), response_obj: {'text': '', 'is_finished': False, 'finish_reason': None, 'logprobs': None, 'original_chunk': ModelResponseStream(id='chatcmpl-e84a7236-69b1-4003-a764-ca4be92e3b2d', created=1762144786, model=None, object='chat.completion.chunk', system_fingerprint=None, choices=[StreamingChoices(finish_reason=None, index=0, delta=Delta(provider_specific_fields=None, content='', role=None, function_call=None, tool_calls=None, audio=None), logprobs=None)], provider_specific_fields=None, usage=None), 'usage': None}
model_response finish reason 3: None; response_obj={'text': '', 'is_finished': False, 'finish_reason': '', 'usage': None, 'index': 0, 'tool_use': None}
model_response.choices[0].delta: Delta(provider_specific_fields=None, content=None, role=None, function_call=None, tool_calls=None, audio=None); completion_obj: {'content': ''}
self.sent_first_chunk: True
completion_obj: {'content': ''}, model_response.choices[0]: StreamingChoices(finish_reason=None, index=0, delta=Delta(provider_specific_fields=None, content=None, role=None, function_call=None, tool_calls=None, audio=None), logprobs=None), response_obj: {'text': '', 'is_finished': False, 'finish_reason': '', 'usage': None, 'index': 0, 'tool_use': None}
model_response finish reason 3: None; response_obj={'text': '', 'is_finished': False, 'finish_reason': '', 'usage': None, 'index': 0, 'tool_use': None}
model_response.choices[0].delta: Delta(provider_specific_fields=None, content=None, role=None, function_call=None, tool_calls=None, audio=None); completion_obj: {'content': ''}
self.sent_first_chunk: True
completion_obj: {'content': ''}, model_response.choices[0]: StreamingChoices(finish_reason=None, index=0, delta=Delta(provider_specific_fields=None, content=None, role=None, function_call=None, tool_calls=None, audio=None), logprobs=None), response_obj: {'text': '', 'is_finished': False, 'finish_reason': '', 'usage': None, 'index': 0, 'tool_use': None}

Raw OpenAI Chunk
ModelResponseStream(id='chatcmpl-15308067-3203-475b-8351-38598d6b85e6', created=1762144786, model=None, object='chat.completion.chunk', system_fingerprint=None, choices=[StreamingChoices(finish_reason='stop', index=0, delta=Delta(provider_specific_fields=None, content='', role=None, function_call=None, tool_calls=None, audio=None), logprobs=None)], provider_specific_fields=None, usage=Usage(completion_tokens=4, prompt_tokens=341, total_tokens=345, completion_tokens_details=None, prompt_tokens_details=PromptTokensDetailsWrapper(audio_tokens=None, cached_tokens=0, text_tokens=None, image_tokens=None, cache_creation_tokens=0), cache_creation_input_tokens=0, cache_read_input_tokens=0))

model_response finish reason 3: stop; response_obj={'text': '', 'is_finished': True, 'finish_reason': 'stop', 'logprobs': None, 'original_chunk': ModelResponseStream(id='chatcmpl-15308067-3203-475b-8351-38598d6b85e6', created=1762144786, model=None, object='chat.completion.chunk', system_fingerprint=None, choices=[StreamingChoices(finish_reason='stop', index=0, delta=Delta(provider_specific_fields=None, content='', role=None, function_call=None, tool_calls=None, audio=None), logprobs=None)], provider_specific_fields=None, usage=Usage(completion_tokens=4, prompt_tokens=341, total_tokens=345, completion_tokens_details=None, prompt_tokens_details=PromptTokensDetailsWrapper(audio_tokens=None, cached_tokens=0, text_tokens=None, image_tokens=None, cache_creation_tokens=0), cache_creation_input_tokens=0, cache_read_input_tokens=0)), 'usage': Usage(completion_tokens=4, prompt_tokens=341, total_tokens=345, completion_tokens_details=None, prompt_tokens_details=PromptTokensDetailsWrapper(audio_tokens=None, cached_tokens=0, text_tokens=None, image_tokens=None, cache_creation_tokens=0), cache_creation_input_tokens=0, cache_read_input_tokens=0)}
original delta: {'provider_specific_fields': None, 'content': '', 'role': None, 'function_call': None, 'tool_calls': None, 'audio': None}
new delta: Delta(provider_specific_fields=None, content='', role=None, function_call=None, tool_calls=None, audio=None)
model_response.choices[0].delta: Delta(provider_specific_fields=None, content='', role=None, function_call=None, tool_calls=None, audio=None); completion_obj: {'content': ''}
self.sent_first_chunk: True
completion_obj: {'content': ''}, model_response.choices[0]: StreamingChoices(finish_reason=None, index=0, delta=Delta(provider_specific_fields=None, content='', role=None, function_call=None, tool_calls=None, audio=None), logprobs=None), response_obj: {'text': '', 'is_finished': True, 'finish_reason': 'stop', 'logprobs': None, 'original_chunk': ModelResponseStream(id='chatcmpl-15308067-3203-475b-8351-38598d6b85e6', created=1762144786, model=None, object='chat.completion.chunk', system_fingerprint=None, choices=[StreamingChoices(finish_reason='stop', index=0, delta=Delta(provider_specific_fields=None, content='', role=None, function_call=None, tool_calls=None, audio=None), logprobs=None)], provider_specific_fields=None, usage=Usage(completion_tokens=4, prompt_tokens=341, total_tokens=345, completion_tokens_details=None, prompt_tokens_details=PromptTokensDetailsWrapper(audio_tokens=None, cached_tokens=0, text_tokens=None, image_tokens=None, cache_creation_tokens=0), cache_creation_input_tokens=0, cache_read_input_tokens=0)), 'usage': Usage(completion_tokens=4, prompt_tokens=341, total_tokens=345, completion_tokens_details=None, prompt_tokens_details=PromptTokensDetailsWrapper(audio_tokens=None, cached_tokens=0, text_tokens=None, image_tokens=None, cache_creation_tokens=0), cache_creation_input_tokens=0, cache_read_input_tokens=0)}
final returned processed chunk: ModelResponseStream(id='chatcmpl-15308067-3203-475b-8351-38598d6b85e6', created=1762144786, model='claude-sonnet-4-5-20250929', object='chat.completion.chunk', system_fingerprint=None, choices=[StreamingChoices(finish_reason='stop', index=0, delta=Delta(provider_specific_fields=None, content=None, role=None, function_call=None, tool_calls=None, audio=None), logprobs=None)], provider_specific_fields=None)
model_response finish reason 3: None; response_obj={'text': '', 'is_finished': False, 'finish_reason': '', 'usage': None, 'index': 0, 'tool_use': None}
model_response.choices[0].delta: Delta(provider_specific_fields=None, content=None, role=None, function_call=None, tool_calls=None, audio=None); completion_obj: {'content': ''}
self.sent_first_chunk: True
completion_obj: {'content': ''}, model_response.choices[0]: StreamingChoices(finish_reason=None, index=0, delta=Delta(provider_specific_fields=None, content=None, role=None, function_call=None, tool_calls=None, audio=None), logprobs=None), response_obj: {'text': '', 'is_finished': False, 'finish_reason': '', 'usage': None, 'index': 0, 'tool_use': None}

Raw OpenAI Chunk
ModelResponseStream(id='chatcmpl-e84a7236-69b1-4003-a764-ca4be92e3b2d', created=1762144786, model=None, object='chat.completion.chunk', system_fingerprint=None, choices=[StreamingChoices(finish_reason='stop', index=0, delta=Delta(provider_specific_fields=None, content='', role=None, function_call=None, tool_calls=None, audio=None), logprobs=None)], provider_specific_fields=None, usage=Usage(completion_tokens=4, prompt_tokens=1193, total_tokens=1197, completion_tokens_details=None, prompt_tokens_details=PromptTokensDetailsWrapper(audio_tokens=None, cached_tokens=0, text_tokens=None, image_tokens=None, cache_creation_tokens=0), cache_creation_input_tokens=0, cache_read_input_tokens=0))

model_response finish reason 3: stop; response_obj={'text': '', 'is_finished': True, 'finish_reason': 'stop', 'logprobs': None, 'original_chunk': ModelResponseStream(id='chatcmpl-e84a7236-69b1-4003-a764-ca4be92e3b2d', created=1762144786, model=None, object='chat.completion.chunk', system_fingerprint=None, choices=[StreamingChoices(finish_reason='stop', index=0, delta=Delta(provider_specific_fields=None, content='', role=None, function_call=None, tool_calls=None, audio=None), logprobs=None)], provider_specific_fields=None, usage=Usage(completion_tokens=4, prompt_tokens=1193, total_tokens=1197, completion_tokens_details=None, prompt_tokens_details=PromptTokensDetailsWrapper(audio_tokens=None, cached_tokens=0, text_tokens=None, image_tokens=None, cache_creation_tokens=0), cache_creation_input_tokens=0, cache_read_input_tokens=0)), 'usage': Usage(completion_tokens=4, prompt_tokens=1193, total_tokens=1197, completion_tokens_details=None, prompt_tokens_details=PromptTokensDetailsWrapper(audio_tokens=None, cached_tokens=0, text_tokens=None, image_tokens=None, cache_creation_tokens=0), cache_creation_input_tokens=0, cache_read_input_tokens=0)}
original delta: {'provider_specific_fields': None, 'content': '', 'role': None, 'function_call': None, 'tool_calls': None, 'audio': None}
new delta: Delta(provider_specific_fields=None, content='', role=None, function_call=None, tool_calls=None, audio=None)
model_response.choices[0].delta: Delta(provider_specific_fields=None, content='', role=None, function_call=None, tool_calls=None, audio=None); completion_obj: {'content': ''}
self.sent_first_chunk: True
completion_obj: {'content': ''}, model_response.choices[0]: StreamingChoices(finish_reason=None, index=0, delta=Delta(provider_specific_fields=None, content='', role=None, function_call=None, tool_calls=None, audio=None), logprobs=None), response_obj: {'text': '', 'is_finished': True, 'finish_reason': 'stop', 'logprobs': None, 'original_chunk': ModelResponseStream(id='chatcmpl-e84a7236-69b1-4003-a764-ca4be92e3b2d', created=1762144786, model=None, object='chat.completion.chunk', system_fingerprint=None, choices=[StreamingChoices(finish_reason='stop', index=0, delta=Delta(provider_specific_fields=None, content='', role=None, function_call=None, tool_calls=None, audio=None), logprobs=None)], provider_specific_fields=None, usage=Usage(completion_tokens=4, prompt_tokens=1193, total_tokens=1197, completion_tokens_details=None, prompt_tokens_details=PromptTokensDetailsWrapper(audio_tokens=None, cached_tokens=0, text_tokens=None, image_tokens=None, cache_creation_tokens=0), cache_creation_input_tokens=0, cache_read_input_tokens=0)), 'usage': Usage(completion_tokens=4, prompt_tokens=1193, total_tokens=1197, completion_tokens_details=None, prompt_tokens_details=PromptTokensDetailsWrapper(audio_tokens=None, cached_tokens=0, text_tokens=None, image_tokens=None, cache_creation_tokens=0), cache_creation_input_tokens=0, cache_read_input_tokens=0)}
final returned processed chunk: ModelResponseStream(id='chatcmpl-e84a7236-69b1-4003-a764-ca4be92e3b2d', created=1762144786, model='claude-sonnet-4-5-20250929', object='chat.completion.chunk', system_fingerprint=None, choices=[StreamingChoices(finish_reason='stop', index=0, delta=Delta(provider_specific_fields=None, content=None, role=None, function_call=None, tool_calls=None, audio=None), logprobs=None)], provider_specific_fields=None)
INFO:     127.0.0.1:53917 - "GET /v1/models HTTP/1.1" 200 OK
INFO:     127.0.0.1:53920 - "POST /v1/chat/completions HTTP/1.1" 200 OK
Initialized litellm callbacks, Async Success Callbacks: [<litellm.proxy.hooks.model_max_budget_limiter._PROXY_VirtualKeyModelMaxBudgetLimiter object at 0x120d623c0>]
ASYNC kwargs[caching]: False; litellm.cache: None; kwargs.get('cache'): None
Final returned optional params: {'stream': True, 'tools': []}
_is_function_call: False
makes async anthropic streaming POST request
model_response finish reason 3: None; response_obj={'text': '', 'is_finished': False, 'finish_reason': '', 'usage': None, 'index': 0, 'tool_use': None}
model_response.choices[0].delta: Delta(provider_specific_fields=None, content=None, role=None, function_call=None, tool_calls=None, audio=None); completion_obj: {'content': ''}
self.sent_first_chunk: True
completion_obj: {'content': ''}, model_response.choices[0]: StreamingChoices(finish_reason=None, index=0, delta=Delta(provider_specific_fields=None, content=None, role=None, function_call=None, tool_calls=None, audio=None), logprobs=None), response_obj: {'text': '', 'is_finished': False, 'finish_reason': '', 'usage': None, 'index': 0, 'tool_use': None}

Raw OpenAI Chunk
ModelResponseStream(id='chatcmpl-a1b184e5-9f97-4d6f-b08a-2b67aecea87c', created=1762144786, model=None, object='chat.completion.chunk', system_fingerprint=None, choices=[StreamingChoices(finish_reason=None, index=0, delta=Delta(provider_specific_fields=None, content='', role=None, function_call=None, tool_calls=None, audio=None), logprobs=None)], provider_specific_fields=None, usage=None)

model_response finish reason 3: None; response_obj={'text': '', 'is_finished': False, 'finish_reason': None, 'logprobs': None, 'original_chunk': ModelResponseStream(id='chatcmpl-a1b184e5-9f97-4d6f-b08a-2b67aecea87c', created=1762144786, model=None, object='chat.completion.chunk', system_fingerprint=None, choices=[StreamingChoices(finish_reason=None, index=0, delta=Delta(provider_specific_fields=None, content='', role=None, function_call=None, tool_calls=None, audio=None), logprobs=None)], provider_specific_fields=None, usage=None), 'usage': None}
original delta: {'provider_specific_fields': None, 'content': '', 'role': None, 'function_call': None, 'tool_calls': None, 'audio': None}
new delta: Delta(provider_specific_fields=None, content='', role=None, function_call=None, tool_calls=None, audio=None)
model_response.choices[0].delta: Delta(provider_specific_fields=None, content='', role=None, function_call=None, tool_calls=None, audio=None); completion_obj: {'content': ''}
self.sent_first_chunk: True
completion_obj: {'content': ''}, model_response.choices[0]: StreamingChoices(finish_reason=None, index=0, delta=Delta(provider_specific_fields=None, content='', role=None, function_call=None, tool_calls=None, audio=None), logprobs=None), response_obj: {'text': '', 'is_finished': False, 'finish_reason': None, 'logprobs': None, 'original_chunk': ModelResponseStream(id='chatcmpl-a1b184e5-9f97-4d6f-b08a-2b67aecea87c', created=1762144786, model=None, object='chat.completion.chunk', system_fingerprint=None, choices=[StreamingChoices(finish_reason=None, index=0, delta=Delta(provider_specific_fields=None, content='', role=None, function_call=None, tool_calls=None, audio=None), logprobs=None)], provider_specific_fields=None, usage=None), 'usage': None}
model_response finish reason 3: None; response_obj={'text': '', 'is_finished': False, 'finish_reason': '', 'usage': None, 'index': 0, 'tool_use': None}
model_response.choices[0].delta: Delta(provider_specific_fields=None, content=None, role=None, function_call=None, tool_calls=None, audio=None); completion_obj: {'content': ''}
self.sent_first_chunk: True
completion_obj: {'content': ''}, model_response.choices[0]: StreamingChoices(finish_reason=None, index=0, delta=Delta(provider_specific_fields=None, content=None, role=None, function_call=None, tool_calls=None, audio=None), logprobs=None), response_obj: {'text': '', 'is_finished': False, 'finish_reason': '', 'usage': None, 'index': 0, 'tool_use': None}
model_response finish reason 3: None; response_obj={'text': '', 'is_finished': False, 'finish_reason': '', 'usage': None, 'index': 0, 'tool_use': None}
model_response.choices[0].delta: Delta(provider_specific_fields=None, content=None, role=None, function_call=None, tool_calls=None, audio=None); completion_obj: {'content': ''}
self.sent_first_chunk: True
completion_obj: {'content': ''}, model_response.choices[0]: StreamingChoices(finish_reason=None, index=0, delta=Delta(provider_specific_fields=None, content=None, role=None, function_call=None, tool_calls=None, audio=None), logprobs=None), response_obj: {'text': '', 'is_finished': False, 'finish_reason': '', 'usage': None, 'index': 0, 'tool_use': None}

Raw OpenAI Chunk
ModelResponseStream(id='chatcmpl-a1b184e5-9f97-4d6f-b08a-2b67aecea87c', created=1762144786, model=None, object='chat.completion.chunk', system_fingerprint=None, choices=[StreamingChoices(finish_reason='stop', index=0, delta=Delta(provider_specific_fields=None, content='', role=None, function_call=None, tool_calls=None, audio=None), logprobs=None)], provider_specific_fields=None, usage=Usage(completion_tokens=4, prompt_tokens=1288, total_tokens=1292, completion_tokens_details=None, prompt_tokens_details=PromptTokensDetailsWrapper(audio_tokens=None, cached_tokens=0, text_tokens=None, image_tokens=None, cache_creation_tokens=0), cache_creation_input_tokens=0, cache_read_input_tokens=0))

model_response finish reason 3: stop; response_obj={'text': '', 'is_finished': True, 'finish_reason': 'stop', 'logprobs': None, 'original_chunk': ModelResponseStream(id='chatcmpl-a1b184e5-9f97-4d6f-b08a-2b67aecea87c', created=1762144786, model=None, object='chat.completion.chunk', system_fingerprint=None, choices=[StreamingChoices(finish_reason='stop', index=0, delta=Delta(provider_specific_fields=None, content='', role=None, function_call=None, tool_calls=None, audio=None), logprobs=None)], provider_specific_fields=None, usage=Usage(completion_tokens=4, prompt_tokens=1288, total_tokens=1292, completion_tokens_details=None, prompt_tokens_details=PromptTokensDetailsWrapper(audio_tokens=None, cached_tokens=0, text_tokens=None, image_tokens=None, cache_creation_tokens=0), cache_creation_input_tokens=0, cache_read_input_tokens=0)), 'usage': Usage(completion_tokens=4, prompt_tokens=1288, total_tokens=1292, completion_tokens_details=None, prompt_tokens_details=PromptTokensDetailsWrapper(audio_tokens=None, cached_tokens=0, text_tokens=None, image_tokens=None, cache_creation_tokens=0), cache_creation_input_tokens=0, cache_read_input_tokens=0)}
original delta: {'provider_specific_fields': None, 'content': '', 'role': None, 'function_call': None, 'tool_calls': None, 'audio': None}
new delta: Delta(provider_specific_fields=None, content='', role=None, function_call=None, tool_calls=None, audio=None)
model_response.choices[0].delta: Delta(provider_specific_fields=None, content='', role=None, function_call=None, tool_calls=None, audio=None); completion_obj: {'content': ''}
self.sent_first_chunk: True
completion_obj: {'content': ''}, model_response.choices[0]: StreamingChoices(finish_reason=None, index=0, delta=Delta(provider_specific_fields=None, content='', role=None, function_call=None, tool_calls=None, audio=None), logprobs=None), response_obj: {'text': '', 'is_finished': True, 'finish_reason': 'stop', 'logprobs': None, 'original_chunk': ModelResponseStream(id='chatcmpl-a1b184e5-9f97-4d6f-b08a-2b67aecea87c', created=1762144786, model=None, object='chat.completion.chunk', system_fingerprint=None, choices=[StreamingChoices(finish_reason='stop', index=0, delta=Delta(provider_specific_fields=None, content='', role=None, function_call=None, tool_calls=None, audio=None), logprobs=None)], provider_specific_fields=None, usage=Usage(completion_tokens=4, prompt_tokens=1288, total_tokens=1292, completion_tokens_details=None, prompt_tokens_details=PromptTokensDetailsWrapper(audio_tokens=None, cached_tokens=0, text_tokens=None, image_tokens=None, cache_creation_tokens=0), cache_creation_input_tokens=0, cache_read_input_tokens=0)), 'usage': Usage(completion_tokens=4, prompt_tokens=1288, total_tokens=1292, completion_tokens_details=None, prompt_tokens_details=PromptTokensDetailsWrapper(audio_tokens=None, cached_tokens=0, text_tokens=None, image_tokens=None, cache_creation_tokens=0), cache_creation_input_tokens=0, cache_read_input_tokens=0)}
final returned processed chunk: ModelResponseStream(id='chatcmpl-a1b184e5-9f97-4d6f-b08a-2b67aecea87c', created=1762144786, model='claude-sonnet-4-5-20250929', object='chat.completion.chunk', system_fingerprint=None, choices=[StreamingChoices(finish_reason='stop', index=0, delta=Delta(provider_specific_fields=None, content=None, role=None, function_call=None, tool_calls=None, audio=None), logprobs=None)], provider_specific_fields=None)
model_response finish reason 3: None; response_obj={'text': '', 'is_finished': False, 'finish_reason': '', 'usage': None, 'index': 0, 'tool_use': None}
model_response.choices[0].delta: Delta(provider_specific_fields=None, content=None, role=None, function_call=None, tool_calls=None, audio=None); completion_obj: {'content': ''}
self.sent_first_chunk: False
completion_obj: {'content': ''}, model_response.choices[0]: StreamingChoices(finish_reason=None, index=0, delta=Delta(provider_specific_fields=None, content=None, role=None, function_call=None, tool_calls=None, audio=None), logprobs=None), response_obj: {'text': '', 'is_finished': False, 'finish_reason': '', 'usage': None, 'index': 0, 'tool_use': None}

Raw OpenAI Chunk
ModelResponseStream(id='chatcmpl-0db176a8-027b-40e8-b48f-c4bab251f372', created=1762144788, model=None, object='chat.completion.chunk', system_fingerprint=None, choices=[StreamingChoices(finish_reason=None, index=0, delta=Delta(provider_specific_fields=None, content='', role=None, function_call=None, tool_calls=None, audio=None), logprobs=None)], provider_specific_fields=None, usage=Usage(completion_tokens=1, prompt_tokens=496, total_tokens=497, completion_tokens_details=None, prompt_tokens_details=PromptTokensDetailsWrapper(audio_tokens=None, cached_tokens=0, text_tokens=None, image_tokens=None, cache_creation_tokens=0, cache_creation_token_details=CacheCreationTokenDetails(ephemeral_5m_input_tokens=0, ephemeral_1h_input_tokens=0)), cache_creation_input_tokens=0, cache_read_input_tokens=0))

model_response finish reason 3: None; response_obj={'text': '', 'is_finished': False, 'finish_reason': None, 'logprobs': None, 'original_chunk': ModelResponseStream(id='chatcmpl-0db176a8-027b-40e8-b48f-c4bab251f372', created=1762144788, model=None, object='chat.completion.chunk', system_fingerprint=None, choices=[StreamingChoices(finish_reason=None, index=0, delta=Delta(provider_specific_fields=None, content='', role=None, function_call=None, tool_calls=None, audio=None), logprobs=None)], provider_specific_fields=None, usage=Usage(completion_tokens=1, prompt_tokens=496, total_tokens=497, completion_tokens_details=None, prompt_tokens_details=PromptTokensDetailsWrapper(audio_tokens=None, cached_tokens=0, text_tokens=None, image_tokens=None, cache_creation_tokens=0, cache_creation_token_details=CacheCreationTokenDetails(ephemeral_5m_input_tokens=0, ephemeral_1h_input_tokens=0)), cache_creation_input_tokens=0, cache_read_input_tokens=0)), 'usage': Usage(completion_tokens=1, prompt_tokens=496, total_tokens=497, completion_tokens_details=None, prompt_tokens_details=PromptTokensDetailsWrapper(audio_tokens=None, cached_tokens=0, text_tokens=None, image_tokens=None, cache_creation_tokens=0, cache_creation_token_details=CacheCreationTokenDetails(ephemeral_5m_input_tokens=0, ephemeral_1h_input_tokens=0)), cache_creation_input_tokens=0, cache_read_input_tokens=0)}
original delta: {'provider_specific_fields': None, 'content': '', 'role': None, 'function_call': None, 'tool_calls': None, 'audio': None}
new delta: Delta(provider_specific_fields=None, content='', role=None, function_call=None, tool_calls=None, audio=None)
model_response.choices[0].delta: Delta(provider_specific_fields=None, content='', role=None, function_call=None, tool_calls=None, audio=None); completion_obj: {'content': ''}
self.sent_first_chunk: False
completion_obj: {'content': ''}, model_response.choices[0]: StreamingChoices(finish_reason=None, index=0, delta=Delta(provider_specific_fields=None, content='', role=None, function_call=None, tool_calls=None, audio=None), logprobs=None), response_obj: {'text': '', 'is_finished': False, 'finish_reason': None, 'logprobs': None, 'original_chunk': ModelResponseStream(id='chatcmpl-0db176a8-027b-40e8-b48f-c4bab251f372', created=1762144788, model=None, object='chat.completion.chunk', system_fingerprint=None, choices=[StreamingChoices(finish_reason=None, index=0, delta=Delta(provider_specific_fields=None, content='', role=None, function_call=None, tool_calls=None, audio=None), logprobs=None)], provider_specific_fields=None, usage=Usage(completion_tokens=1, prompt_tokens=496, total_tokens=497, completion_tokens_details=None, prompt_tokens_details=PromptTokensDetailsWrapper(audio_tokens=None, cached_tokens=0, text_tokens=None, image_tokens=None, cache_creation_tokens=0, cache_creation_token_details=CacheCreationTokenDetails(ephemeral_5m_input_tokens=0, ephemeral_1h_input_tokens=0)), cache_creation_input_tokens=0, cache_read_input_tokens=0)), 'usage': Usage(completion_tokens=1, prompt_tokens=496, total_tokens=497, completion_tokens_details=None, prompt_tokens_details=PromptTokensDetailsWrapper(audio_tokens=None, cached_tokens=0, text_tokens=None, image_tokens=None, cache_creation_tokens=0, cache_creation_token_details=CacheCreationTokenDetails(ephemeral_5m_input_tokens=0, ephemeral_1h_input_tokens=0)), cache_creation_input_tokens=0, cache_read_input_tokens=0)}
model_response finish reason 3: None; response_obj={'text': '', 'is_finished': False, 'finish_reason': '', 'usage': None, 'index': 0, 'tool_use': None}
model_response.choices[0].delta: Delta(provider_specific_fields=None, content=None, role=None, function_call=None, tool_calls=None, audio=None); completion_obj: {'content': ''}
self.sent_first_chunk: False
completion_obj: {'content': ''}, model_response.choices[0]: StreamingChoices(finish_reason=None, index=0, delta=Delta(provider_specific_fields=None, content=None, role=None, function_call=None, tool_calls=None, audio=None), logprobs=None), response_obj: {'text': '', 'is_finished': False, 'finish_reason': '', 'usage': None, 'index': 0, 'tool_use': None}
model_response finish reason 3: None; response_obj={'text': '', 'is_finished': False, 'finish_reason': '', 'usage': None, 'index': 0, 'tool_use': None}
model_response.choices[0].delta: Delta(provider_specific_fields=None, content=None, role=None, function_call=None, tool_calls=None, audio=None); completion_obj: {'content': ''}
self.sent_first_chunk: False
completion_obj: {'content': ''}, model_response.choices[0]: StreamingChoices(finish_reason=None, index=0, delta=Delta(provider_specific_fields=None, content=None, role=None, function_call=None, tool_calls=None, audio=None), logprobs=None), response_obj: {'text': '', 'is_finished': False, 'finish_reason': '', 'usage': None, 'index': 0, 'tool_use': None}

Raw OpenAI Chunk
ModelResponseStream(id='chatcmpl-0db176a8-027b-40e8-b48f-c4bab251f372', created=1762144788, model=None, object='chat.completion.chunk', system_fingerprint=None, choices=[StreamingChoices(finish_reason=None, index=0, delta=Delta(provider_specific_fields=None, content='', role=None, function_call=None, tool_calls=None, audio=None), logprobs=None)], provider_specific_fields=None, usage=None)

model_response finish reason 3: None; response_obj={'text': '', 'is_finished': False, 'finish_reason': None, 'logprobs': None, 'original_chunk': ModelResponseStream(id='chatcmpl-0db176a8-027b-40e8-b48f-c4bab251f372', created=1762144788, model=None, object='chat.completion.chunk', system_fingerprint=None, choices=[StreamingChoices(finish_reason=None, index=0, delta=Delta(provider_specific_fields=None, content='', role=None, function_call=None, tool_calls=None, audio=None), logprobs=None)], provider_specific_fields=None, usage=None), 'usage': None}
original delta: {'provider_specific_fields': None, 'content': '', 'role': None, 'function_call': None, 'tool_calls': None, 'audio': None}
new delta: Delta(provider_specific_fields=None, content='', role=None, function_call=None, tool_calls=None, audio=None)
model_response.choices[0].delta: Delta(provider_specific_fields=None, content='', role=None, function_call=None, tool_calls=None, audio=None); completion_obj: {'content': ''}
self.sent_first_chunk: False
completion_obj: {'content': ''}, model_response.choices[0]: StreamingChoices(finish_reason=None, index=0, delta=Delta(provider_specific_fields=None, content='', role=None, function_call=None, tool_calls=None, audio=None), logprobs=None), response_obj: {'text': '', 'is_finished': False, 'finish_reason': None, 'logprobs': None, 'original_chunk': ModelResponseStream(id='chatcmpl-0db176a8-027b-40e8-b48f-c4bab251f372', created=1762144788, model=None, object='chat.completion.chunk', system_fingerprint=None, choices=[StreamingChoices(finish_reason=None, index=0, delta=Delta(provider_specific_fields=None, content='', role=None, function_call=None, tool_calls=None, audio=None), logprobs=None)], provider_specific_fields=None, usage=None), 'usage': None}
model_response finish reason 3: None; response_obj={'text': '', 'is_finished': False, 'finish_reason': '', 'usage': None, 'index': 0, 'tool_use': None}
model_response.choices[0].delta: Delta(provider_specific_fields=None, content=None, role=None, function_call=None, tool_calls=None, audio=None); completion_obj: {'content': ''}
self.sent_first_chunk: False
completion_obj: {'content': ''}, model_response.choices[0]: StreamingChoices(finish_reason=None, index=0, delta=Delta(provider_specific_fields=None, content=None, role=None, function_call=None, tool_calls=None, audio=None), logprobs=None), response_obj: {'text': '', 'is_finished': False, 'finish_reason': '', 'usage': None, 'index': 0, 'tool_use': None}
model_response finish reason 3: None; response_obj={'text': '', 'is_finished': False, 'finish_reason': '', 'usage': None, 'index': 0, 'tool_use': None}
model_response.choices[0].delta: Delta(provider_specific_fields=None, content=None, role=None, function_call=None, tool_calls=None, audio=None); completion_obj: {'content': ''}
self.sent_first_chunk: False
completion_obj: {'content': ''}, model_response.choices[0]: StreamingChoices(finish_reason=None, index=0, delta=Delta(provider_specific_fields=None, content=None, role=None, function_call=None, tool_calls=None, audio=None), logprobs=None), response_obj: {'text': '', 'is_finished': False, 'finish_reason': '', 'usage': None, 'index': 0, 'tool_use': None}

Raw OpenAI Chunk
ModelResponseStream(id='chatcmpl-0db176a8-027b-40e8-b48f-c4bab251f372', created=1762144788, model=None, object='chat.completion.chunk', system_fingerprint=None, choices=[StreamingChoices(finish_reason=None, index=0, delta=Delta(provider_specific_fields=None, content='No', role=None, function_call=None, tool_calls=None, audio=None), logprobs=None)], provider_specific_fields=None, usage=None)

model_response finish reason 3: None; response_obj={'text': 'No', 'is_finished': False, 'finish_reason': None, 'logprobs': None, 'original_chunk': ModelResponseStream(id='chatcmpl-0db176a8-027b-40e8-b48f-c4bab251f372', created=1762144788, model=None, object='chat.completion.chunk', system_fingerprint=None, choices=[StreamingChoices(finish_reason=None, index=0, delta=Delta(provider_specific_fields=None, content='No', role=None, function_call=None, tool_calls=None, audio=None), logprobs=None)], provider_specific_fields=None, usage=None), 'usage': None}
original delta: {'provider_specific_fields': None, 'content': 'No', 'role': None, 'function_call': None, 'tool_calls': None, 'audio': None}
new delta: Delta(provider_specific_fields=None, content='No', role=None, function_call=None, tool_calls=None, audio=None)
model_response.choices[0].delta: Delta(provider_specific_fields=None, content='No', role=None, function_call=None, tool_calls=None, audio=None); completion_obj: {'content': 'No'}
self.sent_first_chunk: False
completion_obj: {'content': 'No'}, model_response.choices[0]: StreamingChoices(finish_reason=None, index=0, delta=Delta(provider_specific_fields=None, content='No', role=None, function_call=None, tool_calls=None, audio=None), logprobs=None), response_obj: {'text': 'No', 'is_finished': False, 'finish_reason': None, 'logprobs': None, 'original_chunk': ModelResponseStream(id='chatcmpl-0db176a8-027b-40e8-b48f-c4bab251f372', created=1762144788, model=None, object='chat.completion.chunk', system_fingerprint=None, choices=[StreamingChoices(finish_reason=None, index=0, delta=Delta(provider_specific_fields=None, content='No', role=None, function_call=None, tool_calls=None, audio=None), logprobs=None)], provider_specific_fields=None, usage=None), 'usage': None}
choice_json: {'index': 0, 'delta': {'provider_specific_fields': None, 'content': 'No', 'role': None, 'function_call': None, 'tool_calls': None, 'audio': None}, 'logprobs': None}
choices in streaming: [StreamingChoices(finish_reason=None, index=0, delta=Delta(provider_specific_fields=None, content='No', role=None, function_call=None, tool_calls=None, audio=None), logprobs=None)]
final returned processed chunk: ModelResponseStream(id='chatcmpl-0db176a8-027b-40e8-b48f-c4bab251f372', created=1762144788, model='claude-sonnet-4-5-20250929', object='chat.completion.chunk', system_fingerprint=None, choices=[StreamingChoices(finish_reason=None, index=0, delta=Delta(provider_specific_fields=None, content='No', role='assistant', function_call=None, tool_calls=None, audio=None), logprobs=None)], provider_specific_fields=None, citations=None)
model_response finish reason 3: None; response_obj={'text': '', 'is_finished': False, 'finish_reason': '', 'usage': None, 'index': 0, 'tool_use': None}
model_response.choices[0].delta: Delta(provider_specific_fields=None, content=None, role=None, function_call=None, tool_calls=None, audio=None); completion_obj: {'content': ''}
self.sent_first_chunk: True
completion_obj: {'content': ''}, model_response.choices[0]: StreamingChoices(finish_reason=None, index=0, delta=Delta(provider_specific_fields=None, content=None, role=None, function_call=None, tool_calls=None, audio=None), logprobs=None), response_obj: {'text': '', 'is_finished': False, 'finish_reason': '', 'usage': None, 'index': 0, 'tool_use': None}
model_response finish reason 3: None; response_obj={'text': '', 'is_finished': False, 'finish_reason': '', 'usage': None, 'index': 0, 'tool_use': None}
model_response.choices[0].delta: Delta(provider_specific_fields=None, content=None, role=None, function_call=None, tool_calls=None, audio=None); completion_obj: {'content': ''}
self.sent_first_chunk: True
completion_obj: {'content': ''}, model_response.choices[0]: StreamingChoices(finish_reason=None, index=0, delta=Delta(provider_specific_fields=None, content=None, role=None, function_call=None, tool_calls=None, audio=None), logprobs=None), response_obj: {'text': '', 'is_finished': False, 'finish_reason': '', 'usage': None, 'index': 0, 'tool_use': None}

Raw OpenAI Chunk
ModelResponseStream(id='chatcmpl-0db176a8-027b-40e8-b48f-c4bab251f372', created=1762144788, model=None, object='chat.completion.chunk', system_fingerprint=None, choices=[StreamingChoices(finish_reason=None, index=0, delta=Delta(provider_specific_fields=None, content='', role=None, function_call=None, tool_calls=None, audio=None), logprobs=None)], provider_specific_fields=None, usage=None)

model_response finish reason 3: None; response_obj={'text': '', 'is_finished': False, 'finish_reason': None, 'logprobs': None, 'original_chunk': ModelResponseStream(id='chatcmpl-0db176a8-027b-40e8-b48f-c4bab251f372', created=1762144788, model=None, object='chat.completion.chunk', system_fingerprint=None, choices=[StreamingChoices(finish_reason=None, index=0, delta=Delta(provider_specific_fields=None, content='', role=None, function_call=None, tool_calls=None, audio=None), logprobs=None)], provider_specific_fields=None, usage=None), 'usage': None}
original delta: {'provider_specific_fields': None, 'content': '', 'role': None, 'function_call': None, 'tool_calls': None, 'audio': None}
new delta: Delta(provider_specific_fields=None, content='', role=None, function_call=None, tool_calls=None, audio=None)
model_response.choices[0].delta: Delta(provider_specific_fields=None, content='', role=None, function_call=None, tool_calls=None, audio=None); completion_obj: {'content': ''}
self.sent_first_chunk: True
completion_obj: {'content': ''}, model_response.choices[0]: StreamingChoices(finish_reason=None, index=0, delta=Delta(provider_specific_fields=None, content='', role=None, function_call=None, tool_calls=None, audio=None), logprobs=None), response_obj: {'text': '', 'is_finished': False, 'finish_reason': None, 'logprobs': None, 'original_chunk': ModelResponseStream(id='chatcmpl-0db176a8-027b-40e8-b48f-c4bab251f372', created=1762144788, model=None, object='chat.completion.chunk', system_fingerprint=None, choices=[StreamingChoices(finish_reason=None, index=0, delta=Delta(provider_specific_fields=None, content='', role=None, function_call=None, tool_calls=None, audio=None), logprobs=None)], provider_specific_fields=None, usage=None), 'usage': None}
model_response finish reason 3: None; response_obj={'text': '', 'is_finished': False, 'finish_reason': '', 'usage': None, 'index': 0, 'tool_use': None}
model_response.choices[0].delta: Delta(provider_specific_fields=None, content=None, role=None, function_call=None, tool_calls=None, audio=None); completion_obj: {'content': ''}
self.sent_first_chunk: True
completion_obj: {'content': ''}, model_response.choices[0]: StreamingChoices(finish_reason=None, index=0, delta=Delta(provider_specific_fields=None, content=None, role=None, function_call=None, tool_calls=None, audio=None), logprobs=None), response_obj: {'text': '', 'is_finished': False, 'finish_reason': '', 'usage': None, 'index': 0, 'tool_use': None}
model_response finish reason 3: None; response_obj={'text': '', 'is_finished': False, 'finish_reason': '', 'usage': None, 'index': 0, 'tool_use': None}
model_response.choices[0].delta: Delta(provider_specific_fields=None, content=None, role=None, function_call=None, tool_calls=None, audio=None); completion_obj: {'content': ''}
self.sent_first_chunk: True
completion_obj: {'content': ''}, model_response.choices[0]: StreamingChoices(finish_reason=None, index=0, delta=Delta(provider_specific_fields=None, content=None, role=None, function_call=None, tool_calls=None, audio=None), logprobs=None), response_obj: {'text': '', 'is_finished': False, 'finish_reason': '', 'usage': None, 'index': 0, 'tool_use': None}

Raw OpenAI Chunk
ModelResponseStream(id='chatcmpl-0db176a8-027b-40e8-b48f-c4bab251f372', created=1762144788, model=None, object='chat.completion.chunk', system_fingerprint=None, choices=[StreamingChoices(finish_reason='stop', index=0, delta=Delta(provider_specific_fields=None, content='', role=None, function_call=None, tool_calls=None, audio=None), logprobs=None)], provider_specific_fields=None, usage=Usage(completion_tokens=4, prompt_tokens=496, total_tokens=500, completion_tokens_details=None, prompt_tokens_details=PromptTokensDetailsWrapper(audio_tokens=None, cached_tokens=0, text_tokens=None, image_tokens=None, cache_creation_tokens=0), cache_creation_input_tokens=0, cache_read_input_tokens=0))

model_response finish reason 3: stop; response_obj={'text': '', 'is_finished': True, 'finish_reason': 'stop', 'logprobs': None, 'original_chunk': ModelResponseStream(id='chatcmpl-0db176a8-027b-40e8-b48f-c4bab251f372', created=1762144788, model=None, object='chat.completion.chunk', system_fingerprint=None, choices=[StreamingChoices(finish_reason='stop', index=0, delta=Delta(provider_specific_fields=None, content='', role=None, function_call=None, tool_calls=None, audio=None), logprobs=None)], provider_specific_fields=None, usage=Usage(completion_tokens=4, prompt_tokens=496, total_tokens=500, completion_tokens_details=None, prompt_tokens_details=PromptTokensDetailsWrapper(audio_tokens=None, cached_tokens=0, text_tokens=None, image_tokens=None, cache_creation_tokens=0), cache_creation_input_tokens=0, cache_read_input_tokens=0)), 'usage': Usage(completion_tokens=4, prompt_tokens=496, total_tokens=500, completion_tokens_details=None, prompt_tokens_details=PromptTokensDetailsWrapper(audio_tokens=None, cached_tokens=0, text_tokens=None, image_tokens=None, cache_creation_tokens=0), cache_creation_input_tokens=0, cache_read_input_tokens=0)}
original delta: {'provider_specific_fields': None, 'content': '', 'role': None, 'function_call': None, 'tool_calls': None, 'audio': None}
new delta: Delta(provider_specific_fields=None, content='', role=None, function_call=None, tool_calls=None, audio=None)
model_response.choices[0].delta: Delta(provider_specific_fields=None, content='', role=None, function_call=None, tool_calls=None, audio=None); completion_obj: {'content': ''}
self.sent_first_chunk: True
completion_obj: {'content': ''}, model_response.choices[0]: StreamingChoices(finish_reason=None, index=0, delta=Delta(provider_specific_fields=None, content='', role=None, function_call=None, tool_calls=None, audio=None), logprobs=None), response_obj: {'text': '', 'is_finished': True, 'finish_reason': 'stop', 'logprobs': None, 'original_chunk': ModelResponseStream(id='chatcmpl-0db176a8-027b-40e8-b48f-c4bab251f372', created=1762144788, model=None, object='chat.completion.chunk', system_fingerprint=None, choices=[StreamingChoices(finish_reason='stop', index=0, delta=Delta(provider_specific_fields=None, content='', role=None, function_call=None, tool_calls=None, audio=None), logprobs=None)], provider_specific_fields=None, usage=Usage(completion_tokens=4, prompt_tokens=496, total_tokens=500, completion_tokens_details=None, prompt_tokens_details=PromptTokensDetailsWrapper(audio_tokens=None, cached_tokens=0, text_tokens=None, image_tokens=None, cache_creation_tokens=0), cache_creation_input_tokens=0, cache_read_input_tokens=0)), 'usage': Usage(completion_tokens=4, prompt_tokens=496, total_tokens=500, completion_tokens_details=None, prompt_tokens_details=PromptTokensDetailsWrapper(audio_tokens=None, cached_tokens=0, text_tokens=None, image_tokens=None, cache_creation_tokens=0), cache_creation_input_tokens=0, cache_read_input_tokens=0)}
final returned processed chunk: ModelResponseStream(id='chatcmpl-0db176a8-027b-40e8-b48f-c4bab251f372', created=1762144788, model='claude-sonnet-4-5-20250929', object='chat.completion.chunk', system_fingerprint=None, choices=[StreamingChoices(finish_reason='stop', index=0, delta=Delta(provider_specific_fields=None, content=None, role=None, function_call=None, tool_calls=None, audio=None), logprobs=None)], provider_specific_fields=None)
INFO:     127.0.0.1:53926 - "GET /v1/models HTTP/1.1" 200 OK
INFO:     127.0.0.1:53932 - "GET /v1/models HTTP/1.1" 200 OK
INFO:     127.0.0.1:53944 - "GET /v1/models HTTP/1.1" 200 OK
INFO:     127.0.0.1:53950 - "GET /v1/models HTTP/1.1" 200 OK
INFO:     127.0.0.1:53957 - "GET /v1/models HTTP/1.1" 200 OK
INFO:     127.0.0.1:53961 - "GET /v1/models HTTP/1.1" 200 OK
INFO:     127.0.0.1:53970 - "GET /v1/models HTTP/1.1" 200 OK
INFO:     127.0.0.1:53978 - "GET /v1/models HTTP/1.1" 200 OK
INFO:     127.0.0.1:53986 - "GET /v1/models HTTP/1.1" 200 OK
INFO:     127.0.0.1:53991 - "GET /v1/models HTTP/1.1" 200 OK
INFO:     127.0.0.1:53994 - "GET /v1/models HTTP/1.1" 200 OK
INFO:     127.0.0.1:53999 - "GET /v1/models HTTP/1.1" 200 OK
INFO:     127.0.0.1:54004 - "GET /v1/models HTTP/1.1" 200 OK
INFO:     127.0.0.1:54007 - "GET /v1/models HTTP/1.1" 200 OK
INFO:     127.0.0.1:54034 - "GET /v1/models HTTP/1.1" 200 OK
INFO:     127.0.0.1:54041 - "GET /v1/models HTTP/1.1" 200 OK
