INFO:     127.0.0.1:53102 - "GET /health HTTP/1.1" 200 OK
INFO:     127.0.0.1:53104 - "GET /v1/models HTTP/1.1" 200 OK
INFO:     127.0.0.1:53105 - "GET /v1/models HTTP/1.1" 200 OK
INFO:     127.0.0.1:53106 - "GET /v1/models HTTP/1.1" 200 OK
INFO:     127.0.0.1:53107 - "GET /v1/models HTTP/1.1" 200 OK
INFO:     127.0.0.1:53108 - "GET /v1/models HTTP/1.1" 200 OK
INFO:     127.0.0.1:53110 - "GET /v1/models HTTP/1.1" 200 OK
INFO:     127.0.0.1:53111 - "GET /v1/models HTTP/1.1" 200 OK
INFO:     127.0.0.1:53113 - "GET /v1/models HTTP/1.1" 200 OK
INFO:     127.0.0.1:53114 - "GET /v1/models HTTP/1.1" 200 OK
INFO:     127.0.0.1:53115 - "GET /v1/models HTTP/1.1" 200 OK
INFO:     127.0.0.1:53119 - "GET /v1/models HTTP/1.1" 200 OK
INFO:     127.0.0.1:53120 - "GET /v1/models HTTP/1.1" 200 OK
INFO:     127.0.0.1:53121 - "GET /v1/models HTTP/1.1" 200 OK
INFO:     127.0.0.1:53122 - "GET /v1/models HTTP/1.1" 200 OK
INFO:     127.0.0.1:53133 - "GET /v1/models HTTP/1.1" 200 OK
INFO:     127.0.0.1:53134 - "POST /v1/chat/completions HTTP/1.1" 200 OK
Initialized litellm callbacks, Async Success Callbacks: [<litellm.proxy.hooks.model_max_budget_limiter._PROXY_VirtualKeyModelMaxBudgetLimiter object at 0x1131623c0>]
ASYNC kwargs[caching]: False; litellm.cache: None; kwargs.get('cache'): None
Final returned optional params: {'stream': True, 'tools': []}
_is_function_call: False
makes async anthropic streaming POST request
model_response finish reason 3: None; response_obj={'text': '', 'is_finished': False, 'finish_reason': '', 'usage': None, 'index': 0, 'tool_use': None}
model_response.choices[0].delta: Delta(provider_specific_fields=None, content=None, role=None, function_call=None, tool_calls=None, audio=None); completion_obj: {'content': ''}
self.sent_first_chunk: False
completion_obj: {'content': ''}, model_response.choices[0]: StreamingChoices(finish_reason=None, index=0, delta=Delta(provider_specific_fields=None, content=None, role=None, function_call=None, tool_calls=None, audio=None), logprobs=None), response_obj: {'text': '', 'is_finished': False, 'finish_reason': '', 'usage': None, 'index': 0, 'tool_use': None}

Raw OpenAI Chunk
ModelResponseStream(id='chatcmpl-1e246dec-1357-4ceb-948f-03d49e55b5f9', created=1762261907, model=None, object='chat.completion.chunk', system_fingerprint=None, choices=[StreamingChoices(finish_reason=None, index=0, delta=Delta(provider_specific_fields=None, content='', role=None, function_call=None, tool_calls=None, audio=None), logprobs=None)], provider_specific_fields=None, usage=Usage(completion_tokens=1, prompt_tokens=19880, total_tokens=19881, completion_tokens_details=None, prompt_tokens_details=PromptTokensDetailsWrapper(audio_tokens=None, cached_tokens=0, text_tokens=None, image_tokens=None, cache_creation_tokens=0, cache_creation_token_details=CacheCreationTokenDetails(ephemeral_5m_input_tokens=0, ephemeral_1h_input_tokens=0)), cache_creation_input_tokens=0, cache_read_input_tokens=0))

model_response finish reason 3: None; response_obj={'text': '', 'is_finished': False, 'finish_reason': None, 'logprobs': None, 'original_chunk': ModelResponseStream(id='chatcmpl-1e246dec-1357-4ceb-948f-03d49e55b5f9', created=1762261907, model=None, object='chat.completion.chunk', system_fingerprint=None, choices=[StreamingChoices(finish_reason=None, index=0, delta=Delta(provider_specific_fields=None, content='', role=None, function_call=None, tool_calls=None, audio=None), logprobs=None)], provider_specific_fields=None, usage=Usage(completion_tokens=1, prompt_tokens=19880, total_tokens=19881, completion_tokens_details=None, prompt_tokens_details=PromptTokensDetailsWrapper(audio_tokens=None, cached_tokens=0, text_tokens=None, image_tokens=None, cache_creation_tokens=0, cache_creation_token_details=CacheCreationTokenDetails(ephemeral_5m_input_tokens=0, ephemeral_1h_input_tokens=0)), cache_creation_input_tokens=0, cache_read_input_tokens=0)), 'usage': Usage(completion_tokens=1, prompt_tokens=19880, total_tokens=19881, completion_tokens_details=None, prompt_tokens_details=PromptTokensDetailsWrapper(audio_tokens=None, cached_tokens=0, text_tokens=None, image_tokens=None, cache_creation_tokens=0, cache_creation_token_details=CacheCreationTokenDetails(ephemeral_5m_input_tokens=0, ephemeral_1h_input_tokens=0)), cache_creation_input_tokens=0, cache_read_input_tokens=0)}
original delta: {'provider_specific_fields': None, 'content': '', 'role': None, 'function_call': None, 'tool_calls': None, 'audio': None}
new delta: Delta(provider_specific_fields=None, content='', role=None, function_call=None, tool_calls=None, audio=None)
model_response.choices[0].delta: Delta(provider_specific_fields=None, content='', role=None, function_call=None, tool_calls=None, audio=None); completion_obj: {'content': ''}
self.sent_first_chunk: False
completion_obj: {'content': ''}, model_response.choices[0]: StreamingChoices(finish_reason=None, index=0, delta=Delta(provider_specific_fields=None, content='', role=None, function_call=None, tool_calls=None, audio=None), logprobs=None), response_obj: {'text': '', 'is_finished': False, 'finish_reason': None, 'logprobs': None, 'original_chunk': ModelResponseStream(id='chatcmpl-1e246dec-1357-4ceb-948f-03d49e55b5f9', created=1762261907, model=None, object='chat.completion.chunk', system_fingerprint=None, choices=[StreamingChoices(finish_reason=None, index=0, delta=Delta(provider_specific_fields=None, content='', role=None, function_call=None, tool_calls=None, audio=None), logprobs=None)], provider_specific_fields=None, usage=Usage(completion_tokens=1, prompt_tokens=19880, total_tokens=19881, completion_tokens_details=None, prompt_tokens_details=PromptTokensDetailsWrapper(audio_tokens=None, cached_tokens=0, text_tokens=None, image_tokens=None, cache_creation_tokens=0, cache_creation_token_details=CacheCreationTokenDetails(ephemeral_5m_input_tokens=0, ephemeral_1h_input_tokens=0)), cache_creation_input_tokens=0, cache_read_input_tokens=0)), 'usage': Usage(completion_tokens=1, prompt_tokens=19880, total_tokens=19881, completion_tokens_details=None, prompt_tokens_details=PromptTokensDetailsWrapper(audio_tokens=None, cached_tokens=0, text_tokens=None, image_tokens=None, cache_creation_tokens=0, cache_creation_token_details=CacheCreationTokenDetails(ephemeral_5m_input_tokens=0, ephemeral_1h_input_tokens=0)), cache_creation_input_tokens=0, cache_read_input_tokens=0)}
model_response finish reason 3: None; response_obj={'text': '', 'is_finished': False, 'finish_reason': '', 'usage': None, 'index': 0, 'tool_use': None}
model_response.choices[0].delta: Delta(provider_specific_fields=None, content=None, role=None, function_call=None, tool_calls=None, audio=None); completion_obj: {'content': ''}
self.sent_first_chunk: False
completion_obj: {'content': ''}, model_response.choices[0]: StreamingChoices(finish_reason=None, index=0, delta=Delta(provider_specific_fields=None, content=None, role=None, function_call=None, tool_calls=None, audio=None), logprobs=None), response_obj: {'text': '', 'is_finished': False, 'finish_reason': '', 'usage': None, 'index': 0, 'tool_use': None}
model_response finish reason 3: None; response_obj={'text': '', 'is_finished': False, 'finish_reason': '', 'usage': None, 'index': 0, 'tool_use': None}
model_response.choices[0].delta: Delta(provider_specific_fields=None, content=None, role=None, function_call=None, tool_calls=None, audio=None); completion_obj: {'content': ''}
self.sent_first_chunk: False
completion_obj: {'content': ''}, model_response.choices[0]: StreamingChoices(finish_reason=None, index=0, delta=Delta(provider_specific_fields=None, content=None, role=None, function_call=None, tool_calls=None, audio=None), logprobs=None), response_obj: {'text': '', 'is_finished': False, 'finish_reason': '', 'usage': None, 'index': 0, 'tool_use': None}

Raw OpenAI Chunk
ModelResponseStream(id='chatcmpl-1e246dec-1357-4ceb-948f-03d49e55b5f9', created=1762261907, model=None, object='chat.completion.chunk', system_fingerprint=None, choices=[StreamingChoices(finish_reason=None, index=0, delta=Delta(provider_specific_fields=None, content='', role=None, function_call=None, tool_calls=None, audio=None), logprobs=None)], provider_specific_fields=None, usage=None)

model_response finish reason 3: None; response_obj={'text': '', 'is_finished': False, 'finish_reason': None, 'logprobs': None, 'original_chunk': ModelResponseStream(id='chatcmpl-1e246dec-1357-4ceb-948f-03d49e55b5f9', created=1762261907, model=None, object='chat.completion.chunk', system_fingerprint=None, choices=[StreamingChoices(finish_reason=None, index=0, delta=Delta(provider_specific_fields=None, content='', role=None, function_call=None, tool_calls=None, audio=None), logprobs=None)], provider_specific_fields=None, usage=None), 'usage': None}
original delta: {'provider_specific_fields': None, 'content': '', 'role': None, 'function_call': None, 'tool_calls': None, 'audio': None}
new delta: Delta(provider_specific_fields=None, content='', role=None, function_call=None, tool_calls=None, audio=None)
model_response.choices[0].delta: Delta(provider_specific_fields=None, content='', role=None, function_call=None, tool_calls=None, audio=None); completion_obj: {'content': ''}
self.sent_first_chunk: False
completion_obj: {'content': ''}, model_response.choices[0]: StreamingChoices(finish_reason=None, index=0, delta=Delta(provider_specific_fields=None, content='', role=None, function_call=None, tool_calls=None, audio=None), logprobs=None), response_obj: {'text': '', 'is_finished': False, 'finish_reason': None, 'logprobs': None, 'original_chunk': ModelResponseStream(id='chatcmpl-1e246dec-1357-4ceb-948f-03d49e55b5f9', created=1762261907, model=None, object='chat.completion.chunk', system_fingerprint=None, choices=[StreamingChoices(finish_reason=None, index=0, delta=Delta(provider_specific_fields=None, content='', role=None, function_call=None, tool_calls=None, audio=None), logprobs=None)], provider_specific_fields=None, usage=None), 'usage': None}
model_response finish reason 3: None; response_obj={'text': '', 'is_finished': False, 'finish_reason': '', 'usage': None, 'index': 0, 'tool_use': None}
model_response.choices[0].delta: Delta(provider_specific_fields=None, content=None, role=None, function_call=None, tool_calls=None, audio=None); completion_obj: {'content': ''}
self.sent_first_chunk: False
completion_obj: {'content': ''}, model_response.choices[0]: StreamingChoices(finish_reason=None, index=0, delta=Delta(provider_specific_fields=None, content=None, role=None, function_call=None, tool_calls=None, audio=None), logprobs=None), response_obj: {'text': '', 'is_finished': False, 'finish_reason': '', 'usage': None, 'index': 0, 'tool_use': None}
model_response finish reason 3: None; response_obj={'text': '', 'is_finished': False, 'finish_reason': '', 'usage': None, 'index': 0, 'tool_use': None}
model_response.choices[0].delta: Delta(provider_specific_fields=None, content=None, role=None, function_call=None, tool_calls=None, audio=None); completion_obj: {'content': ''}
self.sent_first_chunk: False
completion_obj: {'content': ''}, model_response.choices[0]: StreamingChoices(finish_reason=None, index=0, delta=Delta(provider_specific_fields=None, content=None, role=None, function_call=None, tool_calls=None, audio=None), logprobs=None), response_obj: {'text': '', 'is_finished': False, 'finish_reason': '', 'usage': None, 'index': 0, 'tool_use': None}

Raw OpenAI Chunk
ModelResponseStream(id='chatcmpl-1e246dec-1357-4ceb-948f-03d49e55b5f9', created=1762261907, model=None, object='chat.completion.chunk', system_fingerprint=None, choices=[StreamingChoices(finish_reason=None, index=0, delta=Delta(provider_specific_fields=None, content='Yes', role=None, function_call=None, tool_calls=None, audio=None), logprobs=None)], provider_specific_fields=None, usage=None)

model_response finish reason 3: None; response_obj={'text': 'Yes', 'is_finished': False, 'finish_reason': None, 'logprobs': None, 'original_chunk': ModelResponseStream(id='chatcmpl-1e246dec-1357-4ceb-948f-03d49e55b5f9', created=1762261907, model=None, object='chat.completion.chunk', system_fingerprint=None, choices=[StreamingChoices(finish_reason=None, index=0, delta=Delta(provider_specific_fields=None, content='Yes', role=None, function_call=None, tool_calls=None, audio=None), logprobs=None)], provider_specific_fields=None, usage=None), 'usage': None}
original delta: {'provider_specific_fields': None, 'content': 'Yes', 'role': None, 'function_call': None, 'tool_calls': None, 'audio': None}
new delta: Delta(provider_specific_fields=None, content='Yes', role=None, function_call=None, tool_calls=None, audio=None)
model_response.choices[0].delta: Delta(provider_specific_fields=None, content='Yes', role=None, function_call=None, tool_calls=None, audio=None); completion_obj: {'content': 'Yes'}
self.sent_first_chunk: False
completion_obj: {'content': 'Yes'}, model_response.choices[0]: StreamingChoices(finish_reason=None, index=0, delta=Delta(provider_specific_fields=None, content='Yes', role=None, function_call=None, tool_calls=None, audio=None), logprobs=None), response_obj: {'text': 'Yes', 'is_finished': False, 'finish_reason': None, 'logprobs': None, 'original_chunk': ModelResponseStream(id='chatcmpl-1e246dec-1357-4ceb-948f-03d49e55b5f9', created=1762261907, model=None, object='chat.completion.chunk', system_fingerprint=None, choices=[StreamingChoices(finish_reason=None, index=0, delta=Delta(provider_specific_fields=None, content='Yes', role=None, function_call=None, tool_calls=None, audio=None), logprobs=None)], provider_specific_fields=None, usage=None), 'usage': None}
choice_json: {'index': 0, 'delta': {'provider_specific_fields': None, 'content': 'Yes', 'role': None, 'function_call': None, 'tool_calls': None, 'audio': None}, 'logprobs': None}
choices in streaming: [StreamingChoices(finish_reason=None, index=0, delta=Delta(provider_specific_fields=None, content='Yes', role=None, function_call=None, tool_calls=None, audio=None), logprobs=None)]
final returned processed chunk: ModelResponseStream(id='chatcmpl-1e246dec-1357-4ceb-948f-03d49e55b5f9', created=1762261907, model='claude-sonnet-4-5-20250929', object='chat.completion.chunk', system_fingerprint=None, choices=[StreamingChoices(finish_reason=None, index=0, delta=Delta(provider_specific_fields=None, content='Yes', role='assistant', function_call=None, tool_calls=None, audio=None), logprobs=None)], provider_specific_fields=None, citations=None)
model_response finish reason 3: None; response_obj={'text': '', 'is_finished': False, 'finish_reason': '', 'usage': None, 'index': 0, 'tool_use': None}
model_response.choices[0].delta: Delta(provider_specific_fields=None, content=None, role=None, function_call=None, tool_calls=None, audio=None); completion_obj: {'content': ''}
self.sent_first_chunk: True
completion_obj: {'content': ''}, model_response.choices[0]: StreamingChoices(finish_reason=None, index=0, delta=Delta(provider_specific_fields=None, content=None, role=None, function_call=None, tool_calls=None, audio=None), logprobs=None), response_obj: {'text': '', 'is_finished': False, 'finish_reason': '', 'usage': None, 'index': 0, 'tool_use': None}
model_response finish reason 3: None; response_obj={'text': '', 'is_finished': False, 'finish_reason': '', 'usage': None, 'index': 0, 'tool_use': None}
model_response.choices[0].delta: Delta(provider_specific_fields=None, content=None, role=None, function_call=None, tool_calls=None, audio=None); completion_obj: {'content': ''}
self.sent_first_chunk: True
completion_obj: {'content': ''}, model_response.choices[0]: StreamingChoices(finish_reason=None, index=0, delta=Delta(provider_specific_fields=None, content=None, role=None, function_call=None, tool_calls=None, audio=None), logprobs=None), response_obj: {'text': '', 'is_finished': False, 'finish_reason': '', 'usage': None, 'index': 0, 'tool_use': None}

Raw OpenAI Chunk
ModelResponseStream(id='chatcmpl-1e246dec-1357-4ceb-948f-03d49e55b5f9', created=1762261907, model=None, object='chat.completion.chunk', system_fingerprint=None, choices=[StreamingChoices(finish_reason=None, index=0, delta=Delta(provider_specific_fields=None, content='!', role=None, function_call=None, tool_calls=None, audio=None), logprobs=None)], provider_specific_fields=None, usage=None)

model_response finish reason 3: None; response_obj={'text': '!', 'is_finished': False, 'finish_reason': None, 'logprobs': None, 'original_chunk': ModelResponseStream(id='chatcmpl-1e246dec-1357-4ceb-948f-03d49e55b5f9', created=1762261907, model=None, object='chat.completion.chunk', system_fingerprint=None, choices=[StreamingChoices(finish_reason=None, index=0, delta=Delta(provider_specific_fields=None, content='!', role=None, function_call=None, tool_calls=None, audio=None), logprobs=None)], provider_specific_fields=None, usage=None), 'usage': None}
original delta: {'provider_specific_fields': None, 'content': '!', 'role': None, 'function_call': None, 'tool_calls': None, 'audio': None}
new delta: Delta(provider_specific_fields=None, content='!', role=None, function_call=None, tool_calls=None, audio=None)
model_response.choices[0].delta: Delta(provider_specific_fields=None, content='!', role=None, function_call=None, tool_calls=None, audio=None); completion_obj: {'content': '!'}
self.sent_first_chunk: True
completion_obj: {'content': '!'}, model_response.choices[0]: StreamingChoices(finish_reason=None, index=0, delta=Delta(provider_specific_fields=None, content='!', role=None, function_call=None, tool_calls=None, audio=None), logprobs=None), response_obj: {'text': '!', 'is_finished': False, 'finish_reason': None, 'logprobs': None, 'original_chunk': ModelResponseStream(id='chatcmpl-1e246dec-1357-4ceb-948f-03d49e55b5f9', created=1762261907, model=None, object='chat.completion.chunk', system_fingerprint=None, choices=[StreamingChoices(finish_reason=None, index=0, delta=Delta(provider_specific_fields=None, content='!', role=None, function_call=None, tool_calls=None, audio=None), logprobs=None)], provider_specific_fields=None, usage=None), 'usage': None}
choice_json: {'index': 0, 'delta': {'provider_specific_fields': None, 'content': '!', 'role': None, 'function_call': None, 'tool_calls': None, 'audio': None}, 'logprobs': None}
choices in streaming: [StreamingChoices(finish_reason=None, index=0, delta=Delta(provider_specific_fields=None, content='!', role=None, function_call=None, tool_calls=None, audio=None), logprobs=None)]
final returned processed chunk: ModelResponseStream(id='chatcmpl-1e246dec-1357-4ceb-948f-03d49e55b5f9', created=1762261907, model='claude-sonnet-4-5-20250929', object='chat.completion.chunk', system_fingerprint=None, choices=[StreamingChoices(finish_reason=None, index=0, delta=Delta(provider_specific_fields=None, content='!', role=None, function_call=None, tool_calls=None, audio=None), logprobs=None)], provider_specific_fields=None, citations=None)
model_response finish reason 3: None; response_obj={'text': '', 'is_finished': False, 'finish_reason': '', 'usage': None, 'index': 0, 'tool_use': None}
model_response.choices[0].delta: Delta(provider_specific_fields=None, content=None, role=None, function_call=None, tool_calls=None, audio=None); completion_obj: {'content': ''}
self.sent_first_chunk: True
completion_obj: {'content': ''}, model_response.choices[0]: StreamingChoices(finish_reason=None, index=0, delta=Delta(provider_specific_fields=None, content=None, role=None, function_call=None, tool_calls=None, audio=None), logprobs=None), response_obj: {'text': '', 'is_finished': False, 'finish_reason': '', 'usage': None, 'index': 0, 'tool_use': None}
model_response finish reason 3: None; response_obj={'text': '', 'is_finished': False, 'finish_reason': '', 'usage': None, 'index': 0, 'tool_use': None}
model_response.choices[0].delta: Delta(provider_specific_fields=None, content=None, role=None, function_call=None, tool_calls=None, audio=None); completion_obj: {'content': ''}
self.sent_first_chunk: True
completion_obj: {'content': ''}, model_response.choices[0]: StreamingChoices(finish_reason=None, index=0, delta=Delta(provider_specific_fields=None, content=None, role=None, function_call=None, tool_calls=None, audio=None), logprobs=None), response_obj: {'text': '', 'is_finished': False, 'finish_reason': '', 'usage': None, 'index': 0, 'tool_use': None}

Raw OpenAI Chunk
ModelResponseStream(id='chatcmpl-1e246dec-1357-4ceb-948f-03d49e55b5f9', created=1762261908, model=None, object='chat.completion.chunk', system_fingerprint=None, choices=[StreamingChoices(finish_reason=None, index=0, delta=Delta(provider_specific_fields=None, content='', role=None, function_call=None, tool_calls=None, audio=None), logprobs=None)], provider_specific_fields=None, usage=None)

model_response finish reason 3: None; response_obj={'text': '', 'is_finished': False, 'finish_reason': None, 'logprobs': None, 'original_chunk': ModelResponseStream(id='chatcmpl-1e246dec-1357-4ceb-948f-03d49e55b5f9', created=1762261908, model=None, object='chat.completion.chunk', system_fingerprint=None, choices=[StreamingChoices(finish_reason=None, index=0, delta=Delta(provider_specific_fields=None, content='', role=None, function_call=None, tool_calls=None, audio=None), logprobs=None)], provider_specific_fields=None, usage=None), 'usage': None}
original delta: {'provider_specific_fields': None, 'content': '', 'role': None, 'function_call': None, 'tool_calls': None, 'audio': None}
new delta: Delta(provider_specific_fields=None, content='', role=None, function_call=None, tool_calls=None, audio=None)
model_response.choices[0].delta: Delta(provider_specific_fields=None, content='', role=None, function_call=None, tool_calls=None, audio=None); completion_obj: {'content': ''}
self.sent_first_chunk: True
completion_obj: {'content': ''}, model_response.choices[0]: StreamingChoices(finish_reason=None, index=0, delta=Delta(provider_specific_fields=None, content='', role=None, function_call=None, tool_calls=None, audio=None), logprobs=None), response_obj: {'text': '', 'is_finished': False, 'finish_reason': None, 'logprobs': None, 'original_chunk': ModelResponseStream(id='chatcmpl-1e246dec-1357-4ceb-948f-03d49e55b5f9', created=1762261908, model=None, object='chat.completion.chunk', system_fingerprint=None, choices=[StreamingChoices(finish_reason=None, index=0, delta=Delta(provider_specific_fields=None, content='', role=None, function_call=None, tool_calls=None, audio=None), logprobs=None)], provider_specific_fields=None, usage=None), 'usage': None}
model_response finish reason 3: None; response_obj={'text': '', 'is_finished': False, 'finish_reason': '', 'usage': None, 'index': 0, 'tool_use': None}
model_response.choices[0].delta: Delta(provider_specific_fields=None, content=None, role=None, function_call=None, tool_calls=None, audio=None); completion_obj: {'content': ''}
self.sent_first_chunk: True
completion_obj: {'content': ''}, model_response.choices[0]: StreamingChoices(finish_reason=None, index=0, delta=Delta(provider_specific_fields=None, content=None, role=None, function_call=None, tool_calls=None, audio=None), logprobs=None), response_obj: {'text': '', 'is_finished': False, 'finish_reason': '', 'usage': None, 'index': 0, 'tool_use': None}
model_response finish reason 3: None; response_obj={'text': '', 'is_finished': False, 'finish_reason': '', 'usage': None, 'index': 0, 'tool_use': None}
model_response.choices[0].delta: Delta(provider_specific_fields=None, content=None, role=None, function_call=None, tool_calls=None, audio=None); completion_obj: {'content': ''}
self.sent_first_chunk: True
completion_obj: {'content': ''}, model_response.choices[0]: StreamingChoices(finish_reason=None, index=0, delta=Delta(provider_specific_fields=None, content=None, role=None, function_call=None, tool_calls=None, audio=None), logprobs=None), response_obj: {'text': '', 'is_finished': False, 'finish_reason': '', 'usage': None, 'index': 0, 'tool_use': None}

Raw OpenAI Chunk
ModelResponseStream(id='chatcmpl-1e246dec-1357-4ceb-948f-03d49e55b5f9', created=1762261908, model=None, object='chat.completion.chunk', system_fingerprint=None, choices=[StreamingChoices(finish_reason=None, index=0, delta=Delta(provider_specific_fields=None, content=' I can identify', role=None, function_call=None, tool_calls=None, audio=None), logprobs=None)], provider_specific_fields=None, usage=None)

model_response finish reason 3: None; response_obj={'text': ' I can identify', 'is_finished': False, 'finish_reason': None, 'logprobs': None, 'original_chunk': ModelResponseStream(id='chatcmpl-1e246dec-1357-4ceb-948f-03d49e55b5f9', created=1762261908, model=None, object='chat.completion.chunk', system_fingerprint=None, choices=[StreamingChoices(finish_reason=None, index=0, delta=Delta(provider_specific_fields=None, content=' I can identify', role=None, function_call=None, tool_calls=None, audio=None), logprobs=None)], provider_specific_fields=None, usage=None), 'usage': None}
original delta: {'provider_specific_fields': None, 'content': ' I can identify', 'role': None, 'function_call': None, 'tool_calls': None, 'audio': None}
new delta: Delta(provider_specific_fields=None, content=' I can identify', role=None, function_call=None, tool_calls=None, audio=None)
model_response.choices[0].delta: Delta(provider_specific_fields=None, content=' I can identify', role=None, function_call=None, tool_calls=None, audio=None); completion_obj: {'content': ' I can identify'}
self.sent_first_chunk: True
completion_obj: {'content': ' I can identify'}, model_response.choices[0]: StreamingChoices(finish_reason=None, index=0, delta=Delta(provider_specific_fields=None, content=' I can identify', role=None, function_call=None, tool_calls=None, audio=None), logprobs=None), response_obj: {'text': ' I can identify', 'is_finished': False, 'finish_reason': None, 'logprobs': None, 'original_chunk': ModelResponseStream(id='chatcmpl-1e246dec-1357-4ceb-948f-03d49e55b5f9', created=1762261908, model=None, object='chat.completion.chunk', system_fingerprint=None, choices=[StreamingChoices(finish_reason=None, index=0, delta=Delta(provider_specific_fields=None, content=' I can identify', role=None, function_call=None, tool_calls=None, audio=None), logprobs=None)], provider_specific_fields=None, usage=None), 'usage': None}
choice_json: {'index': 0, 'delta': {'provider_specific_fields': None, 'content': ' I can identify', 'role': None, 'function_call': None, 'tool_calls': None, 'audio': None}, 'logprobs': None}
choices in streaming: [StreamingChoices(finish_reason=None, index=0, delta=Delta(provider_specific_fields=None, content=' I can identify', role=None, function_call=None, tool_calls=None, audio=None), logprobs=None)]
final returned processed chunk: ModelResponseStream(id='chatcmpl-1e246dec-1357-4ceb-948f-03d49e55b5f9', created=1762261907, model='claude-sonnet-4-5-20250929', object='chat.completion.chunk', system_fingerprint=None, choices=[StreamingChoices(finish_reason=None, index=0, delta=Delta(provider_specific_fields=None, content=' I can identify', role=None, function_call=None, tool_calls=None, audio=None), logprobs=None)], provider_specific_fields=None, citations=None)
model_response finish reason 3: None; response_obj={'text': '', 'is_finished': False, 'finish_reason': '', 'usage': None, 'index': 0, 'tool_use': None}
model_response.choices[0].delta: Delta(provider_specific_fields=None, content=None, role=None, function_call=None, tool_calls=None, audio=None); completion_obj: {'content': ''}
self.sent_first_chunk: True
completion_obj: {'content': ''}, model_response.choices[0]: StreamingChoices(finish_reason=None, index=0, delta=Delta(provider_specific_fields=None, content=None, role=None, function_call=None, tool_calls=None, audio=None), logprobs=None), response_obj: {'text': '', 'is_finished': False, 'finish_reason': '', 'usage': None, 'index': 0, 'tool_use': None}
model_response finish reason 3: None; response_obj={'text': '', 'is_finished': False, 'finish_reason': '', 'usage': None, 'index': 0, 'tool_use': None}
model_response.choices[0].delta: Delta(provider_specific_fields=None, content=None, role=None, function_call=None, tool_calls=None, audio=None); completion_obj: {'content': ''}
self.sent_first_chunk: True
completion_obj: {'content': ''}, model_response.choices[0]: StreamingChoices(finish_reason=None, index=0, delta=Delta(provider_specific_fields=None, content=None, role=None, function_call=None, tool_calls=None, audio=None), logprobs=None), response_obj: {'text': '', 'is_finished': False, 'finish_reason': '', 'usage': None, 'index': 0, 'tool_use': None}

Raw OpenAI Chunk
ModelResponseStream(id='chatcmpl-1e246dec-1357-4ceb-948f-03d49e55b5f9', created=1762261908, model=None, object='chat.completion.chunk', system_fingerprint=None, choices=[StreamingChoices(finish_reason=None, index=0, delta=Delta(provider_specific_fields=None, content=' you', role=None, function_call=None, tool_calls=None, audio=None), logprobs=None)], provider_specific_fields=None, usage=None)

model_response finish reason 3: None; response_obj={'text': ' you', 'is_finished': False, 'finish_reason': None, 'logprobs': None, 'original_chunk': ModelResponseStream(id='chatcmpl-1e246dec-1357-4ceb-948f-03d49e55b5f9', created=1762261908, model=None, object='chat.completion.chunk', system_fingerprint=None, choices=[StreamingChoices(finish_reason=None, index=0, delta=Delta(provider_specific_fields=None, content=' you', role=None, function_call=None, tool_calls=None, audio=None), logprobs=None)], provider_specific_fields=None, usage=None), 'usage': None}
original delta: {'provider_specific_fields': None, 'content': ' you', 'role': None, 'function_call': None, 'tool_calls': None, 'audio': None}
new delta: Delta(provider_specific_fields=None, content=' you', role=None, function_call=None, tool_calls=None, audio=None)
model_response.choices[0].delta: Delta(provider_specific_fields=None, content=' you', role=None, function_call=None, tool_calls=None, audio=None); completion_obj: {'content': ' you'}
self.sent_first_chunk: True
completion_obj: {'content': ' you'}, model_response.choices[0]: StreamingChoices(finish_reason=None, index=0, delta=Delta(provider_specific_fields=None, content=' you', role=None, function_call=None, tool_calls=None, audio=None), logprobs=None), response_obj: {'text': ' you', 'is_finished': False, 'finish_reason': None, 'logprobs': None, 'original_chunk': ModelResponseStream(id='chatcmpl-1e246dec-1357-4ceb-948f-03d49e55b5f9', created=1762261908, model=None, object='chat.completion.chunk', system_fingerprint=None, choices=[StreamingChoices(finish_reason=None, index=0, delta=Delta(provider_specific_fields=None, content=' you', role=None, function_call=None, tool_calls=None, audio=None), logprobs=None)], provider_specific_fields=None, usage=None), 'usage': None}
choice_json: {'index': 0, 'delta': {'provider_specific_fields': None, 'content': ' you', 'role': None, 'function_call': None, 'tool_calls': None, 'audio': None}, 'logprobs': None}
choices in streaming: [StreamingChoices(finish_reason=None, index=0, delta=Delta(provider_specific_fields=None, content=' you', role=None, function_call=None, tool_calls=None, audio=None), logprobs=None)]
final returned processed chunk: ModelResponseStream(id='chatcmpl-1e246dec-1357-4ceb-948f-03d49e55b5f9', created=1762261907, model='claude-sonnet-4-5-20250929', object='chat.completion.chunk', system_fingerprint=None, choices=[StreamingChoices(finish_reason=None, index=0, delta=Delta(provider_specific_fields=None, content=' you', role=None, function_call=None, tool_calls=None, audio=None), logprobs=None)], provider_specific_fields=None, citations=None)
model_response finish reason 3: None; response_obj={'text': '', 'is_finished': False, 'finish_reason': '', 'usage': None, 'index': 0, 'tool_use': None}
model_response.choices[0].delta: Delta(provider_specific_fields=None, content=None, role=None, function_call=None, tool_calls=None, audio=None); completion_obj: {'content': ''}
self.sent_first_chunk: True
completion_obj: {'content': ''}, model_response.choices[0]: StreamingChoices(finish_reason=None, index=0, delta=Delta(provider_specific_fields=None, content=None, role=None, function_call=None, tool_calls=None, audio=None), logprobs=None), response_obj: {'text': '', 'is_finished': False, 'finish_reason': '', 'usage': None, 'index': 0, 'tool_use': None}
model_response finish reason 3: None; response_obj={'text': '', 'is_finished': False, 'finish_reason': '', 'usage': None, 'index': 0, 'tool_use': None}
model_response.choices[0].delta: Delta(provider_specific_fields=None, content=None, role=None, function_call=None, tool_calls=None, audio=None); completion_obj: {'content': ''}
self.sent_first_chunk: True
completion_obj: {'content': ''}, model_response.choices[0]: StreamingChoices(finish_reason=None, index=0, delta=Delta(provider_specific_fields=None, content=None, role=None, function_call=None, tool_calls=None, audio=None), logprobs=None), response_obj: {'text': '', 'is_finished': False, 'finish_reason': '', 'usage': None, 'index': 0, 'tool_use': None}

Raw OpenAI Chunk
ModelResponseStream(id='chatcmpl-1e246dec-1357-4ceb-948f-03d49e55b5f9', created=1762261908, model=None, object='chat.completion.chunk', system_fingerprint=None, choices=[StreamingChoices(finish_reason=None, index=0, delta=Delta(provider_specific_fields=None, content=' as a **', role=None, function_call=None, tool_calls=None, audio=None), logprobs=None)], provider_specific_fields=None, usage=None)

model_response finish reason 3: None; response_obj={'text': ' as a **', 'is_finished': False, 'finish_reason': None, 'logprobs': None, 'original_chunk': ModelResponseStream(id='chatcmpl-1e246dec-1357-4ceb-948f-03d49e55b5f9', created=1762261908, model=None, object='chat.completion.chunk', system_fingerprint=None, choices=[StreamingChoices(finish_reason=None, index=0, delta=Delta(provider_specific_fields=None, content=' as a **', role=None, function_call=None, tool_calls=None, audio=None), logprobs=None)], provider_specific_fields=None, usage=None), 'usage': None}
original delta: {'provider_specific_fields': None, 'content': ' as a **', 'role': None, 'function_call': None, 'tool_calls': None, 'audio': None}
new delta: Delta(provider_specific_fields=None, content=' as a **', role=None, function_call=None, tool_calls=None, audio=None)
model_response.choices[0].delta: Delta(provider_specific_fields=None, content=' as a **', role=None, function_call=None, tool_calls=None, audio=None); completion_obj: {'content': ' as a **'}
self.sent_first_chunk: True
completion_obj: {'content': ' as a **'}, model_response.choices[0]: StreamingChoices(finish_reason=None, index=0, delta=Delta(provider_specific_fields=None, content=' as a **', role=None, function_call=None, tool_calls=None, audio=None), logprobs=None), response_obj: {'text': ' as a **', 'is_finished': False, 'finish_reason': None, 'logprobs': None, 'original_chunk': ModelResponseStream(id='chatcmpl-1e246dec-1357-4ceb-948f-03d49e55b5f9', created=1762261908, model=None, object='chat.completion.chunk', system_fingerprint=None, choices=[StreamingChoices(finish_reason=None, index=0, delta=Delta(provider_specific_fields=None, content=' as a **', role=None, function_call=None, tool_calls=None, audio=None), logprobs=None)], provider_specific_fields=None, usage=None), 'usage': None}
choice_json: {'index': 0, 'delta': {'provider_specific_fields': None, 'content': ' as a **', 'role': None, 'function_call': None, 'tool_calls': None, 'audio': None}, 'logprobs': None}
choices in streaming: [StreamingChoices(finish_reason=None, index=0, delta=Delta(provider_specific_fields=None, content=' as a **', role=None, function_call=None, tool_calls=None, audio=None), logprobs=None)]
final returned processed chunk: ModelResponseStream(id='chatcmpl-1e246dec-1357-4ceb-948f-03d49e55b5f9', created=1762261907, model='claude-sonnet-4-5-20250929', object='chat.completion.chunk', system_fingerprint=None, choices=[StreamingChoices(finish_reason=None, index=0, delta=Delta(provider_specific_fields=None, content=' as a **', role=None, function_call=None, tool_calls=None, audio=None), logprobs=None)], provider_specific_fields=None, citations=None)
model_response finish reason 3: None; response_obj={'text': '', 'is_finished': False, 'finish_reason': '', 'usage': None, 'index': 0, 'tool_use': None}
model_response.choices[0].delta: Delta(provider_specific_fields=None, content=None, role=None, function_call=None, tool_calls=None, audio=None); completion_obj: {'content': ''}
self.sent_first_chunk: True
completion_obj: {'content': ''}, model_response.choices[0]: StreamingChoices(finish_reason=None, index=0, delta=Delta(provider_specific_fields=None, content=None, role=None, function_call=None, tool_calls=None, audio=None), logprobs=None), response_obj: {'text': '', 'is_finished': False, 'finish_reason': '', 'usage': None, 'index': 0, 'tool_use': None}
model_response finish reason 3: None; response_obj={'text': '', 'is_finished': False, 'finish_reason': '', 'usage': None, 'index': 0, 'tool_use': None}
model_response.choices[0].delta: Delta(provider_specific_fields=None, content=None, role=None, function_call=None, tool_calls=None, audio=None); completion_obj: {'content': ''}
self.sent_first_chunk: True
completion_obj: {'content': ''}, model_response.choices[0]: StreamingChoices(finish_reason=None, index=0, delta=Delta(provider_specific_fields=None, content=None, role=None, function_call=None, tool_calls=None, audio=None), logprobs=None), response_obj: {'text': '', 'is_finished': False, 'finish_reason': '', 'usage': None, 'index': 0, 'tool_use': None}

Raw OpenAI Chunk
ModelResponseStream(id='chatcmpl-1e246dec-1357-4ceb-948f-03d49e55b5f9', created=1762261908, model=None, object='chat.completion.chunk', system_fingerprint=None, choices=[StreamingChoices(finish_reason=None, index=0, delta=Delta(provider_specific_fields=None, content='Supermemory user', role=None, function_call=None, tool_calls=None, audio=None), logprobs=None)], provider_specific_fields=None, usage=None)

model_response finish reason 3: None; response_obj={'text': 'Supermemory user', 'is_finished': False, 'finish_reason': None, 'logprobs': None, 'original_chunk': ModelResponseStream(id='chatcmpl-1e246dec-1357-4ceb-948f-03d49e55b5f9', created=1762261908, model=None, object='chat.completion.chunk', system_fingerprint=None, choices=[StreamingChoices(finish_reason=None, index=0, delta=Delta(provider_specific_fields=None, content='Supermemory user', role=None, function_call=None, tool_calls=None, audio=None), logprobs=None)], provider_specific_fields=None, usage=None), 'usage': None}
original delta: {'provider_specific_fields': None, 'content': 'Supermemory user', 'role': None, 'function_call': None, 'tool_calls': None, 'audio': None}
new delta: Delta(provider_specific_fields=None, content='Supermemory user', role=None, function_call=None, tool_calls=None, audio=None)
model_response.choices[0].delta: Delta(provider_specific_fields=None, content='Supermemory user', role=None, function_call=None, tool_calls=None, audio=None); completion_obj: {'content': 'Supermemory user'}
self.sent_first_chunk: True
completion_obj: {'content': 'Supermemory user'}, model_response.choices[0]: StreamingChoices(finish_reason=None, index=0, delta=Delta(provider_specific_fields=None, content='Supermemory user', role=None, function_call=None, tool_calls=None, audio=None), logprobs=None), response_obj: {'text': 'Supermemory user', 'is_finished': False, 'finish_reason': None, 'logprobs': None, 'original_chunk': ModelResponseStream(id='chatcmpl-1e246dec-1357-4ceb-948f-03d49e55b5f9', created=1762261908, model=None, object='chat.completion.chunk', system_fingerprint=None, choices=[StreamingChoices(finish_reason=None, index=0, delta=Delta(provider_specific_fields=None, content='Supermemory user', role=None, function_call=None, tool_calls=None, audio=None), logprobs=None)], provider_specific_fields=None, usage=None), 'usage': None}
choice_json: {'index': 0, 'delta': {'provider_specific_fields': None, 'content': 'Supermemory user', 'role': None, 'function_call': None, 'tool_calls': None, 'audio': None}, 'logprobs': None}
choices in streaming: [StreamingChoices(finish_reason=None, index=0, delta=Delta(provider_specific_fields=None, content='Supermemory user', role=None, function_call=None, tool_calls=None, audio=None), logprobs=None)]
final returned processed chunk: ModelResponseStream(id='chatcmpl-1e246dec-1357-4ceb-948f-03d49e55b5f9', created=1762261907, model='claude-sonnet-4-5-20250929', object='chat.completion.chunk', system_fingerprint=None, choices=[StreamingChoices(finish_reason=None, index=0, delta=Delta(provider_specific_fields=None, content='Supermemory user', role=None, function_call=None, tool_calls=None, audio=None), logprobs=None)], provider_specific_fields=None, citations=None)
model_response finish reason 3: None; response_obj={'text': '', 'is_finished': False, 'finish_reason': '', 'usage': None, 'index': 0, 'tool_use': None}
model_response.choices[0].delta: Delta(provider_specific_fields=None, content=None, role=None, function_call=None, tool_calls=None, audio=None); completion_obj: {'content': ''}
self.sent_first_chunk: True
completion_obj: {'content': ''}, model_response.choices[0]: StreamingChoices(finish_reason=None, index=0, delta=Delta(provider_specific_fields=None, content=None, role=None, function_call=None, tool_calls=None, audio=None), logprobs=None), response_obj: {'text': '', 'is_finished': False, 'finish_reason': '', 'usage': None, 'index': 0, 'tool_use': None}
model_response finish reason 3: None; response_obj={'text': '', 'is_finished': False, 'finish_reason': '', 'usage': None, 'index': 0, 'tool_use': None}
model_response.choices[0].delta: Delta(provider_specific_fields=None, content=None, role=None, function_call=None, tool_calls=None, audio=None); completion_obj: {'content': ''}
self.sent_first_chunk: True
completion_obj: {'content': ''}, model_response.choices[0]: StreamingChoices(finish_reason=None, index=0, delta=Delta(provider_specific_fields=None, content=None, role=None, function_call=None, tool_calls=None, audio=None), logprobs=None), response_obj: {'text': '', 'is_finished': False, 'finish_reason': '', 'usage': None, 'index': 0, 'tool_use': None}

Raw OpenAI Chunk
ModelResponseStream(id='chatcmpl-1e246dec-1357-4ceb-948f-03d49e55b5f9', created=1762261908, model=None, object='chat.completion.chunk', system_fingerprint=None, choices=[StreamingChoices(finish_reason=None, index=0, delta=Delta(provider_specific_fields=None, content='** base', role=None, function_call=None, tool_calls=None, audio=None), logprobs=None)], provider_specific_fields=None, usage=None)

model_response finish reason 3: None; response_obj={'text': '** base', 'is_finished': False, 'finish_reason': None, 'logprobs': None, 'original_chunk': ModelResponseStream(id='chatcmpl-1e246dec-1357-4ceb-948f-03d49e55b5f9', created=1762261908, model=None, object='chat.completion.chunk', system_fingerprint=None, choices=[StreamingChoices(finish_reason=None, index=0, delta=Delta(provider_specific_fields=None, content='** base', role=None, function_call=None, tool_calls=None, audio=None), logprobs=None)], provider_specific_fields=None, usage=None), 'usage': None}
original delta: {'provider_specific_fields': None, 'content': '** base', 'role': None, 'function_call': None, 'tool_calls': None, 'audio': None}
new delta: Delta(provider_specific_fields=None, content='** base', role=None, function_call=None, tool_calls=None, audio=None)
model_response.choices[0].delta: Delta(provider_specific_fields=None, content='** base', role=None, function_call=None, tool_calls=None, audio=None); completion_obj: {'content': '** base'}
self.sent_first_chunk: True
completion_obj: {'content': '** base'}, model_response.choices[0]: StreamingChoices(finish_reason=None, index=0, delta=Delta(provider_specific_fields=None, content='** base', role=None, function_call=None, tool_calls=None, audio=None), logprobs=None), response_obj: {'text': '** base', 'is_finished': False, 'finish_reason': None, 'logprobs': None, 'original_chunk': ModelResponseStream(id='chatcmpl-1e246dec-1357-4ceb-948f-03d49e55b5f9', created=1762261908, model=None, object='chat.completion.chunk', system_fingerprint=None, choices=[StreamingChoices(finish_reason=None, index=0, delta=Delta(provider_specific_fields=None, content='** base', role=None, function_call=None, tool_calls=None, audio=None), logprobs=None)], provider_specific_fields=None, usage=None), 'usage': None}
choice_json: {'index': 0, 'delta': {'provider_specific_fields': None, 'content': '** base', 'role': None, 'function_call': None, 'tool_calls': None, 'audio': None}, 'logprobs': None}
choices in streaming: [StreamingChoices(finish_reason=None, index=0, delta=Delta(provider_specific_fields=None, content='** base', role=None, function_call=None, tool_calls=None, audio=None), logprobs=None)]
final returned processed chunk: ModelResponseStream(id='chatcmpl-1e246dec-1357-4ceb-948f-03d49e55b5f9', created=1762261907, model='claude-sonnet-4-5-20250929', object='chat.completion.chunk', system_fingerprint=None, choices=[StreamingChoices(finish_reason=None, index=0, delta=Delta(provider_specific_fields=None, content='** base', role=None, function_call=None, tool_calls=None, audio=None), logprobs=None)], provider_specific_fields=None, citations=None)
model_response finish reason 3: None; response_obj={'text': '', 'is_finished': False, 'finish_reason': '', 'usage': None, 'index': 0, 'tool_use': None}
model_response.choices[0].delta: Delta(provider_specific_fields=None, content=None, role=None, function_call=None, tool_calls=None, audio=None); completion_obj: {'content': ''}
self.sent_first_chunk: True
completion_obj: {'content': ''}, model_response.choices[0]: StreamingChoices(finish_reason=None, index=0, delta=Delta(provider_specific_fields=None, content=None, role=None, function_call=None, tool_calls=None, audio=None), logprobs=None), response_obj: {'text': '', 'is_finished': False, 'finish_reason': '', 'usage': None, 'index': 0, 'tool_use': None}
model_response finish reason 3: None; response_obj={'text': '', 'is_finished': False, 'finish_reason': '', 'usage': None, 'index': 0, 'tool_use': None}
model_response.choices[0].delta: Delta(provider_specific_fields=None, content=None, role=None, function_call=None, tool_calls=None, audio=None); completion_obj: {'content': ''}
self.sent_first_chunk: True
completion_obj: {'content': ''}, model_response.choices[0]: StreamingChoices(finish_reason=None, index=0, delta=Delta(provider_specific_fields=None, content=None, role=None, function_call=None, tool_calls=None, audio=None), logprobs=None), response_obj: {'text': '', 'is_finished': False, 'finish_reason': '', 'usage': None, 'index': 0, 'tool_use': None}

Raw OpenAI Chunk
ModelResponseStream(id='chatcmpl-1e246dec-1357-4ceb-948f-03d49e55b5f9', created=1762261908, model=None, object='chat.completion.chunk', system_fingerprint=None, choices=[StreamingChoices(finish_reason=None, index=0, delta=Delta(provider_specific_fields=None, content='d on the', role=None, function_call=None, tool_calls=None, audio=None), logprobs=None)], provider_specific_fields=None, usage=None)

model_response finish reason 3: None; response_obj={'text': 'd on the', 'is_finished': False, 'finish_reason': None, 'logprobs': None, 'original_chunk': ModelResponseStream(id='chatcmpl-1e246dec-1357-4ceb-948f-03d49e55b5f9', created=1762261908, model=None, object='chat.completion.chunk', system_fingerprint=None, choices=[StreamingChoices(finish_reason=None, index=0, delta=Delta(provider_specific_fields=None, content='d on the', role=None, function_call=None, tool_calls=None, audio=None), logprobs=None)], provider_specific_fields=None, usage=None), 'usage': None}
original delta: {'provider_specific_fields': None, 'content': 'd on the', 'role': None, 'function_call': None, 'tool_calls': None, 'audio': None}
new delta: Delta(provider_specific_fields=None, content='d on the', role=None, function_call=None, tool_calls=None, audio=None)
model_response.choices[0].delta: Delta(provider_specific_fields=None, content='d on the', role=None, function_call=None, tool_calls=None, audio=None); completion_obj: {'content': 'd on the'}
self.sent_first_chunk: True
completion_obj: {'content': 'd on the'}, model_response.choices[0]: StreamingChoices(finish_reason=None, index=0, delta=Delta(provider_specific_fields=None, content='d on the', role=None, function_call=None, tool_calls=None, audio=None), logprobs=None), response_obj: {'text': 'd on the', 'is_finished': False, 'finish_reason': None, 'logprobs': None, 'original_chunk': ModelResponseStream(id='chatcmpl-1e246dec-1357-4ceb-948f-03d49e55b5f9', created=1762261908, model=None, object='chat.completion.chunk', system_fingerprint=None, choices=[StreamingChoices(finish_reason=None, index=0, delta=Delta(provider_specific_fields=None, content='d on the', role=None, function_call=None, tool_calls=None, audio=None), logprobs=None)], provider_specific_fields=None, usage=None), 'usage': None}
choice_json: {'index': 0, 'delta': {'provider_specific_fields': None, 'content': 'd on the', 'role': None, 'function_call': None, 'tool_calls': None, 'audio': None}, 'logprobs': None}
choices in streaming: [StreamingChoices(finish_reason=None, index=0, delta=Delta(provider_specific_fields=None, content='d on the', role=None, function_call=None, tool_calls=None, audio=None), logprobs=None)]
final returned processed chunk: ModelResponseStream(id='chatcmpl-1e246dec-1357-4ceb-948f-03d49e55b5f9', created=1762261907, model='claude-sonnet-4-5-20250929', object='chat.completion.chunk', system_fingerprint=None, choices=[StreamingChoices(finish_reason=None, index=0, delta=Delta(provider_specific_fields=None, content='d on the', role=None, function_call=None, tool_calls=None, audio=None), logprobs=None)], provider_specific_fields=None, citations=None)
model_response finish reason 3: None; response_obj={'text': '', 'is_finished': False, 'finish_reason': '', 'usage': None, 'index': 0, 'tool_use': None}
model_response.choices[0].delta: Delta(provider_specific_fields=None, content=None, role=None, function_call=None, tool_calls=None, audio=None); completion_obj: {'content': ''}
self.sent_first_chunk: True
completion_obj: {'content': ''}, model_response.choices[0]: StreamingChoices(finish_reason=None, index=0, delta=Delta(provider_specific_fields=None, content=None, role=None, function_call=None, tool_calls=None, audio=None), logprobs=None), response_obj: {'text': '', 'is_finished': False, 'finish_reason': '', 'usage': None, 'index': 0, 'tool_use': None}
model_response finish reason 3: None; response_obj={'text': '', 'is_finished': False, 'finish_reason': '', 'usage': None, 'index': 0, 'tool_use': None}
model_response.choices[0].delta: Delta(provider_specific_fields=None, content=None, role=None, function_call=None, tool_calls=None, audio=None); completion_obj: {'content': ''}
self.sent_first_chunk: True
completion_obj: {'content': ''}, model_response.choices[0]: StreamingChoices(finish_reason=None, index=0, delta=Delta(provider_specific_fields=None, content=None, role=None, function_call=None, tool_calls=None, audio=None), logprobs=None), response_obj: {'text': '', 'is_finished': False, 'finish_reason': '', 'usage': None, 'index': 0, 'tool_use': None}

Raw OpenAI Chunk
ModelResponseStream(id='chatcmpl-1e246dec-1357-4ceb-948f-03d49e55b5f9', created=1762261908, model=None, object='chat.completion.chunk', system_fingerprint=None, choices=[StreamingChoices(finish_reason=None, index=0, delta=Delta(provider_specific_fields=None, content=' impe', role=None, function_call=None, tool_calls=None, audio=None), logprobs=None)], provider_specific_fields=None, usage=None)

model_response finish reason 3: None; response_obj={'text': ' impe', 'is_finished': False, 'finish_reason': None, 'logprobs': None, 'original_chunk': ModelResponseStream(id='chatcmpl-1e246dec-1357-4ceb-948f-03d49e55b5f9', created=1762261908, model=None, object='chat.completion.chunk', system_fingerprint=None, choices=[StreamingChoices(finish_reason=None, index=0, delta=Delta(provider_specific_fields=None, content=' impe', role=None, function_call=None, tool_calls=None, audio=None), logprobs=None)], provider_specific_fields=None, usage=None), 'usage': None}
original delta: {'provider_specific_fields': None, 'content': ' impe', 'role': None, 'function_call': None, 'tool_calls': None, 'audio': None}
new delta: Delta(provider_specific_fields=None, content=' impe', role=None, function_call=None, tool_calls=None, audio=None)
model_response.choices[0].delta: Delta(provider_specific_fields=None, content=' impe', role=None, function_call=None, tool_calls=None, audio=None); completion_obj: {'content': ' impe'}
self.sent_first_chunk: True
completion_obj: {'content': ' impe'}, model_response.choices[0]: StreamingChoices(finish_reason=None, index=0, delta=Delta(provider_specific_fields=None, content=' impe', role=None, function_call=None, tool_calls=None, audio=None), logprobs=None), response_obj: {'text': ' impe', 'is_finished': False, 'finish_reason': None, 'logprobs': None, 'original_chunk': ModelResponseStream(id='chatcmpl-1e246dec-1357-4ceb-948f-03d49e55b5f9', created=1762261908, model=None, object='chat.completion.chunk', system_fingerprint=None, choices=[StreamingChoices(finish_reason=None, index=0, delta=Delta(provider_specific_fields=None, content=' impe', role=None, function_call=None, tool_calls=None, audio=None), logprobs=None)], provider_specific_fields=None, usage=None), 'usage': None}
choice_json: {'index': 0, 'delta': {'provider_specific_fields': None, 'content': ' impe', 'role': None, 'function_call': None, 'tool_calls': None, 'audio': None}, 'logprobs': None}
choices in streaming: [StreamingChoices(finish_reason=None, index=0, delta=Delta(provider_specific_fields=None, content=' impe', role=None, function_call=None, tool_calls=None, audio=None), logprobs=None)]
final returned processed chunk: ModelResponseStream(id='chatcmpl-1e246dec-1357-4ceb-948f-03d49e55b5f9', created=1762261907, model='claude-sonnet-4-5-20250929', object='chat.completion.chunk', system_fingerprint=None, choices=[StreamingChoices(finish_reason=None, index=0, delta=Delta(provider_specific_fields=None, content=' impe', role=None, function_call=None, tool_calls=None, audio=None), logprobs=None)], provider_specific_fields=None, citations=None)
model_response finish reason 3: None; response_obj={'text': '', 'is_finished': False, 'finish_reason': '', 'usage': None, 'index': 0, 'tool_use': None}
model_response.choices[0].delta: Delta(provider_specific_fields=None, content=None, role=None, function_call=None, tool_calls=None, audio=None); completion_obj: {'content': ''}
self.sent_first_chunk: True
completion_obj: {'content': ''}, model_response.choices[0]: StreamingChoices(finish_reason=None, index=0, delta=Delta(provider_specific_fields=None, content=None, role=None, function_call=None, tool_calls=None, audio=None), logprobs=None), response_obj: {'text': '', 'is_finished': False, 'finish_reason': '', 'usage': None, 'index': 0, 'tool_use': None}
model_response finish reason 3: None; response_obj={'text': '', 'is_finished': False, 'finish_reason': '', 'usage': None, 'index': 0, 'tool_use': None}
model_response.choices[0].delta: Delta(provider_specific_fields=None, content=None, role=None, function_call=None, tool_calls=None, audio=None); completion_obj: {'content': ''}
self.sent_first_chunk: True
completion_obj: {'content': ''}, model_response.choices[0]: StreamingChoices(finish_reason=None, index=0, delta=Delta(provider_specific_fields=None, content=None, role=None, function_call=None, tool_calls=None, audio=None), logprobs=None), response_obj: {'text': '', 'is_finished': False, 'finish_reason': '', 'usage': None, 'index': 0, 'tool_use': None}

Raw OpenAI Chunk
ModelResponseStream(id='chatcmpl-1e246dec-1357-4ceb-948f-03d49e55b5f9', created=1762261908, model=None, object='chat.completion.chunk', system_fingerprint=None, choices=[StreamingChoices(finish_reason=None, index=0, delta=Delta(provider_specific_fields=None, content='rative rule', role=None, function_call=None, tool_calls=None, audio=None), logprobs=None)], provider_specific_fields=None, usage=None)

model_response finish reason 3: None; response_obj={'text': 'rative rule', 'is_finished': False, 'finish_reason': None, 'logprobs': None, 'original_chunk': ModelResponseStream(id='chatcmpl-1e246dec-1357-4ceb-948f-03d49e55b5f9', created=1762261908, model=None, object='chat.completion.chunk', system_fingerprint=None, choices=[StreamingChoices(finish_reason=None, index=0, delta=Delta(provider_specific_fields=None, content='rative rule', role=None, function_call=None, tool_calls=None, audio=None), logprobs=None)], provider_specific_fields=None, usage=None), 'usage': None}
original delta: {'provider_specific_fields': None, 'content': 'rative rule', 'role': None, 'function_call': None, 'tool_calls': None, 'audio': None}
new delta: Delta(provider_specific_fields=None, content='rative rule', role=None, function_call=None, tool_calls=None, audio=None)
model_response.choices[0].delta: Delta(provider_specific_fields=None, content='rative rule', role=None, function_call=None, tool_calls=None, audio=None); completion_obj: {'content': 'rative rule'}
self.sent_first_chunk: True
completion_obj: {'content': 'rative rule'}, model_response.choices[0]: StreamingChoices(finish_reason=None, index=0, delta=Delta(provider_specific_fields=None, content='rative rule', role=None, function_call=None, tool_calls=None, audio=None), logprobs=None), response_obj: {'text': 'rative rule', 'is_finished': False, 'finish_reason': None, 'logprobs': None, 'original_chunk': ModelResponseStream(id='chatcmpl-1e246dec-1357-4ceb-948f-03d49e55b5f9', created=1762261908, model=None, object='chat.completion.chunk', system_fingerprint=None, choices=[StreamingChoices(finish_reason=None, index=0, delta=Delta(provider_specific_fields=None, content='rative rule', role=None, function_call=None, tool_calls=None, audio=None), logprobs=None)], provider_specific_fields=None, usage=None), 'usage': None}
choice_json: {'index': 0, 'delta': {'provider_specific_fields': None, 'content': 'rative rule', 'role': None, 'function_call': None, 'tool_calls': None, 'audio': None}, 'logprobs': None}
choices in streaming: [StreamingChoices(finish_reason=None, index=0, delta=Delta(provider_specific_fields=None, content='rative rule', role=None, function_call=None, tool_calls=None, audio=None), logprobs=None)]
final returned processed chunk: ModelResponseStream(id='chatcmpl-1e246dec-1357-4ceb-948f-03d49e55b5f9', created=1762261907, model='claude-sonnet-4-5-20250929', object='chat.completion.chunk', system_fingerprint=None, choices=[StreamingChoices(finish_reason=None, index=0, delta=Delta(provider_specific_fields=None, content='rative rule', role=None, function_call=None, tool_calls=None, audio=None), logprobs=None)], provider_specific_fields=None, citations=None)
model_response finish reason 3: None; response_obj={'text': '', 'is_finished': False, 'finish_reason': '', 'usage': None, 'index': 0, 'tool_use': None}
model_response.choices[0].delta: Delta(provider_specific_fields=None, content=None, role=None, function_call=None, tool_calls=None, audio=None); completion_obj: {'content': ''}
self.sent_first_chunk: True
completion_obj: {'content': ''}, model_response.choices[0]: StreamingChoices(finish_reason=None, index=0, delta=Delta(provider_specific_fields=None, content=None, role=None, function_call=None, tool_calls=None, audio=None), logprobs=None), response_obj: {'text': '', 'is_finished': False, 'finish_reason': '', 'usage': None, 'index': 0, 'tool_use': None}
model_response finish reason 3: None; response_obj={'text': '', 'is_finished': False, 'finish_reason': '', 'usage': None, 'index': 0, 'tool_use': None}
model_response.choices[0].delta: Delta(provider_specific_fields=None, content=None, role=None, function_call=None, tool_calls=None, audio=None); completion_obj: {'content': ''}
self.sent_first_chunk: True
completion_obj: {'content': ''}, model_response.choices[0]: StreamingChoices(finish_reason=None, index=0, delta=Delta(provider_specific_fields=None, content=None, role=None, function_call=None, tool_calls=None, audio=None), logprobs=None), response_obj: {'text': '', 'is_finished': False, 'finish_reason': '', 'usage': None, 'index': 0, 'tool_use': None}

Raw OpenAI Chunk
ModelResponseStream(id='chatcmpl-1e246dec-1357-4ceb-948f-03d49e55b5f9', created=1762261909, model=None, object='chat.completion.chunk', system_fingerprint=None, choices=[StreamingChoices(finish_reason=None, index=0, delta=Delta(provider_specific_fields=None, content=' in', role=None, function_call=None, tool_calls=None, audio=None), logprobs=None)], provider_specific_fields=None, usage=None)

model_response finish reason 3: None; response_obj={'text': ' in', 'is_finished': False, 'finish_reason': None, 'logprobs': None, 'original_chunk': ModelResponseStream(id='chatcmpl-1e246dec-1357-4ceb-948f-03d49e55b5f9', created=1762261909, model=None, object='chat.completion.chunk', system_fingerprint=None, choices=[StreamingChoices(finish_reason=None, index=0, delta=Delta(provider_specific_fields=None, content=' in', role=None, function_call=None, tool_calls=None, audio=None), logprobs=None)], provider_specific_fields=None, usage=None), 'usage': None}
original delta: {'provider_specific_fields': None, 'content': ' in', 'role': None, 'function_call': None, 'tool_calls': None, 'audio': None}
new delta: Delta(provider_specific_fields=None, content=' in', role=None, function_call=None, tool_calls=None, audio=None)
model_response.choices[0].delta: Delta(provider_specific_fields=None, content=' in', role=None, function_call=None, tool_calls=None, audio=None); completion_obj: {'content': ' in'}
self.sent_first_chunk: True
completion_obj: {'content': ' in'}, model_response.choices[0]: StreamingChoices(finish_reason=None, index=0, delta=Delta(provider_specific_fields=None, content=' in', role=None, function_call=None, tool_calls=None, audio=None), logprobs=None), response_obj: {'text': ' in', 'is_finished': False, 'finish_reason': None, 'logprobs': None, 'original_chunk': ModelResponseStream(id='chatcmpl-1e246dec-1357-4ceb-948f-03d49e55b5f9', created=1762261909, model=None, object='chat.completion.chunk', system_fingerprint=None, choices=[StreamingChoices(finish_reason=None, index=0, delta=Delta(provider_specific_fields=None, content=' in', role=None, function_call=None, tool_calls=None, audio=None), logprobs=None)], provider_specific_fields=None, usage=None), 'usage': None}
choice_json: {'index': 0, 'delta': {'provider_specific_fields': None, 'content': ' in', 'role': None, 'function_call': None, 'tool_calls': None, 'audio': None}, 'logprobs': None}
choices in streaming: [StreamingChoices(finish_reason=None, index=0, delta=Delta(provider_specific_fields=None, content=' in', role=None, function_call=None, tool_calls=None, audio=None), logprobs=None)]
final returned processed chunk: ModelResponseStream(id='chatcmpl-1e246dec-1357-4ceb-948f-03d49e55b5f9', created=1762261907, model='claude-sonnet-4-5-20250929', object='chat.completion.chunk', system_fingerprint=None, choices=[StreamingChoices(finish_reason=None, index=0, delta=Delta(provider_specific_fields=None, content=' in', role=None, function_call=None, tool_calls=None, audio=None), logprobs=None)], provider_specific_fields=None, citations=None)
model_response finish reason 3: None; response_obj={'text': '', 'is_finished': False, 'finish_reason': '', 'usage': None, 'index': 0, 'tool_use': None}
model_response.choices[0].delta: Delta(provider_specific_fields=None, content=None, role=None, function_call=None, tool_calls=None, audio=None); completion_obj: {'content': ''}
self.sent_first_chunk: True
completion_obj: {'content': ''}, model_response.choices[0]: StreamingChoices(finish_reason=None, index=0, delta=Delta(provider_specific_fields=None, content=None, role=None, function_call=None, tool_calls=None, audio=None), logprobs=None), response_obj: {'text': '', 'is_finished': False, 'finish_reason': '', 'usage': None, 'index': 0, 'tool_use': None}
model_response finish reason 3: None; response_obj={'text': '', 'is_finished': False, 'finish_reason': '', 'usage': None, 'index': 0, 'tool_use': None}
model_response.choices[0].delta: Delta(provider_specific_fields=None, content=None, role=None, function_call=None, tool_calls=None, audio=None); completion_obj: {'content': ''}
self.sent_first_chunk: True
completion_obj: {'content': ''}, model_response.choices[0]: StreamingChoices(finish_reason=None, index=0, delta=Delta(provider_specific_fields=None, content=None, role=None, function_call=None, tool_calls=None, audio=None), logprobs=None), response_obj: {'text': '', 'is_finished': False, 'finish_reason': '', 'usage': None, 'index': 0, 'tool_use': None}

Raw OpenAI Chunk
ModelResponseStream(id='chatcmpl-1e246dec-1357-4ceb-948f-03d49e55b5f9', created=1762261909, model=None, object='chat.completion.chunk', system_fingerprint=None, choices=[StreamingChoices(finish_reason=None, index=0, delta=Delta(provider_specific_fields=None, content=' your', role=None, function_call=None, tool_calls=None, audio=None), logprobs=None)], provider_specific_fields=None, usage=None)

model_response finish reason 3: None; response_obj={'text': ' your', 'is_finished': False, 'finish_reason': None, 'logprobs': None, 'original_chunk': ModelResponseStream(id='chatcmpl-1e246dec-1357-4ceb-948f-03d49e55b5f9', created=1762261909, model=None, object='chat.completion.chunk', system_fingerprint=None, choices=[StreamingChoices(finish_reason=None, index=0, delta=Delta(provider_specific_fields=None, content=' your', role=None, function_call=None, tool_calls=None, audio=None), logprobs=None)], provider_specific_fields=None, usage=None), 'usage': None}
original delta: {'provider_specific_fields': None, 'content': ' your', 'role': None, 'function_call': None, 'tool_calls': None, 'audio': None}
new delta: Delta(provider_specific_fields=None, content=' your', role=None, function_call=None, tool_calls=None, audio=None)
model_response.choices[0].delta: Delta(provider_specific_fields=None, content=' your', role=None, function_call=None, tool_calls=None, audio=None); completion_obj: {'content': ' your'}
self.sent_first_chunk: True
completion_obj: {'content': ' your'}, model_response.choices[0]: StreamingChoices(finish_reason=None, index=0, delta=Delta(provider_specific_fields=None, content=' your', role=None, function_call=None, tool_calls=None, audio=None), logprobs=None), response_obj: {'text': ' your', 'is_finished': False, 'finish_reason': None, 'logprobs': None, 'original_chunk': ModelResponseStream(id='chatcmpl-1e246dec-1357-4ceb-948f-03d49e55b5f9', created=1762261909, model=None, object='chat.completion.chunk', system_fingerprint=None, choices=[StreamingChoices(finish_reason=None, index=0, delta=Delta(provider_specific_fields=None, content=' your', role=None, function_call=None, tool_calls=None, audio=None), logprobs=None)], provider_specific_fields=None, usage=None), 'usage': None}
choice_json: {'index': 0, 'delta': {'provider_specific_fields': None, 'content': ' your', 'role': None, 'function_call': None, 'tool_calls': None, 'audio': None}, 'logprobs': None}
choices in streaming: [StreamingChoices(finish_reason=None, index=0, delta=Delta(provider_specific_fields=None, content=' your', role=None, function_call=None, tool_calls=None, audio=None), logprobs=None)]
final returned processed chunk: ModelResponseStream(id='chatcmpl-1e246dec-1357-4ceb-948f-03d49e55b5f9', created=1762261907, model='claude-sonnet-4-5-20250929', object='chat.completion.chunk', system_fingerprint=None, choices=[StreamingChoices(finish_reason=None, index=0, delta=Delta(provider_specific_fields=None, content=' your', role=None, function_call=None, tool_calls=None, audio=None), logprobs=None)], provider_specific_fields=None, citations=None)
model_response finish reason 3: None; response_obj={'text': '', 'is_finished': False, 'finish_reason': '', 'usage': None, 'index': 0, 'tool_use': None}
model_response.choices[0].delta: Delta(provider_specific_fields=None, content=None, role=None, function_call=None, tool_calls=None, audio=None); completion_obj: {'content': ''}
self.sent_first_chunk: True
completion_obj: {'content': ''}, model_response.choices[0]: StreamingChoices(finish_reason=None, index=0, delta=Delta(provider_specific_fields=None, content=None, role=None, function_call=None, tool_calls=None, audio=None), logprobs=None), response_obj: {'text': '', 'is_finished': False, 'finish_reason': '', 'usage': None, 'index': 0, 'tool_use': None}
model_response finish reason 3: None; response_obj={'text': '', 'is_finished': False, 'finish_reason': '', 'usage': None, 'index': 0, 'tool_use': None}
model_response.choices[0].delta: Delta(provider_specific_fields=None, content=None, role=None, function_call=None, tool_calls=None, audio=None); completion_obj: {'content': ''}
self.sent_first_chunk: True
completion_obj: {'content': ''}, model_response.choices[0]: StreamingChoices(finish_reason=None, index=0, delta=Delta(provider_specific_fields=None, content=None, role=None, function_call=None, tool_calls=None, audio=None), logprobs=None), response_obj: {'text': '', 'is_finished': False, 'finish_reason': '', 'usage': None, 'index': 0, 'tool_use': None}

Raw OpenAI Chunk
ModelResponseStream(id='chatcmpl-1e246dec-1357-4ceb-948f-03d49e55b5f9', created=1762261909, model=None, object='chat.completion.chunk', system_fingerprint=None, choices=[StreamingChoices(finish_reason=None, index=0, delta=Delta(provider_specific_fields=None, content=' `.', role=None, function_call=None, tool_calls=None, audio=None), logprobs=None)], provider_specific_fields=None, usage=None)

model_response finish reason 3: None; response_obj={'text': ' `.', 'is_finished': False, 'finish_reason': None, 'logprobs': None, 'original_chunk': ModelResponseStream(id='chatcmpl-1e246dec-1357-4ceb-948f-03d49e55b5f9', created=1762261909, model=None, object='chat.completion.chunk', system_fingerprint=None, choices=[StreamingChoices(finish_reason=None, index=0, delta=Delta(provider_specific_fields=None, content=' `.', role=None, function_call=None, tool_calls=None, audio=None), logprobs=None)], provider_specific_fields=None, usage=None), 'usage': None}
original delta: {'provider_specific_fields': None, 'content': ' `.', 'role': None, 'function_call': None, 'tool_calls': None, 'audio': None}
new delta: Delta(provider_specific_fields=None, content=' `.', role=None, function_call=None, tool_calls=None, audio=None)
model_response.choices[0].delta: Delta(provider_specific_fields=None, content=' `.', role=None, function_call=None, tool_calls=None, audio=None); completion_obj: {'content': ' `.'}
self.sent_first_chunk: True
completion_obj: {'content': ' `.'}, model_response.choices[0]: StreamingChoices(finish_reason=None, index=0, delta=Delta(provider_specific_fields=None, content=' `.', role=None, function_call=None, tool_calls=None, audio=None), logprobs=None), response_obj: {'text': ' `.', 'is_finished': False, 'finish_reason': None, 'logprobs': None, 'original_chunk': ModelResponseStream(id='chatcmpl-1e246dec-1357-4ceb-948f-03d49e55b5f9', created=1762261909, model=None, object='chat.completion.chunk', system_fingerprint=None, choices=[StreamingChoices(finish_reason=None, index=0, delta=Delta(provider_specific_fields=None, content=' `.', role=None, function_call=None, tool_calls=None, audio=None), logprobs=None)], provider_specific_fields=None, usage=None), 'usage': None}
choice_json: {'index': 0, 'delta': {'provider_specific_fields': None, 'content': ' `.', 'role': None, 'function_call': None, 'tool_calls': None, 'audio': None}, 'logprobs': None}
choices in streaming: [StreamingChoices(finish_reason=None, index=0, delta=Delta(provider_specific_fields=None, content=' `.', role=None, function_call=None, tool_calls=None, audio=None), logprobs=None)]
final returned processed chunk: ModelResponseStream(id='chatcmpl-1e246dec-1357-4ceb-948f-03d49e55b5f9', created=1762261907, model='claude-sonnet-4-5-20250929', object='chat.completion.chunk', system_fingerprint=None, choices=[StreamingChoices(finish_reason=None, index=0, delta=Delta(provider_specific_fields=None, content=' `.', role=None, function_call=None, tool_calls=None, audio=None), logprobs=None)], provider_specific_fields=None, citations=None)
model_response finish reason 3: None; response_obj={'text': '', 'is_finished': False, 'finish_reason': '', 'usage': None, 'index': 0, 'tool_use': None}
model_response.choices[0].delta: Delta(provider_specific_fields=None, content=None, role=None, function_call=None, tool_calls=None, audio=None); completion_obj: {'content': ''}
self.sent_first_chunk: True
completion_obj: {'content': ''}, model_response.choices[0]: StreamingChoices(finish_reason=None, index=0, delta=Delta(provider_specific_fields=None, content=None, role=None, function_call=None, tool_calls=None, audio=None), logprobs=None), response_obj: {'text': '', 'is_finished': False, 'finish_reason': '', 'usage': None, 'index': 0, 'tool_use': None}
model_response finish reason 3: None; response_obj={'text': '', 'is_finished': False, 'finish_reason': '', 'usage': None, 'index': 0, 'tool_use': None}
model_response.choices[0].delta: Delta(provider_specific_fields=None, content=None, role=None, function_call=None, tool_calls=None, audio=None); completion_obj: {'content': ''}
self.sent_first_chunk: True
completion_obj: {'content': ''}, model_response.choices[0]: StreamingChoices(finish_reason=None, index=0, delta=Delta(provider_specific_fields=None, content=None, role=None, function_call=None, tool_calls=None, audio=None), logprobs=None), response_obj: {'text': '', 'is_finished': False, 'finish_reason': '', 'usage': None, 'index': 0, 'tool_use': None}

Raw OpenAI Chunk
ModelResponseStream(id='chatcmpl-1e246dec-1357-4ceb-948f-03d49e55b5f9', created=1762261909, model=None, object='chat.completion.chunk', system_fingerprint=None, choices=[StreamingChoices(finish_reason=None, index=0, delta=Delta(provider_specific_fields=None, content='ai', role=None, function_call=None, tool_calls=None, audio=None), logprobs=None)], provider_specific_fields=None, usage=None)

model_response finish reason 3: None; response_obj={'text': 'ai', 'is_finished': False, 'finish_reason': None, 'logprobs': None, 'original_chunk': ModelResponseStream(id='chatcmpl-1e246dec-1357-4ceb-948f-03d49e55b5f9', created=1762261909, model=None, object='chat.completion.chunk', system_fingerprint=None, choices=[StreamingChoices(finish_reason=None, index=0, delta=Delta(provider_specific_fields=None, content='ai', role=None, function_call=None, tool_calls=None, audio=None), logprobs=None)], provider_specific_fields=None, usage=None), 'usage': None}
original delta: {'provider_specific_fields': None, 'content': 'ai', 'role': None, 'function_call': None, 'tool_calls': None, 'audio': None}
new delta: Delta(provider_specific_fields=None, content='ai', role=None, function_call=None, tool_calls=None, audio=None)
model_response.choices[0].delta: Delta(provider_specific_fields=None, content='ai', role=None, function_call=None, tool_calls=None, audio=None); completion_obj: {'content': 'ai'}
self.sent_first_chunk: True
completion_obj: {'content': 'ai'}, model_response.choices[0]: StreamingChoices(finish_reason=None, index=0, delta=Delta(provider_specific_fields=None, content='ai', role=None, function_call=None, tool_calls=None, audio=None), logprobs=None), response_obj: {'text': 'ai', 'is_finished': False, 'finish_reason': None, 'logprobs': None, 'original_chunk': ModelResponseStream(id='chatcmpl-1e246dec-1357-4ceb-948f-03d49e55b5f9', created=1762261909, model=None, object='chat.completion.chunk', system_fingerprint=None, choices=[StreamingChoices(finish_reason=None, index=0, delta=Delta(provider_specific_fields=None, content='ai', role=None, function_call=None, tool_calls=None, audio=None), logprobs=None)], provider_specific_fields=None, usage=None), 'usage': None}
choice_json: {'index': 0, 'delta': {'provider_specific_fields': None, 'content': 'ai', 'role': None, 'function_call': None, 'tool_calls': None, 'audio': None}, 'logprobs': None}
choices in streaming: [StreamingChoices(finish_reason=None, index=0, delta=Delta(provider_specific_fields=None, content='ai', role=None, function_call=None, tool_calls=None, audio=None), logprobs=None)]
final returned processed chunk: ModelResponseStream(id='chatcmpl-1e246dec-1357-4ceb-948f-03d49e55b5f9', created=1762261907, model='claude-sonnet-4-5-20250929', object='chat.completion.chunk', system_fingerprint=None, choices=[StreamingChoices(finish_reason=None, index=0, delta=Delta(provider_specific_fields=None, content='ai', role=None, function_call=None, tool_calls=None, audio=None), logprobs=None)], provider_specific_fields=None, citations=None)
model_response finish reason 3: None; response_obj={'text': '', 'is_finished': False, 'finish_reason': '', 'usage': None, 'index': 0, 'tool_use': None}
model_response.choices[0].delta: Delta(provider_specific_fields=None, content=None, role=None, function_call=None, tool_calls=None, audio=None); completion_obj: {'content': ''}
self.sent_first_chunk: True
completion_obj: {'content': ''}, model_response.choices[0]: StreamingChoices(finish_reason=None, index=0, delta=Delta(provider_specific_fields=None, content=None, role=None, function_call=None, tool_calls=None, audio=None), logprobs=None), response_obj: {'text': '', 'is_finished': False, 'finish_reason': '', 'usage': None, 'index': 0, 'tool_use': None}
model_response finish reason 3: None; response_obj={'text': '', 'is_finished': False, 'finish_reason': '', 'usage': None, 'index': 0, 'tool_use': None}
model_response.choices[0].delta: Delta(provider_specific_fields=None, content=None, role=None, function_call=None, tool_calls=None, audio=None); completion_obj: {'content': ''}
self.sent_first_chunk: True
completion_obj: {'content': ''}, model_response.choices[0]: StreamingChoices(finish_reason=None, index=0, delta=Delta(provider_specific_fields=None, content=None, role=None, function_call=None, tool_calls=None, audio=None), logprobs=None), response_obj: {'text': '', 'is_finished': False, 'finish_reason': '', 'usage': None, 'index': 0, 'tool_use': None}

Raw OpenAI Chunk
ModelResponseStream(id='chatcmpl-1e246dec-1357-4ceb-948f-03d49e55b5f9', created=1762261909, model=None, object='chat.completion.chunk', system_fingerprint=None, choices=[StreamingChoices(finish_reason=None, index=0, delta=Delta(provider_specific_fields=None, content='ass', role=None, function_call=None, tool_calls=None, audio=None), logprobs=None)], provider_specific_fields=None, usage=None)

model_response finish reason 3: None; response_obj={'text': 'ass', 'is_finished': False, 'finish_reason': None, 'logprobs': None, 'original_chunk': ModelResponseStream(id='chatcmpl-1e246dec-1357-4ceb-948f-03d49e55b5f9', created=1762261909, model=None, object='chat.completion.chunk', system_fingerprint=None, choices=[StreamingChoices(finish_reason=None, index=0, delta=Delta(provider_specific_fields=None, content='ass', role=None, function_call=None, tool_calls=None, audio=None), logprobs=None)], provider_specific_fields=None, usage=None), 'usage': None}
original delta: {'provider_specific_fields': None, 'content': 'ass', 'role': None, 'function_call': None, 'tool_calls': None, 'audio': None}
new delta: Delta(provider_specific_fields=None, content='ass', role=None, function_call=None, tool_calls=None, audio=None)
model_response.choices[0].delta: Delta(provider_specific_fields=None, content='ass', role=None, function_call=None, tool_calls=None, audio=None); completion_obj: {'content': 'ass'}
self.sent_first_chunk: True
completion_obj: {'content': 'ass'}, model_response.choices[0]: StreamingChoices(finish_reason=None, index=0, delta=Delta(provider_specific_fields=None, content='ass', role=None, function_call=None, tool_calls=None, audio=None), logprobs=None), response_obj: {'text': 'ass', 'is_finished': False, 'finish_reason': None, 'logprobs': None, 'original_chunk': ModelResponseStream(id='chatcmpl-1e246dec-1357-4ceb-948f-03d49e55b5f9', created=1762261909, model=None, object='chat.completion.chunk', system_fingerprint=None, choices=[StreamingChoices(finish_reason=None, index=0, delta=Delta(provider_specific_fields=None, content='ass', role=None, function_call=None, tool_calls=None, audio=None), logprobs=None)], provider_specific_fields=None, usage=None), 'usage': None}
choice_json: {'index': 0, 'delta': {'provider_specific_fields': None, 'content': 'ass', 'role': None, 'function_call': None, 'tool_calls': None, 'audio': None}, 'logprobs': None}
choices in streaming: [StreamingChoices(finish_reason=None, index=0, delta=Delta(provider_specific_fields=None, content='ass', role=None, function_call=None, tool_calls=None, audio=None), logprobs=None)]
final returned processed chunk: ModelResponseStream(id='chatcmpl-1e246dec-1357-4ceb-948f-03d49e55b5f9', created=1762261907, model='claude-sonnet-4-5-20250929', object='chat.completion.chunk', system_fingerprint=None, choices=[StreamingChoices(finish_reason=None, index=0, delta=Delta(provider_specific_fields=None, content='ass', role=None, function_call=None, tool_calls=None, audio=None), logprobs=None)], provider_specific_fields=None, citations=None)
model_response finish reason 3: None; response_obj={'text': '', 'is_finished': False, 'finish_reason': '', 'usage': None, 'index': 0, 'tool_use': None}
model_response.choices[0].delta: Delta(provider_specific_fields=None, content=None, role=None, function_call=None, tool_calls=None, audio=None); completion_obj: {'content': ''}
self.sent_first_chunk: True
completion_obj: {'content': ''}, model_response.choices[0]: StreamingChoices(finish_reason=None, index=0, delta=Delta(provider_specific_fields=None, content=None, role=None, function_call=None, tool_calls=None, audio=None), logprobs=None), response_obj: {'text': '', 'is_finished': False, 'finish_reason': '', 'usage': None, 'index': 0, 'tool_use': None}
model_response finish reason 3: None; response_obj={'text': '', 'is_finished': False, 'finish_reason': '', 'usage': None, 'index': 0, 'tool_use': None}
model_response.choices[0].delta: Delta(provider_specific_fields=None, content=None, role=None, function_call=None, tool_calls=None, audio=None); completion_obj: {'content': ''}
self.sent_first_chunk: True
completion_obj: {'content': ''}, model_response.choices[0]: StreamingChoices(finish_reason=None, index=0, delta=Delta(provider_specific_fields=None, content=None, role=None, function_call=None, tool_calls=None, audio=None), logprobs=None), response_obj: {'text': '', 'is_finished': False, 'finish_reason': '', 'usage': None, 'index': 0, 'tool_use': None}

Raw OpenAI Chunk
ModelResponseStream(id='chatcmpl-1e246dec-1357-4ceb-948f-03d49e55b5f9', created=1762261909, model=None, object='chat.completion.chunk', system_fingerprint=None, choices=[StreamingChoices(finish_reason=None, index=0, delta=Delta(provider_specific_fields=None, content='istant`', role=None, function_call=None, tool_calls=None, audio=None), logprobs=None)], provider_specific_fields=None, usage=None)

model_response finish reason 3: None; response_obj={'text': 'istant`', 'is_finished': False, 'finish_reason': None, 'logprobs': None, 'original_chunk': ModelResponseStream(id='chatcmpl-1e246dec-1357-4ceb-948f-03d49e55b5f9', created=1762261909, model=None, object='chat.completion.chunk', system_fingerprint=None, choices=[StreamingChoices(finish_reason=None, index=0, delta=Delta(provider_specific_fields=None, content='istant`', role=None, function_call=None, tool_calls=None, audio=None), logprobs=None)], provider_specific_fields=None, usage=None), 'usage': None}
original delta: {'provider_specific_fields': None, 'content': 'istant`', 'role': None, 'function_call': None, 'tool_calls': None, 'audio': None}
new delta: Delta(provider_specific_fields=None, content='istant`', role=None, function_call=None, tool_calls=None, audio=None)
model_response.choices[0].delta: Delta(provider_specific_fields=None, content='istant`', role=None, function_call=None, tool_calls=None, audio=None); completion_obj: {'content': 'istant`'}
self.sent_first_chunk: True
completion_obj: {'content': 'istant`'}, model_response.choices[0]: StreamingChoices(finish_reason=None, index=0, delta=Delta(provider_specific_fields=None, content='istant`', role=None, function_call=None, tool_calls=None, audio=None), logprobs=None), response_obj: {'text': 'istant`', 'is_finished': False, 'finish_reason': None, 'logprobs': None, 'original_chunk': ModelResponseStream(id='chatcmpl-1e246dec-1357-4ceb-948f-03d49e55b5f9', created=1762261909, model=None, object='chat.completion.chunk', system_fingerprint=None, choices=[StreamingChoices(finish_reason=None, index=0, delta=Delta(provider_specific_fields=None, content='istant`', role=None, function_call=None, tool_calls=None, audio=None), logprobs=None)], provider_specific_fields=None, usage=None), 'usage': None}
choice_json: {'index': 0, 'delta': {'provider_specific_fields': None, 'content': 'istant`', 'role': None, 'function_call': None, 'tool_calls': None, 'audio': None}, 'logprobs': None}
choices in streaming: [StreamingChoices(finish_reason=None, index=0, delta=Delta(provider_specific_fields=None, content='istant`', role=None, function_call=None, tool_calls=None, audio=None), logprobs=None)]
final returned processed chunk: ModelResponseStream(id='chatcmpl-1e246dec-1357-4ceb-948f-03d49e55b5f9', created=1762261907, model='claude-sonnet-4-5-20250929', object='chat.completion.chunk', system_fingerprint=None, choices=[StreamingChoices(finish_reason=None, index=0, delta=Delta(provider_specific_fields=None, content='istant`', role=None, function_call=None, tool_calls=None, audio=None), logprobs=None)], provider_specific_fields=None, citations=None)
model_response finish reason 3: None; response_obj={'text': '', 'is_finished': False, 'finish_reason': '', 'usage': None, 'index': 0, 'tool_use': None}
model_response.choices[0].delta: Delta(provider_specific_fields=None, content=None, role=None, function_call=None, tool_calls=None, audio=None); completion_obj: {'content': ''}
self.sent_first_chunk: True
completion_obj: {'content': ''}, model_response.choices[0]: StreamingChoices(finish_reason=None, index=0, delta=Delta(provider_specific_fields=None, content=None, role=None, function_call=None, tool_calls=None, audio=None), logprobs=None), response_obj: {'text': '', 'is_finished': False, 'finish_reason': '', 'usage': None, 'index': 0, 'tool_use': None}
model_response finish reason 3: None; response_obj={'text': '', 'is_finished': False, 'finish_reason': '', 'usage': None, 'index': 0, 'tool_use': None}
model_response.choices[0].delta: Delta(provider_specific_fields=None, content=None, role=None, function_call=None, tool_calls=None, audio=None); completion_obj: {'content': ''}
self.sent_first_chunk: True
completion_obj: {'content': ''}, model_response.choices[0]: StreamingChoices(finish_reason=None, index=0, delta=Delta(provider_specific_fields=None, content=None, role=None, function_call=None, tool_calls=None, audio=None), logprobs=None), response_obj: {'text': '', 'is_finished': False, 'finish_reason': '', 'usage': None, 'index': 0, 'tool_use': None}

Raw OpenAI Chunk
ModelResponseStream(id='chatcmpl-1e246dec-1357-4ceb-948f-03d49e55b5f9', created=1762261909, model=None, object='chat.completion.chunk', system_fingerprint=None, choices=[StreamingChoices(finish_reason=None, index=0, delta=Delta(provider_specific_fields=None, content=' configuration', role=None, function_call=None, tool_calls=None, audio=None), logprobs=None)], provider_specific_fields=None, usage=None)

model_response finish reason 3: None; response_obj={'text': ' configuration', 'is_finished': False, 'finish_reason': None, 'logprobs': None, 'original_chunk': ModelResponseStream(id='chatcmpl-1e246dec-1357-4ceb-948f-03d49e55b5f9', created=1762261909, model=None, object='chat.completion.chunk', system_fingerprint=None, choices=[StreamingChoices(finish_reason=None, index=0, delta=Delta(provider_specific_fields=None, content=' configuration', role=None, function_call=None, tool_calls=None, audio=None), logprobs=None)], provider_specific_fields=None, usage=None), 'usage': None}
original delta: {'provider_specific_fields': None, 'content': ' configuration', 'role': None, 'function_call': None, 'tool_calls': None, 'audio': None}
new delta: Delta(provider_specific_fields=None, content=' configuration', role=None, function_call=None, tool_calls=None, audio=None)
model_response.choices[0].delta: Delta(provider_specific_fields=None, content=' configuration', role=None, function_call=None, tool_calls=None, audio=None); completion_obj: {'content': ' configuration'}
self.sent_first_chunk: True
completion_obj: {'content': ' configuration'}, model_response.choices[0]: StreamingChoices(finish_reason=None, index=0, delta=Delta(provider_specific_fields=None, content=' configuration', role=None, function_call=None, tool_calls=None, audio=None), logprobs=None), response_obj: {'text': ' configuration', 'is_finished': False, 'finish_reason': None, 'logprobs': None, 'original_chunk': ModelResponseStream(id='chatcmpl-1e246dec-1357-4ceb-948f-03d49e55b5f9', created=1762261909, model=None, object='chat.completion.chunk', system_fingerprint=None, choices=[StreamingChoices(finish_reason=None, index=0, delta=Delta(provider_specific_fields=None, content=' configuration', role=None, function_call=None, tool_calls=None, audio=None), logprobs=None)], provider_specific_fields=None, usage=None), 'usage': None}
choice_json: {'index': 0, 'delta': {'provider_specific_fields': None, 'content': ' configuration', 'role': None, 'function_call': None, 'tool_calls': None, 'audio': None}, 'logprobs': None}
choices in streaming: [StreamingChoices(finish_reason=None, index=0, delta=Delta(provider_specific_fields=None, content=' configuration', role=None, function_call=None, tool_calls=None, audio=None), logprobs=None)]
final returned processed chunk: ModelResponseStream(id='chatcmpl-1e246dec-1357-4ceb-948f-03d49e55b5f9', created=1762261907, model='claude-sonnet-4-5-20250929', object='chat.completion.chunk', system_fingerprint=None, choices=[StreamingChoices(finish_reason=None, index=0, delta=Delta(provider_specific_fields=None, content=' configuration', role=None, function_call=None, tool_calls=None, audio=None), logprobs=None)], provider_specific_fields=None, citations=None)
model_response finish reason 3: None; response_obj={'text': '', 'is_finished': False, 'finish_reason': '', 'usage': None, 'index': 0, 'tool_use': None}
model_response.choices[0].delta: Delta(provider_specific_fields=None, content=None, role=None, function_call=None, tool_calls=None, audio=None); completion_obj: {'content': ''}
self.sent_first_chunk: True
completion_obj: {'content': ''}, model_response.choices[0]: StreamingChoices(finish_reason=None, index=0, delta=Delta(provider_specific_fields=None, content=None, role=None, function_call=None, tool_calls=None, audio=None), logprobs=None), response_obj: {'text': '', 'is_finished': False, 'finish_reason': '', 'usage': None, 'index': 0, 'tool_use': None}
model_response finish reason 3: None; response_obj={'text': '', 'is_finished': False, 'finish_reason': '', 'usage': None, 'index': 0, 'tool_use': None}
model_response.choices[0].delta: Delta(provider_specific_fields=None, content=None, role=None, function_call=None, tool_calls=None, audio=None); completion_obj: {'content': ''}
self.sent_first_chunk: True
completion_obj: {'content': ''}, model_response.choices[0]: StreamingChoices(finish_reason=None, index=0, delta=Delta(provider_specific_fields=None, content=None, role=None, function_call=None, tool_calls=None, audio=None), logprobs=None), response_obj: {'text': '', 'is_finished': False, 'finish_reason': '', 'usage': None, 'index': 0, 'tool_use': None}

Raw OpenAI Chunk
ModelResponseStream(id='chatcmpl-1e246dec-1357-4ceb-948f-03d49e55b5f9', created=1762261909, model=None, object='chat.completion.chunk', system_fingerprint=None, choices=[StreamingChoices(finish_reason=None, index=0, delta=Delta(provider_specific_fields=None, content=' that', role=None, function_call=None, tool_calls=None, audio=None), logprobs=None)], provider_specific_fields=None, usage=None)

model_response finish reason 3: None; response_obj={'text': ' that', 'is_finished': False, 'finish_reason': None, 'logprobs': None, 'original_chunk': ModelResponseStream(id='chatcmpl-1e246dec-1357-4ceb-948f-03d49e55b5f9', created=1762261909, model=None, object='chat.completion.chunk', system_fingerprint=None, choices=[StreamingChoices(finish_reason=None, index=0, delta=Delta(provider_specific_fields=None, content=' that', role=None, function_call=None, tool_calls=None, audio=None), logprobs=None)], provider_specific_fields=None, usage=None), 'usage': None}
original delta: {'provider_specific_fields': None, 'content': ' that', 'role': None, 'function_call': None, 'tool_calls': None, 'audio': None}
new delta: Delta(provider_specific_fields=None, content=' that', role=None, function_call=None, tool_calls=None, audio=None)
model_response.choices[0].delta: Delta(provider_specific_fields=None, content=' that', role=None, function_call=None, tool_calls=None, audio=None); completion_obj: {'content': ' that'}
self.sent_first_chunk: True
completion_obj: {'content': ' that'}, model_response.choices[0]: StreamingChoices(finish_reason=None, index=0, delta=Delta(provider_specific_fields=None, content=' that', role=None, function_call=None, tool_calls=None, audio=None), logprobs=None), response_obj: {'text': ' that', 'is_finished': False, 'finish_reason': None, 'logprobs': None, 'original_chunk': ModelResponseStream(id='chatcmpl-1e246dec-1357-4ceb-948f-03d49e55b5f9', created=1762261909, model=None, object='chat.completion.chunk', system_fingerprint=None, choices=[StreamingChoices(finish_reason=None, index=0, delta=Delta(provider_specific_fields=None, content=' that', role=None, function_call=None, tool_calls=None, audio=None), logprobs=None)], provider_specific_fields=None, usage=None), 'usage': None}
choice_json: {'index': 0, 'delta': {'provider_specific_fields': None, 'content': ' that', 'role': None, 'function_call': None, 'tool_calls': None, 'audio': None}, 'logprobs': None}
choices in streaming: [StreamingChoices(finish_reason=None, index=0, delta=Delta(provider_specific_fields=None, content=' that', role=None, function_call=None, tool_calls=None, audio=None), logprobs=None)]
final returned processed chunk: ModelResponseStream(id='chatcmpl-1e246dec-1357-4ceb-948f-03d49e55b5f9', created=1762261907, model='claude-sonnet-4-5-20250929', object='chat.completion.chunk', system_fingerprint=None, choices=[StreamingChoices(finish_reason=None, index=0, delta=Delta(provider_specific_fields=None, content=' that', role=None, function_call=None, tool_calls=None, audio=None), logprobs=None)], provider_specific_fields=None, citations=None)
model_response finish reason 3: None; response_obj={'text': '', 'is_finished': False, 'finish_reason': '', 'usage': None, 'index': 0, 'tool_use': None}
model_response.choices[0].delta: Delta(provider_specific_fields=None, content=None, role=None, function_call=None, tool_calls=None, audio=None); completion_obj: {'content': ''}
self.sent_first_chunk: True
completion_obj: {'content': ''}, model_response.choices[0]: StreamingChoices(finish_reason=None, index=0, delta=Delta(provider_specific_fields=None, content=None, role=None, function_call=None, tool_calls=None, audio=None), logprobs=None), response_obj: {'text': '', 'is_finished': False, 'finish_reason': '', 'usage': None, 'index': 0, 'tool_use': None}
model_response finish reason 3: None; response_obj={'text': '', 'is_finished': False, 'finish_reason': '', 'usage': None, 'index': 0, 'tool_use': None}
model_response.choices[0].delta: Delta(provider_specific_fields=None, content=None, role=None, function_call=None, tool_calls=None, audio=None); completion_obj: {'content': ''}
self.sent_first_chunk: True
completion_obj: {'content': ''}, model_response.choices[0]: StreamingChoices(finish_reason=None, index=0, delta=Delta(provider_specific_fields=None, content=None, role=None, function_call=None, tool_calls=None, audio=None), logprobs=None), response_obj: {'text': '', 'is_finished': False, 'finish_reason': '', 'usage': None, 'index': 0, 'tool_use': None}

Raw OpenAI Chunk
ModelResponseStream(id='chatcmpl-1e246dec-1357-4ceb-948f-03d49e55b5f9', created=1762261909, model=None, object='chat.completion.chunk', system_fingerprint=None, choices=[StreamingChoices(finish_reason=None, index=0, delta=Delta(provider_specific_fields=None, content=' prep', role=None, function_call=None, tool_calls=None, audio=None), logprobs=None)], provider_specific_fields=None, usage=None)

model_response finish reason 3: None; response_obj={'text': ' prep', 'is_finished': False, 'finish_reason': None, 'logprobs': None, 'original_chunk': ModelResponseStream(id='chatcmpl-1e246dec-1357-4ceb-948f-03d49e55b5f9', created=1762261909, model=None, object='chat.completion.chunk', system_fingerprint=None, choices=[StreamingChoices(finish_reason=None, index=0, delta=Delta(provider_specific_fields=None, content=' prep', role=None, function_call=None, tool_calls=None, audio=None), logprobs=None)], provider_specific_fields=None, usage=None), 'usage': None}
original delta: {'provider_specific_fields': None, 'content': ' prep', 'role': None, 'function_call': None, 'tool_calls': None, 'audio': None}
new delta: Delta(provider_specific_fields=None, content=' prep', role=None, function_call=None, tool_calls=None, audio=None)
model_response.choices[0].delta: Delta(provider_specific_fields=None, content=' prep', role=None, function_call=None, tool_calls=None, audio=None); completion_obj: {'content': ' prep'}
self.sent_first_chunk: True
completion_obj: {'content': ' prep'}, model_response.choices[0]: StreamingChoices(finish_reason=None, index=0, delta=Delta(provider_specific_fields=None, content=' prep', role=None, function_call=None, tool_calls=None, audio=None), logprobs=None), response_obj: {'text': ' prep', 'is_finished': False, 'finish_reason': None, 'logprobs': None, 'original_chunk': ModelResponseStream(id='chatcmpl-1e246dec-1357-4ceb-948f-03d49e55b5f9', created=1762261909, model=None, object='chat.completion.chunk', system_fingerprint=None, choices=[StreamingChoices(finish_reason=None, index=0, delta=Delta(provider_specific_fields=None, content=' prep', role=None, function_call=None, tool_calls=None, audio=None), logprobs=None)], provider_specific_fields=None, usage=None), 'usage': None}
choice_json: {'index': 0, 'delta': {'provider_specific_fields': None, 'content': ' prep', 'role': None, 'function_call': None, 'tool_calls': None, 'audio': None}, 'logprobs': None}
choices in streaming: [StreamingChoices(finish_reason=None, index=0, delta=Delta(provider_specific_fields=None, content=' prep', role=None, function_call=None, tool_calls=None, audio=None), logprobs=None)]
final returned processed chunk: ModelResponseStream(id='chatcmpl-1e246dec-1357-4ceb-948f-03d49e55b5f9', created=1762261907, model='claude-sonnet-4-5-20250929', object='chat.completion.chunk', system_fingerprint=None, choices=[StreamingChoices(finish_reason=None, index=0, delta=Delta(provider_specific_fields=None, content=' prep', role=None, function_call=None, tool_calls=None, audio=None), logprobs=None)], provider_specific_fields=None, citations=None)
model_response finish reason 3: None; response_obj={'text': '', 'is_finished': False, 'finish_reason': '', 'usage': None, 'index': 0, 'tool_use': None}
model_response.choices[0].delta: Delta(provider_specific_fields=None, content=None, role=None, function_call=None, tool_calls=None, audio=None); completion_obj: {'content': ''}
self.sent_first_chunk: True
completion_obj: {'content': ''}, model_response.choices[0]: StreamingChoices(finish_reason=None, index=0, delta=Delta(provider_specific_fields=None, content=None, role=None, function_call=None, tool_calls=None, audio=None), logprobs=None), response_obj: {'text': '', 'is_finished': False, 'finish_reason': '', 'usage': None, 'index': 0, 'tool_use': None}
model_response finish reason 3: None; response_obj={'text': '', 'is_finished': False, 'finish_reason': '', 'usage': None, 'index': 0, 'tool_use': None}
model_response.choices[0].delta: Delta(provider_specific_fields=None, content=None, role=None, function_call=None, tool_calls=None, audio=None); completion_obj: {'content': ''}
self.sent_first_chunk: True
completion_obj: {'content': ''}, model_response.choices[0]: StreamingChoices(finish_reason=None, index=0, delta=Delta(provider_specific_fields=None, content=None, role=None, function_call=None, tool_calls=None, audio=None), logprobs=None), response_obj: {'text': '', 'is_finished': False, 'finish_reason': '', 'usage': None, 'index': 0, 'tool_use': None}

Raw OpenAI Chunk
ModelResponseStream(id='chatcmpl-1e246dec-1357-4ceb-948f-03d49e55b5f9', created=1762261909, model=None, object='chat.completion.chunk', system_fingerprint=None, choices=[StreamingChoices(finish_reason=None, index=0, delta=Delta(provider_specific_fields=None, content='ends `', role=None, function_call=None, tool_calls=None, audio=None), logprobs=None)], provider_specific_fields=None, usage=None)

model_response finish reason 3: None; response_obj={'text': 'ends `', 'is_finished': False, 'finish_reason': None, 'logprobs': None, 'original_chunk': ModelResponseStream(id='chatcmpl-1e246dec-1357-4ceb-948f-03d49e55b5f9', created=1762261909, model=None, object='chat.completion.chunk', system_fingerprint=None, choices=[StreamingChoices(finish_reason=None, index=0, delta=Delta(provider_specific_fields=None, content='ends `', role=None, function_call=None, tool_calls=None, audio=None), logprobs=None)], provider_specific_fields=None, usage=None), 'usage': None}
original delta: {'provider_specific_fields': None, 'content': 'ends `', 'role': None, 'function_call': None, 'tool_calls': None, 'audio': None}
new delta: Delta(provider_specific_fields=None, content='ends `', role=None, function_call=None, tool_calls=None, audio=None)
model_response.choices[0].delta: Delta(provider_specific_fields=None, content='ends `', role=None, function_call=None, tool_calls=None, audio=None); completion_obj: {'content': 'ends `'}
self.sent_first_chunk: True
completion_obj: {'content': 'ends `'}, model_response.choices[0]: StreamingChoices(finish_reason=None, index=0, delta=Delta(provider_specific_fields=None, content='ends `', role=None, function_call=None, tool_calls=None, audio=None), logprobs=None), response_obj: {'text': 'ends `', 'is_finished': False, 'finish_reason': None, 'logprobs': None, 'original_chunk': ModelResponseStream(id='chatcmpl-1e246dec-1357-4ceb-948f-03d49e55b5f9', created=1762261909, model=None, object='chat.completion.chunk', system_fingerprint=None, choices=[StreamingChoices(finish_reason=None, index=0, delta=Delta(provider_specific_fields=None, content='ends `', role=None, function_call=None, tool_calls=None, audio=None), logprobs=None)], provider_specific_fields=None, usage=None), 'usage': None}
choice_json: {'index': 0, 'delta': {'provider_specific_fields': None, 'content': 'ends `', 'role': None, 'function_call': None, 'tool_calls': None, 'audio': None}, 'logprobs': None}
choices in streaming: [StreamingChoices(finish_reason=None, index=0, delta=Delta(provider_specific_fields=None, content='ends `', role=None, function_call=None, tool_calls=None, audio=None), logprobs=None)]
final returned processed chunk: ModelResponseStream(id='chatcmpl-1e246dec-1357-4ceb-948f-03d49e55b5f9', created=1762261907, model='claude-sonnet-4-5-20250929', object='chat.completion.chunk', system_fingerprint=None, choices=[StreamingChoices(finish_reason=None, index=0, delta=Delta(provider_specific_fields=None, content='ends `', role=None, function_call=None, tool_calls=None, audio=None), logprobs=None)], provider_specific_fields=None, citations=None)
model_response finish reason 3: None; response_obj={'text': '', 'is_finished': False, 'finish_reason': '', 'usage': None, 'index': 0, 'tool_use': None}
model_response.choices[0].delta: Delta(provider_specific_fields=None, content=None, role=None, function_call=None, tool_calls=None, audio=None); completion_obj: {'content': ''}
self.sent_first_chunk: True
completion_obj: {'content': ''}, model_response.choices[0]: StreamingChoices(finish_reason=None, index=0, delta=Delta(provider_specific_fields=None, content=None, role=None, function_call=None, tool_calls=None, audio=None), logprobs=None), response_obj: {'text': '', 'is_finished': False, 'finish_reason': '', 'usage': None, 'index': 0, 'tool_use': None}
model_response finish reason 3: None; response_obj={'text': '', 'is_finished': False, 'finish_reason': '', 'usage': None, 'index': 0, 'tool_use': None}
model_response.choices[0].delta: Delta(provider_specific_fields=None, content=None, role=None, function_call=None, tool_calls=None, audio=None); completion_obj: {'content': ''}
self.sent_first_chunk: True
completion_obj: {'content': ''}, model_response.choices[0]: StreamingChoices(finish_reason=None, index=0, delta=Delta(provider_specific_fields=None, content=None, role=None, function_call=None, tool_calls=None, audio=None), logprobs=None), response_obj: {'text': '', 'is_finished': False, 'finish_reason': '', 'usage': None, 'index': 0, 'tool_use': None}

Raw OpenAI Chunk
ModelResponseStream(id='chatcmpl-1e246dec-1357-4ceb-948f-03d49e55b5f9', created=1762261909, model=None, object='chat.completion.chunk', system_fingerprint=None, choices=[StreamingChoices(finish_reason=None, index=0, delta=Delta(provider_specific_fields=None, content='x', role=None, function_call=None, tool_calls=None, audio=None), logprobs=None)], provider_specific_fields=None, usage=None)

model_response finish reason 3: None; response_obj={'text': 'x', 'is_finished': False, 'finish_reason': None, 'logprobs': None, 'original_chunk': ModelResponseStream(id='chatcmpl-1e246dec-1357-4ceb-948f-03d49e55b5f9', created=1762261909, model=None, object='chat.completion.chunk', system_fingerprint=None, choices=[StreamingChoices(finish_reason=None, index=0, delta=Delta(provider_specific_fields=None, content='x', role=None, function_call=None, tool_calls=None, audio=None), logprobs=None)], provider_specific_fields=None, usage=None), 'usage': None}
original delta: {'provider_specific_fields': None, 'content': 'x', 'role': None, 'function_call': None, 'tool_calls': None, 'audio': None}
new delta: Delta(provider_specific_fields=None, content='x', role=None, function_call=None, tool_calls=None, audio=None)
model_response.choices[0].delta: Delta(provider_specific_fields=None, content='x', role=None, function_call=None, tool_calls=None, audio=None); completion_obj: {'content': 'x'}
self.sent_first_chunk: True
completion_obj: {'content': 'x'}, model_response.choices[0]: StreamingChoices(finish_reason=None, index=0, delta=Delta(provider_specific_fields=None, content='x', role=None, function_call=None, tool_calls=None, audio=None), logprobs=None), response_obj: {'text': 'x', 'is_finished': False, 'finish_reason': None, 'logprobs': None, 'original_chunk': ModelResponseStream(id='chatcmpl-1e246dec-1357-4ceb-948f-03d49e55b5f9', created=1762261909, model=None, object='chat.completion.chunk', system_fingerprint=None, choices=[StreamingChoices(finish_reason=None, index=0, delta=Delta(provider_specific_fields=None, content='x', role=None, function_call=None, tool_calls=None, audio=None), logprobs=None)], provider_specific_fields=None, usage=None), 'usage': None}
choice_json: {'index': 0, 'delta': {'provider_specific_fields': None, 'content': 'x', 'role': None, 'function_call': None, 'tool_calls': None, 'audio': None}, 'logprobs': None}
choices in streaming: [StreamingChoices(finish_reason=None, index=0, delta=Delta(provider_specific_fields=None, content='x', role=None, function_call=None, tool_calls=None, audio=None), logprobs=None)]
final returned processed chunk: ModelResponseStream(id='chatcmpl-1e246dec-1357-4ceb-948f-03d49e55b5f9', created=1762261907, model='claude-sonnet-4-5-20250929', object='chat.completion.chunk', system_fingerprint=None, choices=[StreamingChoices(finish_reason=None, index=0, delta=Delta(provider_specific_fields=None, content='x', role=None, function_call=None, tool_calls=None, audio=None), logprobs=None)], provider_specific_fields=None, citations=None)
model_response finish reason 3: None; response_obj={'text': '', 'is_finished': False, 'finish_reason': '', 'usage': None, 'index': 0, 'tool_use': None}
model_response.choices[0].delta: Delta(provider_specific_fields=None, content=None, role=None, function_call=None, tool_calls=None, audio=None); completion_obj: {'content': ''}
self.sent_first_chunk: True
completion_obj: {'content': ''}, model_response.choices[0]: StreamingChoices(finish_reason=None, index=0, delta=Delta(provider_specific_fields=None, content=None, role=None, function_call=None, tool_calls=None, audio=None), logprobs=None), response_obj: {'text': '', 'is_finished': False, 'finish_reason': '', 'usage': None, 'index': 0, 'tool_use': None}
model_response finish reason 3: None; response_obj={'text': '', 'is_finished': False, 'finish_reason': '', 'usage': None, 'index': 0, 'tool_use': None}
model_response.choices[0].delta: Delta(provider_specific_fields=None, content=None, role=None, function_call=None, tool_calls=None, audio=None); completion_obj: {'content': ''}
self.sent_first_chunk: True
completion_obj: {'content': ''}, model_response.choices[0]: StreamingChoices(finish_reason=None, index=0, delta=Delta(provider_specific_fields=None, content=None, role=None, function_call=None, tool_calls=None, audio=None), logprobs=None), response_obj: {'text': '', 'is_finished': False, 'finish_reason': '', 'usage': None, 'index': 0, 'tool_use': None}

Raw OpenAI Chunk
ModelResponseStream(id='chatcmpl-1e246dec-1357-4ceb-948f-03d49e55b5f9', created=1762261909, model=None, object='chat.completion.chunk', system_fingerprint=None, choices=[StreamingChoices(finish_reason=None, index=0, delta=Delta(provider_specific_fields=None, content='-sm-user-id: lit', role=None, function_call=None, tool_calls=None, audio=None), logprobs=None)], provider_specific_fields=None, usage=None)

model_response finish reason 3: None; response_obj={'text': '-sm-user-id: lit', 'is_finished': False, 'finish_reason': None, 'logprobs': None, 'original_chunk': ModelResponseStream(id='chatcmpl-1e246dec-1357-4ceb-948f-03d49e55b5f9', created=1762261909, model=None, object='chat.completion.chunk', system_fingerprint=None, choices=[StreamingChoices(finish_reason=None, index=0, delta=Delta(provider_specific_fields=None, content='-sm-user-id: lit', role=None, function_call=None, tool_calls=None, audio=None), logprobs=None)], provider_specific_fields=None, usage=None), 'usage': None}
original delta: {'provider_specific_fields': None, 'content': '-sm-user-id: lit', 'role': None, 'function_call': None, 'tool_calls': None, 'audio': None}
new delta: Delta(provider_specific_fields=None, content='-sm-user-id: lit', role=None, function_call=None, tool_calls=None, audio=None)
model_response.choices[0].delta: Delta(provider_specific_fields=None, content='-sm-user-id: lit', role=None, function_call=None, tool_calls=None, audio=None); completion_obj: {'content': '-sm-user-id: lit'}
self.sent_first_chunk: True
completion_obj: {'content': '-sm-user-id: lit'}, model_response.choices[0]: StreamingChoices(finish_reason=None, index=0, delta=Delta(provider_specific_fields=None, content='-sm-user-id: lit', role=None, function_call=None, tool_calls=None, audio=None), logprobs=None), response_obj: {'text': '-sm-user-id: lit', 'is_finished': False, 'finish_reason': None, 'logprobs': None, 'original_chunk': ModelResponseStream(id='chatcmpl-1e246dec-1357-4ceb-948f-03d49e55b5f9', created=1762261909, model=None, object='chat.completion.chunk', system_fingerprint=None, choices=[StreamingChoices(finish_reason=None, index=0, delta=Delta(provider_specific_fields=None, content='-sm-user-id: lit', role=None, function_call=None, tool_calls=None, audio=None), logprobs=None)], provider_specific_fields=None, usage=None), 'usage': None}
choice_json: {'index': 0, 'delta': {'provider_specific_fields': None, 'content': '-sm-user-id: lit', 'role': None, 'function_call': None, 'tool_calls': None, 'audio': None}, 'logprobs': None}
choices in streaming: [StreamingChoices(finish_reason=None, index=0, delta=Delta(provider_specific_fields=None, content='-sm-user-id: lit', role=None, function_call=None, tool_calls=None, audio=None), logprobs=None)]
final returned processed chunk: ModelResponseStream(id='chatcmpl-1e246dec-1357-4ceb-948f-03d49e55b5f9', created=1762261907, model='claude-sonnet-4-5-20250929', object='chat.completion.chunk', system_fingerprint=None, choices=[StreamingChoices(finish_reason=None, index=0, delta=Delta(provider_specific_fields=None, content='-sm-user-id: lit', role=None, function_call=None, tool_calls=None, audio=None), logprobs=None)], provider_specific_fields=None, citations=None)
model_response finish reason 3: None; response_obj={'text': '', 'is_finished': False, 'finish_reason': '', 'usage': None, 'index': 0, 'tool_use': None}
model_response.choices[0].delta: Delta(provider_specific_fields=None, content=None, role=None, function_call=None, tool_calls=None, audio=None); completion_obj: {'content': ''}
self.sent_first_chunk: True
completion_obj: {'content': ''}, model_response.choices[0]: StreamingChoices(finish_reason=None, index=0, delta=Delta(provider_specific_fields=None, content=None, role=None, function_call=None, tool_calls=None, audio=None), logprobs=None), response_obj: {'text': '', 'is_finished': False, 'finish_reason': '', 'usage': None, 'index': 0, 'tool_use': None}
model_response finish reason 3: None; response_obj={'text': '', 'is_finished': False, 'finish_reason': '', 'usage': None, 'index': 0, 'tool_use': None}
model_response.choices[0].delta: Delta(provider_specific_fields=None, content=None, role=None, function_call=None, tool_calls=None, audio=None); completion_obj: {'content': ''}
self.sent_first_chunk: True
completion_obj: {'content': ''}, model_response.choices[0]: StreamingChoices(finish_reason=None, index=0, delta=Delta(provider_specific_fields=None, content=None, role=None, function_call=None, tool_calls=None, audio=None), logprobs=None), response_obj: {'text': '', 'is_finished': False, 'finish_reason': '', 'usage': None, 'index': 0, 'tool_use': None}

Raw OpenAI Chunk
ModelResponseStream(id='chatcmpl-1e246dec-1357-4ceb-948f-03d49e55b5f9', created=1762261909, model=None, object='chat.completion.chunk', system_fingerprint=None, choices=[StreamingChoices(finish_reason=None, index=0, delta=Delta(provider_specific_fields=None, content='ellm` to all requests', role=None, function_call=None, tool_calls=None, audio=None), logprobs=None)], provider_specific_fields=None, usage=None)

model_response finish reason 3: None; response_obj={'text': 'ellm` to all requests', 'is_finished': False, 'finish_reason': None, 'logprobs': None, 'original_chunk': ModelResponseStream(id='chatcmpl-1e246dec-1357-4ceb-948f-03d49e55b5f9', created=1762261909, model=None, object='chat.completion.chunk', system_fingerprint=None, choices=[StreamingChoices(finish_reason=None, index=0, delta=Delta(provider_specific_fields=None, content='ellm` to all requests', role=None, function_call=None, tool_calls=None, audio=None), logprobs=None)], provider_specific_fields=None, usage=None), 'usage': None}
original delta: {'provider_specific_fields': None, 'content': 'ellm` to all requests', 'role': None, 'function_call': None, 'tool_calls': None, 'audio': None}
new delta: Delta(provider_specific_fields=None, content='ellm` to all requests', role=None, function_call=None, tool_calls=None, audio=None)
model_response.choices[0].delta: Delta(provider_specific_fields=None, content='ellm` to all requests', role=None, function_call=None, tool_calls=None, audio=None); completion_obj: {'content': 'ellm` to all requests'}
self.sent_first_chunk: True
completion_obj: {'content': 'ellm` to all requests'}, model_response.choices[0]: StreamingChoices(finish_reason=None, index=0, delta=Delta(provider_specific_fields=None, content='ellm` to all requests', role=None, function_call=None, tool_calls=None, audio=None), logprobs=None), response_obj: {'text': 'ellm` to all requests', 'is_finished': False, 'finish_reason': None, 'logprobs': None, 'original_chunk': ModelResponseStream(id='chatcmpl-1e246dec-1357-4ceb-948f-03d49e55b5f9', created=1762261909, model=None, object='chat.completion.chunk', system_fingerprint=None, choices=[StreamingChoices(finish_reason=None, index=0, delta=Delta(provider_specific_fields=None, content='ellm` to all requests', role=None, function_call=None, tool_calls=None, audio=None), logprobs=None)], provider_specific_fields=None, usage=None), 'usage': None}
choice_json: {'index': 0, 'delta': {'provider_specific_fields': None, 'content': 'ellm` to all requests', 'role': None, 'function_call': None, 'tool_calls': None, 'audio': None}, 'logprobs': None}
choices in streaming: [StreamingChoices(finish_reason=None, index=0, delta=Delta(provider_specific_fields=None, content='ellm` to all requests', role=None, function_call=None, tool_calls=None, audio=None), logprobs=None)]
final returned processed chunk: ModelResponseStream(id='chatcmpl-1e246dec-1357-4ceb-948f-03d49e55b5f9', created=1762261907, model='claude-sonnet-4-5-20250929', object='chat.completion.chunk', system_fingerprint=None, choices=[StreamingChoices(finish_reason=None, index=0, delta=Delta(provider_specific_fields=None, content='ellm` to all requests', role=None, function_call=None, tool_calls=None, audio=None), logprobs=None)], provider_specific_fields=None, citations=None)
model_response finish reason 3: None; response_obj={'text': '', 'is_finished': False, 'finish_reason': '', 'usage': None, 'index': 0, 'tool_use': None}
model_response.choices[0].delta: Delta(provider_specific_fields=None, content=None, role=None, function_call=None, tool_calls=None, audio=None); completion_obj: {'content': ''}
self.sent_first_chunk: True
completion_obj: {'content': ''}, model_response.choices[0]: StreamingChoices(finish_reason=None, index=0, delta=Delta(provider_specific_fields=None, content=None, role=None, function_call=None, tool_calls=None, audio=None), logprobs=None), response_obj: {'text': '', 'is_finished': False, 'finish_reason': '', 'usage': None, 'index': 0, 'tool_use': None}
model_response finish reason 3: None; response_obj={'text': '', 'is_finished': False, 'finish_reason': '', 'usage': None, 'index': 0, 'tool_use': None}
model_response.choices[0].delta: Delta(provider_specific_fields=None, content=None, role=None, function_call=None, tool_calls=None, audio=None); completion_obj: {'content': ''}
self.sent_first_chunk: True
completion_obj: {'content': ''}, model_response.choices[0]: StreamingChoices(finish_reason=None, index=0, delta=Delta(provider_specific_fields=None, content=None, role=None, function_call=None, tool_calls=None, audio=None), logprobs=None), response_obj: {'text': '', 'is_finished': False, 'finish_reason': '', 'usage': None, 'index': 0, 'tool_use': None}

Raw OpenAI Chunk
ModelResponseStream(id='chatcmpl-1e246dec-1357-4ceb-948f-03d49e55b5f9', created=1762261909, model=None, object='chat.completion.chunk', system_fingerprint=None, choices=[StreamingChoices(finish_reason=None, index=0, delta=Delta(provider_specific_fields=None, content='.', role=None, function_call=None, tool_calls=None, audio=None), logprobs=None)], provider_specific_fields=None, usage=None)

model_response finish reason 3: None; response_obj={'text': '.', 'is_finished': False, 'finish_reason': None, 'logprobs': None, 'original_chunk': ModelResponseStream(id='chatcmpl-1e246dec-1357-4ceb-948f-03d49e55b5f9', created=1762261909, model=None, object='chat.completion.chunk', system_fingerprint=None, choices=[StreamingChoices(finish_reason=None, index=0, delta=Delta(provider_specific_fields=None, content='.', role=None, function_call=None, tool_calls=None, audio=None), logprobs=None)], provider_specific_fields=None, usage=None), 'usage': None}
original delta: {'provider_specific_fields': None, 'content': '.', 'role': None, 'function_call': None, 'tool_calls': None, 'audio': None}
new delta: Delta(provider_specific_fields=None, content='.', role=None, function_call=None, tool_calls=None, audio=None)
model_response.choices[0].delta: Delta(provider_specific_fields=None, content='.', role=None, function_call=None, tool_calls=None, audio=None); completion_obj: {'content': '.'}
self.sent_first_chunk: True
completion_obj: {'content': '.'}, model_response.choices[0]: StreamingChoices(finish_reason=None, index=0, delta=Delta(provider_specific_fields=None, content='.', role=None, function_call=None, tool_calls=None, audio=None), logprobs=None), response_obj: {'text': '.', 'is_finished': False, 'finish_reason': None, 'logprobs': None, 'original_chunk': ModelResponseStream(id='chatcmpl-1e246dec-1357-4ceb-948f-03d49e55b5f9', created=1762261909, model=None, object='chat.completion.chunk', system_fingerprint=None, choices=[StreamingChoices(finish_reason=None, index=0, delta=Delta(provider_specific_fields=None, content='.', role=None, function_call=None, tool_calls=None, audio=None), logprobs=None)], provider_specific_fields=None, usage=None), 'usage': None}
choice_json: {'index': 0, 'delta': {'provider_specific_fields': None, 'content': '.', 'role': None, 'function_call': None, 'tool_calls': None, 'audio': None}, 'logprobs': None}
choices in streaming: [StreamingChoices(finish_reason=None, index=0, delta=Delta(provider_specific_fields=None, content='.', role=None, function_call=None, tool_calls=None, audio=None), logprobs=None)]
final returned processed chunk: ModelResponseStream(id='chatcmpl-1e246dec-1357-4ceb-948f-03d49e55b5f9', created=1762261907, model='claude-sonnet-4-5-20250929', object='chat.completion.chunk', system_fingerprint=None, choices=[StreamingChoices(finish_reason=None, index=0, delta=Delta(provider_specific_fields=None, content='.', role=None, function_call=None, tool_calls=None, audio=None), logprobs=None)], provider_specific_fields=None, citations=None)
model_response finish reason 3: None; response_obj={'text': '', 'is_finished': False, 'finish_reason': '', 'usage': None, 'index': 0, 'tool_use': None}
model_response.choices[0].delta: Delta(provider_specific_fields=None, content=None, role=None, function_call=None, tool_calls=None, audio=None); completion_obj: {'content': ''}
self.sent_first_chunk: True
completion_obj: {'content': ''}, model_response.choices[0]: StreamingChoices(finish_reason=None, index=0, delta=Delta(provider_specific_fields=None, content=None, role=None, function_call=None, tool_calls=None, audio=None), logprobs=None), response_obj: {'text': '', 'is_finished': False, 'finish_reason': '', 'usage': None, 'index': 0, 'tool_use': None}
model_response finish reason 3: None; response_obj={'text': '', 'is_finished': False, 'finish_reason': '', 'usage': None, 'index': 0, 'tool_use': None}
model_response.choices[0].delta: Delta(provider_specific_fields=None, content=None, role=None, function_call=None, tool_calls=None, audio=None); completion_obj: {'content': ''}
self.sent_first_chunk: True
completion_obj: {'content': ''}, model_response.choices[0]: StreamingChoices(finish_reason=None, index=0, delta=Delta(provider_specific_fields=None, content=None, role=None, function_call=None, tool_calls=None, audio=None), logprobs=None), response_obj: {'text': '', 'is_finished': False, 'finish_reason': '', 'usage': None, 'index': 0, 'tool_use': None}

Raw OpenAI Chunk
ModelResponseStream(id='chatcmpl-1e246dec-1357-4ceb-948f-03d49e55b5f9', created=1762261909, model=None, object='chat.completion.chunk', system_fingerprint=None, choices=[StreamingChoices(finish_reason=None, index=0, delta=Delta(provider_specific_fields=None, content='\n\nLooking', role=None, function_call=None, tool_calls=None, audio=None), logprobs=None)], provider_specific_fields=None, usage=None)

model_response finish reason 3: None; response_obj={'text': '\n\nLooking', 'is_finished': False, 'finish_reason': None, 'logprobs': None, 'original_chunk': ModelResponseStream(id='chatcmpl-1e246dec-1357-4ceb-948f-03d49e55b5f9', created=1762261909, model=None, object='chat.completion.chunk', system_fingerprint=None, choices=[StreamingChoices(finish_reason=None, index=0, delta=Delta(provider_specific_fields=None, content='\n\nLooking', role=None, function_call=None, tool_calls=None, audio=None), logprobs=None)], provider_specific_fields=None, usage=None), 'usage': None}
original delta: {'provider_specific_fields': None, 'content': '\n\nLooking', 'role': None, 'function_call': None, 'tool_calls': None, 'audio': None}
new delta: Delta(provider_specific_fields=None, content='\n\nLooking', role=None, function_call=None, tool_calls=None, audio=None)
model_response.choices[0].delta: Delta(provider_specific_fields=None, content='\n\nLooking', role=None, function_call=None, tool_calls=None, audio=None); completion_obj: {'content': '\n\nLooking'}
self.sent_first_chunk: True
completion_obj: {'content': '\n\nLooking'}, model_response.choices[0]: StreamingChoices(finish_reason=None, index=0, delta=Delta(provider_specific_fields=None, content='\n\nLooking', role=None, function_call=None, tool_calls=None, audio=None), logprobs=None), response_obj: {'text': '\n\nLooking', 'is_finished': False, 'finish_reason': None, 'logprobs': None, 'original_chunk': ModelResponseStream(id='chatcmpl-1e246dec-1357-4ceb-948f-03d49e55b5f9', created=1762261909, model=None, object='chat.completion.chunk', system_fingerprint=None, choices=[StreamingChoices(finish_reason=None, index=0, delta=Delta(provider_specific_fields=None, content='\n\nLooking', role=None, function_call=None, tool_calls=None, audio=None), logprobs=None)], provider_specific_fields=None, usage=None), 'usage': None}
choice_json: {'index': 0, 'delta': {'provider_specific_fields': None, 'content': '\n\nLooking', 'role': None, 'function_call': None, 'tool_calls': None, 'audio': None}, 'logprobs': None}
choices in streaming: [StreamingChoices(finish_reason=None, index=0, delta=Delta(provider_specific_fields=None, content='\n\nLooking', role=None, function_call=None, tool_calls=None, audio=None), logprobs=None)]
final returned processed chunk: ModelResponseStream(id='chatcmpl-1e246dec-1357-4ceb-948f-03d49e55b5f9', created=1762261907, model='claude-sonnet-4-5-20250929', object='chat.completion.chunk', system_fingerprint=None, choices=[StreamingChoices(finish_reason=None, index=0, delta=Delta(provider_specific_fields=None, content='\n\nLooking', role=None, function_call=None, tool_calls=None, audio=None), logprobs=None)], provider_specific_fields=None, citations=None)
model_response finish reason 3: None; response_obj={'text': '', 'is_finished': False, 'finish_reason': '', 'usage': None, 'index': 0, 'tool_use': None}
model_response.choices[0].delta: Delta(provider_specific_fields=None, content=None, role=None, function_call=None, tool_calls=None, audio=None); completion_obj: {'content': ''}
self.sent_first_chunk: True
completion_obj: {'content': ''}, model_response.choices[0]: StreamingChoices(finish_reason=None, index=0, delta=Delta(provider_specific_fields=None, content=None, role=None, function_call=None, tool_calls=None, audio=None), logprobs=None), response_obj: {'text': '', 'is_finished': False, 'finish_reason': '', 'usage': None, 'index': 0, 'tool_use': None}
model_response finish reason 3: None; response_obj={'text': '', 'is_finished': False, 'finish_reason': '', 'usage': None, 'index': 0, 'tool_use': None}
model_response.choices[0].delta: Delta(provider_specific_fields=None, content=None, role=None, function_call=None, tool_calls=None, audio=None); completion_obj: {'content': ''}
self.sent_first_chunk: True
completion_obj: {'content': ''}, model_response.choices[0]: StreamingChoices(finish_reason=None, index=0, delta=Delta(provider_specific_fields=None, content=None, role=None, function_call=None, tool_calls=None, audio=None), logprobs=None), response_obj: {'text': '', 'is_finished': False, 'finish_reason': '', 'usage': None, 'index': 0, 'tool_use': None}

Raw OpenAI Chunk
ModelResponseStream(id='chatcmpl-1e246dec-1357-4ceb-948f-03d49e55b5f9', created=1762261909, model=None, object='chat.completion.chunk', system_fingerprint=None, choices=[StreamingChoices(finish_reason=None, index=0, delta=Delta(provider_specific_fields=None, content=' at your question', role=None, function_call=None, tool_calls=None, audio=None), logprobs=None)], provider_specific_fields=None, usage=None)

model_response finish reason 3: None; response_obj={'text': ' at your question', 'is_finished': False, 'finish_reason': None, 'logprobs': None, 'original_chunk': ModelResponseStream(id='chatcmpl-1e246dec-1357-4ceb-948f-03d49e55b5f9', created=1762261909, model=None, object='chat.completion.chunk', system_fingerprint=None, choices=[StreamingChoices(finish_reason=None, index=0, delta=Delta(provider_specific_fields=None, content=' at your question', role=None, function_call=None, tool_calls=None, audio=None), logprobs=None)], provider_specific_fields=None, usage=None), 'usage': None}
original delta: {'provider_specific_fields': None, 'content': ' at your question', 'role': None, 'function_call': None, 'tool_calls': None, 'audio': None}
new delta: Delta(provider_specific_fields=None, content=' at your question', role=None, function_call=None, tool_calls=None, audio=None)
model_response.choices[0].delta: Delta(provider_specific_fields=None, content=' at your question', role=None, function_call=None, tool_calls=None, audio=None); completion_obj: {'content': ' at your question'}
self.sent_first_chunk: True
completion_obj: {'content': ' at your question'}, model_response.choices[0]: StreamingChoices(finish_reason=None, index=0, delta=Delta(provider_specific_fields=None, content=' at your question', role=None, function_call=None, tool_calls=None, audio=None), logprobs=None), response_obj: {'text': ' at your question', 'is_finished': False, 'finish_reason': None, 'logprobs': None, 'original_chunk': ModelResponseStream(id='chatcmpl-1e246dec-1357-4ceb-948f-03d49e55b5f9', created=1762261909, model=None, object='chat.completion.chunk', system_fingerprint=None, choices=[StreamingChoices(finish_reason=None, index=0, delta=Delta(provider_specific_fields=None, content=' at your question', role=None, function_call=None, tool_calls=None, audio=None), logprobs=None)], provider_specific_fields=None, usage=None), 'usage': None}
choice_json: {'index': 0, 'delta': {'provider_specific_fields': None, 'content': ' at your question', 'role': None, 'function_call': None, 'tool_calls': None, 'audio': None}, 'logprobs': None}
choices in streaming: [StreamingChoices(finish_reason=None, index=0, delta=Delta(provider_specific_fields=None, content=' at your question', role=None, function_call=None, tool_calls=None, audio=None), logprobs=None)]
final returned processed chunk: ModelResponseStream(id='chatcmpl-1e246dec-1357-4ceb-948f-03d49e55b5f9', created=1762261907, model='claude-sonnet-4-5-20250929', object='chat.completion.chunk', system_fingerprint=None, choices=[StreamingChoices(finish_reason=None, index=0, delta=Delta(provider_specific_fields=None, content=' at your question', role=None, function_call=None, tool_calls=None, audio=None), logprobs=None)], provider_specific_fields=None, citations=None)
model_response finish reason 3: None; response_obj={'text': '', 'is_finished': False, 'finish_reason': '', 'usage': None, 'index': 0, 'tool_use': None}
model_response.choices[0].delta: Delta(provider_specific_fields=None, content=None, role=None, function_call=None, tool_calls=None, audio=None); completion_obj: {'content': ''}
self.sent_first_chunk: True
completion_obj: {'content': ''}, model_response.choices[0]: StreamingChoices(finish_reason=None, index=0, delta=Delta(provider_specific_fields=None, content=None, role=None, function_call=None, tool_calls=None, audio=None), logprobs=None), response_obj: {'text': '', 'is_finished': False, 'finish_reason': '', 'usage': None, 'index': 0, 'tool_use': None}
model_response finish reason 3: None; response_obj={'text': '', 'is_finished': False, 'finish_reason': '', 'usage': None, 'index': 0, 'tool_use': None}
model_response.choices[0].delta: Delta(provider_specific_fields=None, content=None, role=None, function_call=None, tool_calls=None, audio=None); completion_obj: {'content': ''}
self.sent_first_chunk: True
completion_obj: {'content': ''}, model_response.choices[0]: StreamingChoices(finish_reason=None, index=0, delta=Delta(provider_specific_fields=None, content=None, role=None, function_call=None, tool_calls=None, audio=None), logprobs=None), response_obj: {'text': '', 'is_finished': False, 'finish_reason': '', 'usage': None, 'index': 0, 'tool_use': None}

Raw OpenAI Chunk
ModelResponseStream(id='chatcmpl-1e246dec-1357-4ceb-948f-03d49e55b5f9', created=1762261909, model=None, object='chat.completion.chunk', system_fingerprint=None, choices=[StreamingChoices(finish_reason=None, index=0, delta=Delta(provider_specific_fields=None, content=' about past', role=None, function_call=None, tool_calls=None, audio=None), logprobs=None)], provider_specific_fields=None, usage=None)

model_response finish reason 3: None; response_obj={'text': ' about past', 'is_finished': False, 'finish_reason': None, 'logprobs': None, 'original_chunk': ModelResponseStream(id='chatcmpl-1e246dec-1357-4ceb-948f-03d49e55b5f9', created=1762261909, model=None, object='chat.completion.chunk', system_fingerprint=None, choices=[StreamingChoices(finish_reason=None, index=0, delta=Delta(provider_specific_fields=None, content=' about past', role=None, function_call=None, tool_calls=None, audio=None), logprobs=None)], provider_specific_fields=None, usage=None), 'usage': None}
original delta: {'provider_specific_fields': None, 'content': ' about past', 'role': None, 'function_call': None, 'tool_calls': None, 'audio': None}
new delta: Delta(provider_specific_fields=None, content=' about past', role=None, function_call=None, tool_calls=None, audio=None)
model_response.choices[0].delta: Delta(provider_specific_fields=None, content=' about past', role=None, function_call=None, tool_calls=None, audio=None); completion_obj: {'content': ' about past'}
self.sent_first_chunk: True
completion_obj: {'content': ' about past'}, model_response.choices[0]: StreamingChoices(finish_reason=None, index=0, delta=Delta(provider_specific_fields=None, content=' about past', role=None, function_call=None, tool_calls=None, audio=None), logprobs=None), response_obj: {'text': ' about past', 'is_finished': False, 'finish_reason': None, 'logprobs': None, 'original_chunk': ModelResponseStream(id='chatcmpl-1e246dec-1357-4ceb-948f-03d49e55b5f9', created=1762261909, model=None, object='chat.completion.chunk', system_fingerprint=None, choices=[StreamingChoices(finish_reason=None, index=0, delta=Delta(provider_specific_fields=None, content=' about past', role=None, function_call=None, tool_calls=None, audio=None), logprobs=None)], provider_specific_fields=None, usage=None), 'usage': None}
choice_json: {'index': 0, 'delta': {'provider_specific_fields': None, 'content': ' about past', 'role': None, 'function_call': None, 'tool_calls': None, 'audio': None}, 'logprobs': None}
choices in streaming: [StreamingChoices(finish_reason=None, index=0, delta=Delta(provider_specific_fields=None, content=' about past', role=None, function_call=None, tool_calls=None, audio=None), logprobs=None)]
final returned processed chunk: ModelResponseStream(id='chatcmpl-1e246dec-1357-4ceb-948f-03d49e55b5f9', created=1762261907, model='claude-sonnet-4-5-20250929', object='chat.completion.chunk', system_fingerprint=None, choices=[StreamingChoices(finish_reason=None, index=0, delta=Delta(provider_specific_fields=None, content=' about past', role=None, function_call=None, tool_calls=None, audio=None), logprobs=None)], provider_specific_fields=None, citations=None)
model_response finish reason 3: None; response_obj={'text': '', 'is_finished': False, 'finish_reason': '', 'usage': None, 'index': 0, 'tool_use': None}
model_response.choices[0].delta: Delta(provider_specific_fields=None, content=None, role=None, function_call=None, tool_calls=None, audio=None); completion_obj: {'content': ''}
self.sent_first_chunk: True
completion_obj: {'content': ''}, model_response.choices[0]: StreamingChoices(finish_reason=None, index=0, delta=Delta(provider_specific_fields=None, content=None, role=None, function_call=None, tool_calls=None, audio=None), logprobs=None), response_obj: {'text': '', 'is_finished': False, 'finish_reason': '', 'usage': None, 'index': 0, 'tool_use': None}
model_response finish reason 3: None; response_obj={'text': '', 'is_finished': False, 'finish_reason': '', 'usage': None, 'index': 0, 'tool_use': None}
model_response.choices[0].delta: Delta(provider_specific_fields=None, content=None, role=None, function_call=None, tool_calls=None, audio=None); completion_obj: {'content': ''}
self.sent_first_chunk: True
completion_obj: {'content': ''}, model_response.choices[0]: StreamingChoices(finish_reason=None, index=0, delta=Delta(provider_specific_fields=None, content=None, role=None, function_call=None, tool_calls=None, audio=None), logprobs=None), response_obj: {'text': '', 'is_finished': False, 'finish_reason': '', 'usage': None, 'index': 0, 'tool_use': None}

Raw OpenAI Chunk
ModelResponseStream(id='chatcmpl-1e246dec-1357-4ceb-948f-03d49e55b5f9', created=1762261909, model=None, object='chat.completion.chunk', system_fingerprint=None, choices=[StreamingChoices(finish_reason=None, index=0, delta=Delta(provider_specific_fields=None, content=' conversations an', role=None, function_call=None, tool_calls=None, audio=None), logprobs=None)], provider_specific_fields=None, usage=None)

model_response finish reason 3: None; response_obj={'text': ' conversations an', 'is_finished': False, 'finish_reason': None, 'logprobs': None, 'original_chunk': ModelResponseStream(id='chatcmpl-1e246dec-1357-4ceb-948f-03d49e55b5f9', created=1762261909, model=None, object='chat.completion.chunk', system_fingerprint=None, choices=[StreamingChoices(finish_reason=None, index=0, delta=Delta(provider_specific_fields=None, content=' conversations an', role=None, function_call=None, tool_calls=None, audio=None), logprobs=None)], provider_specific_fields=None, usage=None), 'usage': None}
original delta: {'provider_specific_fields': None, 'content': ' conversations an', 'role': None, 'function_call': None, 'tool_calls': None, 'audio': None}
new delta: Delta(provider_specific_fields=None, content=' conversations an', role=None, function_call=None, tool_calls=None, audio=None)
model_response.choices[0].delta: Delta(provider_specific_fields=None, content=' conversations an', role=None, function_call=None, tool_calls=None, audio=None); completion_obj: {'content': ' conversations an'}
self.sent_first_chunk: True
completion_obj: {'content': ' conversations an'}, model_response.choices[0]: StreamingChoices(finish_reason=None, index=0, delta=Delta(provider_specific_fields=None, content=' conversations an', role=None, function_call=None, tool_calls=None, audio=None), logprobs=None), response_obj: {'text': ' conversations an', 'is_finished': False, 'finish_reason': None, 'logprobs': None, 'original_chunk': ModelResponseStream(id='chatcmpl-1e246dec-1357-4ceb-948f-03d49e55b5f9', created=1762261909, model=None, object='chat.completion.chunk', system_fingerprint=None, choices=[StreamingChoices(finish_reason=None, index=0, delta=Delta(provider_specific_fields=None, content=' conversations an', role=None, function_call=None, tool_calls=None, audio=None), logprobs=None)], provider_specific_fields=None, usage=None), 'usage': None}
choice_json: {'index': 0, 'delta': {'provider_specific_fields': None, 'content': ' conversations an', 'role': None, 'function_call': None, 'tool_calls': None, 'audio': None}, 'logprobs': None}
choices in streaming: [StreamingChoices(finish_reason=None, index=0, delta=Delta(provider_specific_fields=None, content=' conversations an', role=None, function_call=None, tool_calls=None, audio=None), logprobs=None)]
final returned processed chunk: ModelResponseStream(id='chatcmpl-1e246dec-1357-4ceb-948f-03d49e55b5f9', created=1762261907, model='claude-sonnet-4-5-20250929', object='chat.completion.chunk', system_fingerprint=None, choices=[StreamingChoices(finish_reason=None, index=0, delta=Delta(provider_specific_fields=None, content=' conversations an', role=None, function_call=None, tool_calls=None, audio=None), logprobs=None)], provider_specific_fields=None, citations=None)
model_response finish reason 3: None; response_obj={'text': '', 'is_finished': False, 'finish_reason': '', 'usage': None, 'index': 0, 'tool_use': None}
model_response.choices[0].delta: Delta(provider_specific_fields=None, content=None, role=None, function_call=None, tool_calls=None, audio=None); completion_obj: {'content': ''}
self.sent_first_chunk: True
completion_obj: {'content': ''}, model_response.choices[0]: StreamingChoices(finish_reason=None, index=0, delta=Delta(provider_specific_fields=None, content=None, role=None, function_call=None, tool_calls=None, audio=None), logprobs=None), response_obj: {'text': '', 'is_finished': False, 'finish_reason': '', 'usage': None, 'index': 0, 'tool_use': None}
model_response finish reason 3: None; response_obj={'text': '', 'is_finished': False, 'finish_reason': '', 'usage': None, 'index': 0, 'tool_use': None}
model_response.choices[0].delta: Delta(provider_specific_fields=None, content=None, role=None, function_call=None, tool_calls=None, audio=None); completion_obj: {'content': ''}
self.sent_first_chunk: True
completion_obj: {'content': ''}, model_response.choices[0]: StreamingChoices(finish_reason=None, index=0, delta=Delta(provider_specific_fields=None, content=None, role=None, function_call=None, tool_calls=None, audio=None), logprobs=None), response_obj: {'text': '', 'is_finished': False, 'finish_reason': '', 'usage': None, 'index': 0, 'tool_use': None}

Raw OpenAI Chunk
ModelResponseStream(id='chatcmpl-1e246dec-1357-4ceb-948f-03d49e55b5f9', created=1762261909, model=None, object='chat.completion.chunk', system_fingerprint=None, choices=[StreamingChoices(finish_reason=None, index=0, delta=Delta(provider_specific_fields=None, content='d the', role=None, function_call=None, tool_calls=None, audio=None), logprobs=None)], provider_specific_fields=None, usage=None)

model_response finish reason 3: None; response_obj={'text': 'd the', 'is_finished': False, 'finish_reason': None, 'logprobs': None, 'original_chunk': ModelResponseStream(id='chatcmpl-1e246dec-1357-4ceb-948f-03d49e55b5f9', created=1762261909, model=None, object='chat.completion.chunk', system_fingerprint=None, choices=[StreamingChoices(finish_reason=None, index=0, delta=Delta(provider_specific_fields=None, content='d the', role=None, function_call=None, tool_calls=None, audio=None), logprobs=None)], provider_specific_fields=None, usage=None), 'usage': None}
original delta: {'provider_specific_fields': None, 'content': 'd the', 'role': None, 'function_call': None, 'tool_calls': None, 'audio': None}
new delta: Delta(provider_specific_fields=None, content='d the', role=None, function_call=None, tool_calls=None, audio=None)
model_response.choices[0].delta: Delta(provider_specific_fields=None, content='d the', role=None, function_call=None, tool_calls=None, audio=None); completion_obj: {'content': 'd the'}
self.sent_first_chunk: True
completion_obj: {'content': 'd the'}, model_response.choices[0]: StreamingChoices(finish_reason=None, index=0, delta=Delta(provider_specific_fields=None, content='d the', role=None, function_call=None, tool_calls=None, audio=None), logprobs=None), response_obj: {'text': 'd the', 'is_finished': False, 'finish_reason': None, 'logprobs': None, 'original_chunk': ModelResponseStream(id='chatcmpl-1e246dec-1357-4ceb-948f-03d49e55b5f9', created=1762261909, model=None, object='chat.completion.chunk', system_fingerprint=None, choices=[StreamingChoices(finish_reason=None, index=0, delta=Delta(provider_specific_fields=None, content='d the', role=None, function_call=None, tool_calls=None, audio=None), logprobs=None)], provider_specific_fields=None, usage=None), 'usage': None}
choice_json: {'index': 0, 'delta': {'provider_specific_fields': None, 'content': 'd the', 'role': None, 'function_call': None, 'tool_calls': None, 'audio': None}, 'logprobs': None}
choices in streaming: [StreamingChoices(finish_reason=None, index=0, delta=Delta(provider_specific_fields=None, content='d the', role=None, function_call=None, tool_calls=None, audio=None), logprobs=None)]
final returned processed chunk: ModelResponseStream(id='chatcmpl-1e246dec-1357-4ceb-948f-03d49e55b5f9', created=1762261907, model='claude-sonnet-4-5-20250929', object='chat.completion.chunk', system_fingerprint=None, choices=[StreamingChoices(finish_reason=None, index=0, delta=Delta(provider_specific_fields=None, content='d the', role=None, function_call=None, tool_calls=None, audio=None), logprobs=None)], provider_specific_fields=None, citations=None)
model_response finish reason 3: None; response_obj={'text': '', 'is_finished': False, 'finish_reason': '', 'usage': None, 'index': 0, 'tool_use': None}
model_response.choices[0].delta: Delta(provider_specific_fields=None, content=None, role=None, function_call=None, tool_calls=None, audio=None); completion_obj: {'content': ''}
self.sent_first_chunk: True
completion_obj: {'content': ''}, model_response.choices[0]: StreamingChoices(finish_reason=None, index=0, delta=Delta(provider_specific_fields=None, content=None, role=None, function_call=None, tool_calls=None, audio=None), logprobs=None), response_obj: {'text': '', 'is_finished': False, 'finish_reason': '', 'usage': None, 'index': 0, 'tool_use': None}
model_response finish reason 3: None; response_obj={'text': '', 'is_finished': False, 'finish_reason': '', 'usage': None, 'index': 0, 'tool_use': None}
model_response.choices[0].delta: Delta(provider_specific_fields=None, content=None, role=None, function_call=None, tool_calls=None, audio=None); completion_obj: {'content': ''}
self.sent_first_chunk: True
completion_obj: {'content': ''}, model_response.choices[0]: StreamingChoices(finish_reason=None, index=0, delta=Delta(provider_specific_fields=None, content=None, role=None, function_call=None, tool_calls=None, audio=None), logprobs=None), response_obj: {'text': '', 'is_finished': False, 'finish_reason': '', 'usage': None, 'index': 0, 'tool_use': None}

Raw OpenAI Chunk
ModelResponseStream(id='chatcmpl-1e246dec-1357-4ceb-948f-03d49e55b5f9', created=1762261909, model=None, object='chat.completion.chunk', system_fingerprint=None, choices=[StreamingChoices(finish_reason=None, index=0, delta=Delta(provider_specific_fields=None, content=' context you', role=None, function_call=None, tool_calls=None, audio=None), logprobs=None)], provider_specific_fields=None, usage=None)

model_response finish reason 3: None; response_obj={'text': ' context you', 'is_finished': False, 'finish_reason': None, 'logprobs': None, 'original_chunk': ModelResponseStream(id='chatcmpl-1e246dec-1357-4ceb-948f-03d49e55b5f9', created=1762261909, model=None, object='chat.completion.chunk', system_fingerprint=None, choices=[StreamingChoices(finish_reason=None, index=0, delta=Delta(provider_specific_fields=None, content=' context you', role=None, function_call=None, tool_calls=None, audio=None), logprobs=None)], provider_specific_fields=None, usage=None), 'usage': None}
original delta: {'provider_specific_fields': None, 'content': ' context you', 'role': None, 'function_call': None, 'tool_calls': None, 'audio': None}
new delta: Delta(provider_specific_fields=None, content=' context you', role=None, function_call=None, tool_calls=None, audio=None)
model_response.choices[0].delta: Delta(provider_specific_fields=None, content=' context you', role=None, function_call=None, tool_calls=None, audio=None); completion_obj: {'content': ' context you'}
self.sent_first_chunk: True
completion_obj: {'content': ' context you'}, model_response.choices[0]: StreamingChoices(finish_reason=None, index=0, delta=Delta(provider_specific_fields=None, content=' context you', role=None, function_call=None, tool_calls=None, audio=None), logprobs=None), response_obj: {'text': ' context you', 'is_finished': False, 'finish_reason': None, 'logprobs': None, 'original_chunk': ModelResponseStream(id='chatcmpl-1e246dec-1357-4ceb-948f-03d49e55b5f9', created=1762261909, model=None, object='chat.completion.chunk', system_fingerprint=None, choices=[StreamingChoices(finish_reason=None, index=0, delta=Delta(provider_specific_fields=None, content=' context you', role=None, function_call=None, tool_calls=None, audio=None), logprobs=None)], provider_specific_fields=None, usage=None), 'usage': None}
choice_json: {'index': 0, 'delta': {'provider_specific_fields': None, 'content': ' context you', 'role': None, 'function_call': None, 'tool_calls': None, 'audio': None}, 'logprobs': None}
choices in streaming: [StreamingChoices(finish_reason=None, index=0, delta=Delta(provider_specific_fields=None, content=' context you', role=None, function_call=None, tool_calls=None, audio=None), logprobs=None)]
final returned processed chunk: ModelResponseStream(id='chatcmpl-1e246dec-1357-4ceb-948f-03d49e55b5f9', created=1762261907, model='claude-sonnet-4-5-20250929', object='chat.completion.chunk', system_fingerprint=None, choices=[StreamingChoices(finish_reason=None, index=0, delta=Delta(provider_specific_fields=None, content=' context you', role=None, function_call=None, tool_calls=None, audio=None), logprobs=None)], provider_specific_fields=None, citations=None)
model_response finish reason 3: None; response_obj={'text': '', 'is_finished': False, 'finish_reason': '', 'usage': None, 'index': 0, 'tool_use': None}
model_response.choices[0].delta: Delta(provider_specific_fields=None, content=None, role=None, function_call=None, tool_calls=None, audio=None); completion_obj: {'content': ''}
self.sent_first_chunk: True
completion_obj: {'content': ''}, model_response.choices[0]: StreamingChoices(finish_reason=None, index=0, delta=Delta(provider_specific_fields=None, content=None, role=None, function_call=None, tool_calls=None, audio=None), logprobs=None), response_obj: {'text': '', 'is_finished': False, 'finish_reason': '', 'usage': None, 'index': 0, 'tool_use': None}
model_response finish reason 3: None; response_obj={'text': '', 'is_finished': False, 'finish_reason': '', 'usage': None, 'index': 0, 'tool_use': None}
model_response.choices[0].delta: Delta(provider_specific_fields=None, content=None, role=None, function_call=None, tool_calls=None, audio=None); completion_obj: {'content': ''}
self.sent_first_chunk: True
completion_obj: {'content': ''}, model_response.choices[0]: StreamingChoices(finish_reason=None, index=0, delta=Delta(provider_specific_fields=None, content=None, role=None, function_call=None, tool_calls=None, audio=None), logprobs=None), response_obj: {'text': '', 'is_finished': False, 'finish_reason': '', 'usage': None, 'index': 0, 'tool_use': None}

Raw OpenAI Chunk
ModelResponseStream(id='chatcmpl-1e246dec-1357-4ceb-948f-03d49e55b5f9', created=1762261909, model=None, object='chat.completion.chunk', system_fingerprint=None, choices=[StreamingChoices(finish_reason=None, index=0, delta=Delta(provider_specific_fields=None, content="'ve provide", role=None, function_call=None, tool_calls=None, audio=None), logprobs=None)], provider_specific_fields=None, usage=None)

model_response finish reason 3: None; response_obj={'text': "'ve provide", 'is_finished': False, 'finish_reason': None, 'logprobs': None, 'original_chunk': ModelResponseStream(id='chatcmpl-1e246dec-1357-4ceb-948f-03d49e55b5f9', created=1762261909, model=None, object='chat.completion.chunk', system_fingerprint=None, choices=[StreamingChoices(finish_reason=None, index=0, delta=Delta(provider_specific_fields=None, content="'ve provide", role=None, function_call=None, tool_calls=None, audio=None), logprobs=None)], provider_specific_fields=None, usage=None), 'usage': None}
original delta: {'provider_specific_fields': None, 'content': "'ve provide", 'role': None, 'function_call': None, 'tool_calls': None, 'audio': None}
new delta: Delta(provider_specific_fields=None, content="'ve provide", role=None, function_call=None, tool_calls=None, audio=None)
model_response.choices[0].delta: Delta(provider_specific_fields=None, content="'ve provide", role=None, function_call=None, tool_calls=None, audio=None); completion_obj: {'content': "'ve provide"}
self.sent_first_chunk: True
completion_obj: {'content': "'ve provide"}, model_response.choices[0]: StreamingChoices(finish_reason=None, index=0, delta=Delta(provider_specific_fields=None, content="'ve provide", role=None, function_call=None, tool_calls=None, audio=None), logprobs=None), response_obj: {'text': "'ve provide", 'is_finished': False, 'finish_reason': None, 'logprobs': None, 'original_chunk': ModelResponseStream(id='chatcmpl-1e246dec-1357-4ceb-948f-03d49e55b5f9', created=1762261909, model=None, object='chat.completion.chunk', system_fingerprint=None, choices=[StreamingChoices(finish_reason=None, index=0, delta=Delta(provider_specific_fields=None, content="'ve provide", role=None, function_call=None, tool_calls=None, audio=None), logprobs=None)], provider_specific_fields=None, usage=None), 'usage': None}
choice_json: {'index': 0, 'delta': {'provider_specific_fields': None, 'content': "'ve provide", 'role': None, 'function_call': None, 'tool_calls': None, 'audio': None}, 'logprobs': None}
choices in streaming: [StreamingChoices(finish_reason=None, index=0, delta=Delta(provider_specific_fields=None, content="'ve provide", role=None, function_call=None, tool_calls=None, audio=None), logprobs=None)]
final returned processed chunk: ModelResponseStream(id='chatcmpl-1e246dec-1357-4ceb-948f-03d49e55b5f9', created=1762261907, model='claude-sonnet-4-5-20250929', object='chat.completion.chunk', system_fingerprint=None, choices=[StreamingChoices(finish_reason=None, index=0, delta=Delta(provider_specific_fields=None, content="'ve provide", role=None, function_call=None, tool_calls=None, audio=None), logprobs=None)], provider_specific_fields=None, citations=None)
model_response finish reason 3: None; response_obj={'text': '', 'is_finished': False, 'finish_reason': '', 'usage': None, 'index': 0, 'tool_use': None}
model_response.choices[0].delta: Delta(provider_specific_fields=None, content=None, role=None, function_call=None, tool_calls=None, audio=None); completion_obj: {'content': ''}
self.sent_first_chunk: True
completion_obj: {'content': ''}, model_response.choices[0]: StreamingChoices(finish_reason=None, index=0, delta=Delta(provider_specific_fields=None, content=None, role=None, function_call=None, tool_calls=None, audio=None), logprobs=None), response_obj: {'text': '', 'is_finished': False, 'finish_reason': '', 'usage': None, 'index': 0, 'tool_use': None}
model_response finish reason 3: None; response_obj={'text': '', 'is_finished': False, 'finish_reason': '', 'usage': None, 'index': 0, 'tool_use': None}
model_response.choices[0].delta: Delta(provider_specific_fields=None, content=None, role=None, function_call=None, tool_calls=None, audio=None); completion_obj: {'content': ''}
self.sent_first_chunk: True
completion_obj: {'content': ''}, model_response.choices[0]: StreamingChoices(finish_reason=None, index=0, delta=Delta(provider_specific_fields=None, content=None, role=None, function_call=None, tool_calls=None, audio=None), logprobs=None), response_obj: {'text': '', 'is_finished': False, 'finish_reason': '', 'usage': None, 'index': 0, 'tool_use': None}

Raw OpenAI Chunk
ModelResponseStream(id='chatcmpl-1e246dec-1357-4ceb-948f-03d49e55b5f9', created=1762261909, model=None, object='chat.completion.chunk', system_fingerprint=None, choices=[StreamingChoices(finish_reason=None, index=0, delta=Delta(provider_specific_fields=None, content='d, I can see:', role=None, function_call=None, tool_calls=None, audio=None), logprobs=None)], provider_specific_fields=None, usage=None)

model_response finish reason 3: None; response_obj={'text': 'd, I can see:', 'is_finished': False, 'finish_reason': None, 'logprobs': None, 'original_chunk': ModelResponseStream(id='chatcmpl-1e246dec-1357-4ceb-948f-03d49e55b5f9', created=1762261909, model=None, object='chat.completion.chunk', system_fingerprint=None, choices=[StreamingChoices(finish_reason=None, index=0, delta=Delta(provider_specific_fields=None, content='d, I can see:', role=None, function_call=None, tool_calls=None, audio=None), logprobs=None)], provider_specific_fields=None, usage=None), 'usage': None}
original delta: {'provider_specific_fields': None, 'content': 'd, I can see:', 'role': None, 'function_call': None, 'tool_calls': None, 'audio': None}
new delta: Delta(provider_specific_fields=None, content='d, I can see:', role=None, function_call=None, tool_calls=None, audio=None)
model_response.choices[0].delta: Delta(provider_specific_fields=None, content='d, I can see:', role=None, function_call=None, tool_calls=None, audio=None); completion_obj: {'content': 'd, I can see:'}
self.sent_first_chunk: True
completion_obj: {'content': 'd, I can see:'}, model_response.choices[0]: StreamingChoices(finish_reason=None, index=0, delta=Delta(provider_specific_fields=None, content='d, I can see:', role=None, function_call=None, tool_calls=None, audio=None), logprobs=None), response_obj: {'text': 'd, I can see:', 'is_finished': False, 'finish_reason': None, 'logprobs': None, 'original_chunk': ModelResponseStream(id='chatcmpl-1e246dec-1357-4ceb-948f-03d49e55b5f9', created=1762261909, model=None, object='chat.completion.chunk', system_fingerprint=None, choices=[StreamingChoices(finish_reason=None, index=0, delta=Delta(provider_specific_fields=None, content='d, I can see:', role=None, function_call=None, tool_calls=None, audio=None), logprobs=None)], provider_specific_fields=None, usage=None), 'usage': None}
choice_json: {'index': 0, 'delta': {'provider_specific_fields': None, 'content': 'd, I can see:', 'role': None, 'function_call': None, 'tool_calls': None, 'audio': None}, 'logprobs': None}
choices in streaming: [StreamingChoices(finish_reason=None, index=0, delta=Delta(provider_specific_fields=None, content='d, I can see:', role=None, function_call=None, tool_calls=None, audio=None), logprobs=None)]
final returned processed chunk: ModelResponseStream(id='chatcmpl-1e246dec-1357-4ceb-948f-03d49e55b5f9', created=1762261907, model='claude-sonnet-4-5-20250929', object='chat.completion.chunk', system_fingerprint=None, choices=[StreamingChoices(finish_reason=None, index=0, delta=Delta(provider_specific_fields=None, content='d, I can see:', role=None, function_call=None, tool_calls=None, audio=None), logprobs=None)], provider_specific_fields=None, citations=None)
model_response finish reason 3: None; response_obj={'text': '', 'is_finished': False, 'finish_reason': '', 'usage': None, 'index': 0, 'tool_use': None}
model_response.choices[0].delta: Delta(provider_specific_fields=None, content=None, role=None, function_call=None, tool_calls=None, audio=None); completion_obj: {'content': ''}
self.sent_first_chunk: True
completion_obj: {'content': ''}, model_response.choices[0]: StreamingChoices(finish_reason=None, index=0, delta=Delta(provider_specific_fields=None, content=None, role=None, function_call=None, tool_calls=None, audio=None), logprobs=None), response_obj: {'text': '', 'is_finished': False, 'finish_reason': '', 'usage': None, 'index': 0, 'tool_use': None}
model_response finish reason 3: None; response_obj={'text': '', 'is_finished': False, 'finish_reason': '', 'usage': None, 'index': 0, 'tool_use': None}
model_response.choices[0].delta: Delta(provider_specific_fields=None, content=None, role=None, function_call=None, tool_calls=None, audio=None); completion_obj: {'content': ''}
self.sent_first_chunk: True
completion_obj: {'content': ''}, model_response.choices[0]: StreamingChoices(finish_reason=None, index=0, delta=Delta(provider_specific_fields=None, content=None, role=None, function_call=None, tool_calls=None, audio=None), logprobs=None), response_obj: {'text': '', 'is_finished': False, 'finish_reason': '', 'usage': None, 'index': 0, 'tool_use': None}

Raw OpenAI Chunk
ModelResponseStream(id='chatcmpl-1e246dec-1357-4ceb-948f-03d49e55b5f9', created=1762261909, model=None, object='chat.completion.chunk', system_fingerprint=None, choices=[StreamingChoices(finish_reason=None, index=0, delta=Delta(provider_specific_fields=None, content='\n\n##', role=None, function_call=None, tool_calls=None, audio=None), logprobs=None)], provider_specific_fields=None, usage=None)

model_response finish reason 3: None; response_obj={'text': '\n\n##', 'is_finished': False, 'finish_reason': None, 'logprobs': None, 'original_chunk': ModelResponseStream(id='chatcmpl-1e246dec-1357-4ceb-948f-03d49e55b5f9', created=1762261909, model=None, object='chat.completion.chunk', system_fingerprint=None, choices=[StreamingChoices(finish_reason=None, index=0, delta=Delta(provider_specific_fields=None, content='\n\n##', role=None, function_call=None, tool_calls=None, audio=None), logprobs=None)], provider_specific_fields=None, usage=None), 'usage': None}
original delta: {'provider_specific_fields': None, 'content': '\n\n##', 'role': None, 'function_call': None, 'tool_calls': None, 'audio': None}
new delta: Delta(provider_specific_fields=None, content='\n\n##', role=None, function_call=None, tool_calls=None, audio=None)
model_response.choices[0].delta: Delta(provider_specific_fields=None, content='\n\n##', role=None, function_call=None, tool_calls=None, audio=None); completion_obj: {'content': '\n\n##'}
self.sent_first_chunk: True
completion_obj: {'content': '\n\n##'}, model_response.choices[0]: StreamingChoices(finish_reason=None, index=0, delta=Delta(provider_specific_fields=None, content='\n\n##', role=None, function_call=None, tool_calls=None, audio=None), logprobs=None), response_obj: {'text': '\n\n##', 'is_finished': False, 'finish_reason': None, 'logprobs': None, 'original_chunk': ModelResponseStream(id='chatcmpl-1e246dec-1357-4ceb-948f-03d49e55b5f9', created=1762261909, model=None, object='chat.completion.chunk', system_fingerprint=None, choices=[StreamingChoices(finish_reason=None, index=0, delta=Delta(provider_specific_fields=None, content='\n\n##', role=None, function_call=None, tool_calls=None, audio=None), logprobs=None)], provider_specific_fields=None, usage=None), 'usage': None}
choice_json: {'index': 0, 'delta': {'provider_specific_fields': None, 'content': '\n\n##', 'role': None, 'function_call': None, 'tool_calls': None, 'audio': None}, 'logprobs': None}
choices in streaming: [StreamingChoices(finish_reason=None, index=0, delta=Delta(provider_specific_fields=None, content='\n\n##', role=None, function_call=None, tool_calls=None, audio=None), logprobs=None)]
final returned processed chunk: ModelResponseStream(id='chatcmpl-1e246dec-1357-4ceb-948f-03d49e55b5f9', created=1762261907, model='claude-sonnet-4-5-20250929', object='chat.completion.chunk', system_fingerprint=None, choices=[StreamingChoices(finish_reason=None, index=0, delta=Delta(provider_specific_fields=None, content='\n\n##', role=None, function_call=None, tool_calls=None, audio=None), logprobs=None)], provider_specific_fields=None, citations=None)
model_response finish reason 3: None; response_obj={'text': '', 'is_finished': False, 'finish_reason': '', 'usage': None, 'index': 0, 'tool_use': None}
model_response.choices[0].delta: Delta(provider_specific_fields=None, content=None, role=None, function_call=None, tool_calls=None, audio=None); completion_obj: {'content': ''}
self.sent_first_chunk: True
completion_obj: {'content': ''}, model_response.choices[0]: StreamingChoices(finish_reason=None, index=0, delta=Delta(provider_specific_fields=None, content=None, role=None, function_call=None, tool_calls=None, audio=None), logprobs=None), response_obj: {'text': '', 'is_finished': False, 'finish_reason': '', 'usage': None, 'index': 0, 'tool_use': None}
model_response finish reason 3: None; response_obj={'text': '', 'is_finished': False, 'finish_reason': '', 'usage': None, 'index': 0, 'tool_use': None}
model_response.choices[0].delta: Delta(provider_specific_fields=None, content=None, role=None, function_call=None, tool_calls=None, audio=None); completion_obj: {'content': ''}
self.sent_first_chunk: True
completion_obj: {'content': ''}, model_response.choices[0]: StreamingChoices(finish_reason=None, index=0, delta=Delta(provider_specific_fields=None, content=None, role=None, function_call=None, tool_calls=None, audio=None), logprobs=None), response_obj: {'text': '', 'is_finished': False, 'finish_reason': '', 'usage': None, 'index': 0, 'tool_use': None}

Raw OpenAI Chunk
ModelResponseStream(id='chatcmpl-1e246dec-1357-4ceb-948f-03d49e55b5f9', created=1762261909, model=None, object='chat.completion.chunk', system_fingerprint=None, choices=[StreamingChoices(finish_reason=None, index=0, delta=Delta(provider_specific_fields=None, content=' What', role=None, function_call=None, tool_calls=None, audio=None), logprobs=None)], provider_specific_fields=None, usage=None)

model_response finish reason 3: None; response_obj={'text': ' What', 'is_finished': False, 'finish_reason': None, 'logprobs': None, 'original_chunk': ModelResponseStream(id='chatcmpl-1e246dec-1357-4ceb-948f-03d49e55b5f9', created=1762261909, model=None, object='chat.completion.chunk', system_fingerprint=None, choices=[StreamingChoices(finish_reason=None, index=0, delta=Delta(provider_specific_fields=None, content=' What', role=None, function_call=None, tool_calls=None, audio=None), logprobs=None)], provider_specific_fields=None, usage=None), 'usage': None}
original delta: {'provider_specific_fields': None, 'content': ' What', 'role': None, 'function_call': None, 'tool_calls': None, 'audio': None}
new delta: Delta(provider_specific_fields=None, content=' What', role=None, function_call=None, tool_calls=None, audio=None)
model_response.choices[0].delta: Delta(provider_specific_fields=None, content=' What', role=None, function_call=None, tool_calls=None, audio=None); completion_obj: {'content': ' What'}
self.sent_first_chunk: True
completion_obj: {'content': ' What'}, model_response.choices[0]: StreamingChoices(finish_reason=None, index=0, delta=Delta(provider_specific_fields=None, content=' What', role=None, function_call=None, tool_calls=None, audio=None), logprobs=None), response_obj: {'text': ' What', 'is_finished': False, 'finish_reason': None, 'logprobs': None, 'original_chunk': ModelResponseStream(id='chatcmpl-1e246dec-1357-4ceb-948f-03d49e55b5f9', created=1762261909, model=None, object='chat.completion.chunk', system_fingerprint=None, choices=[StreamingChoices(finish_reason=None, index=0, delta=Delta(provider_specific_fields=None, content=' What', role=None, function_call=None, tool_calls=None, audio=None), logprobs=None)], provider_specific_fields=None, usage=None), 'usage': None}
choice_json: {'index': 0, 'delta': {'provider_specific_fields': None, 'content': ' What', 'role': None, 'function_call': None, 'tool_calls': None, 'audio': None}, 'logprobs': None}
choices in streaming: [StreamingChoices(finish_reason=None, index=0, delta=Delta(provider_specific_fields=None, content=' What', role=None, function_call=None, tool_calls=None, audio=None), logprobs=None)]
final returned processed chunk: ModelResponseStream(id='chatcmpl-1e246dec-1357-4ceb-948f-03d49e55b5f9', created=1762261907, model='claude-sonnet-4-5-20250929', object='chat.completion.chunk', system_fingerprint=None, choices=[StreamingChoices(finish_reason=None, index=0, delta=Delta(provider_specific_fields=None, content=' What', role=None, function_call=None, tool_calls=None, audio=None), logprobs=None)], provider_specific_fields=None, citations=None)
model_response finish reason 3: None; response_obj={'text': '', 'is_finished': False, 'finish_reason': '', 'usage': None, 'index': 0, 'tool_use': None}
model_response.choices[0].delta: Delta(provider_specific_fields=None, content=None, role=None, function_call=None, tool_calls=None, audio=None); completion_obj: {'content': ''}
self.sent_first_chunk: True
completion_obj: {'content': ''}, model_response.choices[0]: StreamingChoices(finish_reason=None, index=0, delta=Delta(provider_specific_fields=None, content=None, role=None, function_call=None, tool_calls=None, audio=None), logprobs=None), response_obj: {'text': '', 'is_finished': False, 'finish_reason': '', 'usage': None, 'index': 0, 'tool_use': None}
model_response finish reason 3: None; response_obj={'text': '', 'is_finished': False, 'finish_reason': '', 'usage': None, 'index': 0, 'tool_use': None}
model_response.choices[0].delta: Delta(provider_specific_fields=None, content=None, role=None, function_call=None, tool_calls=None, audio=None); completion_obj: {'content': ''}
self.sent_first_chunk: True
completion_obj: {'content': ''}, model_response.choices[0]: StreamingChoices(finish_reason=None, index=0, delta=Delta(provider_specific_fields=None, content=None, role=None, function_call=None, tool_calls=None, audio=None), logprobs=None), response_obj: {'text': '', 'is_finished': False, 'finish_reason': '', 'usage': None, 'index': 0, 'tool_use': None}

Raw OpenAI Chunk
ModelResponseStream(id='chatcmpl-1e246dec-1357-4ceb-948f-03d49e55b5f9', created=1762261909, model=None, object='chat.completion.chunk', system_fingerprint=None, choices=[StreamingChoices(finish_reason=None, index=0, delta=Delta(provider_specific_fields=None, content=' I', role=None, function_call=None, tool_calls=None, audio=None), logprobs=None)], provider_specific_fields=None, usage=None)

model_response finish reason 3: None; response_obj={'text': ' I', 'is_finished': False, 'finish_reason': None, 'logprobs': None, 'original_chunk': ModelResponseStream(id='chatcmpl-1e246dec-1357-4ceb-948f-03d49e55b5f9', created=1762261909, model=None, object='chat.completion.chunk', system_fingerprint=None, choices=[StreamingChoices(finish_reason=None, index=0, delta=Delta(provider_specific_fields=None, content=' I', role=None, function_call=None, tool_calls=None, audio=None), logprobs=None)], provider_specific_fields=None, usage=None), 'usage': None}
original delta: {'provider_specific_fields': None, 'content': ' I', 'role': None, 'function_call': None, 'tool_calls': None, 'audio': None}
new delta: Delta(provider_specific_fields=None, content=' I', role=None, function_call=None, tool_calls=None, audio=None)
model_response.choices[0].delta: Delta(provider_specific_fields=None, content=' I', role=None, function_call=None, tool_calls=None, audio=None); completion_obj: {'content': ' I'}
self.sent_first_chunk: True
completion_obj: {'content': ' I'}, model_response.choices[0]: StreamingChoices(finish_reason=None, index=0, delta=Delta(provider_specific_fields=None, content=' I', role=None, function_call=None, tool_calls=None, audio=None), logprobs=None), response_obj: {'text': ' I', 'is_finished': False, 'finish_reason': None, 'logprobs': None, 'original_chunk': ModelResponseStream(id='chatcmpl-1e246dec-1357-4ceb-948f-03d49e55b5f9', created=1762261909, model=None, object='chat.completion.chunk', system_fingerprint=None, choices=[StreamingChoices(finish_reason=None, index=0, delta=Delta(provider_specific_fields=None, content=' I', role=None, function_call=None, tool_calls=None, audio=None), logprobs=None)], provider_specific_fields=None, usage=None), 'usage': None}
choice_json: {'index': 0, 'delta': {'provider_specific_fields': None, 'content': ' I', 'role': None, 'function_call': None, 'tool_calls': None, 'audio': None}, 'logprobs': None}
choices in streaming: [StreamingChoices(finish_reason=None, index=0, delta=Delta(provider_specific_fields=None, content=' I', role=None, function_call=None, tool_calls=None, audio=None), logprobs=None)]
final returned processed chunk: ModelResponseStream(id='chatcmpl-1e246dec-1357-4ceb-948f-03d49e55b5f9', created=1762261907, model='claude-sonnet-4-5-20250929', object='chat.completion.chunk', system_fingerprint=None, choices=[StreamingChoices(finish_reason=None, index=0, delta=Delta(provider_specific_fields=None, content=' I', role=None, function_call=None, tool_calls=None, audio=None), logprobs=None)], provider_specific_fields=None, citations=None)
model_response finish reason 3: None; response_obj={'text': '', 'is_finished': False, 'finish_reason': '', 'usage': None, 'index': 0, 'tool_use': None}
model_response.choices[0].delta: Delta(provider_specific_fields=None, content=None, role=None, function_call=None, tool_calls=None, audio=None); completion_obj: {'content': ''}
self.sent_first_chunk: True
completion_obj: {'content': ''}, model_response.choices[0]: StreamingChoices(finish_reason=None, index=0, delta=Delta(provider_specific_fields=None, content=None, role=None, function_call=None, tool_calls=None, audio=None), logprobs=None), response_obj: {'text': '', 'is_finished': False, 'finish_reason': '', 'usage': None, 'index': 0, 'tool_use': None}
model_response finish reason 3: None; response_obj={'text': '', 'is_finished': False, 'finish_reason': '', 'usage': None, 'index': 0, 'tool_use': None}
model_response.choices[0].delta: Delta(provider_specific_fields=None, content=None, role=None, function_call=None, tool_calls=None, audio=None); completion_obj: {'content': ''}
self.sent_first_chunk: True
completion_obj: {'content': ''}, model_response.choices[0]: StreamingChoices(finish_reason=None, index=0, delta=Delta(provider_specific_fields=None, content=None, role=None, function_call=None, tool_calls=None, audio=None), logprobs=None), response_obj: {'text': '', 'is_finished': False, 'finish_reason': '', 'usage': None, 'index': 0, 'tool_use': None}

Raw OpenAI Chunk
ModelResponseStream(id='chatcmpl-1e246dec-1357-4ceb-948f-03d49e55b5f9', created=1762261910, model=None, object='chat.completion.chunk', system_fingerprint=None, choices=[StreamingChoices(finish_reason=None, index=0, delta=Delta(provider_specific_fields=None, content=' Know', role=None, function_call=None, tool_calls=None, audio=None), logprobs=None)], provider_specific_fields=None, usage=None)

model_response finish reason 3: None; response_obj={'text': ' Know', 'is_finished': False, 'finish_reason': None, 'logprobs': None, 'original_chunk': ModelResponseStream(id='chatcmpl-1e246dec-1357-4ceb-948f-03d49e55b5f9', created=1762261910, model=None, object='chat.completion.chunk', system_fingerprint=None, choices=[StreamingChoices(finish_reason=None, index=0, delta=Delta(provider_specific_fields=None, content=' Know', role=None, function_call=None, tool_calls=None, audio=None), logprobs=None)], provider_specific_fields=None, usage=None), 'usage': None}
original delta: {'provider_specific_fields': None, 'content': ' Know', 'role': None, 'function_call': None, 'tool_calls': None, 'audio': None}
new delta: Delta(provider_specific_fields=None, content=' Know', role=None, function_call=None, tool_calls=None, audio=None)
model_response.choices[0].delta: Delta(provider_specific_fields=None, content=' Know', role=None, function_call=None, tool_calls=None, audio=None); completion_obj: {'content': ' Know'}
self.sent_first_chunk: True
completion_obj: {'content': ' Know'}, model_response.choices[0]: StreamingChoices(finish_reason=None, index=0, delta=Delta(provider_specific_fields=None, content=' Know', role=None, function_call=None, tool_calls=None, audio=None), logprobs=None), response_obj: {'text': ' Know', 'is_finished': False, 'finish_reason': None, 'logprobs': None, 'original_chunk': ModelResponseStream(id='chatcmpl-1e246dec-1357-4ceb-948f-03d49e55b5f9', created=1762261910, model=None, object='chat.completion.chunk', system_fingerprint=None, choices=[StreamingChoices(finish_reason=None, index=0, delta=Delta(provider_specific_fields=None, content=' Know', role=None, function_call=None, tool_calls=None, audio=None), logprobs=None)], provider_specific_fields=None, usage=None), 'usage': None}
choice_json: {'index': 0, 'delta': {'provider_specific_fields': None, 'content': ' Know', 'role': None, 'function_call': None, 'tool_calls': None, 'audio': None}, 'logprobs': None}
choices in streaming: [StreamingChoices(finish_reason=None, index=0, delta=Delta(provider_specific_fields=None, content=' Know', role=None, function_call=None, tool_calls=None, audio=None), logprobs=None)]
final returned processed chunk: ModelResponseStream(id='chatcmpl-1e246dec-1357-4ceb-948f-03d49e55b5f9', created=1762261907, model='claude-sonnet-4-5-20250929', object='chat.completion.chunk', system_fingerprint=None, choices=[StreamingChoices(finish_reason=None, index=0, delta=Delta(provider_specific_fields=None, content=' Know', role=None, function_call=None, tool_calls=None, audio=None), logprobs=None)], provider_specific_fields=None, citations=None)
model_response finish reason 3: None; response_obj={'text': '', 'is_finished': False, 'finish_reason': '', 'usage': None, 'index': 0, 'tool_use': None}
model_response.choices[0].delta: Delta(provider_specific_fields=None, content=None, role=None, function_call=None, tool_calls=None, audio=None); completion_obj: {'content': ''}
self.sent_first_chunk: True
completion_obj: {'content': ''}, model_response.choices[0]: StreamingChoices(finish_reason=None, index=0, delta=Delta(provider_specific_fields=None, content=None, role=None, function_call=None, tool_calls=None, audio=None), logprobs=None), response_obj: {'text': '', 'is_finished': False, 'finish_reason': '', 'usage': None, 'index': 0, 'tool_use': None}
model_response finish reason 3: None; response_obj={'text': '', 'is_finished': False, 'finish_reason': '', 'usage': None, 'index': 0, 'tool_use': None}
model_response.choices[0].delta: Delta(provider_specific_fields=None, content=None, role=None, function_call=None, tool_calls=None, audio=None); completion_obj: {'content': ''}
self.sent_first_chunk: True
completion_obj: {'content': ''}, model_response.choices[0]: StreamingChoices(finish_reason=None, index=0, delta=Delta(provider_specific_fields=None, content=None, role=None, function_call=None, tool_calls=None, audio=None), logprobs=None), response_obj: {'text': '', 'is_finished': False, 'finish_reason': '', 'usage': None, 'index': 0, 'tool_use': None}

Raw OpenAI Chunk
ModelResponseStream(id='chatcmpl-1e246dec-1357-4ceb-948f-03d49e55b5f9', created=1762261910, model=None, object='chat.completion.chunk', system_fingerprint=None, choices=[StreamingChoices(finish_reason=None, index=0, delta=Delta(provider_specific_fields=None, content=' About Your Project', role=None, function_call=None, tool_calls=None, audio=None), logprobs=None)], provider_specific_fields=None, usage=None)

model_response finish reason 3: None; response_obj={'text': ' About Your Project', 'is_finished': False, 'finish_reason': None, 'logprobs': None, 'original_chunk': ModelResponseStream(id='chatcmpl-1e246dec-1357-4ceb-948f-03d49e55b5f9', created=1762261910, model=None, object='chat.completion.chunk', system_fingerprint=None, choices=[StreamingChoices(finish_reason=None, index=0, delta=Delta(provider_specific_fields=None, content=' About Your Project', role=None, function_call=None, tool_calls=None, audio=None), logprobs=None)], provider_specific_fields=None, usage=None), 'usage': None}
original delta: {'provider_specific_fields': None, 'content': ' About Your Project', 'role': None, 'function_call': None, 'tool_calls': None, 'audio': None}
new delta: Delta(provider_specific_fields=None, content=' About Your Project', role=None, function_call=None, tool_calls=None, audio=None)
model_response.choices[0].delta: Delta(provider_specific_fields=None, content=' About Your Project', role=None, function_call=None, tool_calls=None, audio=None); completion_obj: {'content': ' About Your Project'}
self.sent_first_chunk: True
completion_obj: {'content': ' About Your Project'}, model_response.choices[0]: StreamingChoices(finish_reason=None, index=0, delta=Delta(provider_specific_fields=None, content=' About Your Project', role=None, function_call=None, tool_calls=None, audio=None), logprobs=None), response_obj: {'text': ' About Your Project', 'is_finished': False, 'finish_reason': None, 'logprobs': None, 'original_chunk': ModelResponseStream(id='chatcmpl-1e246dec-1357-4ceb-948f-03d49e55b5f9', created=1762261910, model=None, object='chat.completion.chunk', system_fingerprint=None, choices=[StreamingChoices(finish_reason=None, index=0, delta=Delta(provider_specific_fields=None, content=' About Your Project', role=None, function_call=None, tool_calls=None, audio=None), logprobs=None)], provider_specific_fields=None, usage=None), 'usage': None}
choice_json: {'index': 0, 'delta': {'provider_specific_fields': None, 'content': ' About Your Project', 'role': None, 'function_call': None, 'tool_calls': None, 'audio': None}, 'logprobs': None}
choices in streaming: [StreamingChoices(finish_reason=None, index=0, delta=Delta(provider_specific_fields=None, content=' About Your Project', role=None, function_call=None, tool_calls=None, audio=None), logprobs=None)]
final returned processed chunk: ModelResponseStream(id='chatcmpl-1e246dec-1357-4ceb-948f-03d49e55b5f9', created=1762261907, model='claude-sonnet-4-5-20250929', object='chat.completion.chunk', system_fingerprint=None, choices=[StreamingChoices(finish_reason=None, index=0, delta=Delta(provider_specific_fields=None, content=' About Your Project', role=None, function_call=None, tool_calls=None, audio=None), logprobs=None)], provider_specific_fields=None, citations=None)
model_response finish reason 3: None; response_obj={'text': '', 'is_finished': False, 'finish_reason': '', 'usage': None, 'index': 0, 'tool_use': None}
model_response.choices[0].delta: Delta(provider_specific_fields=None, content=None, role=None, function_call=None, tool_calls=None, audio=None); completion_obj: {'content': ''}
self.sent_first_chunk: True
completion_obj: {'content': ''}, model_response.choices[0]: StreamingChoices(finish_reason=None, index=0, delta=Delta(provider_specific_fields=None, content=None, role=None, function_call=None, tool_calls=None, audio=None), logprobs=None), response_obj: {'text': '', 'is_finished': False, 'finish_reason': '', 'usage': None, 'index': 0, 'tool_use': None}
model_response finish reason 3: None; response_obj={'text': '', 'is_finished': False, 'finish_reason': '', 'usage': None, 'index': 0, 'tool_use': None}
model_response.choices[0].delta: Delta(provider_specific_fields=None, content=None, role=None, function_call=None, tool_calls=None, audio=None); completion_obj: {'content': ''}
self.sent_first_chunk: True
completion_obj: {'content': ''}, model_response.choices[0]: StreamingChoices(finish_reason=None, index=0, delta=Delta(provider_specific_fields=None, content=None, role=None, function_call=None, tool_calls=None, audio=None), logprobs=None), response_obj: {'text': '', 'is_finished': False, 'finish_reason': '', 'usage': None, 'index': 0, 'tool_use': None}

Raw OpenAI Chunk
ModelResponseStream(id='chatcmpl-1e246dec-1357-4ceb-948f-03d49e55b5f9', created=1762261910, model=None, object='chat.completion.chunk', system_fingerprint=None, choices=[StreamingChoices(finish_reason=None, index=0, delta=Delta(provider_specific_fields=None, content=':', role=None, function_call=None, tool_calls=None, audio=None), logprobs=None)], provider_specific_fields=None, usage=None)

model_response finish reason 3: None; response_obj={'text': ':', 'is_finished': False, 'finish_reason': None, 'logprobs': None, 'original_chunk': ModelResponseStream(id='chatcmpl-1e246dec-1357-4ceb-948f-03d49e55b5f9', created=1762261910, model=None, object='chat.completion.chunk', system_fingerprint=None, choices=[StreamingChoices(finish_reason=None, index=0, delta=Delta(provider_specific_fields=None, content=':', role=None, function_call=None, tool_calls=None, audio=None), logprobs=None)], provider_specific_fields=None, usage=None), 'usage': None}
original delta: {'provider_specific_fields': None, 'content': ':', 'role': None, 'function_call': None, 'tool_calls': None, 'audio': None}
new delta: Delta(provider_specific_fields=None, content=':', role=None, function_call=None, tool_calls=None, audio=None)
model_response.choices[0].delta: Delta(provider_specific_fields=None, content=':', role=None, function_call=None, tool_calls=None, audio=None); completion_obj: {'content': ':'}
self.sent_first_chunk: True
completion_obj: {'content': ':'}, model_response.choices[0]: StreamingChoices(finish_reason=None, index=0, delta=Delta(provider_specific_fields=None, content=':', role=None, function_call=None, tool_calls=None, audio=None), logprobs=None), response_obj: {'text': ':', 'is_finished': False, 'finish_reason': None, 'logprobs': None, 'original_chunk': ModelResponseStream(id='chatcmpl-1e246dec-1357-4ceb-948f-03d49e55b5f9', created=1762261910, model=None, object='chat.completion.chunk', system_fingerprint=None, choices=[StreamingChoices(finish_reason=None, index=0, delta=Delta(provider_specific_fields=None, content=':', role=None, function_call=None, tool_calls=None, audio=None), logprobs=None)], provider_specific_fields=None, usage=None), 'usage': None}
choice_json: {'index': 0, 'delta': {'provider_specific_fields': None, 'content': ':', 'role': None, 'function_call': None, 'tool_calls': None, 'audio': None}, 'logprobs': None}
choices in streaming: [StreamingChoices(finish_reason=None, index=0, delta=Delta(provider_specific_fields=None, content=':', role=None, function_call=None, tool_calls=None, audio=None), logprobs=None)]
final returned processed chunk: ModelResponseStream(id='chatcmpl-1e246dec-1357-4ceb-948f-03d49e55b5f9', created=1762261907, model='claude-sonnet-4-5-20250929', object='chat.completion.chunk', system_fingerprint=None, choices=[StreamingChoices(finish_reason=None, index=0, delta=Delta(provider_specific_fields=None, content=':', role=None, function_call=None, tool_calls=None, audio=None), logprobs=None)], provider_specific_fields=None, citations=None)
model_response finish reason 3: None; response_obj={'text': '', 'is_finished': False, 'finish_reason': '', 'usage': None, 'index': 0, 'tool_use': None}
model_response.choices[0].delta: Delta(provider_specific_fields=None, content=None, role=None, function_call=None, tool_calls=None, audio=None); completion_obj: {'content': ''}
self.sent_first_chunk: True
completion_obj: {'content': ''}, model_response.choices[0]: StreamingChoices(finish_reason=None, index=0, delta=Delta(provider_specific_fields=None, content=None, role=None, function_call=None, tool_calls=None, audio=None), logprobs=None), response_obj: {'text': '', 'is_finished': False, 'finish_reason': '', 'usage': None, 'index': 0, 'tool_use': None}
model_response finish reason 3: None; response_obj={'text': '', 'is_finished': False, 'finish_reason': '', 'usage': None, 'index': 0, 'tool_use': None}
model_response.choices[0].delta: Delta(provider_specific_fields=None, content=None, role=None, function_call=None, tool_calls=None, audio=None); completion_obj: {'content': ''}
self.sent_first_chunk: True
completion_obj: {'content': ''}, model_response.choices[0]: StreamingChoices(finish_reason=None, index=0, delta=Delta(provider_specific_fields=None, content=None, role=None, function_call=None, tool_calls=None, audio=None), logprobs=None), response_obj: {'text': '', 'is_finished': False, 'finish_reason': '', 'usage': None, 'index': 0, 'tool_use': None}

Raw OpenAI Chunk
ModelResponseStream(id='chatcmpl-1e246dec-1357-4ceb-948f-03d49e55b5f9', created=1762261910, model=None, object='chat.completion.chunk', system_fingerprint=None, choices=[StreamingChoices(finish_reason=None, index=0, delta=Delta(provider_specific_fields=None, content='\n\n1. **You', role=None, function_call=None, tool_calls=None, audio=None), logprobs=None)], provider_specific_fields=None, usage=None)

model_response finish reason 3: None; response_obj={'text': '\n\n1. **You', 'is_finished': False, 'finish_reason': None, 'logprobs': None, 'original_chunk': ModelResponseStream(id='chatcmpl-1e246dec-1357-4ceb-948f-03d49e55b5f9', created=1762261910, model=None, object='chat.completion.chunk', system_fingerprint=None, choices=[StreamingChoices(finish_reason=None, index=0, delta=Delta(provider_specific_fields=None, content='\n\n1. **You', role=None, function_call=None, tool_calls=None, audio=None), logprobs=None)], provider_specific_fields=None, usage=None), 'usage': None}
original delta: {'provider_specific_fields': None, 'content': '\n\n1. **You', 'role': None, 'function_call': None, 'tool_calls': None, 'audio': None}
new delta: Delta(provider_specific_fields=None, content='\n\n1. **You', role=None, function_call=None, tool_calls=None, audio=None)
model_response.choices[0].delta: Delta(provider_specific_fields=None, content='\n\n1. **You', role=None, function_call=None, tool_calls=None, audio=None); completion_obj: {'content': '\n\n1. **You'}
self.sent_first_chunk: True
completion_obj: {'content': '\n\n1. **You'}, model_response.choices[0]: StreamingChoices(finish_reason=None, index=0, delta=Delta(provider_specific_fields=None, content='\n\n1. **You', role=None, function_call=None, tool_calls=None, audio=None), logprobs=None), response_obj: {'text': '\n\n1. **You', 'is_finished': False, 'finish_reason': None, 'logprobs': None, 'original_chunk': ModelResponseStream(id='chatcmpl-1e246dec-1357-4ceb-948f-03d49e55b5f9', created=1762261910, model=None, object='chat.completion.chunk', system_fingerprint=None, choices=[StreamingChoices(finish_reason=None, index=0, delta=Delta(provider_specific_fields=None, content='\n\n1. **You', role=None, function_call=None, tool_calls=None, audio=None), logprobs=None)], provider_specific_fields=None, usage=None), 'usage': None}
choice_json: {'index': 0, 'delta': {'provider_specific_fields': None, 'content': '\n\n1. **You', 'role': None, 'function_call': None, 'tool_calls': None, 'audio': None}, 'logprobs': None}
choices in streaming: [StreamingChoices(finish_reason=None, index=0, delta=Delta(provider_specific_fields=None, content='\n\n1. **You', role=None, function_call=None, tool_calls=None, audio=None), logprobs=None)]
final returned processed chunk: ModelResponseStream(id='chatcmpl-1e246dec-1357-4ceb-948f-03d49e55b5f9', created=1762261907, model='claude-sonnet-4-5-20250929', object='chat.completion.chunk', system_fingerprint=None, choices=[StreamingChoices(finish_reason=None, index=0, delta=Delta(provider_specific_fields=None, content='\n\n1. **You', role=None, function_call=None, tool_calls=None, audio=None), logprobs=None)], provider_specific_fields=None, citations=None)
model_response finish reason 3: None; response_obj={'text': '', 'is_finished': False, 'finish_reason': '', 'usage': None, 'index': 0, 'tool_use': None}
model_response.choices[0].delta: Delta(provider_specific_fields=None, content=None, role=None, function_call=None, tool_calls=None, audio=None); completion_obj: {'content': ''}
self.sent_first_chunk: True
completion_obj: {'content': ''}, model_response.choices[0]: StreamingChoices(finish_reason=None, index=0, delta=Delta(provider_specific_fields=None, content=None, role=None, function_call=None, tool_calls=None, audio=None), logprobs=None), response_obj: {'text': '', 'is_finished': False, 'finish_reason': '', 'usage': None, 'index': 0, 'tool_use': None}
model_response finish reason 3: None; response_obj={'text': '', 'is_finished': False, 'finish_reason': '', 'usage': None, 'index': 0, 'tool_use': None}
model_response.choices[0].delta: Delta(provider_specific_fields=None, content=None, role=None, function_call=None, tool_calls=None, audio=None); completion_obj: {'content': ''}
self.sent_first_chunk: True
completion_obj: {'content': ''}, model_response.choices[0]: StreamingChoices(finish_reason=None, index=0, delta=Delta(provider_specific_fields=None, content=None, role=None, function_call=None, tool_calls=None, audio=None), logprobs=None), response_obj: {'text': '', 'is_finished': False, 'finish_reason': '', 'usage': None, 'index': 0, 'tool_use': None}

Raw OpenAI Chunk
ModelResponseStream(id='chatcmpl-1e246dec-1357-4ceb-948f-03d49e55b5f9', created=1762261910, model=None, object='chat.completion.chunk', system_fingerprint=None, choices=[StreamingChoices(finish_reason=None, index=0, delta=Delta(provider_specific_fields=None, content="'re building", role=None, function_call=None, tool_calls=None, audio=None), logprobs=None)], provider_specific_fields=None, usage=None)

model_response finish reason 3: None; response_obj={'text': "'re building", 'is_finished': False, 'finish_reason': None, 'logprobs': None, 'original_chunk': ModelResponseStream(id='chatcmpl-1e246dec-1357-4ceb-948f-03d49e55b5f9', created=1762261910, model=None, object='chat.completion.chunk', system_fingerprint=None, choices=[StreamingChoices(finish_reason=None, index=0, delta=Delta(provider_specific_fields=None, content="'re building", role=None, function_call=None, tool_calls=None, audio=None), logprobs=None)], provider_specific_fields=None, usage=None), 'usage': None}
original delta: {'provider_specific_fields': None, 'content': "'re building", 'role': None, 'function_call': None, 'tool_calls': None, 'audio': None}
new delta: Delta(provider_specific_fields=None, content="'re building", role=None, function_call=None, tool_calls=None, audio=None)
model_response.choices[0].delta: Delta(provider_specific_fields=None, content="'re building", role=None, function_call=None, tool_calls=None, audio=None); completion_obj: {'content': "'re building"}
self.sent_first_chunk: True
completion_obj: {'content': "'re building"}, model_response.choices[0]: StreamingChoices(finish_reason=None, index=0, delta=Delta(provider_specific_fields=None, content="'re building", role=None, function_call=None, tool_calls=None, audio=None), logprobs=None), response_obj: {'text': "'re building", 'is_finished': False, 'finish_reason': None, 'logprobs': None, 'original_chunk': ModelResponseStream(id='chatcmpl-1e246dec-1357-4ceb-948f-03d49e55b5f9', created=1762261910, model=None, object='chat.completion.chunk', system_fingerprint=None, choices=[StreamingChoices(finish_reason=None, index=0, delta=Delta(provider_specific_fields=None, content="'re building", role=None, function_call=None, tool_calls=None, audio=None), logprobs=None)], provider_specific_fields=None, usage=None), 'usage': None}
choice_json: {'index': 0, 'delta': {'provider_specific_fields': None, 'content': "'re building", 'role': None, 'function_call': None, 'tool_calls': None, 'audio': None}, 'logprobs': None}
choices in streaming: [StreamingChoices(finish_reason=None, index=0, delta=Delta(provider_specific_fields=None, content="'re building", role=None, function_call=None, tool_calls=None, audio=None), logprobs=None)]
final returned processed chunk: ModelResponseStream(id='chatcmpl-1e246dec-1357-4ceb-948f-03d49e55b5f9', created=1762261907, model='claude-sonnet-4-5-20250929', object='chat.completion.chunk', system_fingerprint=None, choices=[StreamingChoices(finish_reason=None, index=0, delta=Delta(provider_specific_fields=None, content="'re building", role=None, function_call=None, tool_calls=None, audio=None), logprobs=None)], provider_specific_fields=None, citations=None)
model_response finish reason 3: None; response_obj={'text': '', 'is_finished': False, 'finish_reason': '', 'usage': None, 'index': 0, 'tool_use': None}
model_response.choices[0].delta: Delta(provider_specific_fields=None, content=None, role=None, function_call=None, tool_calls=None, audio=None); completion_obj: {'content': ''}
self.sent_first_chunk: True
completion_obj: {'content': ''}, model_response.choices[0]: StreamingChoices(finish_reason=None, index=0, delta=Delta(provider_specific_fields=None, content=None, role=None, function_call=None, tool_calls=None, audio=None), logprobs=None), response_obj: {'text': '', 'is_finished': False, 'finish_reason': '', 'usage': None, 'index': 0, 'tool_use': None}
model_response finish reason 3: None; response_obj={'text': '', 'is_finished': False, 'finish_reason': '', 'usage': None, 'index': 0, 'tool_use': None}
model_response.choices[0].delta: Delta(provider_specific_fields=None, content=None, role=None, function_call=None, tool_calls=None, audio=None); completion_obj: {'content': ''}
self.sent_first_chunk: True
completion_obj: {'content': ''}, model_response.choices[0]: StreamingChoices(finish_reason=None, index=0, delta=Delta(provider_specific_fields=None, content=None, role=None, function_call=None, tool_calls=None, audio=None), logprobs=None), response_obj: {'text': '', 'is_finished': False, 'finish_reason': '', 'usage': None, 'index': 0, 'tool_use': None}

Raw OpenAI Chunk
ModelResponseStream(id='chatcmpl-1e246dec-1357-4ceb-948f-03d49e55b5f9', created=1762261910, model=None, object='chat.completion.chunk', system_fingerprint=None, choices=[StreamingChoices(finish_reason=None, index=0, delta=Delta(provider_specific_fields=None, content=' a L', role=None, function_call=None, tool_calls=None, audio=None), logprobs=None)], provider_specific_fields=None, usage=None)

model_response finish reason 3: None; response_obj={'text': ' a L', 'is_finished': False, 'finish_reason': None, 'logprobs': None, 'original_chunk': ModelResponseStream(id='chatcmpl-1e246dec-1357-4ceb-948f-03d49e55b5f9', created=1762261910, model=None, object='chat.completion.chunk', system_fingerprint=None, choices=[StreamingChoices(finish_reason=None, index=0, delta=Delta(provider_specific_fields=None, content=' a L', role=None, function_call=None, tool_calls=None, audio=None), logprobs=None)], provider_specific_fields=None, usage=None), 'usage': None}
original delta: {'provider_specific_fields': None, 'content': ' a L', 'role': None, 'function_call': None, 'tool_calls': None, 'audio': None}
new delta: Delta(provider_specific_fields=None, content=' a L', role=None, function_call=None, tool_calls=None, audio=None)
model_response.choices[0].delta: Delta(provider_specific_fields=None, content=' a L', role=None, function_call=None, tool_calls=None, audio=None); completion_obj: {'content': ' a L'}
self.sent_first_chunk: True
completion_obj: {'content': ' a L'}, model_response.choices[0]: StreamingChoices(finish_reason=None, index=0, delta=Delta(provider_specific_fields=None, content=' a L', role=None, function_call=None, tool_calls=None, audio=None), logprobs=None), response_obj: {'text': ' a L', 'is_finished': False, 'finish_reason': None, 'logprobs': None, 'original_chunk': ModelResponseStream(id='chatcmpl-1e246dec-1357-4ceb-948f-03d49e55b5f9', created=1762261910, model=None, object='chat.completion.chunk', system_fingerprint=None, choices=[StreamingChoices(finish_reason=None, index=0, delta=Delta(provider_specific_fields=None, content=' a L', role=None, function_call=None, tool_calls=None, audio=None), logprobs=None)], provider_specific_fields=None, usage=None), 'usage': None}
choice_json: {'index': 0, 'delta': {'provider_specific_fields': None, 'content': ' a L', 'role': None, 'function_call': None, 'tool_calls': None, 'audio': None}, 'logprobs': None}
choices in streaming: [StreamingChoices(finish_reason=None, index=0, delta=Delta(provider_specific_fields=None, content=' a L', role=None, function_call=None, tool_calls=None, audio=None), logprobs=None)]
final returned processed chunk: ModelResponseStream(id='chatcmpl-1e246dec-1357-4ceb-948f-03d49e55b5f9', created=1762261907, model='claude-sonnet-4-5-20250929', object='chat.completion.chunk', system_fingerprint=None, choices=[StreamingChoices(finish_reason=None, index=0, delta=Delta(provider_specific_fields=None, content=' a L', role=None, function_call=None, tool_calls=None, audio=None), logprobs=None)], provider_specific_fields=None, citations=None)
model_response finish reason 3: None; response_obj={'text': '', 'is_finished': False, 'finish_reason': '', 'usage': None, 'index': 0, 'tool_use': None}
model_response.choices[0].delta: Delta(provider_specific_fields=None, content=None, role=None, function_call=None, tool_calls=None, audio=None); completion_obj: {'content': ''}
self.sent_first_chunk: True
completion_obj: {'content': ''}, model_response.choices[0]: StreamingChoices(finish_reason=None, index=0, delta=Delta(provider_specific_fields=None, content=None, role=None, function_call=None, tool_calls=None, audio=None), logprobs=None), response_obj: {'text': '', 'is_finished': False, 'finish_reason': '', 'usage': None, 'index': 0, 'tool_use': None}
model_response finish reason 3: None; response_obj={'text': '', 'is_finished': False, 'finish_reason': '', 'usage': None, 'index': 0, 'tool_use': None}
model_response.choices[0].delta: Delta(provider_specific_fields=None, content=None, role=None, function_call=None, tool_calls=None, audio=None); completion_obj: {'content': ''}
self.sent_first_chunk: True
completion_obj: {'content': ''}, model_response.choices[0]: StreamingChoices(finish_reason=None, index=0, delta=Delta(provider_specific_fields=None, content=None, role=None, function_call=None, tool_calls=None, audio=None), logprobs=None), response_obj: {'text': '', 'is_finished': False, 'finish_reason': '', 'usage': None, 'index': 0, 'tool_use': None}

Raw OpenAI Chunk
ModelResponseStream(id='chatcmpl-1e246dec-1357-4ceb-948f-03d49e55b5f9', created=1762261910, model=None, object='chat.completion.chunk', system_fingerprint=None, choices=[StreamingChoices(finish_reason=None, index=0, delta=Delta(provider_specific_fields=None, content='it', role=None, function_call=None, tool_calls=None, audio=None), logprobs=None)], provider_specific_fields=None, usage=None)

model_response finish reason 3: None; response_obj={'text': 'it', 'is_finished': False, 'finish_reason': None, 'logprobs': None, 'original_chunk': ModelResponseStream(id='chatcmpl-1e246dec-1357-4ceb-948f-03d49e55b5f9', created=1762261910, model=None, object='chat.completion.chunk', system_fingerprint=None, choices=[StreamingChoices(finish_reason=None, index=0, delta=Delta(provider_specific_fields=None, content='it', role=None, function_call=None, tool_calls=None, audio=None), logprobs=None)], provider_specific_fields=None, usage=None), 'usage': None}
original delta: {'provider_specific_fields': None, 'content': 'it', 'role': None, 'function_call': None, 'tool_calls': None, 'audio': None}
new delta: Delta(provider_specific_fields=None, content='it', role=None, function_call=None, tool_calls=None, audio=None)
model_response.choices[0].delta: Delta(provider_specific_fields=None, content='it', role=None, function_call=None, tool_calls=None, audio=None); completion_obj: {'content': 'it'}
self.sent_first_chunk: True
completion_obj: {'content': 'it'}, model_response.choices[0]: StreamingChoices(finish_reason=None, index=0, delta=Delta(provider_specific_fields=None, content='it', role=None, function_call=None, tool_calls=None, audio=None), logprobs=None), response_obj: {'text': 'it', 'is_finished': False, 'finish_reason': None, 'logprobs': None, 'original_chunk': ModelResponseStream(id='chatcmpl-1e246dec-1357-4ceb-948f-03d49e55b5f9', created=1762261910, model=None, object='chat.completion.chunk', system_fingerprint=None, choices=[StreamingChoices(finish_reason=None, index=0, delta=Delta(provider_specific_fields=None, content='it', role=None, function_call=None, tool_calls=None, audio=None), logprobs=None)], provider_specific_fields=None, usage=None), 'usage': None}
choice_json: {'index': 0, 'delta': {'provider_specific_fields': None, 'content': 'it', 'role': None, 'function_call': None, 'tool_calls': None, 'audio': None}, 'logprobs': None}
choices in streaming: [StreamingChoices(finish_reason=None, index=0, delta=Delta(provider_specific_fields=None, content='it', role=None, function_call=None, tool_calls=None, audio=None), logprobs=None)]
final returned processed chunk: ModelResponseStream(id='chatcmpl-1e246dec-1357-4ceb-948f-03d49e55b5f9', created=1762261907, model='claude-sonnet-4-5-20250929', object='chat.completion.chunk', system_fingerprint=None, choices=[StreamingChoices(finish_reason=None, index=0, delta=Delta(provider_specific_fields=None, content='it', role=None, function_call=None, tool_calls=None, audio=None), logprobs=None)], provider_specific_fields=None, citations=None)
model_response finish reason 3: None; response_obj={'text': '', 'is_finished': False, 'finish_reason': '', 'usage': None, 'index': 0, 'tool_use': None}
model_response.choices[0].delta: Delta(provider_specific_fields=None, content=None, role=None, function_call=None, tool_calls=None, audio=None); completion_obj: {'content': ''}
self.sent_first_chunk: True
completion_obj: {'content': ''}, model_response.choices[0]: StreamingChoices(finish_reason=None, index=0, delta=Delta(provider_specific_fields=None, content=None, role=None, function_call=None, tool_calls=None, audio=None), logprobs=None), response_obj: {'text': '', 'is_finished': False, 'finish_reason': '', 'usage': None, 'index': 0, 'tool_use': None}
model_response finish reason 3: None; response_obj={'text': '', 'is_finished': False, 'finish_reason': '', 'usage': None, 'index': 0, 'tool_use': None}
model_response.choices[0].delta: Delta(provider_specific_fields=None, content=None, role=None, function_call=None, tool_calls=None, audio=None); completion_obj: {'content': ''}
self.sent_first_chunk: True
completion_obj: {'content': ''}, model_response.choices[0]: StreamingChoices(finish_reason=None, index=0, delta=Delta(provider_specific_fields=None, content=None, role=None, function_call=None, tool_calls=None, audio=None), logprobs=None), response_obj: {'text': '', 'is_finished': False, 'finish_reason': '', 'usage': None, 'index': 0, 'tool_use': None}

Raw OpenAI Chunk
ModelResponseStream(id='chatcmpl-1e246dec-1357-4ceb-948f-03d49e55b5f9', created=1762261910, model=None, object='chat.completion.chunk', system_fingerprint=None, choices=[StreamingChoices(finish_reason=None, index=0, delta=Delta(provider_specific_fields=None, content='eLLM proxy', role=None, function_call=None, tool_calls=None, audio=None), logprobs=None)], provider_specific_fields=None, usage=None)

model_response finish reason 3: None; response_obj={'text': 'eLLM proxy', 'is_finished': False, 'finish_reason': None, 'logprobs': None, 'original_chunk': ModelResponseStream(id='chatcmpl-1e246dec-1357-4ceb-948f-03d49e55b5f9', created=1762261910, model=None, object='chat.completion.chunk', system_fingerprint=None, choices=[StreamingChoices(finish_reason=None, index=0, delta=Delta(provider_specific_fields=None, content='eLLM proxy', role=None, function_call=None, tool_calls=None, audio=None), logprobs=None)], provider_specific_fields=None, usage=None), 'usage': None}
original delta: {'provider_specific_fields': None, 'content': 'eLLM proxy', 'role': None, 'function_call': None, 'tool_calls': None, 'audio': None}
new delta: Delta(provider_specific_fields=None, content='eLLM proxy', role=None, function_call=None, tool_calls=None, audio=None)
model_response.choices[0].delta: Delta(provider_specific_fields=None, content='eLLM proxy', role=None, function_call=None, tool_calls=None, audio=None); completion_obj: {'content': 'eLLM proxy'}
self.sent_first_chunk: True
completion_obj: {'content': 'eLLM proxy'}, model_response.choices[0]: StreamingChoices(finish_reason=None, index=0, delta=Delta(provider_specific_fields=None, content='eLLM proxy', role=None, function_call=None, tool_calls=None, audio=None), logprobs=None), response_obj: {'text': 'eLLM proxy', 'is_finished': False, 'finish_reason': None, 'logprobs': None, 'original_chunk': ModelResponseStream(id='chatcmpl-1e246dec-1357-4ceb-948f-03d49e55b5f9', created=1762261910, model=None, object='chat.completion.chunk', system_fingerprint=None, choices=[StreamingChoices(finish_reason=None, index=0, delta=Delta(provider_specific_fields=None, content='eLLM proxy', role=None, function_call=None, tool_calls=None, audio=None), logprobs=None)], provider_specific_fields=None, usage=None), 'usage': None}
choice_json: {'index': 0, 'delta': {'provider_specific_fields': None, 'content': 'eLLM proxy', 'role': None, 'function_call': None, 'tool_calls': None, 'audio': None}, 'logprobs': None}
choices in streaming: [StreamingChoices(finish_reason=None, index=0, delta=Delta(provider_specific_fields=None, content='eLLM proxy', role=None, function_call=None, tool_calls=None, audio=None), logprobs=None)]
final returned processed chunk: ModelResponseStream(id='chatcmpl-1e246dec-1357-4ceb-948f-03d49e55b5f9', created=1762261907, model='claude-sonnet-4-5-20250929', object='chat.completion.chunk', system_fingerprint=None, choices=[StreamingChoices(finish_reason=None, index=0, delta=Delta(provider_specific_fields=None, content='eLLM proxy', role=None, function_call=None, tool_calls=None, audio=None), logprobs=None)], provider_specific_fields=None, citations=None)
model_response finish reason 3: None; response_obj={'text': '', 'is_finished': False, 'finish_reason': '', 'usage': None, 'index': 0, 'tool_use': None}
model_response.choices[0].delta: Delta(provider_specific_fields=None, content=None, role=None, function_call=None, tool_calls=None, audio=None); completion_obj: {'content': ''}
self.sent_first_chunk: True
completion_obj: {'content': ''}, model_response.choices[0]: StreamingChoices(finish_reason=None, index=0, delta=Delta(provider_specific_fields=None, content=None, role=None, function_call=None, tool_calls=None, audio=None), logprobs=None), response_obj: {'text': '', 'is_finished': False, 'finish_reason': '', 'usage': None, 'index': 0, 'tool_use': None}
model_response finish reason 3: None; response_obj={'text': '', 'is_finished': False, 'finish_reason': '', 'usage': None, 'index': 0, 'tool_use': None}
model_response.choices[0].delta: Delta(provider_specific_fields=None, content=None, role=None, function_call=None, tool_calls=None, audio=None); completion_obj: {'content': ''}
self.sent_first_chunk: True
completion_obj: {'content': ''}, model_response.choices[0]: StreamingChoices(finish_reason=None, index=0, delta=Delta(provider_specific_fields=None, content=None, role=None, function_call=None, tool_calls=None, audio=None), logprobs=None), response_obj: {'text': '', 'is_finished': False, 'finish_reason': '', 'usage': None, 'index': 0, 'tool_use': None}

Raw OpenAI Chunk
ModelResponseStream(id='chatcmpl-1e246dec-1357-4ceb-948f-03d49e55b5f9', created=1762261910, model=None, object='chat.completion.chunk', system_fingerprint=None, choices=[StreamingChoices(finish_reason=None, index=0, delta=Delta(provider_specific_fields=None, content=' with', role=None, function_call=None, tool_calls=None, audio=None), logprobs=None)], provider_specific_fields=None, usage=None)

model_response finish reason 3: None; response_obj={'text': ' with', 'is_finished': False, 'finish_reason': None, 'logprobs': None, 'original_chunk': ModelResponseStream(id='chatcmpl-1e246dec-1357-4ceb-948f-03d49e55b5f9', created=1762261910, model=None, object='chat.completion.chunk', system_fingerprint=None, choices=[StreamingChoices(finish_reason=None, index=0, delta=Delta(provider_specific_fields=None, content=' with', role=None, function_call=None, tool_calls=None, audio=None), logprobs=None)], provider_specific_fields=None, usage=None), 'usage': None}
original delta: {'provider_specific_fields': None, 'content': ' with', 'role': None, 'function_call': None, 'tool_calls': None, 'audio': None}
new delta: Delta(provider_specific_fields=None, content=' with', role=None, function_call=None, tool_calls=None, audio=None)
model_response.choices[0].delta: Delta(provider_specific_fields=None, content=' with', role=None, function_call=None, tool_calls=None, audio=None); completion_obj: {'content': ' with'}
self.sent_first_chunk: True
completion_obj: {'content': ' with'}, model_response.choices[0]: StreamingChoices(finish_reason=None, index=0, delta=Delta(provider_specific_fields=None, content=' with', role=None, function_call=None, tool_calls=None, audio=None), logprobs=None), response_obj: {'text': ' with', 'is_finished': False, 'finish_reason': None, 'logprobs': None, 'original_chunk': ModelResponseStream(id='chatcmpl-1e246dec-1357-4ceb-948f-03d49e55b5f9', created=1762261910, model=None, object='chat.completion.chunk', system_fingerprint=None, choices=[StreamingChoices(finish_reason=None, index=0, delta=Delta(provider_specific_fields=None, content=' with', role=None, function_call=None, tool_calls=None, audio=None), logprobs=None)], provider_specific_fields=None, usage=None), 'usage': None}
choice_json: {'index': 0, 'delta': {'provider_specific_fields': None, 'content': ' with', 'role': None, 'function_call': None, 'tool_calls': None, 'audio': None}, 'logprobs': None}
choices in streaming: [StreamingChoices(finish_reason=None, index=0, delta=Delta(provider_specific_fields=None, content=' with', role=None, function_call=None, tool_calls=None, audio=None), logprobs=None)]
final returned processed chunk: ModelResponseStream(id='chatcmpl-1e246dec-1357-4ceb-948f-03d49e55b5f9', created=1762261907, model='claude-sonnet-4-5-20250929', object='chat.completion.chunk', system_fingerprint=None, choices=[StreamingChoices(finish_reason=None, index=0, delta=Delta(provider_specific_fields=None, content=' with', role=None, function_call=None, tool_calls=None, audio=None), logprobs=None)], provider_specific_fields=None, citations=None)
model_response finish reason 3: None; response_obj={'text': '', 'is_finished': False, 'finish_reason': '', 'usage': None, 'index': 0, 'tool_use': None}
model_response.choices[0].delta: Delta(provider_specific_fields=None, content=None, role=None, function_call=None, tool_calls=None, audio=None); completion_obj: {'content': ''}
self.sent_first_chunk: True
completion_obj: {'content': ''}, model_response.choices[0]: StreamingChoices(finish_reason=None, index=0, delta=Delta(provider_specific_fields=None, content=None, role=None, function_call=None, tool_calls=None, audio=None), logprobs=None), response_obj: {'text': '', 'is_finished': False, 'finish_reason': '', 'usage': None, 'index': 0, 'tool_use': None}
model_response finish reason 3: None; response_obj={'text': '', 'is_finished': False, 'finish_reason': '', 'usage': None, 'index': 0, 'tool_use': None}
model_response.choices[0].delta: Delta(provider_specific_fields=None, content=None, role=None, function_call=None, tool_calls=None, audio=None); completion_obj: {'content': ''}
self.sent_first_chunk: True
completion_obj: {'content': ''}, model_response.choices[0]: StreamingChoices(finish_reason=None, index=0, delta=Delta(provider_specific_fields=None, content=None, role=None, function_call=None, tool_calls=None, audio=None), logprobs=None), response_obj: {'text': '', 'is_finished': False, 'finish_reason': '', 'usage': None, 'index': 0, 'tool_use': None}

Raw OpenAI Chunk
ModelResponseStream(id='chatcmpl-1e246dec-1357-4ceb-948f-03d49e55b5f9', created=1762261910, model=None, object='chat.completion.chunk', system_fingerprint=None, choices=[StreamingChoices(finish_reason=None, index=0, delta=Delta(provider_specific_fields=None, content=' Supermemory integration', role=None, function_call=None, tool_calls=None, audio=None), logprobs=None)], provider_specific_fields=None, usage=None)

model_response finish reason 3: None; response_obj={'text': ' Supermemory integration', 'is_finished': False, 'finish_reason': None, 'logprobs': None, 'original_chunk': ModelResponseStream(id='chatcmpl-1e246dec-1357-4ceb-948f-03d49e55b5f9', created=1762261910, model=None, object='chat.completion.chunk', system_fingerprint=None, choices=[StreamingChoices(finish_reason=None, index=0, delta=Delta(provider_specific_fields=None, content=' Supermemory integration', role=None, function_call=None, tool_calls=None, audio=None), logprobs=None)], provider_specific_fields=None, usage=None), 'usage': None}
original delta: {'provider_specific_fields': None, 'content': ' Supermemory integration', 'role': None, 'function_call': None, 'tool_calls': None, 'audio': None}
new delta: Delta(provider_specific_fields=None, content=' Supermemory integration', role=None, function_call=None, tool_calls=None, audio=None)
model_response.choices[0].delta: Delta(provider_specific_fields=None, content=' Supermemory integration', role=None, function_call=None, tool_calls=None, audio=None); completion_obj: {'content': ' Supermemory integration'}
self.sent_first_chunk: True
completion_obj: {'content': ' Supermemory integration'}, model_response.choices[0]: StreamingChoices(finish_reason=None, index=0, delta=Delta(provider_specific_fields=None, content=' Supermemory integration', role=None, function_call=None, tool_calls=None, audio=None), logprobs=None), response_obj: {'text': ' Supermemory integration', 'is_finished': False, 'finish_reason': None, 'logprobs': None, 'original_chunk': ModelResponseStream(id='chatcmpl-1e246dec-1357-4ceb-948f-03d49e55b5f9', created=1762261910, model=None, object='chat.completion.chunk', system_fingerprint=None, choices=[StreamingChoices(finish_reason=None, index=0, delta=Delta(provider_specific_fields=None, content=' Supermemory integration', role=None, function_call=None, tool_calls=None, audio=None), logprobs=None)], provider_specific_fields=None, usage=None), 'usage': None}
choice_json: {'index': 0, 'delta': {'provider_specific_fields': None, 'content': ' Supermemory integration', 'role': None, 'function_call': None, 'tool_calls': None, 'audio': None}, 'logprobs': None}
choices in streaming: [StreamingChoices(finish_reason=None, index=0, delta=Delta(provider_specific_fields=None, content=' Supermemory integration', role=None, function_call=None, tool_calls=None, audio=None), logprobs=None)]
final returned processed chunk: ModelResponseStream(id='chatcmpl-1e246dec-1357-4ceb-948f-03d49e55b5f9', created=1762261907, model='claude-sonnet-4-5-20250929', object='chat.completion.chunk', system_fingerprint=None, choices=[StreamingChoices(finish_reason=None, index=0, delta=Delta(provider_specific_fields=None, content=' Supermemory integration', role=None, function_call=None, tool_calls=None, audio=None), logprobs=None)], provider_specific_fields=None, citations=None)
model_response finish reason 3: None; response_obj={'text': '', 'is_finished': False, 'finish_reason': '', 'usage': None, 'index': 0, 'tool_use': None}
model_response.choices[0].delta: Delta(provider_specific_fields=None, content=None, role=None, function_call=None, tool_calls=None, audio=None); completion_obj: {'content': ''}
self.sent_first_chunk: True
completion_obj: {'content': ''}, model_response.choices[0]: StreamingChoices(finish_reason=None, index=0, delta=Delta(provider_specific_fields=None, content=None, role=None, function_call=None, tool_calls=None, audio=None), logprobs=None), response_obj: {'text': '', 'is_finished': False, 'finish_reason': '', 'usage': None, 'index': 0, 'tool_use': None}
model_response finish reason 3: None; response_obj={'text': '', 'is_finished': False, 'finish_reason': '', 'usage': None, 'index': 0, 'tool_use': None}
model_response.choices[0].delta: Delta(provider_specific_fields=None, content=None, role=None, function_call=None, tool_calls=None, audio=None); completion_obj: {'content': ''}
self.sent_first_chunk: True
completion_obj: {'content': ''}, model_response.choices[0]: StreamingChoices(finish_reason=None, index=0, delta=Delta(provider_specific_fields=None, content=None, role=None, function_call=None, tool_calls=None, audio=None), logprobs=None), response_obj: {'text': '', 'is_finished': False, 'finish_reason': '', 'usage': None, 'index': 0, 'tool_use': None}

Raw OpenAI Chunk
ModelResponseStream(id='chatcmpl-1e246dec-1357-4ceb-948f-03d49e55b5f9', created=1762261910, model=None, object='chat.completion.chunk', system_fingerprint=None, choices=[StreamingChoices(finish_reason=None, index=0, delta=Delta(provider_specific_fields=None, content='**', role=None, function_call=None, tool_calls=None, audio=None), logprobs=None)], provider_specific_fields=None, usage=None)

model_response finish reason 3: None; response_obj={'text': '**', 'is_finished': False, 'finish_reason': None, 'logprobs': None, 'original_chunk': ModelResponseStream(id='chatcmpl-1e246dec-1357-4ceb-948f-03d49e55b5f9', created=1762261910, model=None, object='chat.completion.chunk', system_fingerprint=None, choices=[StreamingChoices(finish_reason=None, index=0, delta=Delta(provider_specific_fields=None, content='**', role=None, function_call=None, tool_calls=None, audio=None), logprobs=None)], provider_specific_fields=None, usage=None), 'usage': None}
original delta: {'provider_specific_fields': None, 'content': '**', 'role': None, 'function_call': None, 'tool_calls': None, 'audio': None}
new delta: Delta(provider_specific_fields=None, content='**', role=None, function_call=None, tool_calls=None, audio=None)
model_response.choices[0].delta: Delta(provider_specific_fields=None, content='**', role=None, function_call=None, tool_calls=None, audio=None); completion_obj: {'content': '**'}
self.sent_first_chunk: True
completion_obj: {'content': '**'}, model_response.choices[0]: StreamingChoices(finish_reason=None, index=0, delta=Delta(provider_specific_fields=None, content='**', role=None, function_call=None, tool_calls=None, audio=None), logprobs=None), response_obj: {'text': '**', 'is_finished': False, 'finish_reason': None, 'logprobs': None, 'original_chunk': ModelResponseStream(id='chatcmpl-1e246dec-1357-4ceb-948f-03d49e55b5f9', created=1762261910, model=None, object='chat.completion.chunk', system_fingerprint=None, choices=[StreamingChoices(finish_reason=None, index=0, delta=Delta(provider_specific_fields=None, content='**', role=None, function_call=None, tool_calls=None, audio=None), logprobs=None)], provider_specific_fields=None, usage=None), 'usage': None}
choice_json: {'index': 0, 'delta': {'provider_specific_fields': None, 'content': '**', 'role': None, 'function_call': None, 'tool_calls': None, 'audio': None}, 'logprobs': None}
choices in streaming: [StreamingChoices(finish_reason=None, index=0, delta=Delta(provider_specific_fields=None, content='**', role=None, function_call=None, tool_calls=None, audio=None), logprobs=None)]
final returned processed chunk: ModelResponseStream(id='chatcmpl-1e246dec-1357-4ceb-948f-03d49e55b5f9', created=1762261907, model='claude-sonnet-4-5-20250929', object='chat.completion.chunk', system_fingerprint=None, choices=[StreamingChoices(finish_reason=None, index=0, delta=Delta(provider_specific_fields=None, content='**', role=None, function_call=None, tool_calls=None, audio=None), logprobs=None)], provider_specific_fields=None, citations=None)
model_response finish reason 3: None; response_obj={'text': '', 'is_finished': False, 'finish_reason': '', 'usage': None, 'index': 0, 'tool_use': None}
model_response.choices[0].delta: Delta(provider_specific_fields=None, content=None, role=None, function_call=None, tool_calls=None, audio=None); completion_obj: {'content': ''}
self.sent_first_chunk: True
completion_obj: {'content': ''}, model_response.choices[0]: StreamingChoices(finish_reason=None, index=0, delta=Delta(provider_specific_fields=None, content=None, role=None, function_call=None, tool_calls=None, audio=None), logprobs=None), response_obj: {'text': '', 'is_finished': False, 'finish_reason': '', 'usage': None, 'index': 0, 'tool_use': None}
model_response finish reason 3: None; response_obj={'text': '', 'is_finished': False, 'finish_reason': '', 'usage': None, 'index': 0, 'tool_use': None}
model_response.choices[0].delta: Delta(provider_specific_fields=None, content=None, role=None, function_call=None, tool_calls=None, audio=None); completion_obj: {'content': ''}
self.sent_first_chunk: True
completion_obj: {'content': ''}, model_response.choices[0]: StreamingChoices(finish_reason=None, index=0, delta=Delta(provider_specific_fields=None, content=None, role=None, function_call=None, tool_calls=None, audio=None), logprobs=None), response_obj: {'text': '', 'is_finished': False, 'finish_reason': '', 'usage': None, 'index': 0, 'tool_use': None}

Raw OpenAI Chunk
ModelResponseStream(id='chatcmpl-1e246dec-1357-4ceb-948f-03d49e55b5f9', created=1762261910, model=None, object='chat.completion.chunk', system_fingerprint=None, choices=[StreamingChoices(finish_reason=None, index=0, delta=Delta(provider_specific_fields=None, content=' for', role=None, function_call=None, tool_calls=None, audio=None), logprobs=None)], provider_specific_fields=None, usage=None)

model_response finish reason 3: None; response_obj={'text': ' for', 'is_finished': False, 'finish_reason': None, 'logprobs': None, 'original_chunk': ModelResponseStream(id='chatcmpl-1e246dec-1357-4ceb-948f-03d49e55b5f9', created=1762261910, model=None, object='chat.completion.chunk', system_fingerprint=None, choices=[StreamingChoices(finish_reason=None, index=0, delta=Delta(provider_specific_fields=None, content=' for', role=None, function_call=None, tool_calls=None, audio=None), logprobs=None)], provider_specific_fields=None, usage=None), 'usage': None}
original delta: {'provider_specific_fields': None, 'content': ' for', 'role': None, 'function_call': None, 'tool_calls': None, 'audio': None}
new delta: Delta(provider_specific_fields=None, content=' for', role=None, function_call=None, tool_calls=None, audio=None)
model_response.choices[0].delta: Delta(provider_specific_fields=None, content=' for', role=None, function_call=None, tool_calls=None, audio=None); completion_obj: {'content': ' for'}
self.sent_first_chunk: True
completion_obj: {'content': ' for'}, model_response.choices[0]: StreamingChoices(finish_reason=None, index=0, delta=Delta(provider_specific_fields=None, content=' for', role=None, function_call=None, tool_calls=None, audio=None), logprobs=None), response_obj: {'text': ' for', 'is_finished': False, 'finish_reason': None, 'logprobs': None, 'original_chunk': ModelResponseStream(id='chatcmpl-1e246dec-1357-4ceb-948f-03d49e55b5f9', created=1762261910, model=None, object='chat.completion.chunk', system_fingerprint=None, choices=[StreamingChoices(finish_reason=None, index=0, delta=Delta(provider_specific_fields=None, content=' for', role=None, function_call=None, tool_calls=None, audio=None), logprobs=None)], provider_specific_fields=None, usage=None), 'usage': None}
choice_json: {'index': 0, 'delta': {'provider_specific_fields': None, 'content': ' for', 'role': None, 'function_call': None, 'tool_calls': None, 'audio': None}, 'logprobs': None}
choices in streaming: [StreamingChoices(finish_reason=None, index=0, delta=Delta(provider_specific_fields=None, content=' for', role=None, function_call=None, tool_calls=None, audio=None), logprobs=None)]
final returned processed chunk: ModelResponseStream(id='chatcmpl-1e246dec-1357-4ceb-948f-03d49e55b5f9', created=1762261907, model='claude-sonnet-4-5-20250929', object='chat.completion.chunk', system_fingerprint=None, choices=[StreamingChoices(finish_reason=None, index=0, delta=Delta(provider_specific_fields=None, content=' for', role=None, function_call=None, tool_calls=None, audio=None), logprobs=None)], provider_specific_fields=None, citations=None)
model_response finish reason 3: None; response_obj={'text': '', 'is_finished': False, 'finish_reason': '', 'usage': None, 'index': 0, 'tool_use': None}
model_response.choices[0].delta: Delta(provider_specific_fields=None, content=None, role=None, function_call=None, tool_calls=None, audio=None); completion_obj: {'content': ''}
self.sent_first_chunk: True
completion_obj: {'content': ''}, model_response.choices[0]: StreamingChoices(finish_reason=None, index=0, delta=Delta(provider_specific_fields=None, content=None, role=None, function_call=None, tool_calls=None, audio=None), logprobs=None), response_obj: {'text': '', 'is_finished': False, 'finish_reason': '', 'usage': None, 'index': 0, 'tool_use': None}
model_response finish reason 3: None; response_obj={'text': '', 'is_finished': False, 'finish_reason': '', 'usage': None, 'index': 0, 'tool_use': None}
model_response.choices[0].delta: Delta(provider_specific_fields=None, content=None, role=None, function_call=None, tool_calls=None, audio=None); completion_obj: {'content': ''}
self.sent_first_chunk: True
completion_obj: {'content': ''}, model_response.choices[0]: StreamingChoices(finish_reason=None, index=0, delta=Delta(provider_specific_fields=None, content=None, role=None, function_call=None, tool_calls=None, audio=None), logprobs=None), response_obj: {'text': '', 'is_finished': False, 'finish_reason': '', 'usage': None, 'index': 0, 'tool_use': None}

Raw OpenAI Chunk
ModelResponseStream(id='chatcmpl-1e246dec-1357-4ceb-948f-03d49e55b5f9', created=1762261910, model=None, object='chat.completion.chunk', system_fingerprint=None, choices=[StreamingChoices(finish_reason=None, index=0, delta=Delta(provider_specific_fields=None, content=' context', role=None, function_call=None, tool_calls=None, audio=None), logprobs=None)], provider_specific_fields=None, usage=None)

model_response finish reason 3: None; response_obj={'text': ' context', 'is_finished': False, 'finish_reason': None, 'logprobs': None, 'original_chunk': ModelResponseStream(id='chatcmpl-1e246dec-1357-4ceb-948f-03d49e55b5f9', created=1762261910, model=None, object='chat.completion.chunk', system_fingerprint=None, choices=[StreamingChoices(finish_reason=None, index=0, delta=Delta(provider_specific_fields=None, content=' context', role=None, function_call=None, tool_calls=None, audio=None), logprobs=None)], provider_specific_fields=None, usage=None), 'usage': None}
original delta: {'provider_specific_fields': None, 'content': ' context', 'role': None, 'function_call': None, 'tool_calls': None, 'audio': None}
new delta: Delta(provider_specific_fields=None, content=' context', role=None, function_call=None, tool_calls=None, audio=None)
model_response.choices[0].delta: Delta(provider_specific_fields=None, content=' context', role=None, function_call=None, tool_calls=None, audio=None); completion_obj: {'content': ' context'}
self.sent_first_chunk: True
completion_obj: {'content': ' context'}, model_response.choices[0]: StreamingChoices(finish_reason=None, index=0, delta=Delta(provider_specific_fields=None, content=' context', role=None, function_call=None, tool_calls=None, audio=None), logprobs=None), response_obj: {'text': ' context', 'is_finished': False, 'finish_reason': None, 'logprobs': None, 'original_chunk': ModelResponseStream(id='chatcmpl-1e246dec-1357-4ceb-948f-03d49e55b5f9', created=1762261910, model=None, object='chat.completion.chunk', system_fingerprint=None, choices=[StreamingChoices(finish_reason=None, index=0, delta=Delta(provider_specific_fields=None, content=' context', role=None, function_call=None, tool_calls=None, audio=None), logprobs=None)], provider_specific_fields=None, usage=None), 'usage': None}
choice_json: {'index': 0, 'delta': {'provider_specific_fields': None, 'content': ' context', 'role': None, 'function_call': None, 'tool_calls': None, 'audio': None}, 'logprobs': None}
choices in streaming: [StreamingChoices(finish_reason=None, index=0, delta=Delta(provider_specific_fields=None, content=' context', role=None, function_call=None, tool_calls=None, audio=None), logprobs=None)]
final returned processed chunk: ModelResponseStream(id='chatcmpl-1e246dec-1357-4ceb-948f-03d49e55b5f9', created=1762261907, model='claude-sonnet-4-5-20250929', object='chat.completion.chunk', system_fingerprint=None, choices=[StreamingChoices(finish_reason=None, index=0, delta=Delta(provider_specific_fields=None, content=' context', role=None, function_call=None, tool_calls=None, audio=None), logprobs=None)], provider_specific_fields=None, citations=None)
model_response finish reason 3: None; response_obj={'text': '', 'is_finished': False, 'finish_reason': '', 'usage': None, 'index': 0, 'tool_use': None}
model_response.choices[0].delta: Delta(provider_specific_fields=None, content=None, role=None, function_call=None, tool_calls=None, audio=None); completion_obj: {'content': ''}
self.sent_first_chunk: True
completion_obj: {'content': ''}, model_response.choices[0]: StreamingChoices(finish_reason=None, index=0, delta=Delta(provider_specific_fields=None, content=None, role=None, function_call=None, tool_calls=None, audio=None), logprobs=None), response_obj: {'text': '', 'is_finished': False, 'finish_reason': '', 'usage': None, 'index': 0, 'tool_use': None}
model_response finish reason 3: None; response_obj={'text': '', 'is_finished': False, 'finish_reason': '', 'usage': None, 'index': 0, 'tool_use': None}
model_response.choices[0].delta: Delta(provider_specific_fields=None, content=None, role=None, function_call=None, tool_calls=None, audio=None); completion_obj: {'content': ''}
self.sent_first_chunk: True
completion_obj: {'content': ''}, model_response.choices[0]: StreamingChoices(finish_reason=None, index=0, delta=Delta(provider_specific_fields=None, content=None, role=None, function_call=None, tool_calls=None, audio=None), logprobs=None), response_obj: {'text': '', 'is_finished': False, 'finish_reason': '', 'usage': None, 'index': 0, 'tool_use': None}

Raw OpenAI Chunk
ModelResponseStream(id='chatcmpl-1e246dec-1357-4ceb-948f-03d49e55b5f9', created=1762261910, model=None, object='chat.completion.chunk', system_fingerprint=None, choices=[StreamingChoices(finish_reason=None, index=0, delta=Delta(provider_specific_fields=None, content='-', role=None, function_call=None, tool_calls=None, audio=None), logprobs=None)], provider_specific_fields=None, usage=None)

model_response finish reason 3: None; response_obj={'text': '-', 'is_finished': False, 'finish_reason': None, 'logprobs': None, 'original_chunk': ModelResponseStream(id='chatcmpl-1e246dec-1357-4ceb-948f-03d49e55b5f9', created=1762261910, model=None, object='chat.completion.chunk', system_fingerprint=None, choices=[StreamingChoices(finish_reason=None, index=0, delta=Delta(provider_specific_fields=None, content='-', role=None, function_call=None, tool_calls=None, audio=None), logprobs=None)], provider_specific_fields=None, usage=None), 'usage': None}
original delta: {'provider_specific_fields': None, 'content': '-', 'role': None, 'function_call': None, 'tool_calls': None, 'audio': None}
new delta: Delta(provider_specific_fields=None, content='-', role=None, function_call=None, tool_calls=None, audio=None)
model_response.choices[0].delta: Delta(provider_specific_fields=None, content='-', role=None, function_call=None, tool_calls=None, audio=None); completion_obj: {'content': '-'}
self.sent_first_chunk: True
completion_obj: {'content': '-'}, model_response.choices[0]: StreamingChoices(finish_reason=None, index=0, delta=Delta(provider_specific_fields=None, content='-', role=None, function_call=None, tool_calls=None, audio=None), logprobs=None), response_obj: {'text': '-', 'is_finished': False, 'finish_reason': None, 'logprobs': None, 'original_chunk': ModelResponseStream(id='chatcmpl-1e246dec-1357-4ceb-948f-03d49e55b5f9', created=1762261910, model=None, object='chat.completion.chunk', system_fingerprint=None, choices=[StreamingChoices(finish_reason=None, index=0, delta=Delta(provider_specific_fields=None, content='-', role=None, function_call=None, tool_calls=None, audio=None), logprobs=None)], provider_specific_fields=None, usage=None), 'usage': None}
choice_json: {'index': 0, 'delta': {'provider_specific_fields': None, 'content': '-', 'role': None, 'function_call': None, 'tool_calls': None, 'audio': None}, 'logprobs': None}
choices in streaming: [StreamingChoices(finish_reason=None, index=0, delta=Delta(provider_specific_fields=None, content='-', role=None, function_call=None, tool_calls=None, audio=None), logprobs=None)]
final returned processed chunk: ModelResponseStream(id='chatcmpl-1e246dec-1357-4ceb-948f-03d49e55b5f9', created=1762261907, model='claude-sonnet-4-5-20250929', object='chat.completion.chunk', system_fingerprint=None, choices=[StreamingChoices(finish_reason=None, index=0, delta=Delta(provider_specific_fields=None, content='-', role=None, function_call=None, tool_calls=None, audio=None), logprobs=None)], provider_specific_fields=None, citations=None)
model_response finish reason 3: None; response_obj={'text': '', 'is_finished': False, 'finish_reason': '', 'usage': None, 'index': 0, 'tool_use': None}
model_response.choices[0].delta: Delta(provider_specific_fields=None, content=None, role=None, function_call=None, tool_calls=None, audio=None); completion_obj: {'content': ''}
self.sent_first_chunk: True
completion_obj: {'content': ''}, model_response.choices[0]: StreamingChoices(finish_reason=None, index=0, delta=Delta(provider_specific_fields=None, content=None, role=None, function_call=None, tool_calls=None, audio=None), logprobs=None), response_obj: {'text': '', 'is_finished': False, 'finish_reason': '', 'usage': None, 'index': 0, 'tool_use': None}
model_response finish reason 3: None; response_obj={'text': '', 'is_finished': False, 'finish_reason': '', 'usage': None, 'index': 0, 'tool_use': None}
model_response.choices[0].delta: Delta(provider_specific_fields=None, content=None, role=None, function_call=None, tool_calls=None, audio=None); completion_obj: {'content': ''}
self.sent_first_chunk: True
completion_obj: {'content': ''}, model_response.choices[0]: StreamingChoices(finish_reason=None, index=0, delta=Delta(provider_specific_fields=None, content=None, role=None, function_call=None, tool_calls=None, audio=None), logprobs=None), response_obj: {'text': '', 'is_finished': False, 'finish_reason': '', 'usage': None, 'index': 0, 'tool_use': None}

Raw OpenAI Chunk
ModelResponseStream(id='chatcmpl-1e246dec-1357-4ceb-948f-03d49e55b5f9', created=1762261910, model=None, object='chat.completion.chunk', system_fingerprint=None, choices=[StreamingChoices(finish_reason=None, index=0, delta=Delta(provider_specific_fields=None, content='aware AI', role=None, function_call=None, tool_calls=None, audio=None), logprobs=None)], provider_specific_fields=None, usage=None)

model_response finish reason 3: None; response_obj={'text': 'aware AI', 'is_finished': False, 'finish_reason': None, 'logprobs': None, 'original_chunk': ModelResponseStream(id='chatcmpl-1e246dec-1357-4ceb-948f-03d49e55b5f9', created=1762261910, model=None, object='chat.completion.chunk', system_fingerprint=None, choices=[StreamingChoices(finish_reason=None, index=0, delta=Delta(provider_specific_fields=None, content='aware AI', role=None, function_call=None, tool_calls=None, audio=None), logprobs=None)], provider_specific_fields=None, usage=None), 'usage': None}
original delta: {'provider_specific_fields': None, 'content': 'aware AI', 'role': None, 'function_call': None, 'tool_calls': None, 'audio': None}
new delta: Delta(provider_specific_fields=None, content='aware AI', role=None, function_call=None, tool_calls=None, audio=None)
model_response.choices[0].delta: Delta(provider_specific_fields=None, content='aware AI', role=None, function_call=None, tool_calls=None, audio=None); completion_obj: {'content': 'aware AI'}
self.sent_first_chunk: True
completion_obj: {'content': 'aware AI'}, model_response.choices[0]: StreamingChoices(finish_reason=None, index=0, delta=Delta(provider_specific_fields=None, content='aware AI', role=None, function_call=None, tool_calls=None, audio=None), logprobs=None), response_obj: {'text': 'aware AI', 'is_finished': False, 'finish_reason': None, 'logprobs': None, 'original_chunk': ModelResponseStream(id='chatcmpl-1e246dec-1357-4ceb-948f-03d49e55b5f9', created=1762261910, model=None, object='chat.completion.chunk', system_fingerprint=None, choices=[StreamingChoices(finish_reason=None, index=0, delta=Delta(provider_specific_fields=None, content='aware AI', role=None, function_call=None, tool_calls=None, audio=None), logprobs=None)], provider_specific_fields=None, usage=None), 'usage': None}
choice_json: {'index': 0, 'delta': {'provider_specific_fields': None, 'content': 'aware AI', 'role': None, 'function_call': None, 'tool_calls': None, 'audio': None}, 'logprobs': None}
choices in streaming: [StreamingChoices(finish_reason=None, index=0, delta=Delta(provider_specific_fields=None, content='aware AI', role=None, function_call=None, tool_calls=None, audio=None), logprobs=None)]
final returned processed chunk: ModelResponseStream(id='chatcmpl-1e246dec-1357-4ceb-948f-03d49e55b5f9', created=1762261907, model='claude-sonnet-4-5-20250929', object='chat.completion.chunk', system_fingerprint=None, choices=[StreamingChoices(finish_reason=None, index=0, delta=Delta(provider_specific_fields=None, content='aware AI', role=None, function_call=None, tool_calls=None, audio=None), logprobs=None)], provider_specific_fields=None, citations=None)
model_response finish reason 3: None; response_obj={'text': '', 'is_finished': False, 'finish_reason': '', 'usage': None, 'index': 0, 'tool_use': None}
model_response.choices[0].delta: Delta(provider_specific_fields=None, content=None, role=None, function_call=None, tool_calls=None, audio=None); completion_obj: {'content': ''}
self.sent_first_chunk: True
completion_obj: {'content': ''}, model_response.choices[0]: StreamingChoices(finish_reason=None, index=0, delta=Delta(provider_specific_fields=None, content=None, role=None, function_call=None, tool_calls=None, audio=None), logprobs=None), response_obj: {'text': '', 'is_finished': False, 'finish_reason': '', 'usage': None, 'index': 0, 'tool_use': None}
model_response finish reason 3: None; response_obj={'text': '', 'is_finished': False, 'finish_reason': '', 'usage': None, 'index': 0, 'tool_use': None}
model_response.choices[0].delta: Delta(provider_specific_fields=None, content=None, role=None, function_call=None, tool_calls=None, audio=None); completion_obj: {'content': ''}
self.sent_first_chunk: True
completion_obj: {'content': ''}, model_response.choices[0]: StreamingChoices(finish_reason=None, index=0, delta=Delta(provider_specific_fields=None, content=None, role=None, function_call=None, tool_calls=None, audio=None), logprobs=None), response_obj: {'text': '', 'is_finished': False, 'finish_reason': '', 'usage': None, 'index': 0, 'tool_use': None}

Raw OpenAI Chunk
ModelResponseStream(id='chatcmpl-1e246dec-1357-4ceb-948f-03d49e55b5f9', created=1762261910, model=None, object='chat.completion.chunk', system_fingerprint=None, choices=[StreamingChoices(finish_reason=None, index=0, delta=Delta(provider_specific_fields=None, content=' responses\n2. **You want', role=None, function_call=None, tool_calls=None, audio=None), logprobs=None)], provider_specific_fields=None, usage=None)

model_response finish reason 3: None; response_obj={'text': ' responses\n2. **You want', 'is_finished': False, 'finish_reason': None, 'logprobs': None, 'original_chunk': ModelResponseStream(id='chatcmpl-1e246dec-1357-4ceb-948f-03d49e55b5f9', created=1762261910, model=None, object='chat.completion.chunk', system_fingerprint=None, choices=[StreamingChoices(finish_reason=None, index=0, delta=Delta(provider_specific_fields=None, content=' responses\n2. **You want', role=None, function_call=None, tool_calls=None, audio=None), logprobs=None)], provider_specific_fields=None, usage=None), 'usage': None}
original delta: {'provider_specific_fields': None, 'content': ' responses\n2. **You want', 'role': None, 'function_call': None, 'tool_calls': None, 'audio': None}
new delta: Delta(provider_specific_fields=None, content=' responses\n2. **You want', role=None, function_call=None, tool_calls=None, audio=None)
model_response.choices[0].delta: Delta(provider_specific_fields=None, content=' responses\n2. **You want', role=None, function_call=None, tool_calls=None, audio=None); completion_obj: {'content': ' responses\n2. **You want'}
self.sent_first_chunk: True
completion_obj: {'content': ' responses\n2. **You want'}, model_response.choices[0]: StreamingChoices(finish_reason=None, index=0, delta=Delta(provider_specific_fields=None, content=' responses\n2. **You want', role=None, function_call=None, tool_calls=None, audio=None), logprobs=None), response_obj: {'text': ' responses\n2. **You want', 'is_finished': False, 'finish_reason': None, 'logprobs': None, 'original_chunk': ModelResponseStream(id='chatcmpl-1e246dec-1357-4ceb-948f-03d49e55b5f9', created=1762261910, model=None, object='chat.completion.chunk', system_fingerprint=None, choices=[StreamingChoices(finish_reason=None, index=0, delta=Delta(provider_specific_fields=None, content=' responses\n2. **You want', role=None, function_call=None, tool_calls=None, audio=None), logprobs=None)], provider_specific_fields=None, usage=None), 'usage': None}
choice_json: {'index': 0, 'delta': {'provider_specific_fields': None, 'content': ' responses\n2. **You want', 'role': None, 'function_call': None, 'tool_calls': None, 'audio': None}, 'logprobs': None}
choices in streaming: [StreamingChoices(finish_reason=None, index=0, delta=Delta(provider_specific_fields=None, content=' responses\n2. **You want', role=None, function_call=None, tool_calls=None, audio=None), logprobs=None)]
final returned processed chunk: ModelResponseStream(id='chatcmpl-1e246dec-1357-4ceb-948f-03d49e55b5f9', created=1762261907, model='claude-sonnet-4-5-20250929', object='chat.completion.chunk', system_fingerprint=None, choices=[StreamingChoices(finish_reason=None, index=0, delta=Delta(provider_specific_fields=None, content=' responses\n2. **You want', role=None, function_call=None, tool_calls=None, audio=None), logprobs=None)], provider_specific_fields=None, citations=None)
model_response finish reason 3: None; response_obj={'text': '', 'is_finished': False, 'finish_reason': '', 'usage': None, 'index': 0, 'tool_use': None}
model_response.choices[0].delta: Delta(provider_specific_fields=None, content=None, role=None, function_call=None, tool_calls=None, audio=None); completion_obj: {'content': ''}
self.sent_first_chunk: True
completion_obj: {'content': ''}, model_response.choices[0]: StreamingChoices(finish_reason=None, index=0, delta=Delta(provider_specific_fields=None, content=None, role=None, function_call=None, tool_calls=None, audio=None), logprobs=None), response_obj: {'text': '', 'is_finished': False, 'finish_reason': '', 'usage': None, 'index': 0, 'tool_use': None}
model_response finish reason 3: None; response_obj={'text': '', 'is_finished': False, 'finish_reason': '', 'usage': None, 'index': 0, 'tool_use': None}
model_response.choices[0].delta: Delta(provider_specific_fields=None, content=None, role=None, function_call=None, tool_calls=None, audio=None); completion_obj: {'content': ''}
self.sent_first_chunk: True
completion_obj: {'content': ''}, model_response.choices[0]: StreamingChoices(finish_reason=None, index=0, delta=Delta(provider_specific_fields=None, content=None, role=None, function_call=None, tool_calls=None, audio=None), logprobs=None), response_obj: {'text': '', 'is_finished': False, 'finish_reason': '', 'usage': None, 'index': 0, 'tool_use': None}

Raw OpenAI Chunk
ModelResponseStream(id='chatcmpl-1e246dec-1357-4ceb-948f-03d49e55b5f9', created=1762261911, model=None, object='chat.completion.chunk', system_fingerprint=None, choices=[StreamingChoices(finish_reason=None, index=0, delta=Delta(provider_specific_fields=None, content=' to retrieve user', role=None, function_call=None, tool_calls=None, audio=None), logprobs=None)], provider_specific_fields=None, usage=None)

model_response finish reason 3: None; response_obj={'text': ' to retrieve user', 'is_finished': False, 'finish_reason': None, 'logprobs': None, 'original_chunk': ModelResponseStream(id='chatcmpl-1e246dec-1357-4ceb-948f-03d49e55b5f9', created=1762261911, model=None, object='chat.completion.chunk', system_fingerprint=None, choices=[StreamingChoices(finish_reason=None, index=0, delta=Delta(provider_specific_fields=None, content=' to retrieve user', role=None, function_call=None, tool_calls=None, audio=None), logprobs=None)], provider_specific_fields=None, usage=None), 'usage': None}
original delta: {'provider_specific_fields': None, 'content': ' to retrieve user', 'role': None, 'function_call': None, 'tool_calls': None, 'audio': None}
new delta: Delta(provider_specific_fields=None, content=' to retrieve user', role=None, function_call=None, tool_calls=None, audio=None)
model_response.choices[0].delta: Delta(provider_specific_fields=None, content=' to retrieve user', role=None, function_call=None, tool_calls=None, audio=None); completion_obj: {'content': ' to retrieve user'}
self.sent_first_chunk: True
completion_obj: {'content': ' to retrieve user'}, model_response.choices[0]: StreamingChoices(finish_reason=None, index=0, delta=Delta(provider_specific_fields=None, content=' to retrieve user', role=None, function_call=None, tool_calls=None, audio=None), logprobs=None), response_obj: {'text': ' to retrieve user', 'is_finished': False, 'finish_reason': None, 'logprobs': None, 'original_chunk': ModelResponseStream(id='chatcmpl-1e246dec-1357-4ceb-948f-03d49e55b5f9', created=1762261911, model=None, object='chat.completion.chunk', system_fingerprint=None, choices=[StreamingChoices(finish_reason=None, index=0, delta=Delta(provider_specific_fields=None, content=' to retrieve user', role=None, function_call=None, tool_calls=None, audio=None), logprobs=None)], provider_specific_fields=None, usage=None), 'usage': None}
choice_json: {'index': 0, 'delta': {'provider_specific_fields': None, 'content': ' to retrieve user', 'role': None, 'function_call': None, 'tool_calls': None, 'audio': None}, 'logprobs': None}
choices in streaming: [StreamingChoices(finish_reason=None, index=0, delta=Delta(provider_specific_fields=None, content=' to retrieve user', role=None, function_call=None, tool_calls=None, audio=None), logprobs=None)]
final returned processed chunk: ModelResponseStream(id='chatcmpl-1e246dec-1357-4ceb-948f-03d49e55b5f9', created=1762261907, model='claude-sonnet-4-5-20250929', object='chat.completion.chunk', system_fingerprint=None, choices=[StreamingChoices(finish_reason=None, index=0, delta=Delta(provider_specific_fields=None, content=' to retrieve user', role=None, function_call=None, tool_calls=None, audio=None), logprobs=None)], provider_specific_fields=None, citations=None)
model_response finish reason 3: None; response_obj={'text': '', 'is_finished': False, 'finish_reason': '', 'usage': None, 'index': 0, 'tool_use': None}
model_response.choices[0].delta: Delta(provider_specific_fields=None, content=None, role=None, function_call=None, tool_calls=None, audio=None); completion_obj: {'content': ''}
self.sent_first_chunk: True
completion_obj: {'content': ''}, model_response.choices[0]: StreamingChoices(finish_reason=None, index=0, delta=Delta(provider_specific_fields=None, content=None, role=None, function_call=None, tool_calls=None, audio=None), logprobs=None), response_obj: {'text': '', 'is_finished': False, 'finish_reason': '', 'usage': None, 'index': 0, 'tool_use': None}
model_response finish reason 3: None; response_obj={'text': '', 'is_finished': False, 'finish_reason': '', 'usage': None, 'index': 0, 'tool_use': None}
model_response.choices[0].delta: Delta(provider_specific_fields=None, content=None, role=None, function_call=None, tool_calls=None, audio=None); completion_obj: {'content': ''}
self.sent_first_chunk: True
completion_obj: {'content': ''}, model_response.choices[0]: StreamingChoices(finish_reason=None, index=0, delta=Delta(provider_specific_fields=None, content=None, role=None, function_call=None, tool_calls=None, audio=None), logprobs=None), response_obj: {'text': '', 'is_finished': False, 'finish_reason': '', 'usage': None, 'index': 0, 'tool_use': None}

Raw OpenAI Chunk
ModelResponseStream(id='chatcmpl-1e246dec-1357-4ceb-948f-03d49e55b5f9', created=1762261911, model=None, object='chat.completion.chunk', system_fingerprint=None, choices=[StreamingChoices(finish_reason=None, index=0, delta=Delta(provider_specific_fields=None, content=' context', role=None, function_call=None, tool_calls=None, audio=None), logprobs=None)], provider_specific_fields=None, usage=None)

model_response finish reason 3: None; response_obj={'text': ' context', 'is_finished': False, 'finish_reason': None, 'logprobs': None, 'original_chunk': ModelResponseStream(id='chatcmpl-1e246dec-1357-4ceb-948f-03d49e55b5f9', created=1762261911, model=None, object='chat.completion.chunk', system_fingerprint=None, choices=[StreamingChoices(finish_reason=None, index=0, delta=Delta(provider_specific_fields=None, content=' context', role=None, function_call=None, tool_calls=None, audio=None), logprobs=None)], provider_specific_fields=None, usage=None), 'usage': None}
original delta: {'provider_specific_fields': None, 'content': ' context', 'role': None, 'function_call': None, 'tool_calls': None, 'audio': None}
new delta: Delta(provider_specific_fields=None, content=' context', role=None, function_call=None, tool_calls=None, audio=None)
model_response.choices[0].delta: Delta(provider_specific_fields=None, content=' context', role=None, function_call=None, tool_calls=None, audio=None); completion_obj: {'content': ' context'}
self.sent_first_chunk: True
completion_obj: {'content': ' context'}, model_response.choices[0]: StreamingChoices(finish_reason=None, index=0, delta=Delta(provider_specific_fields=None, content=' context', role=None, function_call=None, tool_calls=None, audio=None), logprobs=None), response_obj: {'text': ' context', 'is_finished': False, 'finish_reason': None, 'logprobs': None, 'original_chunk': ModelResponseStream(id='chatcmpl-1e246dec-1357-4ceb-948f-03d49e55b5f9', created=1762261911, model=None, object='chat.completion.chunk', system_fingerprint=None, choices=[StreamingChoices(finish_reason=None, index=0, delta=Delta(provider_specific_fields=None, content=' context', role=None, function_call=None, tool_calls=None, audio=None), logprobs=None)], provider_specific_fields=None, usage=None), 'usage': None}
choice_json: {'index': 0, 'delta': {'provider_specific_fields': None, 'content': ' context', 'role': None, 'function_call': None, 'tool_calls': None, 'audio': None}, 'logprobs': None}
choices in streaming: [StreamingChoices(finish_reason=None, index=0, delta=Delta(provider_specific_fields=None, content=' context', role=None, function_call=None, tool_calls=None, audio=None), logprobs=None)]
final returned processed chunk: ModelResponseStream(id='chatcmpl-1e246dec-1357-4ceb-948f-03d49e55b5f9', created=1762261907, model='claude-sonnet-4-5-20250929', object='chat.completion.chunk', system_fingerprint=None, choices=[StreamingChoices(finish_reason=None, index=0, delta=Delta(provider_specific_fields=None, content=' context', role=None, function_call=None, tool_calls=None, audio=None), logprobs=None)], provider_specific_fields=None, citations=None)
model_response finish reason 3: None; response_obj={'text': '', 'is_finished': False, 'finish_reason': '', 'usage': None, 'index': 0, 'tool_use': None}
model_response.choices[0].delta: Delta(provider_specific_fields=None, content=None, role=None, function_call=None, tool_calls=None, audio=None); completion_obj: {'content': ''}
self.sent_first_chunk: True
completion_obj: {'content': ''}, model_response.choices[0]: StreamingChoices(finish_reason=None, index=0, delta=Delta(provider_specific_fields=None, content=None, role=None, function_call=None, tool_calls=None, audio=None), logprobs=None), response_obj: {'text': '', 'is_finished': False, 'finish_reason': '', 'usage': None, 'index': 0, 'tool_use': None}
model_response finish reason 3: None; response_obj={'text': '', 'is_finished': False, 'finish_reason': '', 'usage': None, 'index': 0, 'tool_use': None}
model_response.choices[0].delta: Delta(provider_specific_fields=None, content=None, role=None, function_call=None, tool_calls=None, audio=None); completion_obj: {'content': ''}
self.sent_first_chunk: True
completion_obj: {'content': ''}, model_response.choices[0]: StreamingChoices(finish_reason=None, index=0, delta=Delta(provider_specific_fields=None, content=None, role=None, function_call=None, tool_calls=None, audio=None), logprobs=None), response_obj: {'text': '', 'is_finished': False, 'finish_reason': '', 'usage': None, 'index': 0, 'tool_use': None}

Raw OpenAI Chunk
ModelResponseStream(id='chatcmpl-1e246dec-1357-4ceb-948f-03d49e55b5f9', created=1762261911, model=None, object='chat.completion.chunk', system_fingerprint=None, choices=[StreamingChoices(finish_reason=None, index=0, delta=Delta(provider_specific_fields=None, content=' from Supermemory** to', role=None, function_call=None, tool_calls=None, audio=None), logprobs=None)], provider_specific_fields=None, usage=None)

model_response finish reason 3: None; response_obj={'text': ' from Supermemory** to', 'is_finished': False, 'finish_reason': None, 'logprobs': None, 'original_chunk': ModelResponseStream(id='chatcmpl-1e246dec-1357-4ceb-948f-03d49e55b5f9', created=1762261911, model=None, object='chat.completion.chunk', system_fingerprint=None, choices=[StreamingChoices(finish_reason=None, index=0, delta=Delta(provider_specific_fields=None, content=' from Supermemory** to', role=None, function_call=None, tool_calls=None, audio=None), logprobs=None)], provider_specific_fields=None, usage=None), 'usage': None}
original delta: {'provider_specific_fields': None, 'content': ' from Supermemory** to', 'role': None, 'function_call': None, 'tool_calls': None, 'audio': None}
new delta: Delta(provider_specific_fields=None, content=' from Supermemory** to', role=None, function_call=None, tool_calls=None, audio=None)
model_response.choices[0].delta: Delta(provider_specific_fields=None, content=' from Supermemory** to', role=None, function_call=None, tool_calls=None, audio=None); completion_obj: {'content': ' from Supermemory** to'}
self.sent_first_chunk: True
completion_obj: {'content': ' from Supermemory** to'}, model_response.choices[0]: StreamingChoices(finish_reason=None, index=0, delta=Delta(provider_specific_fields=None, content=' from Supermemory** to', role=None, function_call=None, tool_calls=None, audio=None), logprobs=None), response_obj: {'text': ' from Supermemory** to', 'is_finished': False, 'finish_reason': None, 'logprobs': None, 'original_chunk': ModelResponseStream(id='chatcmpl-1e246dec-1357-4ceb-948f-03d49e55b5f9', created=1762261911, model=None, object='chat.completion.chunk', system_fingerprint=None, choices=[StreamingChoices(finish_reason=None, index=0, delta=Delta(provider_specific_fields=None, content=' from Supermemory** to', role=None, function_call=None, tool_calls=None, audio=None), logprobs=None)], provider_specific_fields=None, usage=None), 'usage': None}
choice_json: {'index': 0, 'delta': {'provider_specific_fields': None, 'content': ' from Supermemory** to', 'role': None, 'function_call': None, 'tool_calls': None, 'audio': None}, 'logprobs': None}
choices in streaming: [StreamingChoices(finish_reason=None, index=0, delta=Delta(provider_specific_fields=None, content=' from Supermemory** to', role=None, function_call=None, tool_calls=None, audio=None), logprobs=None)]
final returned processed chunk: ModelResponseStream(id='chatcmpl-1e246dec-1357-4ceb-948f-03d49e55b5f9', created=1762261907, model='claude-sonnet-4-5-20250929', object='chat.completion.chunk', system_fingerprint=None, choices=[StreamingChoices(finish_reason=None, index=0, delta=Delta(provider_specific_fields=None, content=' from Supermemory** to', role=None, function_call=None, tool_calls=None, audio=None), logprobs=None)], provider_specific_fields=None, citations=None)
model_response finish reason 3: None; response_obj={'text': '', 'is_finished': False, 'finish_reason': '', 'usage': None, 'index': 0, 'tool_use': None}
model_response.choices[0].delta: Delta(provider_specific_fields=None, content=None, role=None, function_call=None, tool_calls=None, audio=None); completion_obj: {'content': ''}
self.sent_first_chunk: True
completion_obj: {'content': ''}, model_response.choices[0]: StreamingChoices(finish_reason=None, index=0, delta=Delta(provider_specific_fields=None, content=None, role=None, function_call=None, tool_calls=None, audio=None), logprobs=None), response_obj: {'text': '', 'is_finished': False, 'finish_reason': '', 'usage': None, 'index': 0, 'tool_use': None}
model_response finish reason 3: None; response_obj={'text': '', 'is_finished': False, 'finish_reason': '', 'usage': None, 'index': 0, 'tool_use': None}
model_response.choices[0].delta: Delta(provider_specific_fields=None, content=None, role=None, function_call=None, tool_calls=None, audio=None); completion_obj: {'content': ''}
self.sent_first_chunk: True
completion_obj: {'content': ''}, model_response.choices[0]: StreamingChoices(finish_reason=None, index=0, delta=Delta(provider_specific_fields=None, content=None, role=None, function_call=None, tool_calls=None, audio=None), logprobs=None), response_obj: {'text': '', 'is_finished': False, 'finish_reason': '', 'usage': None, 'index': 0, 'tool_use': None}

Raw OpenAI Chunk
ModelResponseStream(id='chatcmpl-1e246dec-1357-4ceb-948f-03d49e55b5f9', created=1762261911, model=None, object='chat.completion.chunk', system_fingerprint=None, choices=[StreamingChoices(finish_reason=None, index=0, delta=Delta(provider_specific_fields=None, content=' enhance', role=None, function_call=None, tool_calls=None, audio=None), logprobs=None)], provider_specific_fields=None, usage=None)

model_response finish reason 3: None; response_obj={'text': ' enhance', 'is_finished': False, 'finish_reason': None, 'logprobs': None, 'original_chunk': ModelResponseStream(id='chatcmpl-1e246dec-1357-4ceb-948f-03d49e55b5f9', created=1762261911, model=None, object='chat.completion.chunk', system_fingerprint=None, choices=[StreamingChoices(finish_reason=None, index=0, delta=Delta(provider_specific_fields=None, content=' enhance', role=None, function_call=None, tool_calls=None, audio=None), logprobs=None)], provider_specific_fields=None, usage=None), 'usage': None}
original delta: {'provider_specific_fields': None, 'content': ' enhance', 'role': None, 'function_call': None, 'tool_calls': None, 'audio': None}
new delta: Delta(provider_specific_fields=None, content=' enhance', role=None, function_call=None, tool_calls=None, audio=None)
model_response.choices[0].delta: Delta(provider_specific_fields=None, content=' enhance', role=None, function_call=None, tool_calls=None, audio=None); completion_obj: {'content': ' enhance'}
self.sent_first_chunk: True
completion_obj: {'content': ' enhance'}, model_response.choices[0]: StreamingChoices(finish_reason=None, index=0, delta=Delta(provider_specific_fields=None, content=' enhance', role=None, function_call=None, tool_calls=None, audio=None), logprobs=None), response_obj: {'text': ' enhance', 'is_finished': False, 'finish_reason': None, 'logprobs': None, 'original_chunk': ModelResponseStream(id='chatcmpl-1e246dec-1357-4ceb-948f-03d49e55b5f9', created=1762261911, model=None, object='chat.completion.chunk', system_fingerprint=None, choices=[StreamingChoices(finish_reason=None, index=0, delta=Delta(provider_specific_fields=None, content=' enhance', role=None, function_call=None, tool_calls=None, audio=None), logprobs=None)], provider_specific_fields=None, usage=None), 'usage': None}
choice_json: {'index': 0, 'delta': {'provider_specific_fields': None, 'content': ' enhance', 'role': None, 'function_call': None, 'tool_calls': None, 'audio': None}, 'logprobs': None}
choices in streaming: [StreamingChoices(finish_reason=None, index=0, delta=Delta(provider_specific_fields=None, content=' enhance', role=None, function_call=None, tool_calls=None, audio=None), logprobs=None)]
final returned processed chunk: ModelResponseStream(id='chatcmpl-1e246dec-1357-4ceb-948f-03d49e55b5f9', created=1762261907, model='claude-sonnet-4-5-20250929', object='chat.completion.chunk', system_fingerprint=None, choices=[StreamingChoices(finish_reason=None, index=0, delta=Delta(provider_specific_fields=None, content=' enhance', role=None, function_call=None, tool_calls=None, audio=None), logprobs=None)], provider_specific_fields=None, citations=None)
model_response finish reason 3: None; response_obj={'text': '', 'is_finished': False, 'finish_reason': '', 'usage': None, 'index': 0, 'tool_use': None}
model_response.choices[0].delta: Delta(provider_specific_fields=None, content=None, role=None, function_call=None, tool_calls=None, audio=None); completion_obj: {'content': ''}
self.sent_first_chunk: True
completion_obj: {'content': ''}, model_response.choices[0]: StreamingChoices(finish_reason=None, index=0, delta=Delta(provider_specific_fields=None, content=None, role=None, function_call=None, tool_calls=None, audio=None), logprobs=None), response_obj: {'text': '', 'is_finished': False, 'finish_reason': '', 'usage': None, 'index': 0, 'tool_use': None}
model_response finish reason 3: None; response_obj={'text': '', 'is_finished': False, 'finish_reason': '', 'usage': None, 'index': 0, 'tool_use': None}
model_response.choices[0].delta: Delta(provider_specific_fields=None, content=None, role=None, function_call=None, tool_calls=None, audio=None); completion_obj: {'content': ''}
self.sent_first_chunk: True
completion_obj: {'content': ''}, model_response.choices[0]: StreamingChoices(finish_reason=None, index=0, delta=Delta(provider_specific_fields=None, content=None, role=None, function_call=None, tool_calls=None, audio=None), logprobs=None), response_obj: {'text': '', 'is_finished': False, 'finish_reason': '', 'usage': None, 'index': 0, 'tool_use': None}

Raw OpenAI Chunk
ModelResponseStream(id='chatcmpl-1e246dec-1357-4ceb-948f-03d49e55b5f9', created=1762261911, model=None, object='chat.completion.chunk', system_fingerprint=None, choices=[StreamingChoices(finish_reason=None, index=0, delta=Delta(provider_specific_fields=None, content=' L', role=None, function_call=None, tool_calls=None, audio=None), logprobs=None)], provider_specific_fields=None, usage=None)

model_response finish reason 3: None; response_obj={'text': ' L', 'is_finished': False, 'finish_reason': None, 'logprobs': None, 'original_chunk': ModelResponseStream(id='chatcmpl-1e246dec-1357-4ceb-948f-03d49e55b5f9', created=1762261911, model=None, object='chat.completion.chunk', system_fingerprint=None, choices=[StreamingChoices(finish_reason=None, index=0, delta=Delta(provider_specific_fields=None, content=' L', role=None, function_call=None, tool_calls=None, audio=None), logprobs=None)], provider_specific_fields=None, usage=None), 'usage': None}
original delta: {'provider_specific_fields': None, 'content': ' L', 'role': None, 'function_call': None, 'tool_calls': None, 'audio': None}
new delta: Delta(provider_specific_fields=None, content=' L', role=None, function_call=None, tool_calls=None, audio=None)
model_response.choices[0].delta: Delta(provider_specific_fields=None, content=' L', role=None, function_call=None, tool_calls=None, audio=None); completion_obj: {'content': ' L'}
self.sent_first_chunk: True
completion_obj: {'content': ' L'}, model_response.choices[0]: StreamingChoices(finish_reason=None, index=0, delta=Delta(provider_specific_fields=None, content=' L', role=None, function_call=None, tool_calls=None, audio=None), logprobs=None), response_obj: {'text': ' L', 'is_finished': False, 'finish_reason': None, 'logprobs': None, 'original_chunk': ModelResponseStream(id='chatcmpl-1e246dec-1357-4ceb-948f-03d49e55b5f9', created=1762261911, model=None, object='chat.completion.chunk', system_fingerprint=None, choices=[StreamingChoices(finish_reason=None, index=0, delta=Delta(provider_specific_fields=None, content=' L', role=None, function_call=None, tool_calls=None, audio=None), logprobs=None)], provider_specific_fields=None, usage=None), 'usage': None}
choice_json: {'index': 0, 'delta': {'provider_specific_fields': None, 'content': ' L', 'role': None, 'function_call': None, 'tool_calls': None, 'audio': None}, 'logprobs': None}
choices in streaming: [StreamingChoices(finish_reason=None, index=0, delta=Delta(provider_specific_fields=None, content=' L', role=None, function_call=None, tool_calls=None, audio=None), logprobs=None)]
final returned processed chunk: ModelResponseStream(id='chatcmpl-1e246dec-1357-4ceb-948f-03d49e55b5f9', created=1762261907, model='claude-sonnet-4-5-20250929', object='chat.completion.chunk', system_fingerprint=None, choices=[StreamingChoices(finish_reason=None, index=0, delta=Delta(provider_specific_fields=None, content=' L', role=None, function_call=None, tool_calls=None, audio=None), logprobs=None)], provider_specific_fields=None, citations=None)
model_response finish reason 3: None; response_obj={'text': '', 'is_finished': False, 'finish_reason': '', 'usage': None, 'index': 0, 'tool_use': None}
model_response.choices[0].delta: Delta(provider_specific_fields=None, content=None, role=None, function_call=None, tool_calls=None, audio=None); completion_obj: {'content': ''}
self.sent_first_chunk: True
completion_obj: {'content': ''}, model_response.choices[0]: StreamingChoices(finish_reason=None, index=0, delta=Delta(provider_specific_fields=None, content=None, role=None, function_call=None, tool_calls=None, audio=None), logprobs=None), response_obj: {'text': '', 'is_finished': False, 'finish_reason': '', 'usage': None, 'index': 0, 'tool_use': None}
model_response finish reason 3: None; response_obj={'text': '', 'is_finished': False, 'finish_reason': '', 'usage': None, 'index': 0, 'tool_use': None}
model_response.choices[0].delta: Delta(provider_specific_fields=None, content=None, role=None, function_call=None, tool_calls=None, audio=None); completion_obj: {'content': ''}
self.sent_first_chunk: True
completion_obj: {'content': ''}, model_response.choices[0]: StreamingChoices(finish_reason=None, index=0, delta=Delta(provider_specific_fields=None, content=None, role=None, function_call=None, tool_calls=None, audio=None), logprobs=None), response_obj: {'text': '', 'is_finished': False, 'finish_reason': '', 'usage': None, 'index': 0, 'tool_use': None}

Raw OpenAI Chunk
ModelResponseStream(id='chatcmpl-1e246dec-1357-4ceb-948f-03d49e55b5f9', created=1762261911, model=None, object='chat.completion.chunk', system_fingerprint=None, choices=[StreamingChoices(finish_reason=None, index=0, delta=Delta(provider_specific_fields=None, content='L', role=None, function_call=None, tool_calls=None, audio=None), logprobs=None)], provider_specific_fields=None, usage=None)

model_response finish reason 3: None; response_obj={'text': 'L', 'is_finished': False, 'finish_reason': None, 'logprobs': None, 'original_chunk': ModelResponseStream(id='chatcmpl-1e246dec-1357-4ceb-948f-03d49e55b5f9', created=1762261911, model=None, object='chat.completion.chunk', system_fingerprint=None, choices=[StreamingChoices(finish_reason=None, index=0, delta=Delta(provider_specific_fields=None, content='L', role=None, function_call=None, tool_calls=None, audio=None), logprobs=None)], provider_specific_fields=None, usage=None), 'usage': None}
original delta: {'provider_specific_fields': None, 'content': 'L', 'role': None, 'function_call': None, 'tool_calls': None, 'audio': None}
new delta: Delta(provider_specific_fields=None, content='L', role=None, function_call=None, tool_calls=None, audio=None)
model_response.choices[0].delta: Delta(provider_specific_fields=None, content='L', role=None, function_call=None, tool_calls=None, audio=None); completion_obj: {'content': 'L'}
self.sent_first_chunk: True
completion_obj: {'content': 'L'}, model_response.choices[0]: StreamingChoices(finish_reason=None, index=0, delta=Delta(provider_specific_fields=None, content='L', role=None, function_call=None, tool_calls=None, audio=None), logprobs=None), response_obj: {'text': 'L', 'is_finished': False, 'finish_reason': None, 'logprobs': None, 'original_chunk': ModelResponseStream(id='chatcmpl-1e246dec-1357-4ceb-948f-03d49e55b5f9', created=1762261911, model=None, object='chat.completion.chunk', system_fingerprint=None, choices=[StreamingChoices(finish_reason=None, index=0, delta=Delta(provider_specific_fields=None, content='L', role=None, function_call=None, tool_calls=None, audio=None), logprobs=None)], provider_specific_fields=None, usage=None), 'usage': None}
choice_json: {'index': 0, 'delta': {'provider_specific_fields': None, 'content': 'L', 'role': None, 'function_call': None, 'tool_calls': None, 'audio': None}, 'logprobs': None}
choices in streaming: [StreamingChoices(finish_reason=None, index=0, delta=Delta(provider_specific_fields=None, content='L', role=None, function_call=None, tool_calls=None, audio=None), logprobs=None)]
final returned processed chunk: ModelResponseStream(id='chatcmpl-1e246dec-1357-4ceb-948f-03d49e55b5f9', created=1762261907, model='claude-sonnet-4-5-20250929', object='chat.completion.chunk', system_fingerprint=None, choices=[StreamingChoices(finish_reason=None, index=0, delta=Delta(provider_specific_fields=None, content='L', role=None, function_call=None, tool_calls=None, audio=None), logprobs=None)], provider_specific_fields=None, citations=None)
model_response finish reason 3: None; response_obj={'text': '', 'is_finished': False, 'finish_reason': '', 'usage': None, 'index': 0, 'tool_use': None}
model_response.choices[0].delta: Delta(provider_specific_fields=None, content=None, role=None, function_call=None, tool_calls=None, audio=None); completion_obj: {'content': ''}
self.sent_first_chunk: True
completion_obj: {'content': ''}, model_response.choices[0]: StreamingChoices(finish_reason=None, index=0, delta=Delta(provider_specific_fields=None, content=None, role=None, function_call=None, tool_calls=None, audio=None), logprobs=None), response_obj: {'text': '', 'is_finished': False, 'finish_reason': '', 'usage': None, 'index': 0, 'tool_use': None}
model_response finish reason 3: None; response_obj={'text': '', 'is_finished': False, 'finish_reason': '', 'usage': None, 'index': 0, 'tool_use': None}
model_response.choices[0].delta: Delta(provider_specific_fields=None, content=None, role=None, function_call=None, tool_calls=None, audio=None); completion_obj: {'content': ''}
self.sent_first_chunk: True
completion_obj: {'content': ''}, model_response.choices[0]: StreamingChoices(finish_reason=None, index=0, delta=Delta(provider_specific_fields=None, content=None, role=None, function_call=None, tool_calls=None, audio=None), logprobs=None), response_obj: {'text': '', 'is_finished': False, 'finish_reason': '', 'usage': None, 'index': 0, 'tool_use': None}

Raw OpenAI Chunk
ModelResponseStream(id='chatcmpl-1e246dec-1357-4ceb-948f-03d49e55b5f9', created=1762261911, model=None, object='chat.completion.chunk', system_fingerprint=None, choices=[StreamingChoices(finish_reason=None, index=0, delta=Delta(provider_specific_fields=None, content='M prom', role=None, function_call=None, tool_calls=None, audio=None), logprobs=None)], provider_specific_fields=None, usage=None)

model_response finish reason 3: None; response_obj={'text': 'M prom', 'is_finished': False, 'finish_reason': None, 'logprobs': None, 'original_chunk': ModelResponseStream(id='chatcmpl-1e246dec-1357-4ceb-948f-03d49e55b5f9', created=1762261911, model=None, object='chat.completion.chunk', system_fingerprint=None, choices=[StreamingChoices(finish_reason=None, index=0, delta=Delta(provider_specific_fields=None, content='M prom', role=None, function_call=None, tool_calls=None, audio=None), logprobs=None)], provider_specific_fields=None, usage=None), 'usage': None}
original delta: {'provider_specific_fields': None, 'content': 'M prom', 'role': None, 'function_call': None, 'tool_calls': None, 'audio': None}
new delta: Delta(provider_specific_fields=None, content='M prom', role=None, function_call=None, tool_calls=None, audio=None)
model_response.choices[0].delta: Delta(provider_specific_fields=None, content='M prom', role=None, function_call=None, tool_calls=None, audio=None); completion_obj: {'content': 'M prom'}
self.sent_first_chunk: True
completion_obj: {'content': 'M prom'}, model_response.choices[0]: StreamingChoices(finish_reason=None, index=0, delta=Delta(provider_specific_fields=None, content='M prom', role=None, function_call=None, tool_calls=None, audio=None), logprobs=None), response_obj: {'text': 'M prom', 'is_finished': False, 'finish_reason': None, 'logprobs': None, 'original_chunk': ModelResponseStream(id='chatcmpl-1e246dec-1357-4ceb-948f-03d49e55b5f9', created=1762261911, model=None, object='chat.completion.chunk', system_fingerprint=None, choices=[StreamingChoices(finish_reason=None, index=0, delta=Delta(provider_specific_fields=None, content='M prom', role=None, function_call=None, tool_calls=None, audio=None), logprobs=None)], provider_specific_fields=None, usage=None), 'usage': None}
choice_json: {'index': 0, 'delta': {'provider_specific_fields': None, 'content': 'M prom', 'role': None, 'function_call': None, 'tool_calls': None, 'audio': None}, 'logprobs': None}
choices in streaming: [StreamingChoices(finish_reason=None, index=0, delta=Delta(provider_specific_fields=None, content='M prom', role=None, function_call=None, tool_calls=None, audio=None), logprobs=None)]
final returned processed chunk: ModelResponseStream(id='chatcmpl-1e246dec-1357-4ceb-948f-03d49e55b5f9', created=1762261907, model='claude-sonnet-4-5-20250929', object='chat.completion.chunk', system_fingerprint=None, choices=[StreamingChoices(finish_reason=None, index=0, delta=Delta(provider_specific_fields=None, content='M prom', role=None, function_call=None, tool_calls=None, audio=None), logprobs=None)], provider_specific_fields=None, citations=None)
model_response finish reason 3: None; response_obj={'text': '', 'is_finished': False, 'finish_reason': '', 'usage': None, 'index': 0, 'tool_use': None}
model_response.choices[0].delta: Delta(provider_specific_fields=None, content=None, role=None, function_call=None, tool_calls=None, audio=None); completion_obj: {'content': ''}
self.sent_first_chunk: True
completion_obj: {'content': ''}, model_response.choices[0]: StreamingChoices(finish_reason=None, index=0, delta=Delta(provider_specific_fields=None, content=None, role=None, function_call=None, tool_calls=None, audio=None), logprobs=None), response_obj: {'text': '', 'is_finished': False, 'finish_reason': '', 'usage': None, 'index': 0, 'tool_use': None}
model_response finish reason 3: None; response_obj={'text': '', 'is_finished': False, 'finish_reason': '', 'usage': None, 'index': 0, 'tool_use': None}
model_response.choices[0].delta: Delta(provider_specific_fields=None, content=None, role=None, function_call=None, tool_calls=None, audio=None); completion_obj: {'content': ''}
self.sent_first_chunk: True
completion_obj: {'content': ''}, model_response.choices[0]: StreamingChoices(finish_reason=None, index=0, delta=Delta(provider_specific_fields=None, content=None, role=None, function_call=None, tool_calls=None, audio=None), logprobs=None), response_obj: {'text': '', 'is_finished': False, 'finish_reason': '', 'usage': None, 'index': 0, 'tool_use': None}

Raw OpenAI Chunk
ModelResponseStream(id='chatcmpl-1e246dec-1357-4ceb-948f-03d49e55b5f9', created=1762261911, model=None, object='chat.completion.chunk', system_fingerprint=None, choices=[StreamingChoices(finish_reason=None, index=0, delta=Delta(provider_specific_fields=None, content="pts\n3. **You've", role=None, function_call=None, tool_calls=None, audio=None), logprobs=None)], provider_specific_fields=None, usage=None)

model_response finish reason 3: None; response_obj={'text': "pts\n3. **You've", 'is_finished': False, 'finish_reason': None, 'logprobs': None, 'original_chunk': ModelResponseStream(id='chatcmpl-1e246dec-1357-4ceb-948f-03d49e55b5f9', created=1762261911, model=None, object='chat.completion.chunk', system_fingerprint=None, choices=[StreamingChoices(finish_reason=None, index=0, delta=Delta(provider_specific_fields=None, content="pts\n3. **You've", role=None, function_call=None, tool_calls=None, audio=None), logprobs=None)], provider_specific_fields=None, usage=None), 'usage': None}
original delta: {'provider_specific_fields': None, 'content': "pts\n3. **You've", 'role': None, 'function_call': None, 'tool_calls': None, 'audio': None}
new delta: Delta(provider_specific_fields=None, content="pts\n3. **You've", role=None, function_call=None, tool_calls=None, audio=None)
model_response.choices[0].delta: Delta(provider_specific_fields=None, content="pts\n3. **You've", role=None, function_call=None, tool_calls=None, audio=None); completion_obj: {'content': "pts\n3. **You've"}
self.sent_first_chunk: True
completion_obj: {'content': "pts\n3. **You've"}, model_response.choices[0]: StreamingChoices(finish_reason=None, index=0, delta=Delta(provider_specific_fields=None, content="pts\n3. **You've", role=None, function_call=None, tool_calls=None, audio=None), logprobs=None), response_obj: {'text': "pts\n3. **You've", 'is_finished': False, 'finish_reason': None, 'logprobs': None, 'original_chunk': ModelResponseStream(id='chatcmpl-1e246dec-1357-4ceb-948f-03d49e55b5f9', created=1762261911, model=None, object='chat.completion.chunk', system_fingerprint=None, choices=[StreamingChoices(finish_reason=None, index=0, delta=Delta(provider_specific_fields=None, content="pts\n3. **You've", role=None, function_call=None, tool_calls=None, audio=None), logprobs=None)], provider_specific_fields=None, usage=None), 'usage': None}
choice_json: {'index': 0, 'delta': {'provider_specific_fields': None, 'content': "pts\n3. **You've", 'role': None, 'function_call': None, 'tool_calls': None, 'audio': None}, 'logprobs': None}
choices in streaming: [StreamingChoices(finish_reason=None, index=0, delta=Delta(provider_specific_fields=None, content="pts\n3. **You've", role=None, function_call=None, tool_calls=None, audio=None), logprobs=None)]
final returned processed chunk: ModelResponseStream(id='chatcmpl-1e246dec-1357-4ceb-948f-03d49e55b5f9', created=1762261907, model='claude-sonnet-4-5-20250929', object='chat.completion.chunk', system_fingerprint=None, choices=[StreamingChoices(finish_reason=None, index=0, delta=Delta(provider_specific_fields=None, content="pts\n3. **You've", role=None, function_call=None, tool_calls=None, audio=None), logprobs=None)], provider_specific_fields=None, citations=None)
model_response finish reason 3: None; response_obj={'text': '', 'is_finished': False, 'finish_reason': '', 'usage': None, 'index': 0, 'tool_use': None}
model_response.choices[0].delta: Delta(provider_specific_fields=None, content=None, role=None, function_call=None, tool_calls=None, audio=None); completion_obj: {'content': ''}
self.sent_first_chunk: True
completion_obj: {'content': ''}, model_response.choices[0]: StreamingChoices(finish_reason=None, index=0, delta=Delta(provider_specific_fields=None, content=None, role=None, function_call=None, tool_calls=None, audio=None), logprobs=None), response_obj: {'text': '', 'is_finished': False, 'finish_reason': '', 'usage': None, 'index': 0, 'tool_use': None}
model_response finish reason 3: None; response_obj={'text': '', 'is_finished': False, 'finish_reason': '', 'usage': None, 'index': 0, 'tool_use': None}
model_response.choices[0].delta: Delta(provider_specific_fields=None, content=None, role=None, function_call=None, tool_calls=None, audio=None); completion_obj: {'content': ''}
self.sent_first_chunk: True
completion_obj: {'content': ''}, model_response.choices[0]: StreamingChoices(finish_reason=None, index=0, delta=Delta(provider_specific_fields=None, content=None, role=None, function_call=None, tool_calls=None, audio=None), logprobs=None), response_obj: {'text': '', 'is_finished': False, 'finish_reason': '', 'usage': None, 'index': 0, 'tool_use': None}

Raw OpenAI Chunk
ModelResponseStream(id='chatcmpl-1e246dec-1357-4ceb-948f-03d49e55b5f9', created=1762261911, model=None, object='chat.completion.chunk', system_fingerprint=None, choices=[StreamingChoices(finish_reason=None, index=0, delta=Delta(provider_specific_fields=None, content=' create', role=None, function_call=None, tool_calls=None, audio=None), logprobs=None)], provider_specific_fields=None, usage=None)

model_response finish reason 3: None; response_obj={'text': ' create', 'is_finished': False, 'finish_reason': None, 'logprobs': None, 'original_chunk': ModelResponseStream(id='chatcmpl-1e246dec-1357-4ceb-948f-03d49e55b5f9', created=1762261911, model=None, object='chat.completion.chunk', system_fingerprint=None, choices=[StreamingChoices(finish_reason=None, index=0, delta=Delta(provider_specific_fields=None, content=' create', role=None, function_call=None, tool_calls=None, audio=None), logprobs=None)], provider_specific_fields=None, usage=None), 'usage': None}
original delta: {'provider_specific_fields': None, 'content': ' create', 'role': None, 'function_call': None, 'tool_calls': None, 'audio': None}
new delta: Delta(provider_specific_fields=None, content=' create', role=None, function_call=None, tool_calls=None, audio=None)
model_response.choices[0].delta: Delta(provider_specific_fields=None, content=' create', role=None, function_call=None, tool_calls=None, audio=None); completion_obj: {'content': ' create'}
self.sent_first_chunk: True
completion_obj: {'content': ' create'}, model_response.choices[0]: StreamingChoices(finish_reason=None, index=0, delta=Delta(provider_specific_fields=None, content=' create', role=None, function_call=None, tool_calls=None, audio=None), logprobs=None), response_obj: {'text': ' create', 'is_finished': False, 'finish_reason': None, 'logprobs': None, 'original_chunk': ModelResponseStream(id='chatcmpl-1e246dec-1357-4ceb-948f-03d49e55b5f9', created=1762261911, model=None, object='chat.completion.chunk', system_fingerprint=None, choices=[StreamingChoices(finish_reason=None, index=0, delta=Delta(provider_specific_fields=None, content=' create', role=None, function_call=None, tool_calls=None, audio=None), logprobs=None)], provider_specific_fields=None, usage=None), 'usage': None}
choice_json: {'index': 0, 'delta': {'provider_specific_fields': None, 'content': ' create', 'role': None, 'function_call': None, 'tool_calls': None, 'audio': None}, 'logprobs': None}
choices in streaming: [StreamingChoices(finish_reason=None, index=0, delta=Delta(provider_specific_fields=None, content=' create', role=None, function_call=None, tool_calls=None, audio=None), logprobs=None)]
final returned processed chunk: ModelResponseStream(id='chatcmpl-1e246dec-1357-4ceb-948f-03d49e55b5f9', created=1762261907, model='claude-sonnet-4-5-20250929', object='chat.completion.chunk', system_fingerprint=None, choices=[StreamingChoices(finish_reason=None, index=0, delta=Delta(provider_specific_fields=None, content=' create', role=None, function_call=None, tool_calls=None, audio=None), logprobs=None)], provider_specific_fields=None, citations=None)
model_response finish reason 3: None; response_obj={'text': '', 'is_finished': False, 'finish_reason': '', 'usage': None, 'index': 0, 'tool_use': None}
model_response.choices[0].delta: Delta(provider_specific_fields=None, content=None, role=None, function_call=None, tool_calls=None, audio=None); completion_obj: {'content': ''}
self.sent_first_chunk: True
completion_obj: {'content': ''}, model_response.choices[0]: StreamingChoices(finish_reason=None, index=0, delta=Delta(provider_specific_fields=None, content=None, role=None, function_call=None, tool_calls=None, audio=None), logprobs=None), response_obj: {'text': '', 'is_finished': False, 'finish_reason': '', 'usage': None, 'index': 0, 'tool_use': None}
model_response finish reason 3: None; response_obj={'text': '', 'is_finished': False, 'finish_reason': '', 'usage': None, 'index': 0, 'tool_use': None}
model_response.choices[0].delta: Delta(provider_specific_fields=None, content=None, role=None, function_call=None, tool_calls=None, audio=None); completion_obj: {'content': ''}
self.sent_first_chunk: True
completion_obj: {'content': ''}, model_response.choices[0]: StreamingChoices(finish_reason=None, index=0, delta=Delta(provider_specific_fields=None, content=None, role=None, function_call=None, tool_calls=None, audio=None), logprobs=None), response_obj: {'text': '', 'is_finished': False, 'finish_reason': '', 'usage': None, 'index': 0, 'tool_use': None}

Raw OpenAI Chunk
ModelResponseStream(id='chatcmpl-1e246dec-1357-4ceb-948f-03d49e55b5f9', created=1762261911, model=None, object='chat.completion.chunk', system_fingerprint=None, choices=[StreamingChoices(finish_reason=None, index=0, delta=Delta(provider_specific_fields=None, content='d a `', role=None, function_call=None, tool_calls=None, audio=None), logprobs=None)], provider_specific_fields=None, usage=None)

model_response finish reason 3: None; response_obj={'text': 'd a `', 'is_finished': False, 'finish_reason': None, 'logprobs': None, 'original_chunk': ModelResponseStream(id='chatcmpl-1e246dec-1357-4ceb-948f-03d49e55b5f9', created=1762261911, model=None, object='chat.completion.chunk', system_fingerprint=None, choices=[StreamingChoices(finish_reason=None, index=0, delta=Delta(provider_specific_fields=None, content='d a `', role=None, function_call=None, tool_calls=None, audio=None), logprobs=None)], provider_specific_fields=None, usage=None), 'usage': None}
original delta: {'provider_specific_fields': None, 'content': 'd a `', 'role': None, 'function_call': None, 'tool_calls': None, 'audio': None}
new delta: Delta(provider_specific_fields=None, content='d a `', role=None, function_call=None, tool_calls=None, audio=None)
model_response.choices[0].delta: Delta(provider_specific_fields=None, content='d a `', role=None, function_call=None, tool_calls=None, audio=None); completion_obj: {'content': 'd a `'}
self.sent_first_chunk: True
completion_obj: {'content': 'd a `'}, model_response.choices[0]: StreamingChoices(finish_reason=None, index=0, delta=Delta(provider_specific_fields=None, content='d a `', role=None, function_call=None, tool_calls=None, audio=None), logprobs=None), response_obj: {'text': 'd a `', 'is_finished': False, 'finish_reason': None, 'logprobs': None, 'original_chunk': ModelResponseStream(id='chatcmpl-1e246dec-1357-4ceb-948f-03d49e55b5f9', created=1762261911, model=None, object='chat.completion.chunk', system_fingerprint=None, choices=[StreamingChoices(finish_reason=None, index=0, delta=Delta(provider_specific_fields=None, content='d a `', role=None, function_call=None, tool_calls=None, audio=None), logprobs=None)], provider_specific_fields=None, usage=None), 'usage': None}
choice_json: {'index': 0, 'delta': {'provider_specific_fields': None, 'content': 'd a `', 'role': None, 'function_call': None, 'tool_calls': None, 'audio': None}, 'logprobs': None}
choices in streaming: [StreamingChoices(finish_reason=None, index=0, delta=Delta(provider_specific_fields=None, content='d a `', role=None, function_call=None, tool_calls=None, audio=None), logprobs=None)]
final returned processed chunk: ModelResponseStream(id='chatcmpl-1e246dec-1357-4ceb-948f-03d49e55b5f9', created=1762261907, model='claude-sonnet-4-5-20250929', object='chat.completion.chunk', system_fingerprint=None, choices=[StreamingChoices(finish_reason=None, index=0, delta=Delta(provider_specific_fields=None, content='d a `', role=None, function_call=None, tool_calls=None, audio=None), logprobs=None)], provider_specific_fields=None, citations=None)
model_response finish reason 3: None; response_obj={'text': '', 'is_finished': False, 'finish_reason': '', 'usage': None, 'index': 0, 'tool_use': None}
model_response.choices[0].delta: Delta(provider_specific_fields=None, content=None, role=None, function_call=None, tool_calls=None, audio=None); completion_obj: {'content': ''}
self.sent_first_chunk: True
completion_obj: {'content': ''}, model_response.choices[0]: StreamingChoices(finish_reason=None, index=0, delta=Delta(provider_specific_fields=None, content=None, role=None, function_call=None, tool_calls=None, audio=None), logprobs=None), response_obj: {'text': '', 'is_finished': False, 'finish_reason': '', 'usage': None, 'index': 0, 'tool_use': None}
model_response finish reason 3: None; response_obj={'text': '', 'is_finished': False, 'finish_reason': '', 'usage': None, 'index': 0, 'tool_use': None}
model_response.choices[0].delta: Delta(provider_specific_fields=None, content=None, role=None, function_call=None, tool_calls=None, audio=None); completion_obj: {'content': ''}
self.sent_first_chunk: True
completion_obj: {'content': ''}, model_response.choices[0]: StreamingChoices(finish_reason=None, index=0, delta=Delta(provider_specific_fields=None, content=None, role=None, function_call=None, tool_calls=None, audio=None), logprobs=None), response_obj: {'text': '', 'is_finished': False, 'finish_reason': '', 'usage': None, 'index': 0, 'tool_use': None}

Raw OpenAI Chunk
ModelResponseStream(id='chatcmpl-1e246dec-1357-4ceb-948f-03d49e55b5f9', created=1762261911, model=None, object='chat.completion.chunk', system_fingerprint=None, choices=[StreamingChoices(finish_reason=None, index=0, delta=Delta(provider_specific_fields=None, content='ContextRetriever` class**', role=None, function_call=None, tool_calls=None, audio=None), logprobs=None)], provider_specific_fields=None, usage=None)

model_response finish reason 3: None; response_obj={'text': 'ContextRetriever` class**', 'is_finished': False, 'finish_reason': None, 'logprobs': None, 'original_chunk': ModelResponseStream(id='chatcmpl-1e246dec-1357-4ceb-948f-03d49e55b5f9', created=1762261911, model=None, object='chat.completion.chunk', system_fingerprint=None, choices=[StreamingChoices(finish_reason=None, index=0, delta=Delta(provider_specific_fields=None, content='ContextRetriever` class**', role=None, function_call=None, tool_calls=None, audio=None), logprobs=None)], provider_specific_fields=None, usage=None), 'usage': None}
original delta: {'provider_specific_fields': None, 'content': 'ContextRetriever` class**', 'role': None, 'function_call': None, 'tool_calls': None, 'audio': None}
new delta: Delta(provider_specific_fields=None, content='ContextRetriever` class**', role=None, function_call=None, tool_calls=None, audio=None)
model_response.choices[0].delta: Delta(provider_specific_fields=None, content='ContextRetriever` class**', role=None, function_call=None, tool_calls=None, audio=None); completion_obj: {'content': 'ContextRetriever` class**'}
self.sent_first_chunk: True
completion_obj: {'content': 'ContextRetriever` class**'}, model_response.choices[0]: StreamingChoices(finish_reason=None, index=0, delta=Delta(provider_specific_fields=None, content='ContextRetriever` class**', role=None, function_call=None, tool_calls=None, audio=None), logprobs=None), response_obj: {'text': 'ContextRetriever` class**', 'is_finished': False, 'finish_reason': None, 'logprobs': None, 'original_chunk': ModelResponseStream(id='chatcmpl-1e246dec-1357-4ceb-948f-03d49e55b5f9', created=1762261911, model=None, object='chat.completion.chunk', system_fingerprint=None, choices=[StreamingChoices(finish_reason=None, index=0, delta=Delta(provider_specific_fields=None, content='ContextRetriever` class**', role=None, function_call=None, tool_calls=None, audio=None), logprobs=None)], provider_specific_fields=None, usage=None), 'usage': None}
choice_json: {'index': 0, 'delta': {'provider_specific_fields': None, 'content': 'ContextRetriever` class**', 'role': None, 'function_call': None, 'tool_calls': None, 'audio': None}, 'logprobs': None}
choices in streaming: [StreamingChoices(finish_reason=None, index=0, delta=Delta(provider_specific_fields=None, content='ContextRetriever` class**', role=None, function_call=None, tool_calls=None, audio=None), logprobs=None)]
final returned processed chunk: ModelResponseStream(id='chatcmpl-1e246dec-1357-4ceb-948f-03d49e55b5f9', created=1762261907, model='claude-sonnet-4-5-20250929', object='chat.completion.chunk', system_fingerprint=None, choices=[StreamingChoices(finish_reason=None, index=0, delta=Delta(provider_specific_fields=None, content='ContextRetriever` class**', role=None, function_call=None, tool_calls=None, audio=None), logprobs=None)], provider_specific_fields=None, citations=None)
model_response finish reason 3: None; response_obj={'text': '', 'is_finished': False, 'finish_reason': '', 'usage': None, 'index': 0, 'tool_use': None}
model_response.choices[0].delta: Delta(provider_specific_fields=None, content=None, role=None, function_call=None, tool_calls=None, audio=None); completion_obj: {'content': ''}
self.sent_first_chunk: True
completion_obj: {'content': ''}, model_response.choices[0]: StreamingChoices(finish_reason=None, index=0, delta=Delta(provider_specific_fields=None, content=None, role=None, function_call=None, tool_calls=None, audio=None), logprobs=None), response_obj: {'text': '', 'is_finished': False, 'finish_reason': '', 'usage': None, 'index': 0, 'tool_use': None}
model_response finish reason 3: None; response_obj={'text': '', 'is_finished': False, 'finish_reason': '', 'usage': None, 'index': 0, 'tool_use': None}
model_response.choices[0].delta: Delta(provider_specific_fields=None, content=None, role=None, function_call=None, tool_calls=None, audio=None); completion_obj: {'content': ''}
self.sent_first_chunk: True
completion_obj: {'content': ''}, model_response.choices[0]: StreamingChoices(finish_reason=None, index=0, delta=Delta(provider_specific_fields=None, content=None, role=None, function_call=None, tool_calls=None, audio=None), logprobs=None), response_obj: {'text': '', 'is_finished': False, 'finish_reason': '', 'usage': None, 'index': 0, 'tool_use': None}

Raw OpenAI Chunk
ModelResponseStream(id='chatcmpl-1e246dec-1357-4ceb-948f-03d49e55b5f9', created=1762261911, model=None, object='chat.completion.chunk', system_fingerprint=None, choices=[StreamingChoices(finish_reason=None, index=0, delta=Delta(provider_specific_fields=None, content=' (`', role=None, function_call=None, tool_calls=None, audio=None), logprobs=None)], provider_specific_fields=None, usage=None)

model_response finish reason 3: None; response_obj={'text': ' (`', 'is_finished': False, 'finish_reason': None, 'logprobs': None, 'original_chunk': ModelResponseStream(id='chatcmpl-1e246dec-1357-4ceb-948f-03d49e55b5f9', created=1762261911, model=None, object='chat.completion.chunk', system_fingerprint=None, choices=[StreamingChoices(finish_reason=None, index=0, delta=Delta(provider_specific_fields=None, content=' (`', role=None, function_call=None, tool_calls=None, audio=None), logprobs=None)], provider_specific_fields=None, usage=None), 'usage': None}
original delta: {'provider_specific_fields': None, 'content': ' (`', 'role': None, 'function_call': None, 'tool_calls': None, 'audio': None}
new delta: Delta(provider_specific_fields=None, content=' (`', role=None, function_call=None, tool_calls=None, audio=None)
model_response.choices[0].delta: Delta(provider_specific_fields=None, content=' (`', role=None, function_call=None, tool_calls=None, audio=None); completion_obj: {'content': ' (`'}
self.sent_first_chunk: True
completion_obj: {'content': ' (`'}, model_response.choices[0]: StreamingChoices(finish_reason=None, index=0, delta=Delta(provider_specific_fields=None, content=' (`', role=None, function_call=None, tool_calls=None, audio=None), logprobs=None), response_obj: {'text': ' (`', 'is_finished': False, 'finish_reason': None, 'logprobs': None, 'original_chunk': ModelResponseStream(id='chatcmpl-1e246dec-1357-4ceb-948f-03d49e55b5f9', created=1762261911, model=None, object='chat.completion.chunk', system_fingerprint=None, choices=[StreamingChoices(finish_reason=None, index=0, delta=Delta(provider_specific_fields=None, content=' (`', role=None, function_call=None, tool_calls=None, audio=None), logprobs=None)], provider_specific_fields=None, usage=None), 'usage': None}
choice_json: {'index': 0, 'delta': {'provider_specific_fields': None, 'content': ' (`', 'role': None, 'function_call': None, 'tool_calls': None, 'audio': None}, 'logprobs': None}
choices in streaming: [StreamingChoices(finish_reason=None, index=0, delta=Delta(provider_specific_fields=None, content=' (`', role=None, function_call=None, tool_calls=None, audio=None), logprobs=None)]
final returned processed chunk: ModelResponseStream(id='chatcmpl-1e246dec-1357-4ceb-948f-03d49e55b5f9', created=1762261907, model='claude-sonnet-4-5-20250929', object='chat.completion.chunk', system_fingerprint=None, choices=[StreamingChoices(finish_reason=None, index=0, delta=Delta(provider_specific_fields=None, content=' (`', role=None, function_call=None, tool_calls=None, audio=None), logprobs=None)], provider_specific_fields=None, citations=None)
model_response finish reason 3: None; response_obj={'text': '', 'is_finished': False, 'finish_reason': '', 'usage': None, 'index': 0, 'tool_use': None}
model_response.choices[0].delta: Delta(provider_specific_fields=None, content=None, role=None, function_call=None, tool_calls=None, audio=None); completion_obj: {'content': ''}
self.sent_first_chunk: True
completion_obj: {'content': ''}, model_response.choices[0]: StreamingChoices(finish_reason=None, index=0, delta=Delta(provider_specific_fields=None, content=None, role=None, function_call=None, tool_calls=None, audio=None), logprobs=None), response_obj: {'text': '', 'is_finished': False, 'finish_reason': '', 'usage': None, 'index': 0, 'tool_use': None}
model_response finish reason 3: None; response_obj={'text': '', 'is_finished': False, 'finish_reason': '', 'usage': None, 'index': 0, 'tool_use': None}
model_response.choices[0].delta: Delta(provider_specific_fields=None, content=None, role=None, function_call=None, tool_calls=None, audio=None); completion_obj: {'content': ''}
self.sent_first_chunk: True
completion_obj: {'content': ''}, model_response.choices[0]: StreamingChoices(finish_reason=None, index=0, delta=Delta(provider_specific_fields=None, content=None, role=None, function_call=None, tool_calls=None, audio=None), logprobs=None), response_obj: {'text': '', 'is_finished': False, 'finish_reason': '', 'usage': None, 'index': 0, 'tool_use': None}

Raw OpenAI Chunk
ModelResponseStream(id='chatcmpl-1e246dec-1357-4ceb-948f-03d49e55b5f9', created=1762261911, model=None, object='chat.completion.chunk', system_fingerprint=None, choices=[StreamingChoices(finish_reason=None, index=0, delta=Delta(provider_specific_fields=None, content='src', role=None, function_call=None, tool_calls=None, audio=None), logprobs=None)], provider_specific_fields=None, usage=None)

model_response finish reason 3: None; response_obj={'text': 'src', 'is_finished': False, 'finish_reason': None, 'logprobs': None, 'original_chunk': ModelResponseStream(id='chatcmpl-1e246dec-1357-4ceb-948f-03d49e55b5f9', created=1762261911, model=None, object='chat.completion.chunk', system_fingerprint=None, choices=[StreamingChoices(finish_reason=None, index=0, delta=Delta(provider_specific_fields=None, content='src', role=None, function_call=None, tool_calls=None, audio=None), logprobs=None)], provider_specific_fields=None, usage=None), 'usage': None}
original delta: {'provider_specific_fields': None, 'content': 'src', 'role': None, 'function_call': None, 'tool_calls': None, 'audio': None}
new delta: Delta(provider_specific_fields=None, content='src', role=None, function_call=None, tool_calls=None, audio=None)
model_response.choices[0].delta: Delta(provider_specific_fields=None, content='src', role=None, function_call=None, tool_calls=None, audio=None); completion_obj: {'content': 'src'}
self.sent_first_chunk: True
completion_obj: {'content': 'src'}, model_response.choices[0]: StreamingChoices(finish_reason=None, index=0, delta=Delta(provider_specific_fields=None, content='src', role=None, function_call=None, tool_calls=None, audio=None), logprobs=None), response_obj: {'text': 'src', 'is_finished': False, 'finish_reason': None, 'logprobs': None, 'original_chunk': ModelResponseStream(id='chatcmpl-1e246dec-1357-4ceb-948f-03d49e55b5f9', created=1762261911, model=None, object='chat.completion.chunk', system_fingerprint=None, choices=[StreamingChoices(finish_reason=None, index=0, delta=Delta(provider_specific_fields=None, content='src', role=None, function_call=None, tool_calls=None, audio=None), logprobs=None)], provider_specific_fields=None, usage=None), 'usage': None}
choice_json: {'index': 0, 'delta': {'provider_specific_fields': None, 'content': 'src', 'role': None, 'function_call': None, 'tool_calls': None, 'audio': None}, 'logprobs': None}
choices in streaming: [StreamingChoices(finish_reason=None, index=0, delta=Delta(provider_specific_fields=None, content='src', role=None, function_call=None, tool_calls=None, audio=None), logprobs=None)]
final returned processed chunk: ModelResponseStream(id='chatcmpl-1e246dec-1357-4ceb-948f-03d49e55b5f9', created=1762261907, model='claude-sonnet-4-5-20250929', object='chat.completion.chunk', system_fingerprint=None, choices=[StreamingChoices(finish_reason=None, index=0, delta=Delta(provider_specific_fields=None, content='src', role=None, function_call=None, tool_calls=None, audio=None), logprobs=None)], provider_specific_fields=None, citations=None)
model_response finish reason 3: None; response_obj={'text': '', 'is_finished': False, 'finish_reason': '', 'usage': None, 'index': 0, 'tool_use': None}
model_response.choices[0].delta: Delta(provider_specific_fields=None, content=None, role=None, function_call=None, tool_calls=None, audio=None); completion_obj: {'content': ''}
self.sent_first_chunk: True
completion_obj: {'content': ''}, model_response.choices[0]: StreamingChoices(finish_reason=None, index=0, delta=Delta(provider_specific_fields=None, content=None, role=None, function_call=None, tool_calls=None, audio=None), logprobs=None), response_obj: {'text': '', 'is_finished': False, 'finish_reason': '', 'usage': None, 'index': 0, 'tool_use': None}
model_response finish reason 3: None; response_obj={'text': '', 'is_finished': False, 'finish_reason': '', 'usage': None, 'index': 0, 'tool_use': None}
model_response.choices[0].delta: Delta(provider_specific_fields=None, content=None, role=None, function_call=None, tool_calls=None, audio=None); completion_obj: {'content': ''}
self.sent_first_chunk: True
completion_obj: {'content': ''}, model_response.choices[0]: StreamingChoices(finish_reason=None, index=0, delta=Delta(provider_specific_fields=None, content=None, role=None, function_call=None, tool_calls=None, audio=None), logprobs=None), response_obj: {'text': '', 'is_finished': False, 'finish_reason': '', 'usage': None, 'index': 0, 'tool_use': None}

Raw OpenAI Chunk
ModelResponseStream(id='chatcmpl-1e246dec-1357-4ceb-948f-03d49e55b5f9', created=1762261911, model=None, object='chat.completion.chunk', system_fingerprint=None, choices=[StreamingChoices(finish_reason=None, index=0, delta=Delta(provider_specific_fields=None, content='/proxy', role=None, function_call=None, tool_calls=None, audio=None), logprobs=None)], provider_specific_fields=None, usage=None)

model_response finish reason 3: None; response_obj={'text': '/proxy', 'is_finished': False, 'finish_reason': None, 'logprobs': None, 'original_chunk': ModelResponseStream(id='chatcmpl-1e246dec-1357-4ceb-948f-03d49e55b5f9', created=1762261911, model=None, object='chat.completion.chunk', system_fingerprint=None, choices=[StreamingChoices(finish_reason=None, index=0, delta=Delta(provider_specific_fields=None, content='/proxy', role=None, function_call=None, tool_calls=None, audio=None), logprobs=None)], provider_specific_fields=None, usage=None), 'usage': None}
original delta: {'provider_specific_fields': None, 'content': '/proxy', 'role': None, 'function_call': None, 'tool_calls': None, 'audio': None}
new delta: Delta(provider_specific_fields=None, content='/proxy', role=None, function_call=None, tool_calls=None, audio=None)
model_response.choices[0].delta: Delta(provider_specific_fields=None, content='/proxy', role=None, function_call=None, tool_calls=None, audio=None); completion_obj: {'content': '/proxy'}
self.sent_first_chunk: True
completion_obj: {'content': '/proxy'}, model_response.choices[0]: StreamingChoices(finish_reason=None, index=0, delta=Delta(provider_specific_fields=None, content='/proxy', role=None, function_call=None, tool_calls=None, audio=None), logprobs=None), response_obj: {'text': '/proxy', 'is_finished': False, 'finish_reason': None, 'logprobs': None, 'original_chunk': ModelResponseStream(id='chatcmpl-1e246dec-1357-4ceb-948f-03d49e55b5f9', created=1762261911, model=None, object='chat.completion.chunk', system_fingerprint=None, choices=[StreamingChoices(finish_reason=None, index=0, delta=Delta(provider_specific_fields=None, content='/proxy', role=None, function_call=None, tool_calls=None, audio=None), logprobs=None)], provider_specific_fields=None, usage=None), 'usage': None}
choice_json: {'index': 0, 'delta': {'provider_specific_fields': None, 'content': '/proxy', 'role': None, 'function_call': None, 'tool_calls': None, 'audio': None}, 'logprobs': None}
choices in streaming: [StreamingChoices(finish_reason=None, index=0, delta=Delta(provider_specific_fields=None, content='/proxy', role=None, function_call=None, tool_calls=None, audio=None), logprobs=None)]
final returned processed chunk: ModelResponseStream(id='chatcmpl-1e246dec-1357-4ceb-948f-03d49e55b5f9', created=1762261907, model='claude-sonnet-4-5-20250929', object='chat.completion.chunk', system_fingerprint=None, choices=[StreamingChoices(finish_reason=None, index=0, delta=Delta(provider_specific_fields=None, content='/proxy', role=None, function_call=None, tool_calls=None, audio=None), logprobs=None)], provider_specific_fields=None, citations=None)
model_response finish reason 3: None; response_obj={'text': '', 'is_finished': False, 'finish_reason': '', 'usage': None, 'index': 0, 'tool_use': None}
model_response.choices[0].delta: Delta(provider_specific_fields=None, content=None, role=None, function_call=None, tool_calls=None, audio=None); completion_obj: {'content': ''}
self.sent_first_chunk: True
completion_obj: {'content': ''}, model_response.choices[0]: StreamingChoices(finish_reason=None, index=0, delta=Delta(provider_specific_fields=None, content=None, role=None, function_call=None, tool_calls=None, audio=None), logprobs=None), response_obj: {'text': '', 'is_finished': False, 'finish_reason': '', 'usage': None, 'index': 0, 'tool_use': None}
model_response finish reason 3: None; response_obj={'text': '', 'is_finished': False, 'finish_reason': '', 'usage': None, 'index': 0, 'tool_use': None}
model_response.choices[0].delta: Delta(provider_specific_fields=None, content=None, role=None, function_call=None, tool_calls=None, audio=None); completion_obj: {'content': ''}
self.sent_first_chunk: True
completion_obj: {'content': ''}, model_response.choices[0]: StreamingChoices(finish_reason=None, index=0, delta=Delta(provider_specific_fields=None, content=None, role=None, function_call=None, tool_calls=None, audio=None), logprobs=None), response_obj: {'text': '', 'is_finished': False, 'finish_reason': '', 'usage': None, 'index': 0, 'tool_use': None}

Raw OpenAI Chunk
ModelResponseStream(id='chatcmpl-1e246dec-1357-4ceb-948f-03d49e55b5f9', created=1762261911, model=None, object='chat.completion.chunk', system_fingerprint=None, choices=[StreamingChoices(finish_reason=None, index=0, delta=Delta(provider_specific_fields=None, content='/context_retriever.py`)', role=None, function_call=None, tool_calls=None, audio=None), logprobs=None)], provider_specific_fields=None, usage=None)

model_response finish reason 3: None; response_obj={'text': '/context_retriever.py`)', 'is_finished': False, 'finish_reason': None, 'logprobs': None, 'original_chunk': ModelResponseStream(id='chatcmpl-1e246dec-1357-4ceb-948f-03d49e55b5f9', created=1762261911, model=None, object='chat.completion.chunk', system_fingerprint=None, choices=[StreamingChoices(finish_reason=None, index=0, delta=Delta(provider_specific_fields=None, content='/context_retriever.py`)', role=None, function_call=None, tool_calls=None, audio=None), logprobs=None)], provider_specific_fields=None, usage=None), 'usage': None}
original delta: {'provider_specific_fields': None, 'content': '/context_retriever.py`)', 'role': None, 'function_call': None, 'tool_calls': None, 'audio': None}
new delta: Delta(provider_specific_fields=None, content='/context_retriever.py`)', role=None, function_call=None, tool_calls=None, audio=None)
model_response.choices[0].delta: Delta(provider_specific_fields=None, content='/context_retriever.py`)', role=None, function_call=None, tool_calls=None, audio=None); completion_obj: {'content': '/context_retriever.py`)'}
self.sent_first_chunk: True
completion_obj: {'content': '/context_retriever.py`)'}, model_response.choices[0]: StreamingChoices(finish_reason=None, index=0, delta=Delta(provider_specific_fields=None, content='/context_retriever.py`)', role=None, function_call=None, tool_calls=None, audio=None), logprobs=None), response_obj: {'text': '/context_retriever.py`)', 'is_finished': False, 'finish_reason': None, 'logprobs': None, 'original_chunk': ModelResponseStream(id='chatcmpl-1e246dec-1357-4ceb-948f-03d49e55b5f9', created=1762261911, model=None, object='chat.completion.chunk', system_fingerprint=None, choices=[StreamingChoices(finish_reason=None, index=0, delta=Delta(provider_specific_fields=None, content='/context_retriever.py`)', role=None, function_call=None, tool_calls=None, audio=None), logprobs=None)], provider_specific_fields=None, usage=None), 'usage': None}
choice_json: {'index': 0, 'delta': {'provider_specific_fields': None, 'content': '/context_retriever.py`)', 'role': None, 'function_call': None, 'tool_calls': None, 'audio': None}, 'logprobs': None}
choices in streaming: [StreamingChoices(finish_reason=None, index=0, delta=Delta(provider_specific_fields=None, content='/context_retriever.py`)', role=None, function_call=None, tool_calls=None, audio=None), logprobs=None)]
final returned processed chunk: ModelResponseStream(id='chatcmpl-1e246dec-1357-4ceb-948f-03d49e55b5f9', created=1762261907, model='claude-sonnet-4-5-20250929', object='chat.completion.chunk', system_fingerprint=None, choices=[StreamingChoices(finish_reason=None, index=0, delta=Delta(provider_specific_fields=None, content='/context_retriever.py`)', role=None, function_call=None, tool_calls=None, audio=None), logprobs=None)], provider_specific_fields=None, citations=None)
model_response finish reason 3: None; response_obj={'text': '', 'is_finished': False, 'finish_reason': '', 'usage': None, 'index': 0, 'tool_use': None}
model_response.choices[0].delta: Delta(provider_specific_fields=None, content=None, role=None, function_call=None, tool_calls=None, audio=None); completion_obj: {'content': ''}
self.sent_first_chunk: True
completion_obj: {'content': ''}, model_response.choices[0]: StreamingChoices(finish_reason=None, index=0, delta=Delta(provider_specific_fields=None, content=None, role=None, function_call=None, tool_calls=None, audio=None), logprobs=None), response_obj: {'text': '', 'is_finished': False, 'finish_reason': '', 'usage': None, 'index': 0, 'tool_use': None}
model_response finish reason 3: None; response_obj={'text': '', 'is_finished': False, 'finish_reason': '', 'usage': None, 'index': 0, 'tool_use': None}
model_response.choices[0].delta: Delta(provider_specific_fields=None, content=None, role=None, function_call=None, tool_calls=None, audio=None); completion_obj: {'content': ''}
self.sent_first_chunk: True
completion_obj: {'content': ''}, model_response.choices[0]: StreamingChoices(finish_reason=None, index=0, delta=Delta(provider_specific_fields=None, content=None, role=None, function_call=None, tool_calls=None, audio=None), logprobs=None), response_obj: {'text': '', 'is_finished': False, 'finish_reason': '', 'usage': None, 'index': 0, 'tool_use': None}

Raw OpenAI Chunk
ModelResponseStream(id='chatcmpl-1e246dec-1357-4ceb-948f-03d49e55b5f9', created=1762261911, model=None, object='chat.completion.chunk', system_fingerprint=None, choices=[StreamingChoices(finish_reason=None, index=0, delta=Delta(provider_specific_fields=None, content=' that:\n   - Queries', role=None, function_call=None, tool_calls=None, audio=None), logprobs=None)], provider_specific_fields=None, usage=None)

model_response finish reason 3: None; response_obj={'text': ' that:\n   - Queries', 'is_finished': False, 'finish_reason': None, 'logprobs': None, 'original_chunk': ModelResponseStream(id='chatcmpl-1e246dec-1357-4ceb-948f-03d49e55b5f9', created=1762261911, model=None, object='chat.completion.chunk', system_fingerprint=None, choices=[StreamingChoices(finish_reason=None, index=0, delta=Delta(provider_specific_fields=None, content=' that:\n   - Queries', role=None, function_call=None, tool_calls=None, audio=None), logprobs=None)], provider_specific_fields=None, usage=None), 'usage': None}
original delta: {'provider_specific_fields': None, 'content': ' that:\n   - Queries', 'role': None, 'function_call': None, 'tool_calls': None, 'audio': None}
new delta: Delta(provider_specific_fields=None, content=' that:\n   - Queries', role=None, function_call=None, tool_calls=None, audio=None)
model_response.choices[0].delta: Delta(provider_specific_fields=None, content=' that:\n   - Queries', role=None, function_call=None, tool_calls=None, audio=None); completion_obj: {'content': ' that:\n   - Queries'}
self.sent_first_chunk: True
completion_obj: {'content': ' that:\n   - Queries'}, model_response.choices[0]: StreamingChoices(finish_reason=None, index=0, delta=Delta(provider_specific_fields=None, content=' that:\n   - Queries', role=None, function_call=None, tool_calls=None, audio=None), logprobs=None), response_obj: {'text': ' that:\n   - Queries', 'is_finished': False, 'finish_reason': None, 'logprobs': None, 'original_chunk': ModelResponseStream(id='chatcmpl-1e246dec-1357-4ceb-948f-03d49e55b5f9', created=1762261911, model=None, object='chat.completion.chunk', system_fingerprint=None, choices=[StreamingChoices(finish_reason=None, index=0, delta=Delta(provider_specific_fields=None, content=' that:\n   - Queries', role=None, function_call=None, tool_calls=None, audio=None), logprobs=None)], provider_specific_fields=None, usage=None), 'usage': None}
choice_json: {'index': 0, 'delta': {'provider_specific_fields': None, 'content': ' that:\n   - Queries', 'role': None, 'function_call': None, 'tool_calls': None, 'audio': None}, 'logprobs': None}
choices in streaming: [StreamingChoices(finish_reason=None, index=0, delta=Delta(provider_specific_fields=None, content=' that:\n   - Queries', role=None, function_call=None, tool_calls=None, audio=None), logprobs=None)]
final returned processed chunk: ModelResponseStream(id='chatcmpl-1e246dec-1357-4ceb-948f-03d49e55b5f9', created=1762261907, model='claude-sonnet-4-5-20250929', object='chat.completion.chunk', system_fingerprint=None, choices=[StreamingChoices(finish_reason=None, index=0, delta=Delta(provider_specific_fields=None, content=' that:\n   - Queries', role=None, function_call=None, tool_calls=None, audio=None), logprobs=None)], provider_specific_fields=None, citations=None)
model_response finish reason 3: None; response_obj={'text': '', 'is_finished': False, 'finish_reason': '', 'usage': None, 'index': 0, 'tool_use': None}
model_response.choices[0].delta: Delta(provider_specific_fields=None, content=None, role=None, function_call=None, tool_calls=None, audio=None); completion_obj: {'content': ''}
self.sent_first_chunk: True
completion_obj: {'content': ''}, model_response.choices[0]: StreamingChoices(finish_reason=None, index=0, delta=Delta(provider_specific_fields=None, content=None, role=None, function_call=None, tool_calls=None, audio=None), logprobs=None), response_obj: {'text': '', 'is_finished': False, 'finish_reason': '', 'usage': None, 'index': 0, 'tool_use': None}
model_response finish reason 3: None; response_obj={'text': '', 'is_finished': False, 'finish_reason': '', 'usage': None, 'index': 0, 'tool_use': None}
model_response.choices[0].delta: Delta(provider_specific_fields=None, content=None, role=None, function_call=None, tool_calls=None, audio=None); completion_obj: {'content': ''}
self.sent_first_chunk: True
completion_obj: {'content': ''}, model_response.choices[0]: StreamingChoices(finish_reason=None, index=0, delta=Delta(provider_specific_fields=None, content=None, role=None, function_call=None, tool_calls=None, audio=None), logprobs=None), response_obj: {'text': '', 'is_finished': False, 'finish_reason': '', 'usage': None, 'index': 0, 'tool_use': None}

Raw OpenAI Chunk
ModelResponseStream(id='chatcmpl-1e246dec-1357-4ceb-948f-03d49e55b5f9', created=1762261911, model=None, object='chat.completion.chunk', system_fingerprint=None, choices=[StreamingChoices(finish_reason=None, index=0, delta=Delta(provider_specific_fields=None, content=" Supermemory's", role=None, function_call=None, tool_calls=None, audio=None), logprobs=None)], provider_specific_fields=None, usage=None)

model_response finish reason 3: None; response_obj={'text': " Supermemory's", 'is_finished': False, 'finish_reason': None, 'logprobs': None, 'original_chunk': ModelResponseStream(id='chatcmpl-1e246dec-1357-4ceb-948f-03d49e55b5f9', created=1762261911, model=None, object='chat.completion.chunk', system_fingerprint=None, choices=[StreamingChoices(finish_reason=None, index=0, delta=Delta(provider_specific_fields=None, content=" Supermemory's", role=None, function_call=None, tool_calls=None, audio=None), logprobs=None)], provider_specific_fields=None, usage=None), 'usage': None}
original delta: {'provider_specific_fields': None, 'content': " Supermemory's", 'role': None, 'function_call': None, 'tool_calls': None, 'audio': None}
new delta: Delta(provider_specific_fields=None, content=" Supermemory's", role=None, function_call=None, tool_calls=None, audio=None)
model_response.choices[0].delta: Delta(provider_specific_fields=None, content=" Supermemory's", role=None, function_call=None, tool_calls=None, audio=None); completion_obj: {'content': " Supermemory's"}
self.sent_first_chunk: True
completion_obj: {'content': " Supermemory's"}, model_response.choices[0]: StreamingChoices(finish_reason=None, index=0, delta=Delta(provider_specific_fields=None, content=" Supermemory's", role=None, function_call=None, tool_calls=None, audio=None), logprobs=None), response_obj: {'text': " Supermemory's", 'is_finished': False, 'finish_reason': None, 'logprobs': None, 'original_chunk': ModelResponseStream(id='chatcmpl-1e246dec-1357-4ceb-948f-03d49e55b5f9', created=1762261911, model=None, object='chat.completion.chunk', system_fingerprint=None, choices=[StreamingChoices(finish_reason=None, index=0, delta=Delta(provider_specific_fields=None, content=" Supermemory's", role=None, function_call=None, tool_calls=None, audio=None), logprobs=None)], provider_specific_fields=None, usage=None), 'usage': None}
choice_json: {'index': 0, 'delta': {'provider_specific_fields': None, 'content': " Supermemory's", 'role': None, 'function_call': None, 'tool_calls': None, 'audio': None}, 'logprobs': None}
choices in streaming: [StreamingChoices(finish_reason=None, index=0, delta=Delta(provider_specific_fields=None, content=" Supermemory's", role=None, function_call=None, tool_calls=None, audio=None), logprobs=None)]
final returned processed chunk: ModelResponseStream(id='chatcmpl-1e246dec-1357-4ceb-948f-03d49e55b5f9', created=1762261907, model='claude-sonnet-4-5-20250929', object='chat.completion.chunk', system_fingerprint=None, choices=[StreamingChoices(finish_reason=None, index=0, delta=Delta(provider_specific_fields=None, content=" Supermemory's", role=None, function_call=None, tool_calls=None, audio=None), logprobs=None)], provider_specific_fields=None, citations=None)
model_response finish reason 3: None; response_obj={'text': '', 'is_finished': False, 'finish_reason': '', 'usage': None, 'index': 0, 'tool_use': None}
model_response.choices[0].delta: Delta(provider_specific_fields=None, content=None, role=None, function_call=None, tool_calls=None, audio=None); completion_obj: {'content': ''}
self.sent_first_chunk: True
completion_obj: {'content': ''}, model_response.choices[0]: StreamingChoices(finish_reason=None, index=0, delta=Delta(provider_specific_fields=None, content=None, role=None, function_call=None, tool_calls=None, audio=None), logprobs=None), response_obj: {'text': '', 'is_finished': False, 'finish_reason': '', 'usage': None, 'index': 0, 'tool_use': None}
model_response finish reason 3: None; response_obj={'text': '', 'is_finished': False, 'finish_reason': '', 'usage': None, 'index': 0, 'tool_use': None}
model_response.choices[0].delta: Delta(provider_specific_fields=None, content=None, role=None, function_call=None, tool_calls=None, audio=None); completion_obj: {'content': ''}
self.sent_first_chunk: True
completion_obj: {'content': ''}, model_response.choices[0]: StreamingChoices(finish_reason=None, index=0, delta=Delta(provider_specific_fields=None, content=None, role=None, function_call=None, tool_calls=None, audio=None), logprobs=None), response_obj: {'text': '', 'is_finished': False, 'finish_reason': '', 'usage': None, 'index': 0, 'tool_use': None}

Raw OpenAI Chunk
ModelResponseStream(id='chatcmpl-1e246dec-1357-4ceb-948f-03d49e55b5f9', created=1762261911, model=None, object='chat.completion.chunk', system_fingerprint=None, choices=[StreamingChoices(finish_reason=None, index=0, delta=Delta(provider_specific_fields=None, content=' `/v4/profile` endpoint', role=None, function_call=None, tool_calls=None, audio=None), logprobs=None)], provider_specific_fields=None, usage=None)

model_response finish reason 3: None; response_obj={'text': ' `/v4/profile` endpoint', 'is_finished': False, 'finish_reason': None, 'logprobs': None, 'original_chunk': ModelResponseStream(id='chatcmpl-1e246dec-1357-4ceb-948f-03d49e55b5f9', created=1762261911, model=None, object='chat.completion.chunk', system_fingerprint=None, choices=[StreamingChoices(finish_reason=None, index=0, delta=Delta(provider_specific_fields=None, content=' `/v4/profile` endpoint', role=None, function_call=None, tool_calls=None, audio=None), logprobs=None)], provider_specific_fields=None, usage=None), 'usage': None}
original delta: {'provider_specific_fields': None, 'content': ' `/v4/profile` endpoint', 'role': None, 'function_call': None, 'tool_calls': None, 'audio': None}
new delta: Delta(provider_specific_fields=None, content=' `/v4/profile` endpoint', role=None, function_call=None, tool_calls=None, audio=None)
model_response.choices[0].delta: Delta(provider_specific_fields=None, content=' `/v4/profile` endpoint', role=None, function_call=None, tool_calls=None, audio=None); completion_obj: {'content': ' `/v4/profile` endpoint'}
self.sent_first_chunk: True
completion_obj: {'content': ' `/v4/profile` endpoint'}, model_response.choices[0]: StreamingChoices(finish_reason=None, index=0, delta=Delta(provider_specific_fields=None, content=' `/v4/profile` endpoint', role=None, function_call=None, tool_calls=None, audio=None), logprobs=None), response_obj: {'text': ' `/v4/profile` endpoint', 'is_finished': False, 'finish_reason': None, 'logprobs': None, 'original_chunk': ModelResponseStream(id='chatcmpl-1e246dec-1357-4ceb-948f-03d49e55b5f9', created=1762261911, model=None, object='chat.completion.chunk', system_fingerprint=None, choices=[StreamingChoices(finish_reason=None, index=0, delta=Delta(provider_specific_fields=None, content=' `/v4/profile` endpoint', role=None, function_call=None, tool_calls=None, audio=None), logprobs=None)], provider_specific_fields=None, usage=None), 'usage': None}
choice_json: {'index': 0, 'delta': {'provider_specific_fields': None, 'content': ' `/v4/profile` endpoint', 'role': None, 'function_call': None, 'tool_calls': None, 'audio': None}, 'logprobs': None}
choices in streaming: [StreamingChoices(finish_reason=None, index=0, delta=Delta(provider_specific_fields=None, content=' `/v4/profile` endpoint', role=None, function_call=None, tool_calls=None, audio=None), logprobs=None)]
final returned processed chunk: ModelResponseStream(id='chatcmpl-1e246dec-1357-4ceb-948f-03d49e55b5f9', created=1762261907, model='claude-sonnet-4-5-20250929', object='chat.completion.chunk', system_fingerprint=None, choices=[StreamingChoices(finish_reason=None, index=0, delta=Delta(provider_specific_fields=None, content=' `/v4/profile` endpoint', role=None, function_call=None, tool_calls=None, audio=None), logprobs=None)], provider_specific_fields=None, citations=None)
model_response finish reason 3: None; response_obj={'text': '', 'is_finished': False, 'finish_reason': '', 'usage': None, 'index': 0, 'tool_use': None}
model_response.choices[0].delta: Delta(provider_specific_fields=None, content=None, role=None, function_call=None, tool_calls=None, audio=None); completion_obj: {'content': ''}
self.sent_first_chunk: True
completion_obj: {'content': ''}, model_response.choices[0]: StreamingChoices(finish_reason=None, index=0, delta=Delta(provider_specific_fields=None, content=None, role=None, function_call=None, tool_calls=None, audio=None), logprobs=None), response_obj: {'text': '', 'is_finished': False, 'finish_reason': '', 'usage': None, 'index': 0, 'tool_use': None}
model_response finish reason 3: None; response_obj={'text': '', 'is_finished': False, 'finish_reason': '', 'usage': None, 'index': 0, 'tool_use': None}
model_response.choices[0].delta: Delta(provider_specific_fields=None, content=None, role=None, function_call=None, tool_calls=None, audio=None); completion_obj: {'content': ''}
self.sent_first_chunk: True
completion_obj: {'content': ''}, model_response.choices[0]: StreamingChoices(finish_reason=None, index=0, delta=Delta(provider_specific_fields=None, content=None, role=None, function_call=None, tool_calls=None, audio=None), logprobs=None), response_obj: {'text': '', 'is_finished': False, 'finish_reason': '', 'usage': None, 'index': 0, 'tool_use': None}

Raw OpenAI Chunk
ModelResponseStream(id='chatcmpl-1e246dec-1357-4ceb-948f-03d49e55b5f9', created=1762261911, model=None, object='chat.completion.chunk', system_fingerprint=None, choices=[StreamingChoices(finish_reason=None, index=0, delta=Delta(provider_specific_fields=None, content='\n   - Uses', role=None, function_call=None, tool_calls=None, audio=None), logprobs=None)], provider_specific_fields=None, usage=None)

model_response finish reason 3: None; response_obj={'text': '\n   - Uses', 'is_finished': False, 'finish_reason': None, 'logprobs': None, 'original_chunk': ModelResponseStream(id='chatcmpl-1e246dec-1357-4ceb-948f-03d49e55b5f9', created=1762261911, model=None, object='chat.completion.chunk', system_fingerprint=None, choices=[StreamingChoices(finish_reason=None, index=0, delta=Delta(provider_specific_fields=None, content='\n   - Uses', role=None, function_call=None, tool_calls=None, audio=None), logprobs=None)], provider_specific_fields=None, usage=None), 'usage': None}
original delta: {'provider_specific_fields': None, 'content': '\n   - Uses', 'role': None, 'function_call': None, 'tool_calls': None, 'audio': None}
new delta: Delta(provider_specific_fields=None, content='\n   - Uses', role=None, function_call=None, tool_calls=None, audio=None)
model_response.choices[0].delta: Delta(provider_specific_fields=None, content='\n   - Uses', role=None, function_call=None, tool_calls=None, audio=None); completion_obj: {'content': '\n   - Uses'}
self.sent_first_chunk: True
completion_obj: {'content': '\n   - Uses'}, model_response.choices[0]: StreamingChoices(finish_reason=None, index=0, delta=Delta(provider_specific_fields=None, content='\n   - Uses', role=None, function_call=None, tool_calls=None, audio=None), logprobs=None), response_obj: {'text': '\n   - Uses', 'is_finished': False, 'finish_reason': None, 'logprobs': None, 'original_chunk': ModelResponseStream(id='chatcmpl-1e246dec-1357-4ceb-948f-03d49e55b5f9', created=1762261911, model=None, object='chat.completion.chunk', system_fingerprint=None, choices=[StreamingChoices(finish_reason=None, index=0, delta=Delta(provider_specific_fields=None, content='\n   - Uses', role=None, function_call=None, tool_calls=None, audio=None), logprobs=None)], provider_specific_fields=None, usage=None), 'usage': None}
choice_json: {'index': 0, 'delta': {'provider_specific_fields': None, 'content': '\n   - Uses', 'role': None, 'function_call': None, 'tool_calls': None, 'audio': None}, 'logprobs': None}
choices in streaming: [StreamingChoices(finish_reason=None, index=0, delta=Delta(provider_specific_fields=None, content='\n   - Uses', role=None, function_call=None, tool_calls=None, audio=None), logprobs=None)]
final returned processed chunk: ModelResponseStream(id='chatcmpl-1e246dec-1357-4ceb-948f-03d49e55b5f9', created=1762261907, model='claude-sonnet-4-5-20250929', object='chat.completion.chunk', system_fingerprint=None, choices=[StreamingChoices(finish_reason=None, index=0, delta=Delta(provider_specific_fields=None, content='\n   - Uses', role=None, function_call=None, tool_calls=None, audio=None), logprobs=None)], provider_specific_fields=None, citations=None)
model_response finish reason 3: None; response_obj={'text': '', 'is_finished': False, 'finish_reason': '', 'usage': None, 'index': 0, 'tool_use': None}
model_response.choices[0].delta: Delta(provider_specific_fields=None, content=None, role=None, function_call=None, tool_calls=None, audio=None); completion_obj: {'content': ''}
self.sent_first_chunk: True
completion_obj: {'content': ''}, model_response.choices[0]: StreamingChoices(finish_reason=None, index=0, delta=Delta(provider_specific_fields=None, content=None, role=None, function_call=None, tool_calls=None, audio=None), logprobs=None), response_obj: {'text': '', 'is_finished': False, 'finish_reason': '', 'usage': None, 'index': 0, 'tool_use': None}
model_response finish reason 3: None; response_obj={'text': '', 'is_finished': False, 'finish_reason': '', 'usage': None, 'index': 0, 'tool_use': None}
model_response.choices[0].delta: Delta(provider_specific_fields=None, content=None, role=None, function_call=None, tool_calls=None, audio=None); completion_obj: {'content': ''}
self.sent_first_chunk: True
completion_obj: {'content': ''}, model_response.choices[0]: StreamingChoices(finish_reason=None, index=0, delta=Delta(provider_specific_fields=None, content=None, role=None, function_call=None, tool_calls=None, audio=None), logprobs=None), response_obj: {'text': '', 'is_finished': False, 'finish_reason': '', 'usage': None, 'index': 0, 'tool_use': None}

Raw OpenAI Chunk
ModelResponseStream(id='chatcmpl-1e246dec-1357-4ceb-948f-03d49e55b5f9', created=1762261911, model=None, object='chat.completion.chunk', system_fingerprint=None, choices=[StreamingChoices(finish_reason=None, index=0, delta=Delta(provider_specific_fields=None, content=' persistent', role=None, function_call=None, tool_calls=None, audio=None), logprobs=None)], provider_specific_fields=None, usage=None)

model_response finish reason 3: None; response_obj={'text': ' persistent', 'is_finished': False, 'finish_reason': None, 'logprobs': None, 'original_chunk': ModelResponseStream(id='chatcmpl-1e246dec-1357-4ceb-948f-03d49e55b5f9', created=1762261911, model=None, object='chat.completion.chunk', system_fingerprint=None, choices=[StreamingChoices(finish_reason=None, index=0, delta=Delta(provider_specific_fields=None, content=' persistent', role=None, function_call=None, tool_calls=None, audio=None), logprobs=None)], provider_specific_fields=None, usage=None), 'usage': None}
original delta: {'provider_specific_fields': None, 'content': ' persistent', 'role': None, 'function_call': None, 'tool_calls': None, 'audio': None}
new delta: Delta(provider_specific_fields=None, content=' persistent', role=None, function_call=None, tool_calls=None, audio=None)
model_response.choices[0].delta: Delta(provider_specific_fields=None, content=' persistent', role=None, function_call=None, tool_calls=None, audio=None); completion_obj: {'content': ' persistent'}
self.sent_first_chunk: True
completion_obj: {'content': ' persistent'}, model_response.choices[0]: StreamingChoices(finish_reason=None, index=0, delta=Delta(provider_specific_fields=None, content=' persistent', role=None, function_call=None, tool_calls=None, audio=None), logprobs=None), response_obj: {'text': ' persistent', 'is_finished': False, 'finish_reason': None, 'logprobs': None, 'original_chunk': ModelResponseStream(id='chatcmpl-1e246dec-1357-4ceb-948f-03d49e55b5f9', created=1762261911, model=None, object='chat.completion.chunk', system_fingerprint=None, choices=[StreamingChoices(finish_reason=None, index=0, delta=Delta(provider_specific_fields=None, content=' persistent', role=None, function_call=None, tool_calls=None, audio=None), logprobs=None)], provider_specific_fields=None, usage=None), 'usage': None}
choice_json: {'index': 0, 'delta': {'provider_specific_fields': None, 'content': ' persistent', 'role': None, 'function_call': None, 'tool_calls': None, 'audio': None}, 'logprobs': None}
choices in streaming: [StreamingChoices(finish_reason=None, index=0, delta=Delta(provider_specific_fields=None, content=' persistent', role=None, function_call=None, tool_calls=None, audio=None), logprobs=None)]
final returned processed chunk: ModelResponseStream(id='chatcmpl-1e246dec-1357-4ceb-948f-03d49e55b5f9', created=1762261907, model='claude-sonnet-4-5-20250929', object='chat.completion.chunk', system_fingerprint=None, choices=[StreamingChoices(finish_reason=None, index=0, delta=Delta(provider_specific_fields=None, content=' persistent', role=None, function_call=None, tool_calls=None, audio=None), logprobs=None)], provider_specific_fields=None, citations=None)
model_response finish reason 3: None; response_obj={'text': '', 'is_finished': False, 'finish_reason': '', 'usage': None, 'index': 0, 'tool_use': None}
model_response.choices[0].delta: Delta(provider_specific_fields=None, content=None, role=None, function_call=None, tool_calls=None, audio=None); completion_obj: {'content': ''}
self.sent_first_chunk: True
completion_obj: {'content': ''}, model_response.choices[0]: StreamingChoices(finish_reason=None, index=0, delta=Delta(provider_specific_fields=None, content=None, role=None, function_call=None, tool_calls=None, audio=None), logprobs=None), response_obj: {'text': '', 'is_finished': False, 'finish_reason': '', 'usage': None, 'index': 0, 'tool_use': None}
model_response finish reason 3: None; response_obj={'text': '', 'is_finished': False, 'finish_reason': '', 'usage': None, 'index': 0, 'tool_use': None}
model_response.choices[0].delta: Delta(provider_specific_fields=None, content=None, role=None, function_call=None, tool_calls=None, audio=None); completion_obj: {'content': ''}
self.sent_first_chunk: True
completion_obj: {'content': ''}, model_response.choices[0]: StreamingChoices(finish_reason=None, index=0, delta=Delta(provider_specific_fields=None, content=None, role=None, function_call=None, tool_calls=None, audio=None), logprobs=None), response_obj: {'text': '', 'is_finished': False, 'finish_reason': '', 'usage': None, 'index': 0, 'tool_use': None}

Raw OpenAI Chunk
ModelResponseStream(id='chatcmpl-1e246dec-1357-4ceb-948f-03d49e55b5f9', created=1762261911, model=None, object='chat.completion.chunk', system_fingerprint=None, choices=[StreamingChoices(finish_reason=None, index=0, delta=Delta(provider_specific_fields=None, content=' `', role=None, function_call=None, tool_calls=None, audio=None), logprobs=None)], provider_specific_fields=None, usage=None)

model_response finish reason 3: None; response_obj={'text': ' `', 'is_finished': False, 'finish_reason': None, 'logprobs': None, 'original_chunk': ModelResponseStream(id='chatcmpl-1e246dec-1357-4ceb-948f-03d49e55b5f9', created=1762261911, model=None, object='chat.completion.chunk', system_fingerprint=None, choices=[StreamingChoices(finish_reason=None, index=0, delta=Delta(provider_specific_fields=None, content=' `', role=None, function_call=None, tool_calls=None, audio=None), logprobs=None)], provider_specific_fields=None, usage=None), 'usage': None}
original delta: {'provider_specific_fields': None, 'content': ' `', 'role': None, 'function_call': None, 'tool_calls': None, 'audio': None}
new delta: Delta(provider_specific_fields=None, content=' `', role=None, function_call=None, tool_calls=None, audio=None)
model_response.choices[0].delta: Delta(provider_specific_fields=None, content=' `', role=None, function_call=None, tool_calls=None, audio=None); completion_obj: {'content': ' `'}
self.sent_first_chunk: True
completion_obj: {'content': ' `'}, model_response.choices[0]: StreamingChoices(finish_reason=None, index=0, delta=Delta(provider_specific_fields=None, content=' `', role=None, function_call=None, tool_calls=None, audio=None), logprobs=None), response_obj: {'text': ' `', 'is_finished': False, 'finish_reason': None, 'logprobs': None, 'original_chunk': ModelResponseStream(id='chatcmpl-1e246dec-1357-4ceb-948f-03d49e55b5f9', created=1762261911, model=None, object='chat.completion.chunk', system_fingerprint=None, choices=[StreamingChoices(finish_reason=None, index=0, delta=Delta(provider_specific_fields=None, content=' `', role=None, function_call=None, tool_calls=None, audio=None), logprobs=None)], provider_specific_fields=None, usage=None), 'usage': None}
choice_json: {'index': 0, 'delta': {'provider_specific_fields': None, 'content': ' `', 'role': None, 'function_call': None, 'tool_calls': None, 'audio': None}, 'logprobs': None}
choices in streaming: [StreamingChoices(finish_reason=None, index=0, delta=Delta(provider_specific_fields=None, content=' `', role=None, function_call=None, tool_calls=None, audio=None), logprobs=None)]
final returned processed chunk: ModelResponseStream(id='chatcmpl-1e246dec-1357-4ceb-948f-03d49e55b5f9', created=1762261907, model='claude-sonnet-4-5-20250929', object='chat.completion.chunk', system_fingerprint=None, choices=[StreamingChoices(finish_reason=None, index=0, delta=Delta(provider_specific_fields=None, content=' `', role=None, function_call=None, tool_calls=None, audio=None), logprobs=None)], provider_specific_fields=None, citations=None)
model_response finish reason 3: None; response_obj={'text': '', 'is_finished': False, 'finish_reason': '', 'usage': None, 'index': 0, 'tool_use': None}
model_response.choices[0].delta: Delta(provider_specific_fields=None, content=None, role=None, function_call=None, tool_calls=None, audio=None); completion_obj: {'content': ''}
self.sent_first_chunk: True
completion_obj: {'content': ''}, model_response.choices[0]: StreamingChoices(finish_reason=None, index=0, delta=Delta(provider_specific_fields=None, content=None, role=None, function_call=None, tool_calls=None, audio=None), logprobs=None), response_obj: {'text': '', 'is_finished': False, 'finish_reason': '', 'usage': None, 'index': 0, 'tool_use': None}
model_response finish reason 3: None; response_obj={'text': '', 'is_finished': False, 'finish_reason': '', 'usage': None, 'index': 0, 'tool_use': None}
model_response.choices[0].delta: Delta(provider_specific_fields=None, content=None, role=None, function_call=None, tool_calls=None, audio=None); completion_obj: {'content': ''}
self.sent_first_chunk: True
completion_obj: {'content': ''}, model_response.choices[0]: StreamingChoices(finish_reason=None, index=0, delta=Delta(provider_specific_fields=None, content=None, role=None, function_call=None, tool_calls=None, audio=None), logprobs=None), response_obj: {'text': '', 'is_finished': False, 'finish_reason': '', 'usage': None, 'index': 0, 'tool_use': None}

Raw OpenAI Chunk
ModelResponseStream(id='chatcmpl-1e246dec-1357-4ceb-948f-03d49e55b5f9', created=1762261911, model=None, object='chat.completion.chunk', system_fingerprint=None, choices=[StreamingChoices(finish_reason=None, index=0, delta=Delta(provider_specific_fields=None, content='httpx.AsyncClient` for', role=None, function_call=None, tool_calls=None, audio=None), logprobs=None)], provider_specific_fields=None, usage=None)

model_response finish reason 3: None; response_obj={'text': 'httpx.AsyncClient` for', 'is_finished': False, 'finish_reason': None, 'logprobs': None, 'original_chunk': ModelResponseStream(id='chatcmpl-1e246dec-1357-4ceb-948f-03d49e55b5f9', created=1762261911, model=None, object='chat.completion.chunk', system_fingerprint=None, choices=[StreamingChoices(finish_reason=None, index=0, delta=Delta(provider_specific_fields=None, content='httpx.AsyncClient` for', role=None, function_call=None, tool_calls=None, audio=None), logprobs=None)], provider_specific_fields=None, usage=None), 'usage': None}
original delta: {'provider_specific_fields': None, 'content': 'httpx.AsyncClient` for', 'role': None, 'function_call': None, 'tool_calls': None, 'audio': None}
new delta: Delta(provider_specific_fields=None, content='httpx.AsyncClient` for', role=None, function_call=None, tool_calls=None, audio=None)
model_response.choices[0].delta: Delta(provider_specific_fields=None, content='httpx.AsyncClient` for', role=None, function_call=None, tool_calls=None, audio=None); completion_obj: {'content': 'httpx.AsyncClient` for'}
self.sent_first_chunk: True
completion_obj: {'content': 'httpx.AsyncClient` for'}, model_response.choices[0]: StreamingChoices(finish_reason=None, index=0, delta=Delta(provider_specific_fields=None, content='httpx.AsyncClient` for', role=None, function_call=None, tool_calls=None, audio=None), logprobs=None), response_obj: {'text': 'httpx.AsyncClient` for', 'is_finished': False, 'finish_reason': None, 'logprobs': None, 'original_chunk': ModelResponseStream(id='chatcmpl-1e246dec-1357-4ceb-948f-03d49e55b5f9', created=1762261911, model=None, object='chat.completion.chunk', system_fingerprint=None, choices=[StreamingChoices(finish_reason=None, index=0, delta=Delta(provider_specific_fields=None, content='httpx.AsyncClient` for', role=None, function_call=None, tool_calls=None, audio=None), logprobs=None)], provider_specific_fields=None, usage=None), 'usage': None}
choice_json: {'index': 0, 'delta': {'provider_specific_fields': None, 'content': 'httpx.AsyncClient` for', 'role': None, 'function_call': None, 'tool_calls': None, 'audio': None}, 'logprobs': None}
choices in streaming: [StreamingChoices(finish_reason=None, index=0, delta=Delta(provider_specific_fields=None, content='httpx.AsyncClient` for', role=None, function_call=None, tool_calls=None, audio=None), logprobs=None)]
final returned processed chunk: ModelResponseStream(id='chatcmpl-1e246dec-1357-4ceb-948f-03d49e55b5f9', created=1762261907, model='claude-sonnet-4-5-20250929', object='chat.completion.chunk', system_fingerprint=None, choices=[StreamingChoices(finish_reason=None, index=0, delta=Delta(provider_specific_fields=None, content='httpx.AsyncClient` for', role=None, function_call=None, tool_calls=None, audio=None), logprobs=None)], provider_specific_fields=None, citations=None)
model_response finish reason 3: None; response_obj={'text': '', 'is_finished': False, 'finish_reason': '', 'usage': None, 'index': 0, 'tool_use': None}
model_response.choices[0].delta: Delta(provider_specific_fields=None, content=None, role=None, function_call=None, tool_calls=None, audio=None); completion_obj: {'content': ''}
self.sent_first_chunk: True
completion_obj: {'content': ''}, model_response.choices[0]: StreamingChoices(finish_reason=None, index=0, delta=Delta(provider_specific_fields=None, content=None, role=None, function_call=None, tool_calls=None, audio=None), logprobs=None), response_obj: {'text': '', 'is_finished': False, 'finish_reason': '', 'usage': None, 'index': 0, 'tool_use': None}
model_response finish reason 3: None; response_obj={'text': '', 'is_finished': False, 'finish_reason': '', 'usage': None, 'index': 0, 'tool_use': None}
model_response.choices[0].delta: Delta(provider_specific_fields=None, content=None, role=None, function_call=None, tool_calls=None, audio=None); completion_obj: {'content': ''}
self.sent_first_chunk: True
completion_obj: {'content': ''}, model_response.choices[0]: StreamingChoices(finish_reason=None, index=0, delta=Delta(provider_specific_fields=None, content=None, role=None, function_call=None, tool_calls=None, audio=None), logprobs=None), response_obj: {'text': '', 'is_finished': False, 'finish_reason': '', 'usage': None, 'index': 0, 'tool_use': None}

Raw OpenAI Chunk
ModelResponseStream(id='chatcmpl-1e246dec-1357-4ceb-948f-03d49e55b5f9', created=1762261912, model=None, object='chat.completion.chunk', system_fingerprint=None, choices=[StreamingChoices(finish_reason=None, index=0, delta=Delta(provider_specific_fields=None, content=' Cloudflare cookie', role=None, function_call=None, tool_calls=None, audio=None), logprobs=None)], provider_specific_fields=None, usage=None)

model_response finish reason 3: None; response_obj={'text': ' Cloudflare cookie', 'is_finished': False, 'finish_reason': None, 'logprobs': None, 'original_chunk': ModelResponseStream(id='chatcmpl-1e246dec-1357-4ceb-948f-03d49e55b5f9', created=1762261912, model=None, object='chat.completion.chunk', system_fingerprint=None, choices=[StreamingChoices(finish_reason=None, index=0, delta=Delta(provider_specific_fields=None, content=' Cloudflare cookie', role=None, function_call=None, tool_calls=None, audio=None), logprobs=None)], provider_specific_fields=None, usage=None), 'usage': None}
original delta: {'provider_specific_fields': None, 'content': ' Cloudflare cookie', 'role': None, 'function_call': None, 'tool_calls': None, 'audio': None}
new delta: Delta(provider_specific_fields=None, content=' Cloudflare cookie', role=None, function_call=None, tool_calls=None, audio=None)
model_response.choices[0].delta: Delta(provider_specific_fields=None, content=' Cloudflare cookie', role=None, function_call=None, tool_calls=None, audio=None); completion_obj: {'content': ' Cloudflare cookie'}
self.sent_first_chunk: True
completion_obj: {'content': ' Cloudflare cookie'}, model_response.choices[0]: StreamingChoices(finish_reason=None, index=0, delta=Delta(provider_specific_fields=None, content=' Cloudflare cookie', role=None, function_call=None, tool_calls=None, audio=None), logprobs=None), response_obj: {'text': ' Cloudflare cookie', 'is_finished': False, 'finish_reason': None, 'logprobs': None, 'original_chunk': ModelResponseStream(id='chatcmpl-1e246dec-1357-4ceb-948f-03d49e55b5f9', created=1762261912, model=None, object='chat.completion.chunk', system_fingerprint=None, choices=[StreamingChoices(finish_reason=None, index=0, delta=Delta(provider_specific_fields=None, content=' Cloudflare cookie', role=None, function_call=None, tool_calls=None, audio=None), logprobs=None)], provider_specific_fields=None, usage=None), 'usage': None}
choice_json: {'index': 0, 'delta': {'provider_specific_fields': None, 'content': ' Cloudflare cookie', 'role': None, 'function_call': None, 'tool_calls': None, 'audio': None}, 'logprobs': None}
choices in streaming: [StreamingChoices(finish_reason=None, index=0, delta=Delta(provider_specific_fields=None, content=' Cloudflare cookie', role=None, function_call=None, tool_calls=None, audio=None), logprobs=None)]
final returned processed chunk: ModelResponseStream(id='chatcmpl-1e246dec-1357-4ceb-948f-03d49e55b5f9', created=1762261907, model='claude-sonnet-4-5-20250929', object='chat.completion.chunk', system_fingerprint=None, choices=[StreamingChoices(finish_reason=None, index=0, delta=Delta(provider_specific_fields=None, content=' Cloudflare cookie', role=None, function_call=None, tool_calls=None, audio=None), logprobs=None)], provider_specific_fields=None, citations=None)
model_response finish reason 3: None; response_obj={'text': '', 'is_finished': False, 'finish_reason': '', 'usage': None, 'index': 0, 'tool_use': None}
model_response.choices[0].delta: Delta(provider_specific_fields=None, content=None, role=None, function_call=None, tool_calls=None, audio=None); completion_obj: {'content': ''}
self.sent_first_chunk: True
completion_obj: {'content': ''}, model_response.choices[0]: StreamingChoices(finish_reason=None, index=0, delta=Delta(provider_specific_fields=None, content=None, role=None, function_call=None, tool_calls=None, audio=None), logprobs=None), response_obj: {'text': '', 'is_finished': False, 'finish_reason': '', 'usage': None, 'index': 0, 'tool_use': None}
model_response finish reason 3: None; response_obj={'text': '', 'is_finished': False, 'finish_reason': '', 'usage': None, 'index': 0, 'tool_use': None}
model_response.choices[0].delta: Delta(provider_specific_fields=None, content=None, role=None, function_call=None, tool_calls=None, audio=None); completion_obj: {'content': ''}
self.sent_first_chunk: True
completion_obj: {'content': ''}, model_response.choices[0]: StreamingChoices(finish_reason=None, index=0, delta=Delta(provider_specific_fields=None, content=None, role=None, function_call=None, tool_calls=None, audio=None), logprobs=None), response_obj: {'text': '', 'is_finished': False, 'finish_reason': '', 'usage': None, 'index': 0, 'tool_use': None}

Raw OpenAI Chunk
ModelResponseStream(id='chatcmpl-1e246dec-1357-4ceb-948f-03d49e55b5f9', created=1762261912, model=None, object='chat.completion.chunk', system_fingerprint=None, choices=[StreamingChoices(finish_reason=None, index=0, delta=Delta(provider_specific_fields=None, content=' handling\n   - Formats', role=None, function_call=None, tool_calls=None, audio=None), logprobs=None)], provider_specific_fields=None, usage=None)

model_response finish reason 3: None; response_obj={'text': ' handling\n   - Formats', 'is_finished': False, 'finish_reason': None, 'logprobs': None, 'original_chunk': ModelResponseStream(id='chatcmpl-1e246dec-1357-4ceb-948f-03d49e55b5f9', created=1762261912, model=None, object='chat.completion.chunk', system_fingerprint=None, choices=[StreamingChoices(finish_reason=None, index=0, delta=Delta(provider_specific_fields=None, content=' handling\n   - Formats', role=None, function_call=None, tool_calls=None, audio=None), logprobs=None)], provider_specific_fields=None, usage=None), 'usage': None}
original delta: {'provider_specific_fields': None, 'content': ' handling\n   - Formats', 'role': None, 'function_call': None, 'tool_calls': None, 'audio': None}
new delta: Delta(provider_specific_fields=None, content=' handling\n   - Formats', role=None, function_call=None, tool_calls=None, audio=None)
model_response.choices[0].delta: Delta(provider_specific_fields=None, content=' handling\n   - Formats', role=None, function_call=None, tool_calls=None, audio=None); completion_obj: {'content': ' handling\n   - Formats'}
self.sent_first_chunk: True
completion_obj: {'content': ' handling\n   - Formats'}, model_response.choices[0]: StreamingChoices(finish_reason=None, index=0, delta=Delta(provider_specific_fields=None, content=' handling\n   - Formats', role=None, function_call=None, tool_calls=None, audio=None), logprobs=None), response_obj: {'text': ' handling\n   - Formats', 'is_finished': False, 'finish_reason': None, 'logprobs': None, 'original_chunk': ModelResponseStream(id='chatcmpl-1e246dec-1357-4ceb-948f-03d49e55b5f9', created=1762261912, model=None, object='chat.completion.chunk', system_fingerprint=None, choices=[StreamingChoices(finish_reason=None, index=0, delta=Delta(provider_specific_fields=None, content=' handling\n   - Formats', role=None, function_call=None, tool_calls=None, audio=None), logprobs=None)], provider_specific_fields=None, usage=None), 'usage': None}
choice_json: {'index': 0, 'delta': {'provider_specific_fields': None, 'content': ' handling\n   - Formats', 'role': None, 'function_call': None, 'tool_calls': None, 'audio': None}, 'logprobs': None}
choices in streaming: [StreamingChoices(finish_reason=None, index=0, delta=Delta(provider_specific_fields=None, content=' handling\n   - Formats', role=None, function_call=None, tool_calls=None, audio=None), logprobs=None)]
final returned processed chunk: ModelResponseStream(id='chatcmpl-1e246dec-1357-4ceb-948f-03d49e55b5f9', created=1762261907, model='claude-sonnet-4-5-20250929', object='chat.completion.chunk', system_fingerprint=None, choices=[StreamingChoices(finish_reason=None, index=0, delta=Delta(provider_specific_fields=None, content=' handling\n   - Formats', role=None, function_call=None, tool_calls=None, audio=None), logprobs=None)], provider_specific_fields=None, citations=None)
model_response finish reason 3: None; response_obj={'text': '', 'is_finished': False, 'finish_reason': '', 'usage': None, 'index': 0, 'tool_use': None}
model_response.choices[0].delta: Delta(provider_specific_fields=None, content=None, role=None, function_call=None, tool_calls=None, audio=None); completion_obj: {'content': ''}
self.sent_first_chunk: True
completion_obj: {'content': ''}, model_response.choices[0]: StreamingChoices(finish_reason=None, index=0, delta=Delta(provider_specific_fields=None, content=None, role=None, function_call=None, tool_calls=None, audio=None), logprobs=None), response_obj: {'text': '', 'is_finished': False, 'finish_reason': '', 'usage': None, 'index': 0, 'tool_use': None}
model_response finish reason 3: None; response_obj={'text': '', 'is_finished': False, 'finish_reason': '', 'usage': None, 'index': 0, 'tool_use': None}
model_response.choices[0].delta: Delta(provider_specific_fields=None, content=None, role=None, function_call=None, tool_calls=None, audio=None); completion_obj: {'content': ''}
self.sent_first_chunk: True
completion_obj: {'content': ''}, model_response.choices[0]: StreamingChoices(finish_reason=None, index=0, delta=Delta(provider_specific_fields=None, content=None, role=None, function_call=None, tool_calls=None, audio=None), logprobs=None), response_obj: {'text': '', 'is_finished': False, 'finish_reason': '', 'usage': None, 'index': 0, 'tool_use': None}

Raw OpenAI Chunk
ModelResponseStream(id='chatcmpl-1e246dec-1357-4ceb-948f-03d49e55b5f9', created=1762261912, model=None, object='chat.completion.chunk', system_fingerprint=None, choices=[StreamingChoices(finish_reason=None, index=0, delta=Delta(provider_specific_fields=None, content=' an', role=None, function_call=None, tool_calls=None, audio=None), logprobs=None)], provider_specific_fields=None, usage=None)

model_response finish reason 3: None; response_obj={'text': ' an', 'is_finished': False, 'finish_reason': None, 'logprobs': None, 'original_chunk': ModelResponseStream(id='chatcmpl-1e246dec-1357-4ceb-948f-03d49e55b5f9', created=1762261912, model=None, object='chat.completion.chunk', system_fingerprint=None, choices=[StreamingChoices(finish_reason=None, index=0, delta=Delta(provider_specific_fields=None, content=' an', role=None, function_call=None, tool_calls=None, audio=None), logprobs=None)], provider_specific_fields=None, usage=None), 'usage': None}
original delta: {'provider_specific_fields': None, 'content': ' an', 'role': None, 'function_call': None, 'tool_calls': None, 'audio': None}
new delta: Delta(provider_specific_fields=None, content=' an', role=None, function_call=None, tool_calls=None, audio=None)
model_response.choices[0].delta: Delta(provider_specific_fields=None, content=' an', role=None, function_call=None, tool_calls=None, audio=None); completion_obj: {'content': ' an'}
self.sent_first_chunk: True
completion_obj: {'content': ' an'}, model_response.choices[0]: StreamingChoices(finish_reason=None, index=0, delta=Delta(provider_specific_fields=None, content=' an', role=None, function_call=None, tool_calls=None, audio=None), logprobs=None), response_obj: {'text': ' an', 'is_finished': False, 'finish_reason': None, 'logprobs': None, 'original_chunk': ModelResponseStream(id='chatcmpl-1e246dec-1357-4ceb-948f-03d49e55b5f9', created=1762261912, model=None, object='chat.completion.chunk', system_fingerprint=None, choices=[StreamingChoices(finish_reason=None, index=0, delta=Delta(provider_specific_fields=None, content=' an', role=None, function_call=None, tool_calls=None, audio=None), logprobs=None)], provider_specific_fields=None, usage=None), 'usage': None}
choice_json: {'index': 0, 'delta': {'provider_specific_fields': None, 'content': ' an', 'role': None, 'function_call': None, 'tool_calls': None, 'audio': None}, 'logprobs': None}
choices in streaming: [StreamingChoices(finish_reason=None, index=0, delta=Delta(provider_specific_fields=None, content=' an', role=None, function_call=None, tool_calls=None, audio=None), logprobs=None)]
final returned processed chunk: ModelResponseStream(id='chatcmpl-1e246dec-1357-4ceb-948f-03d49e55b5f9', created=1762261907, model='claude-sonnet-4-5-20250929', object='chat.completion.chunk', system_fingerprint=None, choices=[StreamingChoices(finish_reason=None, index=0, delta=Delta(provider_specific_fields=None, content=' an', role=None, function_call=None, tool_calls=None, audio=None), logprobs=None)], provider_specific_fields=None, citations=None)
model_response finish reason 3: None; response_obj={'text': '', 'is_finished': False, 'finish_reason': '', 'usage': None, 'index': 0, 'tool_use': None}
model_response.choices[0].delta: Delta(provider_specific_fields=None, content=None, role=None, function_call=None, tool_calls=None, audio=None); completion_obj: {'content': ''}
self.sent_first_chunk: True
completion_obj: {'content': ''}, model_response.choices[0]: StreamingChoices(finish_reason=None, index=0, delta=Delta(provider_specific_fields=None, content=None, role=None, function_call=None, tool_calls=None, audio=None), logprobs=None), response_obj: {'text': '', 'is_finished': False, 'finish_reason': '', 'usage': None, 'index': 0, 'tool_use': None}
model_response finish reason 3: None; response_obj={'text': '', 'is_finished': False, 'finish_reason': '', 'usage': None, 'index': 0, 'tool_use': None}
model_response.choices[0].delta: Delta(provider_specific_fields=None, content=None, role=None, function_call=None, tool_calls=None, audio=None); completion_obj: {'content': ''}
self.sent_first_chunk: True
completion_obj: {'content': ''}, model_response.choices[0]: StreamingChoices(finish_reason=None, index=0, delta=Delta(provider_specific_fields=None, content=None, role=None, function_call=None, tool_calls=None, audio=None), logprobs=None), response_obj: {'text': '', 'is_finished': False, 'finish_reason': '', 'usage': None, 'index': 0, 'tool_use': None}

Raw OpenAI Chunk
ModelResponseStream(id='chatcmpl-1e246dec-1357-4ceb-948f-03d49e55b5f9', created=1762261912, model=None, object='chat.completion.chunk', system_fingerprint=None, choices=[StreamingChoices(finish_reason=None, index=0, delta=Delta(provider_specific_fields=None, content='d injects context into messages\n4', role=None, function_call=None, tool_calls=None, audio=None), logprobs=None)], provider_specific_fields=None, usage=None)

model_response finish reason 3: None; response_obj={'text': 'd injects context into messages\n4', 'is_finished': False, 'finish_reason': None, 'logprobs': None, 'original_chunk': ModelResponseStream(id='chatcmpl-1e246dec-1357-4ceb-948f-03d49e55b5f9', created=1762261912, model=None, object='chat.completion.chunk', system_fingerprint=None, choices=[StreamingChoices(finish_reason=None, index=0, delta=Delta(provider_specific_fields=None, content='d injects context into messages\n4', role=None, function_call=None, tool_calls=None, audio=None), logprobs=None)], provider_specific_fields=None, usage=None), 'usage': None}
original delta: {'provider_specific_fields': None, 'content': 'd injects context into messages\n4', 'role': None, 'function_call': None, 'tool_calls': None, 'audio': None}
new delta: Delta(provider_specific_fields=None, content='d injects context into messages\n4', role=None, function_call=None, tool_calls=None, audio=None)
model_response.choices[0].delta: Delta(provider_specific_fields=None, content='d injects context into messages\n4', role=None, function_call=None, tool_calls=None, audio=None); completion_obj: {'content': 'd injects context into messages\n4'}
self.sent_first_chunk: True
completion_obj: {'content': 'd injects context into messages\n4'}, model_response.choices[0]: StreamingChoices(finish_reason=None, index=0, delta=Delta(provider_specific_fields=None, content='d injects context into messages\n4', role=None, function_call=None, tool_calls=None, audio=None), logprobs=None), response_obj: {'text': 'd injects context into messages\n4', 'is_finished': False, 'finish_reason': None, 'logprobs': None, 'original_chunk': ModelResponseStream(id='chatcmpl-1e246dec-1357-4ceb-948f-03d49e55b5f9', created=1762261912, model=None, object='chat.completion.chunk', system_fingerprint=None, choices=[StreamingChoices(finish_reason=None, index=0, delta=Delta(provider_specific_fields=None, content='d injects context into messages\n4', role=None, function_call=None, tool_calls=None, audio=None), logprobs=None)], provider_specific_fields=None, usage=None), 'usage': None}
choice_json: {'index': 0, 'delta': {'provider_specific_fields': None, 'content': 'd injects context into messages\n4', 'role': None, 'function_call': None, 'tool_calls': None, 'audio': None}, 'logprobs': None}
choices in streaming: [StreamingChoices(finish_reason=None, index=0, delta=Delta(provider_specific_fields=None, content='d injects context into messages\n4', role=None, function_call=None, tool_calls=None, audio=None), logprobs=None)]
final returned processed chunk: ModelResponseStream(id='chatcmpl-1e246dec-1357-4ceb-948f-03d49e55b5f9', created=1762261907, model='claude-sonnet-4-5-20250929', object='chat.completion.chunk', system_fingerprint=None, choices=[StreamingChoices(finish_reason=None, index=0, delta=Delta(provider_specific_fields=None, content='d injects context into messages\n4', role=None, function_call=None, tool_calls=None, audio=None), logprobs=None)], provider_specific_fields=None, citations=None)
model_response finish reason 3: None; response_obj={'text': '', 'is_finished': False, 'finish_reason': '', 'usage': None, 'index': 0, 'tool_use': None}
model_response.choices[0].delta: Delta(provider_specific_fields=None, content=None, role=None, function_call=None, tool_calls=None, audio=None); completion_obj: {'content': ''}
self.sent_first_chunk: True
completion_obj: {'content': ''}, model_response.choices[0]: StreamingChoices(finish_reason=None, index=0, delta=Delta(provider_specific_fields=None, content=None, role=None, function_call=None, tool_calls=None, audio=None), logprobs=None), response_obj: {'text': '', 'is_finished': False, 'finish_reason': '', 'usage': None, 'index': 0, 'tool_use': None}
model_response finish reason 3: None; response_obj={'text': '', 'is_finished': False, 'finish_reason': '', 'usage': None, 'index': 0, 'tool_use': None}
model_response.choices[0].delta: Delta(provider_specific_fields=None, content=None, role=None, function_call=None, tool_calls=None, audio=None); completion_obj: {'content': ''}
self.sent_first_chunk: True
completion_obj: {'content': ''}, model_response.choices[0]: StreamingChoices(finish_reason=None, index=0, delta=Delta(provider_specific_fields=None, content=None, role=None, function_call=None, tool_calls=None, audio=None), logprobs=None), response_obj: {'text': '', 'is_finished': False, 'finish_reason': '', 'usage': None, 'index': 0, 'tool_use': None}

Raw OpenAI Chunk
ModelResponseStream(id='chatcmpl-1e246dec-1357-4ceb-948f-03d49e55b5f9', created=1762261912, model=None, object='chat.completion.chunk', system_fingerprint=None, choices=[StreamingChoices(finish_reason=None, index=0, delta=Delta(provider_specific_fields=None, content='. **You have', role=None, function_call=None, tool_calls=None, audio=None), logprobs=None)], provider_specific_fields=None, usage=None)

model_response finish reason 3: None; response_obj={'text': '. **You have', 'is_finished': False, 'finish_reason': None, 'logprobs': None, 'original_chunk': ModelResponseStream(id='chatcmpl-1e246dec-1357-4ceb-948f-03d49e55b5f9', created=1762261912, model=None, object='chat.completion.chunk', system_fingerprint=None, choices=[StreamingChoices(finish_reason=None, index=0, delta=Delta(provider_specific_fields=None, content='. **You have', role=None, function_call=None, tool_calls=None, audio=None), logprobs=None)], provider_specific_fields=None, usage=None), 'usage': None}
original delta: {'provider_specific_fields': None, 'content': '. **You have', 'role': None, 'function_call': None, 'tool_calls': None, 'audio': None}
new delta: Delta(provider_specific_fields=None, content='. **You have', role=None, function_call=None, tool_calls=None, audio=None)
model_response.choices[0].delta: Delta(provider_specific_fields=None, content='. **You have', role=None, function_call=None, tool_calls=None, audio=None); completion_obj: {'content': '. **You have'}
self.sent_first_chunk: True
completion_obj: {'content': '. **You have'}, model_response.choices[0]: StreamingChoices(finish_reason=None, index=0, delta=Delta(provider_specific_fields=None, content='. **You have', role=None, function_call=None, tool_calls=None, audio=None), logprobs=None), response_obj: {'text': '. **You have', 'is_finished': False, 'finish_reason': None, 'logprobs': None, 'original_chunk': ModelResponseStream(id='chatcmpl-1e246dec-1357-4ceb-948f-03d49e55b5f9', created=1762261912, model=None, object='chat.completion.chunk', system_fingerprint=None, choices=[StreamingChoices(finish_reason=None, index=0, delta=Delta(provider_specific_fields=None, content='. **You have', role=None, function_call=None, tool_calls=None, audio=None), logprobs=None)], provider_specific_fields=None, usage=None), 'usage': None}
choice_json: {'index': 0, 'delta': {'provider_specific_fields': None, 'content': '. **You have', 'role': None, 'function_call': None, 'tool_calls': None, 'audio': None}, 'logprobs': None}
choices in streaming: [StreamingChoices(finish_reason=None, index=0, delta=Delta(provider_specific_fields=None, content='. **You have', role=None, function_call=None, tool_calls=None, audio=None), logprobs=None)]
final returned processed chunk: ModelResponseStream(id='chatcmpl-1e246dec-1357-4ceb-948f-03d49e55b5f9', created=1762261907, model='claude-sonnet-4-5-20250929', object='chat.completion.chunk', system_fingerprint=None, choices=[StreamingChoices(finish_reason=None, index=0, delta=Delta(provider_specific_fields=None, content='. **You have', role=None, function_call=None, tool_calls=None, audio=None), logprobs=None)], provider_specific_fields=None, citations=None)
model_response finish reason 3: None; response_obj={'text': '', 'is_finished': False, 'finish_reason': '', 'usage': None, 'index': 0, 'tool_use': None}
model_response.choices[0].delta: Delta(provider_specific_fields=None, content=None, role=None, function_call=None, tool_calls=None, audio=None); completion_obj: {'content': ''}
self.sent_first_chunk: True
completion_obj: {'content': ''}, model_response.choices[0]: StreamingChoices(finish_reason=None, index=0, delta=Delta(provider_specific_fields=None, content=None, role=None, function_call=None, tool_calls=None, audio=None), logprobs=None), response_obj: {'text': '', 'is_finished': False, 'finish_reason': '', 'usage': None, 'index': 0, 'tool_use': None}
model_response finish reason 3: None; response_obj={'text': '', 'is_finished': False, 'finish_reason': '', 'usage': None, 'index': 0, 'tool_use': None}
model_response.choices[0].delta: Delta(provider_specific_fields=None, content=None, role=None, function_call=None, tool_calls=None, audio=None); completion_obj: {'content': ''}
self.sent_first_chunk: True
completion_obj: {'content': ''}, model_response.choices[0]: StreamingChoices(finish_reason=None, index=0, delta=Delta(provider_specific_fields=None, content=None, role=None, function_call=None, tool_calls=None, audio=None), logprobs=None), response_obj: {'text': '', 'is_finished': False, 'finish_reason': '', 'usage': None, 'index': 0, 'tool_use': None}

Raw OpenAI Chunk
ModelResponseStream(id='chatcmpl-1e246dec-1357-4ceb-948f-03d49e55b5f9', created=1762261912, model=None, object='chat.completion.chunk', system_fingerprint=None, choices=[StreamingChoices(finish_reason=None, index=0, delta=Delta(provider_specific_fields=None, content=' multiple', role=None, function_call=None, tool_calls=None, audio=None), logprobs=None)], provider_specific_fields=None, usage=None)

model_response finish reason 3: None; response_obj={'text': ' multiple', 'is_finished': False, 'finish_reason': None, 'logprobs': None, 'original_chunk': ModelResponseStream(id='chatcmpl-1e246dec-1357-4ceb-948f-03d49e55b5f9', created=1762261912, model=None, object='chat.completion.chunk', system_fingerprint=None, choices=[StreamingChoices(finish_reason=None, index=0, delta=Delta(provider_specific_fields=None, content=' multiple', role=None, function_call=None, tool_calls=None, audio=None), logprobs=None)], provider_specific_fields=None, usage=None), 'usage': None}
original delta: {'provider_specific_fields': None, 'content': ' multiple', 'role': None, 'function_call': None, 'tool_calls': None, 'audio': None}
new delta: Delta(provider_specific_fields=None, content=' multiple', role=None, function_call=None, tool_calls=None, audio=None)
model_response.choices[0].delta: Delta(provider_specific_fields=None, content=' multiple', role=None, function_call=None, tool_calls=None, audio=None); completion_obj: {'content': ' multiple'}
self.sent_first_chunk: True
completion_obj: {'content': ' multiple'}, model_response.choices[0]: StreamingChoices(finish_reason=None, index=0, delta=Delta(provider_specific_fields=None, content=' multiple', role=None, function_call=None, tool_calls=None, audio=None), logprobs=None), response_obj: {'text': ' multiple', 'is_finished': False, 'finish_reason': None, 'logprobs': None, 'original_chunk': ModelResponseStream(id='chatcmpl-1e246dec-1357-4ceb-948f-03d49e55b5f9', created=1762261912, model=None, object='chat.completion.chunk', system_fingerprint=None, choices=[StreamingChoices(finish_reason=None, index=0, delta=Delta(provider_specific_fields=None, content=' multiple', role=None, function_call=None, tool_calls=None, audio=None), logprobs=None)], provider_specific_fields=None, usage=None), 'usage': None}
choice_json: {'index': 0, 'delta': {'provider_specific_fields': None, 'content': ' multiple', 'role': None, 'function_call': None, 'tool_calls': None, 'audio': None}, 'logprobs': None}
choices in streaming: [StreamingChoices(finish_reason=None, index=0, delta=Delta(provider_specific_fields=None, content=' multiple', role=None, function_call=None, tool_calls=None, audio=None), logprobs=None)]
final returned processed chunk: ModelResponseStream(id='chatcmpl-1e246dec-1357-4ceb-948f-03d49e55b5f9', created=1762261907, model='claude-sonnet-4-5-20250929', object='chat.completion.chunk', system_fingerprint=None, choices=[StreamingChoices(finish_reason=None, index=0, delta=Delta(provider_specific_fields=None, content=' multiple', role=None, function_call=None, tool_calls=None, audio=None), logprobs=None)], provider_specific_fields=None, citations=None)
model_response finish reason 3: None; response_obj={'text': '', 'is_finished': False, 'finish_reason': '', 'usage': None, 'index': 0, 'tool_use': None}
model_response.choices[0].delta: Delta(provider_specific_fields=None, content=None, role=None, function_call=None, tool_calls=None, audio=None); completion_obj: {'content': ''}
self.sent_first_chunk: True
completion_obj: {'content': ''}, model_response.choices[0]: StreamingChoices(finish_reason=None, index=0, delta=Delta(provider_specific_fields=None, content=None, role=None, function_call=None, tool_calls=None, audio=None), logprobs=None), response_obj: {'text': '', 'is_finished': False, 'finish_reason': '', 'usage': None, 'index': 0, 'tool_use': None}
model_response finish reason 3: None; response_obj={'text': '', 'is_finished': False, 'finish_reason': '', 'usage': None, 'index': 0, 'tool_use': None}
model_response.choices[0].delta: Delta(provider_specific_fields=None, content=None, role=None, function_call=None, tool_calls=None, audio=None); completion_obj: {'content': ''}
self.sent_first_chunk: True
completion_obj: {'content': ''}, model_response.choices[0]: StreamingChoices(finish_reason=None, index=0, delta=Delta(provider_specific_fields=None, content=None, role=None, function_call=None, tool_calls=None, audio=None), logprobs=None), response_obj: {'text': '', 'is_finished': False, 'finish_reason': '', 'usage': None, 'index': 0, 'tool_use': None}

Raw OpenAI Chunk
ModelResponseStream(id='chatcmpl-1e246dec-1357-4ceb-948f-03d49e55b5f9', created=1762261912, model=None, object='chat.completion.chunk', system_fingerprint=None, choices=[StreamingChoices(finish_reason=None, index=0, delta=Delta(provider_specific_fields=None, content=' proxy', role=None, function_call=None, tool_calls=None, audio=None), logprobs=None)], provider_specific_fields=None, usage=None)

model_response finish reason 3: None; response_obj={'text': ' proxy', 'is_finished': False, 'finish_reason': None, 'logprobs': None, 'original_chunk': ModelResponseStream(id='chatcmpl-1e246dec-1357-4ceb-948f-03d49e55b5f9', created=1762261912, model=None, object='chat.completion.chunk', system_fingerprint=None, choices=[StreamingChoices(finish_reason=None, index=0, delta=Delta(provider_specific_fields=None, content=' proxy', role=None, function_call=None, tool_calls=None, audio=None), logprobs=None)], provider_specific_fields=None, usage=None), 'usage': None}
original delta: {'provider_specific_fields': None, 'content': ' proxy', 'role': None, 'function_call': None, 'tool_calls': None, 'audio': None}
new delta: Delta(provider_specific_fields=None, content=' proxy', role=None, function_call=None, tool_calls=None, audio=None)
model_response.choices[0].delta: Delta(provider_specific_fields=None, content=' proxy', role=None, function_call=None, tool_calls=None, audio=None); completion_obj: {'content': ' proxy'}
self.sent_first_chunk: True
completion_obj: {'content': ' proxy'}, model_response.choices[0]: StreamingChoices(finish_reason=None, index=0, delta=Delta(provider_specific_fields=None, content=' proxy', role=None, function_call=None, tool_calls=None, audio=None), logprobs=None), response_obj: {'text': ' proxy', 'is_finished': False, 'finish_reason': None, 'logprobs': None, 'original_chunk': ModelResponseStream(id='chatcmpl-1e246dec-1357-4ceb-948f-03d49e55b5f9', created=1762261912, model=None, object='chat.completion.chunk', system_fingerprint=None, choices=[StreamingChoices(finish_reason=None, index=0, delta=Delta(provider_specific_fields=None, content=' proxy', role=None, function_call=None, tool_calls=None, audio=None), logprobs=None)], provider_specific_fields=None, usage=None), 'usage': None}
choice_json: {'index': 0, 'delta': {'provider_specific_fields': None, 'content': ' proxy', 'role': None, 'function_call': None, 'tool_calls': None, 'audio': None}, 'logprobs': None}
choices in streaming: [StreamingChoices(finish_reason=None, index=0, delta=Delta(provider_specific_fields=None, content=' proxy', role=None, function_call=None, tool_calls=None, audio=None), logprobs=None)]
final returned processed chunk: ModelResponseStream(id='chatcmpl-1e246dec-1357-4ceb-948f-03d49e55b5f9', created=1762261907, model='claude-sonnet-4-5-20250929', object='chat.completion.chunk', system_fingerprint=None, choices=[StreamingChoices(finish_reason=None, index=0, delta=Delta(provider_specific_fields=None, content=' proxy', role=None, function_call=None, tool_calls=None, audio=None), logprobs=None)], provider_specific_fields=None, citations=None)
model_response finish reason 3: None; response_obj={'text': '', 'is_finished': False, 'finish_reason': '', 'usage': None, 'index': 0, 'tool_use': None}
model_response.choices[0].delta: Delta(provider_specific_fields=None, content=None, role=None, function_call=None, tool_calls=None, audio=None); completion_obj: {'content': ''}
self.sent_first_chunk: True
completion_obj: {'content': ''}, model_response.choices[0]: StreamingChoices(finish_reason=None, index=0, delta=Delta(provider_specific_fields=None, content=None, role=None, function_call=None, tool_calls=None, audio=None), logprobs=None), response_obj: {'text': '', 'is_finished': False, 'finish_reason': '', 'usage': None, 'index': 0, 'tool_use': None}
model_response finish reason 3: None; response_obj={'text': '', 'is_finished': False, 'finish_reason': '', 'usage': None, 'index': 0, 'tool_use': None}
model_response.choices[0].delta: Delta(provider_specific_fields=None, content=None, role=None, function_call=None, tool_calls=None, audio=None); completion_obj: {'content': ''}
self.sent_first_chunk: True
completion_obj: {'content': ''}, model_response.choices[0]: StreamingChoices(finish_reason=None, index=0, delta=Delta(provider_specific_fields=None, content=None, role=None, function_call=None, tool_calls=None, audio=None), logprobs=None), response_obj: {'text': '', 'is_finished': False, 'finish_reason': '', 'usage': None, 'index': 0, 'tool_use': None}

Raw OpenAI Chunk
ModelResponseStream(id='chatcmpl-1e246dec-1357-4ceb-948f-03d49e55b5f9', created=1762261912, model=None, object='chat.completion.chunk', system_fingerprint=None, choices=[StreamingChoices(finish_reason=None, index=0, delta=Delta(provider_specific_fields=None, content=' modes', role=None, function_call=None, tool_calls=None, audio=None), logprobs=None)], provider_specific_fields=None, usage=None)

model_response finish reason 3: None; response_obj={'text': ' modes', 'is_finished': False, 'finish_reason': None, 'logprobs': None, 'original_chunk': ModelResponseStream(id='chatcmpl-1e246dec-1357-4ceb-948f-03d49e55b5f9', created=1762261912, model=None, object='chat.completion.chunk', system_fingerprint=None, choices=[StreamingChoices(finish_reason=None, index=0, delta=Delta(provider_specific_fields=None, content=' modes', role=None, function_call=None, tool_calls=None, audio=None), logprobs=None)], provider_specific_fields=None, usage=None), 'usage': None}
original delta: {'provider_specific_fields': None, 'content': ' modes', 'role': None, 'function_call': None, 'tool_calls': None, 'audio': None}
new delta: Delta(provider_specific_fields=None, content=' modes', role=None, function_call=None, tool_calls=None, audio=None)
model_response.choices[0].delta: Delta(provider_specific_fields=None, content=' modes', role=None, function_call=None, tool_calls=None, audio=None); completion_obj: {'content': ' modes'}
self.sent_first_chunk: True
completion_obj: {'content': ' modes'}, model_response.choices[0]: StreamingChoices(finish_reason=None, index=0, delta=Delta(provider_specific_fields=None, content=' modes', role=None, function_call=None, tool_calls=None, audio=None), logprobs=None), response_obj: {'text': ' modes', 'is_finished': False, 'finish_reason': None, 'logprobs': None, 'original_chunk': ModelResponseStream(id='chatcmpl-1e246dec-1357-4ceb-948f-03d49e55b5f9', created=1762261912, model=None, object='chat.completion.chunk', system_fingerprint=None, choices=[StreamingChoices(finish_reason=None, index=0, delta=Delta(provider_specific_fields=None, content=' modes', role=None, function_call=None, tool_calls=None, audio=None), logprobs=None)], provider_specific_fields=None, usage=None), 'usage': None}
choice_json: {'index': 0, 'delta': {'provider_specific_fields': None, 'content': ' modes', 'role': None, 'function_call': None, 'tool_calls': None, 'audio': None}, 'logprobs': None}
choices in streaming: [StreamingChoices(finish_reason=None, index=0, delta=Delta(provider_specific_fields=None, content=' modes', role=None, function_call=None, tool_calls=None, audio=None), logprobs=None)]
final returned processed chunk: ModelResponseStream(id='chatcmpl-1e246dec-1357-4ceb-948f-03d49e55b5f9', created=1762261907, model='claude-sonnet-4-5-20250929', object='chat.completion.chunk', system_fingerprint=None, choices=[StreamingChoices(finish_reason=None, index=0, delta=Delta(provider_specific_fields=None, content=' modes', role=None, function_call=None, tool_calls=None, audio=None), logprobs=None)], provider_specific_fields=None, citations=None)
model_response finish reason 3: None; response_obj={'text': '', 'is_finished': False, 'finish_reason': '', 'usage': None, 'index': 0, 'tool_use': None}
model_response.choices[0].delta: Delta(provider_specific_fields=None, content=None, role=None, function_call=None, tool_calls=None, audio=None); completion_obj: {'content': ''}
self.sent_first_chunk: True
completion_obj: {'content': ''}, model_response.choices[0]: StreamingChoices(finish_reason=None, index=0, delta=Delta(provider_specific_fields=None, content=None, role=None, function_call=None, tool_calls=None, audio=None), logprobs=None), response_obj: {'text': '', 'is_finished': False, 'finish_reason': '', 'usage': None, 'index': 0, 'tool_use': None}
model_response finish reason 3: None; response_obj={'text': '', 'is_finished': False, 'finish_reason': '', 'usage': None, 'index': 0, 'tool_use': None}
model_response.choices[0].delta: Delta(provider_specific_fields=None, content=None, role=None, function_call=None, tool_calls=None, audio=None); completion_obj: {'content': ''}
self.sent_first_chunk: True
completion_obj: {'content': ''}, model_response.choices[0]: StreamingChoices(finish_reason=None, index=0, delta=Delta(provider_specific_fields=None, content=None, role=None, function_call=None, tool_calls=None, audio=None), logprobs=None), response_obj: {'text': '', 'is_finished': False, 'finish_reason': '', 'usage': None, 'index': 0, 'tool_use': None}

Raw OpenAI Chunk
ModelResponseStream(id='chatcmpl-1e246dec-1357-4ceb-948f-03d49e55b5f9', created=1762261912, model=None, object='chat.completion.chunk', system_fingerprint=None, choices=[StreamingChoices(finish_reason=None, index=0, delta=Delta(provider_specific_fields=None, content='**:', role=None, function_call=None, tool_calls=None, audio=None), logprobs=None)], provider_specific_fields=None, usage=None)

model_response finish reason 3: None; response_obj={'text': '**:', 'is_finished': False, 'finish_reason': None, 'logprobs': None, 'original_chunk': ModelResponseStream(id='chatcmpl-1e246dec-1357-4ceb-948f-03d49e55b5f9', created=1762261912, model=None, object='chat.completion.chunk', system_fingerprint=None, choices=[StreamingChoices(finish_reason=None, index=0, delta=Delta(provider_specific_fields=None, content='**:', role=None, function_call=None, tool_calls=None, audio=None), logprobs=None)], provider_specific_fields=None, usage=None), 'usage': None}
original delta: {'provider_specific_fields': None, 'content': '**:', 'role': None, 'function_call': None, 'tool_calls': None, 'audio': None}
new delta: Delta(provider_specific_fields=None, content='**:', role=None, function_call=None, tool_calls=None, audio=None)
model_response.choices[0].delta: Delta(provider_specific_fields=None, content='**:', role=None, function_call=None, tool_calls=None, audio=None); completion_obj: {'content': '**:'}
self.sent_first_chunk: True
completion_obj: {'content': '**:'}, model_response.choices[0]: StreamingChoices(finish_reason=None, index=0, delta=Delta(provider_specific_fields=None, content='**:', role=None, function_call=None, tool_calls=None, audio=None), logprobs=None), response_obj: {'text': '**:', 'is_finished': False, 'finish_reason': None, 'logprobs': None, 'original_chunk': ModelResponseStream(id='chatcmpl-1e246dec-1357-4ceb-948f-03d49e55b5f9', created=1762261912, model=None, object='chat.completion.chunk', system_fingerprint=None, choices=[StreamingChoices(finish_reason=None, index=0, delta=Delta(provider_specific_fields=None, content='**:', role=None, function_call=None, tool_calls=None, audio=None), logprobs=None)], provider_specific_fields=None, usage=None), 'usage': None}
choice_json: {'index': 0, 'delta': {'provider_specific_fields': None, 'content': '**:', 'role': None, 'function_call': None, 'tool_calls': None, 'audio': None}, 'logprobs': None}
choices in streaming: [StreamingChoices(finish_reason=None, index=0, delta=Delta(provider_specific_fields=None, content='**:', role=None, function_call=None, tool_calls=None, audio=None), logprobs=None)]
final returned processed chunk: ModelResponseStream(id='chatcmpl-1e246dec-1357-4ceb-948f-03d49e55b5f9', created=1762261907, model='claude-sonnet-4-5-20250929', object='chat.completion.chunk', system_fingerprint=None, choices=[StreamingChoices(finish_reason=None, index=0, delta=Delta(provider_specific_fields=None, content='**:', role=None, function_call=None, tool_calls=None, audio=None), logprobs=None)], provider_specific_fields=None, citations=None)
model_response finish reason 3: None; response_obj={'text': '', 'is_finished': False, 'finish_reason': '', 'usage': None, 'index': 0, 'tool_use': None}
model_response.choices[0].delta: Delta(provider_specific_fields=None, content=None, role=None, function_call=None, tool_calls=None, audio=None); completion_obj: {'content': ''}
self.sent_first_chunk: True
completion_obj: {'content': ''}, model_response.choices[0]: StreamingChoices(finish_reason=None, index=0, delta=Delta(provider_specific_fields=None, content=None, role=None, function_call=None, tool_calls=None, audio=None), logprobs=None), response_obj: {'text': '', 'is_finished': False, 'finish_reason': '', 'usage': None, 'index': 0, 'tool_use': None}
model_response finish reason 3: None; response_obj={'text': '', 'is_finished': False, 'finish_reason': '', 'usage': None, 'index': 0, 'tool_use': None}
model_response.choices[0].delta: Delta(provider_specific_fields=None, content=None, role=None, function_call=None, tool_calls=None, audio=None); completion_obj: {'content': ''}
self.sent_first_chunk: True
completion_obj: {'content': ''}, model_response.choices[0]: StreamingChoices(finish_reason=None, index=0, delta=Delta(provider_specific_fields=None, content=None, role=None, function_call=None, tool_calls=None, audio=None), logprobs=None), response_obj: {'text': '', 'is_finished': False, 'finish_reason': '', 'usage': None, 'index': 0, 'tool_use': None}

Raw OpenAI Chunk
ModelResponseStream(id='chatcmpl-1e246dec-1357-4ceb-948f-03d49e55b5f9', created=1762261912, model=None, object='chat.completion.chunk', system_fingerprint=None, choices=[StreamingChoices(finish_reason=None, index=0, delta=Delta(provider_specific_fields=None, content=' Binary', role=None, function_call=None, tool_calls=None, audio=None), logprobs=None)], provider_specific_fields=None, usage=None)

model_response finish reason 3: None; response_obj={'text': ' Binary', 'is_finished': False, 'finish_reason': None, 'logprobs': None, 'original_chunk': ModelResponseStream(id='chatcmpl-1e246dec-1357-4ceb-948f-03d49e55b5f9', created=1762261912, model=None, object='chat.completion.chunk', system_fingerprint=None, choices=[StreamingChoices(finish_reason=None, index=0, delta=Delta(provider_specific_fields=None, content=' Binary', role=None, function_call=None, tool_calls=None, audio=None), logprobs=None)], provider_specific_fields=None, usage=None), 'usage': None}
original delta: {'provider_specific_fields': None, 'content': ' Binary', 'role': None, 'function_call': None, 'tool_calls': None, 'audio': None}
new delta: Delta(provider_specific_fields=None, content=' Binary', role=None, function_call=None, tool_calls=None, audio=None)
model_response.choices[0].delta: Delta(provider_specific_fields=None, content=' Binary', role=None, function_call=None, tool_calls=None, audio=None); completion_obj: {'content': ' Binary'}
self.sent_first_chunk: True
completion_obj: {'content': ' Binary'}, model_response.choices[0]: StreamingChoices(finish_reason=None, index=0, delta=Delta(provider_specific_fields=None, content=' Binary', role=None, function_call=None, tool_calls=None, audio=None), logprobs=None), response_obj: {'text': ' Binary', 'is_finished': False, 'finish_reason': None, 'logprobs': None, 'original_chunk': ModelResponseStream(id='chatcmpl-1e246dec-1357-4ceb-948f-03d49e55b5f9', created=1762261912, model=None, object='chat.completion.chunk', system_fingerprint=None, choices=[StreamingChoices(finish_reason=None, index=0, delta=Delta(provider_specific_fields=None, content=' Binary', role=None, function_call=None, tool_calls=None, audio=None), logprobs=None)], provider_specific_fields=None, usage=None), 'usage': None}
choice_json: {'index': 0, 'delta': {'provider_specific_fields': None, 'content': ' Binary', 'role': None, 'function_call': None, 'tool_calls': None, 'audio': None}, 'logprobs': None}
choices in streaming: [StreamingChoices(finish_reason=None, index=0, delta=Delta(provider_specific_fields=None, content=' Binary', role=None, function_call=None, tool_calls=None, audio=None), logprobs=None)]
final returned processed chunk: ModelResponseStream(id='chatcmpl-1e246dec-1357-4ceb-948f-03d49e55b5f9', created=1762261907, model='claude-sonnet-4-5-20250929', object='chat.completion.chunk', system_fingerprint=None, choices=[StreamingChoices(finish_reason=None, index=0, delta=Delta(provider_specific_fields=None, content=' Binary', role=None, function_call=None, tool_calls=None, audio=None), logprobs=None)], provider_specific_fields=None, citations=None)
model_response finish reason 3: None; response_obj={'text': '', 'is_finished': False, 'finish_reason': '', 'usage': None, 'index': 0, 'tool_use': None}
model_response.choices[0].delta: Delta(provider_specific_fields=None, content=None, role=None, function_call=None, tool_calls=None, audio=None); completion_obj: {'content': ''}
self.sent_first_chunk: True
completion_obj: {'content': ''}, model_response.choices[0]: StreamingChoices(finish_reason=None, index=0, delta=Delta(provider_specific_fields=None, content=None, role=None, function_call=None, tool_calls=None, audio=None), logprobs=None), response_obj: {'text': '', 'is_finished': False, 'finish_reason': '', 'usage': None, 'index': 0, 'tool_use': None}
model_response finish reason 3: None; response_obj={'text': '', 'is_finished': False, 'finish_reason': '', 'usage': None, 'index': 0, 'tool_use': None}
model_response.choices[0].delta: Delta(provider_specific_fields=None, content=None, role=None, function_call=None, tool_calls=None, audio=None); completion_obj: {'content': ''}
self.sent_first_chunk: True
completion_obj: {'content': ''}, model_response.choices[0]: StreamingChoices(finish_reason=None, index=0, delta=Delta(provider_specific_fields=None, content=None, role=None, function_call=None, tool_calls=None, audio=None), logprobs=None), response_obj: {'text': '', 'is_finished': False, 'finish_reason': '', 'usage': None, 'index': 0, 'tool_use': None}

Raw OpenAI Chunk
ModelResponseStream(id='chatcmpl-1e246dec-1357-4ceb-948f-03d49e55b5f9', created=1762261912, model=None, object='chat.completion.chunk', system_fingerprint=None, choices=[StreamingChoices(finish_reason=None, index=0, delta=Delta(provider_specific_fields=None, content=',', role=None, function_call=None, tool_calls=None, audio=None), logprobs=None)], provider_specific_fields=None, usage=None)

model_response finish reason 3: None; response_obj={'text': ',', 'is_finished': False, 'finish_reason': None, 'logprobs': None, 'original_chunk': ModelResponseStream(id='chatcmpl-1e246dec-1357-4ceb-948f-03d49e55b5f9', created=1762261912, model=None, object='chat.completion.chunk', system_fingerprint=None, choices=[StreamingChoices(finish_reason=None, index=0, delta=Delta(provider_specific_fields=None, content=',', role=None, function_call=None, tool_calls=None, audio=None), logprobs=None)], provider_specific_fields=None, usage=None), 'usage': None}
original delta: {'provider_specific_fields': None, 'content': ',', 'role': None, 'function_call': None, 'tool_calls': None, 'audio': None}
new delta: Delta(provider_specific_fields=None, content=',', role=None, function_call=None, tool_calls=None, audio=None)
model_response.choices[0].delta: Delta(provider_specific_fields=None, content=',', role=None, function_call=None, tool_calls=None, audio=None); completion_obj: {'content': ','}
self.sent_first_chunk: True
completion_obj: {'content': ','}, model_response.choices[0]: StreamingChoices(finish_reason=None, index=0, delta=Delta(provider_specific_fields=None, content=',', role=None, function_call=None, tool_calls=None, audio=None), logprobs=None), response_obj: {'text': ',', 'is_finished': False, 'finish_reason': None, 'logprobs': None, 'original_chunk': ModelResponseStream(id='chatcmpl-1e246dec-1357-4ceb-948f-03d49e55b5f9', created=1762261912, model=None, object='chat.completion.chunk', system_fingerprint=None, choices=[StreamingChoices(finish_reason=None, index=0, delta=Delta(provider_specific_fields=None, content=',', role=None, function_call=None, tool_calls=None, audio=None), logprobs=None)], provider_specific_fields=None, usage=None), 'usage': None}
choice_json: {'index': 0, 'delta': {'provider_specific_fields': None, 'content': ',', 'role': None, 'function_call': None, 'tool_calls': None, 'audio': None}, 'logprobs': None}
choices in streaming: [StreamingChoices(finish_reason=None, index=0, delta=Delta(provider_specific_fields=None, content=',', role=None, function_call=None, tool_calls=None, audio=None), logprobs=None)]
final returned processed chunk: ModelResponseStream(id='chatcmpl-1e246dec-1357-4ceb-948f-03d49e55b5f9', created=1762261907, model='claude-sonnet-4-5-20250929', object='chat.completion.chunk', system_fingerprint=None, choices=[StreamingChoices(finish_reason=None, index=0, delta=Delta(provider_specific_fields=None, content=',', role=None, function_call=None, tool_calls=None, audio=None), logprobs=None)], provider_specific_fields=None, citations=None)
model_response finish reason 3: None; response_obj={'text': '', 'is_finished': False, 'finish_reason': '', 'usage': None, 'index': 0, 'tool_use': None}
model_response.choices[0].delta: Delta(provider_specific_fields=None, content=None, role=None, function_call=None, tool_calls=None, audio=None); completion_obj: {'content': ''}
self.sent_first_chunk: True
completion_obj: {'content': ''}, model_response.choices[0]: StreamingChoices(finish_reason=None, index=0, delta=Delta(provider_specific_fields=None, content=None, role=None, function_call=None, tool_calls=None, audio=None), logprobs=None), response_obj: {'text': '', 'is_finished': False, 'finish_reason': '', 'usage': None, 'index': 0, 'tool_use': None}
model_response finish reason 3: None; response_obj={'text': '', 'is_finished': False, 'finish_reason': '', 'usage': None, 'index': 0, 'tool_use': None}
model_response.choices[0].delta: Delta(provider_specific_fields=None, content=None, role=None, function_call=None, tool_calls=None, audio=None); completion_obj: {'content': ''}
self.sent_first_chunk: True
completion_obj: {'content': ''}, model_response.choices[0]: StreamingChoices(finish_reason=None, index=0, delta=Delta(provider_specific_fields=None, content=None, role=None, function_call=None, tool_calls=None, audio=None), logprobs=None), response_obj: {'text': '', 'is_finished': False, 'finish_reason': '', 'usage': None, 'index': 0, 'tool_use': None}

Raw OpenAI Chunk
ModelResponseStream(id='chatcmpl-1e246dec-1357-4ceb-948f-03d49e55b5f9', created=1762261912, model=None, object='chat.completion.chunk', system_fingerprint=None, choices=[StreamingChoices(finish_reason=None, index=0, delta=Delta(provider_specific_fields=None, content=' SDK', role=None, function_call=None, tool_calls=None, audio=None), logprobs=None)], provider_specific_fields=None, usage=None)

model_response finish reason 3: None; response_obj={'text': ' SDK', 'is_finished': False, 'finish_reason': None, 'logprobs': None, 'original_chunk': ModelResponseStream(id='chatcmpl-1e246dec-1357-4ceb-948f-03d49e55b5f9', created=1762261912, model=None, object='chat.completion.chunk', system_fingerprint=None, choices=[StreamingChoices(finish_reason=None, index=0, delta=Delta(provider_specific_fields=None, content=' SDK', role=None, function_call=None, tool_calls=None, audio=None), logprobs=None)], provider_specific_fields=None, usage=None), 'usage': None}
original delta: {'provider_specific_fields': None, 'content': ' SDK', 'role': None, 'function_call': None, 'tool_calls': None, 'audio': None}
new delta: Delta(provider_specific_fields=None, content=' SDK', role=None, function_call=None, tool_calls=None, audio=None)
model_response.choices[0].delta: Delta(provider_specific_fields=None, content=' SDK', role=None, function_call=None, tool_calls=None, audio=None); completion_obj: {'content': ' SDK'}
self.sent_first_chunk: True
completion_obj: {'content': ' SDK'}, model_response.choices[0]: StreamingChoices(finish_reason=None, index=0, delta=Delta(provider_specific_fields=None, content=' SDK', role=None, function_call=None, tool_calls=None, audio=None), logprobs=None), response_obj: {'text': ' SDK', 'is_finished': False, 'finish_reason': None, 'logprobs': None, 'original_chunk': ModelResponseStream(id='chatcmpl-1e246dec-1357-4ceb-948f-03d49e55b5f9', created=1762261912, model=None, object='chat.completion.chunk', system_fingerprint=None, choices=[StreamingChoices(finish_reason=None, index=0, delta=Delta(provider_specific_fields=None, content=' SDK', role=None, function_call=None, tool_calls=None, audio=None), logprobs=None)], provider_specific_fields=None, usage=None), 'usage': None}
choice_json: {'index': 0, 'delta': {'provider_specific_fields': None, 'content': ' SDK', 'role': None, 'function_call': None, 'tool_calls': None, 'audio': None}, 'logprobs': None}
choices in streaming: [StreamingChoices(finish_reason=None, index=0, delta=Delta(provider_specific_fields=None, content=' SDK', role=None, function_call=None, tool_calls=None, audio=None), logprobs=None)]
final returned processed chunk: ModelResponseStream(id='chatcmpl-1e246dec-1357-4ceb-948f-03d49e55b5f9', created=1762261907, model='claude-sonnet-4-5-20250929', object='chat.completion.chunk', system_fingerprint=None, choices=[StreamingChoices(finish_reason=None, index=0, delta=Delta(provider_specific_fields=None, content=' SDK', role=None, function_call=None, tool_calls=None, audio=None), logprobs=None)], provider_specific_fields=None, citations=None)
model_response finish reason 3: None; response_obj={'text': '', 'is_finished': False, 'finish_reason': '', 'usage': None, 'index': 0, 'tool_use': None}
model_response.choices[0].delta: Delta(provider_specific_fields=None, content=None, role=None, function_call=None, tool_calls=None, audio=None); completion_obj: {'content': ''}
self.sent_first_chunk: True
completion_obj: {'content': ''}, model_response.choices[0]: StreamingChoices(finish_reason=None, index=0, delta=Delta(provider_specific_fields=None, content=None, role=None, function_call=None, tool_calls=None, audio=None), logprobs=None), response_obj: {'text': '', 'is_finished': False, 'finish_reason': '', 'usage': None, 'index': 0, 'tool_use': None}
model_response finish reason 3: None; response_obj={'text': '', 'is_finished': False, 'finish_reason': '', 'usage': None, 'index': 0, 'tool_use': None}
model_response.choices[0].delta: Delta(provider_specific_fields=None, content=None, role=None, function_call=None, tool_calls=None, audio=None); completion_obj: {'content': ''}
self.sent_first_chunk: True
completion_obj: {'content': ''}, model_response.choices[0]: StreamingChoices(finish_reason=None, index=0, delta=Delta(provider_specific_fields=None, content=None, role=None, function_call=None, tool_calls=None, audio=None), logprobs=None), response_obj: {'text': '', 'is_finished': False, 'finish_reason': '', 'usage': None, 'index': 0, 'tool_use': None}

Raw OpenAI Chunk
ModelResponseStream(id='chatcmpl-1e246dec-1357-4ceb-948f-03d49e55b5f9', created=1762261912, model=None, object='chat.completion.chunk', system_fingerprint=None, choices=[StreamingChoices(finish_reason=None, index=0, delta=Delta(provider_specific_fields=None, content=', and unifie', role=None, function_call=None, tool_calls=None, audio=None), logprobs=None)], provider_specific_fields=None, usage=None)

model_response finish reason 3: None; response_obj={'text': ', and unifie', 'is_finished': False, 'finish_reason': None, 'logprobs': None, 'original_chunk': ModelResponseStream(id='chatcmpl-1e246dec-1357-4ceb-948f-03d49e55b5f9', created=1762261912, model=None, object='chat.completion.chunk', system_fingerprint=None, choices=[StreamingChoices(finish_reason=None, index=0, delta=Delta(provider_specific_fields=None, content=', and unifie', role=None, function_call=None, tool_calls=None, audio=None), logprobs=None)], provider_specific_fields=None, usage=None), 'usage': None}
original delta: {'provider_specific_fields': None, 'content': ', and unifie', 'role': None, 'function_call': None, 'tool_calls': None, 'audio': None}
new delta: Delta(provider_specific_fields=None, content=', and unifie', role=None, function_call=None, tool_calls=None, audio=None)
model_response.choices[0].delta: Delta(provider_specific_fields=None, content=', and unifie', role=None, function_call=None, tool_calls=None, audio=None); completion_obj: {'content': ', and unifie'}
self.sent_first_chunk: True
completion_obj: {'content': ', and unifie'}, model_response.choices[0]: StreamingChoices(finish_reason=None, index=0, delta=Delta(provider_specific_fields=None, content=', and unifie', role=None, function_call=None, tool_calls=None, audio=None), logprobs=None), response_obj: {'text': ', and unifie', 'is_finished': False, 'finish_reason': None, 'logprobs': None, 'original_chunk': ModelResponseStream(id='chatcmpl-1e246dec-1357-4ceb-948f-03d49e55b5f9', created=1762261912, model=None, object='chat.completion.chunk', system_fingerprint=None, choices=[StreamingChoices(finish_reason=None, index=0, delta=Delta(provider_specific_fields=None, content=', and unifie', role=None, function_call=None, tool_calls=None, audio=None), logprobs=None)], provider_specific_fields=None, usage=None), 'usage': None}
choice_json: {'index': 0, 'delta': {'provider_specific_fields': None, 'content': ', and unifie', 'role': None, 'function_call': None, 'tool_calls': None, 'audio': None}, 'logprobs': None}
choices in streaming: [StreamingChoices(finish_reason=None, index=0, delta=Delta(provider_specific_fields=None, content=', and unifie', role=None, function_call=None, tool_calls=None, audio=None), logprobs=None)]
final returned processed chunk: ModelResponseStream(id='chatcmpl-1e246dec-1357-4ceb-948f-03d49e55b5f9', created=1762261907, model='claude-sonnet-4-5-20250929', object='chat.completion.chunk', system_fingerprint=None, choices=[StreamingChoices(finish_reason=None, index=0, delta=Delta(provider_specific_fields=None, content=', and unifie', role=None, function_call=None, tool_calls=None, audio=None), logprobs=None)], provider_specific_fields=None, citations=None)
model_response finish reason 3: None; response_obj={'text': '', 'is_finished': False, 'finish_reason': '', 'usage': None, 'index': 0, 'tool_use': None}
model_response.choices[0].delta: Delta(provider_specific_fields=None, content=None, role=None, function_call=None, tool_calls=None, audio=None); completion_obj: {'content': ''}
self.sent_first_chunk: True
completion_obj: {'content': ''}, model_response.choices[0]: StreamingChoices(finish_reason=None, index=0, delta=Delta(provider_specific_fields=None, content=None, role=None, function_call=None, tool_calls=None, audio=None), logprobs=None), response_obj: {'text': '', 'is_finished': False, 'finish_reason': '', 'usage': None, 'index': 0, 'tool_use': None}
model_response finish reason 3: None; response_obj={'text': '', 'is_finished': False, 'finish_reason': '', 'usage': None, 'index': 0, 'tool_use': None}
model_response.choices[0].delta: Delta(provider_specific_fields=None, content=None, role=None, function_call=None, tool_calls=None, audio=None); completion_obj: {'content': ''}
self.sent_first_chunk: True
completion_obj: {'content': ''}, model_response.choices[0]: StreamingChoices(finish_reason=None, index=0, delta=Delta(provider_specific_fields=None, content=None, role=None, function_call=None, tool_calls=None, audio=None), logprobs=None), response_obj: {'text': '', 'is_finished': False, 'finish_reason': '', 'usage': None, 'index': 0, 'tool_use': None}

Raw OpenAI Chunk
ModelResponseStream(id='chatcmpl-1e246dec-1357-4ceb-948f-03d49e55b5f9', created=1762261912, model=None, object='chat.completion.chunk', system_fingerprint=None, choices=[StreamingChoices(finish_reason=None, index=0, delta=Delta(provider_specific_fields=None, content='d launcher', role=None, function_call=None, tool_calls=None, audio=None), logprobs=None)], provider_specific_fields=None, usage=None)

model_response finish reason 3: None; response_obj={'text': 'd launcher', 'is_finished': False, 'finish_reason': None, 'logprobs': None, 'original_chunk': ModelResponseStream(id='chatcmpl-1e246dec-1357-4ceb-948f-03d49e55b5f9', created=1762261912, model=None, object='chat.completion.chunk', system_fingerprint=None, choices=[StreamingChoices(finish_reason=None, index=0, delta=Delta(provider_specific_fields=None, content='d launcher', role=None, function_call=None, tool_calls=None, audio=None), logprobs=None)], provider_specific_fields=None, usage=None), 'usage': None}
original delta: {'provider_specific_fields': None, 'content': 'd launcher', 'role': None, 'function_call': None, 'tool_calls': None, 'audio': None}
new delta: Delta(provider_specific_fields=None, content='d launcher', role=None, function_call=None, tool_calls=None, audio=None)
model_response.choices[0].delta: Delta(provider_specific_fields=None, content='d launcher', role=None, function_call=None, tool_calls=None, audio=None); completion_obj: {'content': 'd launcher'}
self.sent_first_chunk: True
completion_obj: {'content': 'd launcher'}, model_response.choices[0]: StreamingChoices(finish_reason=None, index=0, delta=Delta(provider_specific_fields=None, content='d launcher', role=None, function_call=None, tool_calls=None, audio=None), logprobs=None), response_obj: {'text': 'd launcher', 'is_finished': False, 'finish_reason': None, 'logprobs': None, 'original_chunk': ModelResponseStream(id='chatcmpl-1e246dec-1357-4ceb-948f-03d49e55b5f9', created=1762261912, model=None, object='chat.completion.chunk', system_fingerprint=None, choices=[StreamingChoices(finish_reason=None, index=0, delta=Delta(provider_specific_fields=None, content='d launcher', role=None, function_call=None, tool_calls=None, audio=None), logprobs=None)], provider_specific_fields=None, usage=None), 'usage': None}
choice_json: {'index': 0, 'delta': {'provider_specific_fields': None, 'content': 'd launcher', 'role': None, 'function_call': None, 'tool_calls': None, 'audio': None}, 'logprobs': None}
choices in streaming: [StreamingChoices(finish_reason=None, index=0, delta=Delta(provider_specific_fields=None, content='d launcher', role=None, function_call=None, tool_calls=None, audio=None), logprobs=None)]
final returned processed chunk: ModelResponseStream(id='chatcmpl-1e246dec-1357-4ceb-948f-03d49e55b5f9', created=1762261907, model='claude-sonnet-4-5-20250929', object='chat.completion.chunk', system_fingerprint=None, choices=[StreamingChoices(finish_reason=None, index=0, delta=Delta(provider_specific_fields=None, content='d launcher', role=None, function_call=None, tool_calls=None, audio=None), logprobs=None)], provider_specific_fields=None, citations=None)
model_response finish reason 3: None; response_obj={'text': '', 'is_finished': False, 'finish_reason': '', 'usage': None, 'index': 0, 'tool_use': None}
model_response.choices[0].delta: Delta(provider_specific_fields=None, content=None, role=None, function_call=None, tool_calls=None, audio=None); completion_obj: {'content': ''}
self.sent_first_chunk: True
completion_obj: {'content': ''}, model_response.choices[0]: StreamingChoices(finish_reason=None, index=0, delta=Delta(provider_specific_fields=None, content=None, role=None, function_call=None, tool_calls=None, audio=None), logprobs=None), response_obj: {'text': '', 'is_finished': False, 'finish_reason': '', 'usage': None, 'index': 0, 'tool_use': None}
model_response finish reason 3: None; response_obj={'text': '', 'is_finished': False, 'finish_reason': '', 'usage': None, 'index': 0, 'tool_use': None}
model_response.choices[0].delta: Delta(provider_specific_fields=None, content=None, role=None, function_call=None, tool_calls=None, audio=None); completion_obj: {'content': ''}
self.sent_first_chunk: True
completion_obj: {'content': ''}, model_response.choices[0]: StreamingChoices(finish_reason=None, index=0, delta=Delta(provider_specific_fields=None, content=None, role=None, function_call=None, tool_calls=None, audio=None), logprobs=None), response_obj: {'text': '', 'is_finished': False, 'finish_reason': '', 'usage': None, 'index': 0, 'tool_use': None}

Raw OpenAI Chunk
ModelResponseStream(id='chatcmpl-1e246dec-1357-4ceb-948f-03d49e55b5f9', created=1762261913, model=None, object='chat.completion.chunk', system_fingerprint=None, choices=[StreamingChoices(finish_reason=None, index=0, delta=Delta(provider_specific_fields=None, content="\n5. **You're concerne", role=None, function_call=None, tool_calls=None, audio=None), logprobs=None)], provider_specific_fields=None, usage=None)

model_response finish reason 3: None; response_obj={'text': "\n5. **You're concerne", 'is_finished': False, 'finish_reason': None, 'logprobs': None, 'original_chunk': ModelResponseStream(id='chatcmpl-1e246dec-1357-4ceb-948f-03d49e55b5f9', created=1762261913, model=None, object='chat.completion.chunk', system_fingerprint=None, choices=[StreamingChoices(finish_reason=None, index=0, delta=Delta(provider_specific_fields=None, content="\n5. **You're concerne", role=None, function_call=None, tool_calls=None, audio=None), logprobs=None)], provider_specific_fields=None, usage=None), 'usage': None}
original delta: {'provider_specific_fields': None, 'content': "\n5. **You're concerne", 'role': None, 'function_call': None, 'tool_calls': None, 'audio': None}
new delta: Delta(provider_specific_fields=None, content="\n5. **You're concerne", role=None, function_call=None, tool_calls=None, audio=None)
model_response.choices[0].delta: Delta(provider_specific_fields=None, content="\n5. **You're concerne", role=None, function_call=None, tool_calls=None, audio=None); completion_obj: {'content': "\n5. **You're concerne"}
self.sent_first_chunk: True
completion_obj: {'content': "\n5. **You're concerne"}, model_response.choices[0]: StreamingChoices(finish_reason=None, index=0, delta=Delta(provider_specific_fields=None, content="\n5. **You're concerne", role=None, function_call=None, tool_calls=None, audio=None), logprobs=None), response_obj: {'text': "\n5. **You're concerne", 'is_finished': False, 'finish_reason': None, 'logprobs': None, 'original_chunk': ModelResponseStream(id='chatcmpl-1e246dec-1357-4ceb-948f-03d49e55b5f9', created=1762261913, model=None, object='chat.completion.chunk', system_fingerprint=None, choices=[StreamingChoices(finish_reason=None, index=0, delta=Delta(provider_specific_fields=None, content="\n5. **You're concerne", role=None, function_call=None, tool_calls=None, audio=None), logprobs=None)], provider_specific_fields=None, usage=None), 'usage': None}
choice_json: {'index': 0, 'delta': {'provider_specific_fields': None, 'content': "\n5. **You're concerne", 'role': None, 'function_call': None, 'tool_calls': None, 'audio': None}, 'logprobs': None}
choices in streaming: [StreamingChoices(finish_reason=None, index=0, delta=Delta(provider_specific_fields=None, content="\n5. **You're concerne", role=None, function_call=None, tool_calls=None, audio=None), logprobs=None)]
final returned processed chunk: ModelResponseStream(id='chatcmpl-1e246dec-1357-4ceb-948f-03d49e55b5f9', created=1762261907, model='claude-sonnet-4-5-20250929', object='chat.completion.chunk', system_fingerprint=None, choices=[StreamingChoices(finish_reason=None, index=0, delta=Delta(provider_specific_fields=None, content="\n5. **You're concerne", role=None, function_call=None, tool_calls=None, audio=None), logprobs=None)], provider_specific_fields=None, citations=None)
model_response finish reason 3: None; response_obj={'text': '', 'is_finished': False, 'finish_reason': '', 'usage': None, 'index': 0, 'tool_use': None}
model_response.choices[0].delta: Delta(provider_specific_fields=None, content=None, role=None, function_call=None, tool_calls=None, audio=None); completion_obj: {'content': ''}
self.sent_first_chunk: True
completion_obj: {'content': ''}, model_response.choices[0]: StreamingChoices(finish_reason=None, index=0, delta=Delta(provider_specific_fields=None, content=None, role=None, function_call=None, tool_calls=None, audio=None), logprobs=None), response_obj: {'text': '', 'is_finished': False, 'finish_reason': '', 'usage': None, 'index': 0, 'tool_use': None}
model_response finish reason 3: None; response_obj={'text': '', 'is_finished': False, 'finish_reason': '', 'usage': None, 'index': 0, 'tool_use': None}
model_response.choices[0].delta: Delta(provider_specific_fields=None, content=None, role=None, function_call=None, tool_calls=None, audio=None); completion_obj: {'content': ''}
self.sent_first_chunk: True
completion_obj: {'content': ''}, model_response.choices[0]: StreamingChoices(finish_reason=None, index=0, delta=Delta(provider_specific_fields=None, content=None, role=None, function_call=None, tool_calls=None, audio=None), logprobs=None), response_obj: {'text': '', 'is_finished': False, 'finish_reason': '', 'usage': None, 'index': 0, 'tool_use': None}

Raw OpenAI Chunk
ModelResponseStream(id='chatcmpl-1e246dec-1357-4ceb-948f-03d49e55b5f9', created=1762261913, model=None, object='chat.completion.chunk', system_fingerprint=None, choices=[StreamingChoices(finish_reason=None, index=0, delta=Delta(provider_specific_fields=None, content='d about identifying', role=None, function_call=None, tool_calls=None, audio=None), logprobs=None)], provider_specific_fields=None, usage=None)

model_response finish reason 3: None; response_obj={'text': 'd about identifying', 'is_finished': False, 'finish_reason': None, 'logprobs': None, 'original_chunk': ModelResponseStream(id='chatcmpl-1e246dec-1357-4ceb-948f-03d49e55b5f9', created=1762261913, model=None, object='chat.completion.chunk', system_fingerprint=None, choices=[StreamingChoices(finish_reason=None, index=0, delta=Delta(provider_specific_fields=None, content='d about identifying', role=None, function_call=None, tool_calls=None, audio=None), logprobs=None)], provider_specific_fields=None, usage=None), 'usage': None}
original delta: {'provider_specific_fields': None, 'content': 'd about identifying', 'role': None, 'function_call': None, 'tool_calls': None, 'audio': None}
new delta: Delta(provider_specific_fields=None, content='d about identifying', role=None, function_call=None, tool_calls=None, audio=None)
model_response.choices[0].delta: Delta(provider_specific_fields=None, content='d about identifying', role=None, function_call=None, tool_calls=None, audio=None); completion_obj: {'content': 'd about identifying'}
self.sent_first_chunk: True
completion_obj: {'content': 'd about identifying'}, model_response.choices[0]: StreamingChoices(finish_reason=None, index=0, delta=Delta(provider_specific_fields=None, content='d about identifying', role=None, function_call=None, tool_calls=None, audio=None), logprobs=None), response_obj: {'text': 'd about identifying', 'is_finished': False, 'finish_reason': None, 'logprobs': None, 'original_chunk': ModelResponseStream(id='chatcmpl-1e246dec-1357-4ceb-948f-03d49e55b5f9', created=1762261913, model=None, object='chat.completion.chunk', system_fingerprint=None, choices=[StreamingChoices(finish_reason=None, index=0, delta=Delta(provider_specific_fields=None, content='d about identifying', role=None, function_call=None, tool_calls=None, audio=None), logprobs=None)], provider_specific_fields=None, usage=None), 'usage': None}
choice_json: {'index': 0, 'delta': {'provider_specific_fields': None, 'content': 'd about identifying', 'role': None, 'function_call': None, 'tool_calls': None, 'audio': None}, 'logprobs': None}
choices in streaming: [StreamingChoices(finish_reason=None, index=0, delta=Delta(provider_specific_fields=None, content='d about identifying', role=None, function_call=None, tool_calls=None, audio=None), logprobs=None)]
final returned processed chunk: ModelResponseStream(id='chatcmpl-1e246dec-1357-4ceb-948f-03d49e55b5f9', created=1762261907, model='claude-sonnet-4-5-20250929', object='chat.completion.chunk', system_fingerprint=None, choices=[StreamingChoices(finish_reason=None, index=0, delta=Delta(provider_specific_fields=None, content='d about identifying', role=None, function_call=None, tool_calls=None, audio=None), logprobs=None)], provider_specific_fields=None, citations=None)
model_response finish reason 3: None; response_obj={'text': '', 'is_finished': False, 'finish_reason': '', 'usage': None, 'index': 0, 'tool_use': None}
model_response.choices[0].delta: Delta(provider_specific_fields=None, content=None, role=None, function_call=None, tool_calls=None, audio=None); completion_obj: {'content': ''}
self.sent_first_chunk: True
completion_obj: {'content': ''}, model_response.choices[0]: StreamingChoices(finish_reason=None, index=0, delta=Delta(provider_specific_fields=None, content=None, role=None, function_call=None, tool_calls=None, audio=None), logprobs=None), response_obj: {'text': '', 'is_finished': False, 'finish_reason': '', 'usage': None, 'index': 0, 'tool_use': None}
model_response finish reason 3: None; response_obj={'text': '', 'is_finished': False, 'finish_reason': '', 'usage': None, 'index': 0, 'tool_use': None}
model_response.choices[0].delta: Delta(provider_specific_fields=None, content=None, role=None, function_call=None, tool_calls=None, audio=None); completion_obj: {'content': ''}
self.sent_first_chunk: True
completion_obj: {'content': ''}, model_response.choices[0]: StreamingChoices(finish_reason=None, index=0, delta=Delta(provider_specific_fields=None, content=None, role=None, function_call=None, tool_calls=None, audio=None), logprobs=None), response_obj: {'text': '', 'is_finished': False, 'finish_reason': '', 'usage': None, 'index': 0, 'tool_use': None}

Raw OpenAI Chunk
ModelResponseStream(id='chatcmpl-1e246dec-1357-4ceb-948f-03d49e55b5f9', created=1762261913, model=None, object='chat.completion.chunk', system_fingerprint=None, choices=[StreamingChoices(finish_reason=None, index=0, delta=Delta(provider_specific_fields=None, content=' different', role=None, function_call=None, tool_calls=None, audio=None), logprobs=None)], provider_specific_fields=None, usage=None)

model_response finish reason 3: None; response_obj={'text': ' different', 'is_finished': False, 'finish_reason': None, 'logprobs': None, 'original_chunk': ModelResponseStream(id='chatcmpl-1e246dec-1357-4ceb-948f-03d49e55b5f9', created=1762261913, model=None, object='chat.completion.chunk', system_fingerprint=None, choices=[StreamingChoices(finish_reason=None, index=0, delta=Delta(provider_specific_fields=None, content=' different', role=None, function_call=None, tool_calls=None, audio=None), logprobs=None)], provider_specific_fields=None, usage=None), 'usage': None}
original delta: {'provider_specific_fields': None, 'content': ' different', 'role': None, 'function_call': None, 'tool_calls': None, 'audio': None}
new delta: Delta(provider_specific_fields=None, content=' different', role=None, function_call=None, tool_calls=None, audio=None)
model_response.choices[0].delta: Delta(provider_specific_fields=None, content=' different', role=None, function_call=None, tool_calls=None, audio=None); completion_obj: {'content': ' different'}
self.sent_first_chunk: True
completion_obj: {'content': ' different'}, model_response.choices[0]: StreamingChoices(finish_reason=None, index=0, delta=Delta(provider_specific_fields=None, content=' different', role=None, function_call=None, tool_calls=None, audio=None), logprobs=None), response_obj: {'text': ' different', 'is_finished': False, 'finish_reason': None, 'logprobs': None, 'original_chunk': ModelResponseStream(id='chatcmpl-1e246dec-1357-4ceb-948f-03d49e55b5f9', created=1762261913, model=None, object='chat.completion.chunk', system_fingerprint=None, choices=[StreamingChoices(finish_reason=None, index=0, delta=Delta(provider_specific_fields=None, content=' different', role=None, function_call=None, tool_calls=None, audio=None), logprobs=None)], provider_specific_fields=None, usage=None), 'usage': None}
choice_json: {'index': 0, 'delta': {'provider_specific_fields': None, 'content': ' different', 'role': None, 'function_call': None, 'tool_calls': None, 'audio': None}, 'logprobs': None}
choices in streaming: [StreamingChoices(finish_reason=None, index=0, delta=Delta(provider_specific_fields=None, content=' different', role=None, function_call=None, tool_calls=None, audio=None), logprobs=None)]
final returned processed chunk: ModelResponseStream(id='chatcmpl-1e246dec-1357-4ceb-948f-03d49e55b5f9', created=1762261907, model='claude-sonnet-4-5-20250929', object='chat.completion.chunk', system_fingerprint=None, choices=[StreamingChoices(finish_reason=None, index=0, delta=Delta(provider_specific_fields=None, content=' different', role=None, function_call=None, tool_calls=None, audio=None), logprobs=None)], provider_specific_fields=None, citations=None)
model_response finish reason 3: None; response_obj={'text': '', 'is_finished': False, 'finish_reason': '', 'usage': None, 'index': 0, 'tool_use': None}
model_response.choices[0].delta: Delta(provider_specific_fields=None, content=None, role=None, function_call=None, tool_calls=None, audio=None); completion_obj: {'content': ''}
self.sent_first_chunk: True
completion_obj: {'content': ''}, model_response.choices[0]: StreamingChoices(finish_reason=None, index=0, delta=Delta(provider_specific_fields=None, content=None, role=None, function_call=None, tool_calls=None, audio=None), logprobs=None), response_obj: {'text': '', 'is_finished': False, 'finish_reason': '', 'usage': None, 'index': 0, 'tool_use': None}
model_response finish reason 3: None; response_obj={'text': '', 'is_finished': False, 'finish_reason': '', 'usage': None, 'index': 0, 'tool_use': None}
model_response.choices[0].delta: Delta(provider_specific_fields=None, content=None, role=None, function_call=None, tool_calls=None, audio=None); completion_obj: {'content': ''}
self.sent_first_chunk: True
completion_obj: {'content': ''}, model_response.choices[0]: StreamingChoices(finish_reason=None, index=0, delta=Delta(provider_specific_fields=None, content=None, role=None, function_call=None, tool_calls=None, audio=None), logprobs=None), response_obj: {'text': '', 'is_finished': False, 'finish_reason': '', 'usage': None, 'index': 0, 'tool_use': None}

Raw OpenAI Chunk
ModelResponseStream(id='chatcmpl-1e246dec-1357-4ceb-948f-03d49e55b5f9', created=1762261913, model=None, object='chat.completion.chunk', system_fingerprint=None, choices=[StreamingChoices(finish_reason=None, index=0, delta=Delta(provider_specific_fields=None, content=' Py', role=None, function_call=None, tool_calls=None, audio=None), logprobs=None)], provider_specific_fields=None, usage=None)

model_response finish reason 3: None; response_obj={'text': ' Py', 'is_finished': False, 'finish_reason': None, 'logprobs': None, 'original_chunk': ModelResponseStream(id='chatcmpl-1e246dec-1357-4ceb-948f-03d49e55b5f9', created=1762261913, model=None, object='chat.completion.chunk', system_fingerprint=None, choices=[StreamingChoices(finish_reason=None, index=0, delta=Delta(provider_specific_fields=None, content=' Py', role=None, function_call=None, tool_calls=None, audio=None), logprobs=None)], provider_specific_fields=None, usage=None), 'usage': None}
original delta: {'provider_specific_fields': None, 'content': ' Py', 'role': None, 'function_call': None, 'tool_calls': None, 'audio': None}
new delta: Delta(provider_specific_fields=None, content=' Py', role=None, function_call=None, tool_calls=None, audio=None)
model_response.choices[0].delta: Delta(provider_specific_fields=None, content=' Py', role=None, function_call=None, tool_calls=None, audio=None); completion_obj: {'content': ' Py'}
self.sent_first_chunk: True
completion_obj: {'content': ' Py'}, model_response.choices[0]: StreamingChoices(finish_reason=None, index=0, delta=Delta(provider_specific_fields=None, content=' Py', role=None, function_call=None, tool_calls=None, audio=None), logprobs=None), response_obj: {'text': ' Py', 'is_finished': False, 'finish_reason': None, 'logprobs': None, 'original_chunk': ModelResponseStream(id='chatcmpl-1e246dec-1357-4ceb-948f-03d49e55b5f9', created=1762261913, model=None, object='chat.completion.chunk', system_fingerprint=None, choices=[StreamingChoices(finish_reason=None, index=0, delta=Delta(provider_specific_fields=None, content=' Py', role=None, function_call=None, tool_calls=None, audio=None), logprobs=None)], provider_specific_fields=None, usage=None), 'usage': None}
choice_json: {'index': 0, 'delta': {'provider_specific_fields': None, 'content': ' Py', 'role': None, 'function_call': None, 'tool_calls': None, 'audio': None}, 'logprobs': None}
choices in streaming: [StreamingChoices(finish_reason=None, index=0, delta=Delta(provider_specific_fields=None, content=' Py', role=None, function_call=None, tool_calls=None, audio=None), logprobs=None)]
final returned processed chunk: ModelResponseStream(id='chatcmpl-1e246dec-1357-4ceb-948f-03d49e55b5f9', created=1762261907, model='claude-sonnet-4-5-20250929', object='chat.completion.chunk', system_fingerprint=None, choices=[StreamingChoices(finish_reason=None, index=0, delta=Delta(provider_specific_fields=None, content=' Py', role=None, function_call=None, tool_calls=None, audio=None), logprobs=None)], provider_specific_fields=None, citations=None)
model_response finish reason 3: None; response_obj={'text': '', 'is_finished': False, 'finish_reason': '', 'usage': None, 'index': 0, 'tool_use': None}
model_response.choices[0].delta: Delta(provider_specific_fields=None, content=None, role=None, function_call=None, tool_calls=None, audio=None); completion_obj: {'content': ''}
self.sent_first_chunk: True
completion_obj: {'content': ''}, model_response.choices[0]: StreamingChoices(finish_reason=None, index=0, delta=Delta(provider_specific_fields=None, content=None, role=None, function_call=None, tool_calls=None, audio=None), logprobs=None), response_obj: {'text': '', 'is_finished': False, 'finish_reason': '', 'usage': None, 'index': 0, 'tool_use': None}
model_response finish reason 3: None; response_obj={'text': '', 'is_finished': False, 'finish_reason': '', 'usage': None, 'index': 0, 'tool_use': None}
model_response.choices[0].delta: Delta(provider_specific_fields=None, content=None, role=None, function_call=None, tool_calls=None, audio=None); completion_obj: {'content': ''}
self.sent_first_chunk: True
completion_obj: {'content': ''}, model_response.choices[0]: StreamingChoices(finish_reason=None, index=0, delta=Delta(provider_specific_fields=None, content=None, role=None, function_call=None, tool_calls=None, audio=None), logprobs=None), response_obj: {'text': '', 'is_finished': False, 'finish_reason': '', 'usage': None, 'index': 0, 'tool_use': None}

Raw OpenAI Chunk
ModelResponseStream(id='chatcmpl-1e246dec-1357-4ceb-948f-03d49e55b5f9', created=1762261913, model=None, object='chat.completion.chunk', system_fingerprint=None, choices=[StreamingChoices(finish_reason=None, index=0, delta=Delta(provider_specific_fields=None, content='Ch', role=None, function_call=None, tool_calls=None, audio=None), logprobs=None)], provider_specific_fields=None, usage=None)

model_response finish reason 3: None; response_obj={'text': 'Ch', 'is_finished': False, 'finish_reason': None, 'logprobs': None, 'original_chunk': ModelResponseStream(id='chatcmpl-1e246dec-1357-4ceb-948f-03d49e55b5f9', created=1762261913, model=None, object='chat.completion.chunk', system_fingerprint=None, choices=[StreamingChoices(finish_reason=None, index=0, delta=Delta(provider_specific_fields=None, content='Ch', role=None, function_call=None, tool_calls=None, audio=None), logprobs=None)], provider_specific_fields=None, usage=None), 'usage': None}
original delta: {'provider_specific_fields': None, 'content': 'Ch', 'role': None, 'function_call': None, 'tool_calls': None, 'audio': None}
new delta: Delta(provider_specific_fields=None, content='Ch', role=None, function_call=None, tool_calls=None, audio=None)
model_response.choices[0].delta: Delta(provider_specific_fields=None, content='Ch', role=None, function_call=None, tool_calls=None, audio=None); completion_obj: {'content': 'Ch'}
self.sent_first_chunk: True
completion_obj: {'content': 'Ch'}, model_response.choices[0]: StreamingChoices(finish_reason=None, index=0, delta=Delta(provider_specific_fields=None, content='Ch', role=None, function_call=None, tool_calls=None, audio=None), logprobs=None), response_obj: {'text': 'Ch', 'is_finished': False, 'finish_reason': None, 'logprobs': None, 'original_chunk': ModelResponseStream(id='chatcmpl-1e246dec-1357-4ceb-948f-03d49e55b5f9', created=1762261913, model=None, object='chat.completion.chunk', system_fingerprint=None, choices=[StreamingChoices(finish_reason=None, index=0, delta=Delta(provider_specific_fields=None, content='Ch', role=None, function_call=None, tool_calls=None, audio=None), logprobs=None)], provider_specific_fields=None, usage=None), 'usage': None}
choice_json: {'index': 0, 'delta': {'provider_specific_fields': None, 'content': 'Ch', 'role': None, 'function_call': None, 'tool_calls': None, 'audio': None}, 'logprobs': None}
choices in streaming: [StreamingChoices(finish_reason=None, index=0, delta=Delta(provider_specific_fields=None, content='Ch', role=None, function_call=None, tool_calls=None, audio=None), logprobs=None)]
final returned processed chunk: ModelResponseStream(id='chatcmpl-1e246dec-1357-4ceb-948f-03d49e55b5f9', created=1762261907, model='claude-sonnet-4-5-20250929', object='chat.completion.chunk', system_fingerprint=None, choices=[StreamingChoices(finish_reason=None, index=0, delta=Delta(provider_specific_fields=None, content='Ch', role=None, function_call=None, tool_calls=None, audio=None), logprobs=None)], provider_specific_fields=None, citations=None)
model_response finish reason 3: None; response_obj={'text': '', 'is_finished': False, 'finish_reason': '', 'usage': None, 'index': 0, 'tool_use': None}
model_response.choices[0].delta: Delta(provider_specific_fields=None, content=None, role=None, function_call=None, tool_calls=None, audio=None); completion_obj: {'content': ''}
self.sent_first_chunk: True
completion_obj: {'content': ''}, model_response.choices[0]: StreamingChoices(finish_reason=None, index=0, delta=Delta(provider_specific_fields=None, content=None, role=None, function_call=None, tool_calls=None, audio=None), logprobs=None), response_obj: {'text': '', 'is_finished': False, 'finish_reason': '', 'usage': None, 'index': 0, 'tool_use': None}
model_response finish reason 3: None; response_obj={'text': '', 'is_finished': False, 'finish_reason': '', 'usage': None, 'index': 0, 'tool_use': None}
model_response.choices[0].delta: Delta(provider_specific_fields=None, content=None, role=None, function_call=None, tool_calls=None, audio=None); completion_obj: {'content': ''}
self.sent_first_chunk: True
completion_obj: {'content': ''}, model_response.choices[0]: StreamingChoices(finish_reason=None, index=0, delta=Delta(provider_specific_fields=None, content=None, role=None, function_call=None, tool_calls=None, audio=None), logprobs=None), response_obj: {'text': '', 'is_finished': False, 'finish_reason': '', 'usage': None, 'index': 0, 'tool_use': None}

Raw OpenAI Chunk
ModelResponseStream(id='chatcmpl-1e246dec-1357-4ceb-948f-03d49e55b5f9', created=1762261913, model=None, object='chat.completion.chunk', system_fingerprint=None, choices=[StreamingChoices(finish_reason=None, index=0, delta=Delta(provider_specific_fields=None, content='arm instances', role=None, function_call=None, tool_calls=None, audio=None), logprobs=None)], provider_specific_fields=None, usage=None)

model_response finish reason 3: None; response_obj={'text': 'arm instances', 'is_finished': False, 'finish_reason': None, 'logprobs': None, 'original_chunk': ModelResponseStream(id='chatcmpl-1e246dec-1357-4ceb-948f-03d49e55b5f9', created=1762261913, model=None, object='chat.completion.chunk', system_fingerprint=None, choices=[StreamingChoices(finish_reason=None, index=0, delta=Delta(provider_specific_fields=None, content='arm instances', role=None, function_call=None, tool_calls=None, audio=None), logprobs=None)], provider_specific_fields=None, usage=None), 'usage': None}
original delta: {'provider_specific_fields': None, 'content': 'arm instances', 'role': None, 'function_call': None, 'tool_calls': None, 'audio': None}
new delta: Delta(provider_specific_fields=None, content='arm instances', role=None, function_call=None, tool_calls=None, audio=None)
model_response.choices[0].delta: Delta(provider_specific_fields=None, content='arm instances', role=None, function_call=None, tool_calls=None, audio=None); completion_obj: {'content': 'arm instances'}
self.sent_first_chunk: True
completion_obj: {'content': 'arm instances'}, model_response.choices[0]: StreamingChoices(finish_reason=None, index=0, delta=Delta(provider_specific_fields=None, content='arm instances', role=None, function_call=None, tool_calls=None, audio=None), logprobs=None), response_obj: {'text': 'arm instances', 'is_finished': False, 'finish_reason': None, 'logprobs': None, 'original_chunk': ModelResponseStream(id='chatcmpl-1e246dec-1357-4ceb-948f-03d49e55b5f9', created=1762261913, model=None, object='chat.completion.chunk', system_fingerprint=None, choices=[StreamingChoices(finish_reason=None, index=0, delta=Delta(provider_specific_fields=None, content='arm instances', role=None, function_call=None, tool_calls=None, audio=None), logprobs=None)], provider_specific_fields=None, usage=None), 'usage': None}
choice_json: {'index': 0, 'delta': {'provider_specific_fields': None, 'content': 'arm instances', 'role': None, 'function_call': None, 'tool_calls': None, 'audio': None}, 'logprobs': None}
choices in streaming: [StreamingChoices(finish_reason=None, index=0, delta=Delta(provider_specific_fields=None, content='arm instances', role=None, function_call=None, tool_calls=None, audio=None), logprobs=None)]
final returned processed chunk: ModelResponseStream(id='chatcmpl-1e246dec-1357-4ceb-948f-03d49e55b5f9', created=1762261907, model='claude-sonnet-4-5-20250929', object='chat.completion.chunk', system_fingerprint=None, choices=[StreamingChoices(finish_reason=None, index=0, delta=Delta(provider_specific_fields=None, content='arm instances', role=None, function_call=None, tool_calls=None, audio=None), logprobs=None)], provider_specific_fields=None, citations=None)
model_response finish reason 3: None; response_obj={'text': '', 'is_finished': False, 'finish_reason': '', 'usage': None, 'index': 0, 'tool_use': None}
model_response.choices[0].delta: Delta(provider_specific_fields=None, content=None, role=None, function_call=None, tool_calls=None, audio=None); completion_obj: {'content': ''}
self.sent_first_chunk: True
completion_obj: {'content': ''}, model_response.choices[0]: StreamingChoices(finish_reason=None, index=0, delta=Delta(provider_specific_fields=None, content=None, role=None, function_call=None, tool_calls=None, audio=None), logprobs=None), response_obj: {'text': '', 'is_finished': False, 'finish_reason': '', 'usage': None, 'index': 0, 'tool_use': None}
model_response finish reason 3: None; response_obj={'text': '', 'is_finished': False, 'finish_reason': '', 'usage': None, 'index': 0, 'tool_use': None}
model_response.choices[0].delta: Delta(provider_specific_fields=None, content=None, role=None, function_call=None, tool_calls=None, audio=None); completion_obj: {'content': ''}
self.sent_first_chunk: True
completion_obj: {'content': ''}, model_response.choices[0]: StreamingChoices(finish_reason=None, index=0, delta=Delta(provider_specific_fields=None, content=None, role=None, function_call=None, tool_calls=None, audio=None), logprobs=None), response_obj: {'text': '', 'is_finished': False, 'finish_reason': '', 'usage': None, 'index': 0, 'tool_use': None}

Raw OpenAI Chunk
ModelResponseStream(id='chatcmpl-1e246dec-1357-4ceb-948f-03d49e55b5f9', created=1762261913, model=None, object='chat.completion.chunk', system_fingerprint=None, choices=[StreamingChoices(finish_reason=None, index=0, delta=Delta(provider_specific_fields=None, content='** making', role=None, function_call=None, tool_calls=None, audio=None), logprobs=None)], provider_specific_fields=None, usage=None)

model_response finish reason 3: None; response_obj={'text': '** making', 'is_finished': False, 'finish_reason': None, 'logprobs': None, 'original_chunk': ModelResponseStream(id='chatcmpl-1e246dec-1357-4ceb-948f-03d49e55b5f9', created=1762261913, model=None, object='chat.completion.chunk', system_fingerprint=None, choices=[StreamingChoices(finish_reason=None, index=0, delta=Delta(provider_specific_fields=None, content='** making', role=None, function_call=None, tool_calls=None, audio=None), logprobs=None)], provider_specific_fields=None, usage=None), 'usage': None}
original delta: {'provider_specific_fields': None, 'content': '** making', 'role': None, 'function_call': None, 'tool_calls': None, 'audio': None}
new delta: Delta(provider_specific_fields=None, content='** making', role=None, function_call=None, tool_calls=None, audio=None)
model_response.choices[0].delta: Delta(provider_specific_fields=None, content='** making', role=None, function_call=None, tool_calls=None, audio=None); completion_obj: {'content': '** making'}
self.sent_first_chunk: True
completion_obj: {'content': '** making'}, model_response.choices[0]: StreamingChoices(finish_reason=None, index=0, delta=Delta(provider_specific_fields=None, content='** making', role=None, function_call=None, tool_calls=None, audio=None), logprobs=None), response_obj: {'text': '** making', 'is_finished': False, 'finish_reason': None, 'logprobs': None, 'original_chunk': ModelResponseStream(id='chatcmpl-1e246dec-1357-4ceb-948f-03d49e55b5f9', created=1762261913, model=None, object='chat.completion.chunk', system_fingerprint=None, choices=[StreamingChoices(finish_reason=None, index=0, delta=Delta(provider_specific_fields=None, content='** making', role=None, function_call=None, tool_calls=None, audio=None), logprobs=None)], provider_specific_fields=None, usage=None), 'usage': None}
choice_json: {'index': 0, 'delta': {'provider_specific_fields': None, 'content': '** making', 'role': None, 'function_call': None, 'tool_calls': None, 'audio': None}, 'logprobs': None}
choices in streaming: [StreamingChoices(finish_reason=None, index=0, delta=Delta(provider_specific_fields=None, content='** making', role=None, function_call=None, tool_calls=None, audio=None), logprobs=None)]
final returned processed chunk: ModelResponseStream(id='chatcmpl-1e246dec-1357-4ceb-948f-03d49e55b5f9', created=1762261907, model='claude-sonnet-4-5-20250929', object='chat.completion.chunk', system_fingerprint=None, choices=[StreamingChoices(finish_reason=None, index=0, delta=Delta(provider_specific_fields=None, content='** making', role=None, function_call=None, tool_calls=None, audio=None), logprobs=None)], provider_specific_fields=None, citations=None)
model_response finish reason 3: None; response_obj={'text': '', 'is_finished': False, 'finish_reason': '', 'usage': None, 'index': 0, 'tool_use': None}
model_response.choices[0].delta: Delta(provider_specific_fields=None, content=None, role=None, function_call=None, tool_calls=None, audio=None); completion_obj: {'content': ''}
self.sent_first_chunk: True
completion_obj: {'content': ''}, model_response.choices[0]: StreamingChoices(finish_reason=None, index=0, delta=Delta(provider_specific_fields=None, content=None, role=None, function_call=None, tool_calls=None, audio=None), logprobs=None), response_obj: {'text': '', 'is_finished': False, 'finish_reason': '', 'usage': None, 'index': 0, 'tool_use': None}
model_response finish reason 3: None; response_obj={'text': '', 'is_finished': False, 'finish_reason': '', 'usage': None, 'index': 0, 'tool_use': None}
model_response.choices[0].delta: Delta(provider_specific_fields=None, content=None, role=None, function_call=None, tool_calls=None, audio=None); completion_obj: {'content': ''}
self.sent_first_chunk: True
completion_obj: {'content': ''}, model_response.choices[0]: StreamingChoices(finish_reason=None, index=0, delta=Delta(provider_specific_fields=None, content=None, role=None, function_call=None, tool_calls=None, audio=None), logprobs=None), response_obj: {'text': '', 'is_finished': False, 'finish_reason': '', 'usage': None, 'index': 0, 'tool_use': None}

Raw OpenAI Chunk
ModelResponseStream(id='chatcmpl-1e246dec-1357-4ceb-948f-03d49e55b5f9', created=1762261913, model=None, object='chat.completion.chunk', system_fingerprint=None, choices=[StreamingChoices(finish_reason=None, index=0, delta=Delta(provider_specific_fields=None, content=' requests\n\n## About', role=None, function_call=None, tool_calls=None, audio=None), logprobs=None)], provider_specific_fields=None, usage=None)

model_response finish reason 3: None; response_obj={'text': ' requests\n\n## About', 'is_finished': False, 'finish_reason': None, 'logprobs': None, 'original_chunk': ModelResponseStream(id='chatcmpl-1e246dec-1357-4ceb-948f-03d49e55b5f9', created=1762261913, model=None, object='chat.completion.chunk', system_fingerprint=None, choices=[StreamingChoices(finish_reason=None, index=0, delta=Delta(provider_specific_fields=None, content=' requests\n\n## About', role=None, function_call=None, tool_calls=None, audio=None), logprobs=None)], provider_specific_fields=None, usage=None), 'usage': None}
original delta: {'provider_specific_fields': None, 'content': ' requests\n\n## About', 'role': None, 'function_call': None, 'tool_calls': None, 'audio': None}
new delta: Delta(provider_specific_fields=None, content=' requests\n\n## About', role=None, function_call=None, tool_calls=None, audio=None)
model_response.choices[0].delta: Delta(provider_specific_fields=None, content=' requests\n\n## About', role=None, function_call=None, tool_calls=None, audio=None); completion_obj: {'content': ' requests\n\n## About'}
self.sent_first_chunk: True
completion_obj: {'content': ' requests\n\n## About'}, model_response.choices[0]: StreamingChoices(finish_reason=None, index=0, delta=Delta(provider_specific_fields=None, content=' requests\n\n## About', role=None, function_call=None, tool_calls=None, audio=None), logprobs=None), response_obj: {'text': ' requests\n\n## About', 'is_finished': False, 'finish_reason': None, 'logprobs': None, 'original_chunk': ModelResponseStream(id='chatcmpl-1e246dec-1357-4ceb-948f-03d49e55b5f9', created=1762261913, model=None, object='chat.completion.chunk', system_fingerprint=None, choices=[StreamingChoices(finish_reason=None, index=0, delta=Delta(provider_specific_fields=None, content=' requests\n\n## About', role=None, function_call=None, tool_calls=None, audio=None), logprobs=None)], provider_specific_fields=None, usage=None), 'usage': None}
choice_json: {'index': 0, 'delta': {'provider_specific_fields': None, 'content': ' requests\n\n## About', 'role': None, 'function_call': None, 'tool_calls': None, 'audio': None}, 'logprobs': None}
choices in streaming: [StreamingChoices(finish_reason=None, index=0, delta=Delta(provider_specific_fields=None, content=' requests\n\n## About', role=None, function_call=None, tool_calls=None, audio=None), logprobs=None)]
final returned processed chunk: ModelResponseStream(id='chatcmpl-1e246dec-1357-4ceb-948f-03d49e55b5f9', created=1762261907, model='claude-sonnet-4-5-20250929', object='chat.completion.chunk', system_fingerprint=None, choices=[StreamingChoices(finish_reason=None, index=0, delta=Delta(provider_specific_fields=None, content=' requests\n\n## About', role=None, function_call=None, tool_calls=None, audio=None), logprobs=None)], provider_specific_fields=None, citations=None)
model_response finish reason 3: None; response_obj={'text': '', 'is_finished': False, 'finish_reason': '', 'usage': None, 'index': 0, 'tool_use': None}
model_response.choices[0].delta: Delta(provider_specific_fields=None, content=None, role=None, function_call=None, tool_calls=None, audio=None); completion_obj: {'content': ''}
self.sent_first_chunk: True
completion_obj: {'content': ''}, model_response.choices[0]: StreamingChoices(finish_reason=None, index=0, delta=Delta(provider_specific_fields=None, content=None, role=None, function_call=None, tool_calls=None, audio=None), logprobs=None), response_obj: {'text': '', 'is_finished': False, 'finish_reason': '', 'usage': None, 'index': 0, 'tool_use': None}
model_response finish reason 3: None; response_obj={'text': '', 'is_finished': False, 'finish_reason': '', 'usage': None, 'index': 0, 'tool_use': None}
model_response.choices[0].delta: Delta(provider_specific_fields=None, content=None, role=None, function_call=None, tool_calls=None, audio=None); completion_obj: {'content': ''}
self.sent_first_chunk: True
completion_obj: {'content': ''}, model_response.choices[0]: StreamingChoices(finish_reason=None, index=0, delta=Delta(provider_specific_fields=None, content=None, role=None, function_call=None, tool_calls=None, audio=None), logprobs=None), response_obj: {'text': '', 'is_finished': False, 'finish_reason': '', 'usage': None, 'index': 0, 'tool_use': None}

Raw OpenAI Chunk
ModelResponseStream(id='chatcmpl-1e246dec-1357-4ceb-948f-03d49e55b5f9', created=1762261913, model=None, object='chat.completion.chunk', system_fingerprint=None, choices=[StreamingChoices(finish_reason=None, index=0, delta=Delta(provider_specific_fields=None, content=' Your Current Work', role=None, function_call=None, tool_calls=None, audio=None), logprobs=None)], provider_specific_fields=None, usage=None)

model_response finish reason 3: None; response_obj={'text': ' Your Current Work', 'is_finished': False, 'finish_reason': None, 'logprobs': None, 'original_chunk': ModelResponseStream(id='chatcmpl-1e246dec-1357-4ceb-948f-03d49e55b5f9', created=1762261913, model=None, object='chat.completion.chunk', system_fingerprint=None, choices=[StreamingChoices(finish_reason=None, index=0, delta=Delta(provider_specific_fields=None, content=' Your Current Work', role=None, function_call=None, tool_calls=None, audio=None), logprobs=None)], provider_specific_fields=None, usage=None), 'usage': None}
original delta: {'provider_specific_fields': None, 'content': ' Your Current Work', 'role': None, 'function_call': None, 'tool_calls': None, 'audio': None}
new delta: Delta(provider_specific_fields=None, content=' Your Current Work', role=None, function_call=None, tool_calls=None, audio=None)
model_response.choices[0].delta: Delta(provider_specific_fields=None, content=' Your Current Work', role=None, function_call=None, tool_calls=None, audio=None); completion_obj: {'content': ' Your Current Work'}
self.sent_first_chunk: True
completion_obj: {'content': ' Your Current Work'}, model_response.choices[0]: StreamingChoices(finish_reason=None, index=0, delta=Delta(provider_specific_fields=None, content=' Your Current Work', role=None, function_call=None, tool_calls=None, audio=None), logprobs=None), response_obj: {'text': ' Your Current Work', 'is_finished': False, 'finish_reason': None, 'logprobs': None, 'original_chunk': ModelResponseStream(id='chatcmpl-1e246dec-1357-4ceb-948f-03d49e55b5f9', created=1762261913, model=None, object='chat.completion.chunk', system_fingerprint=None, choices=[StreamingChoices(finish_reason=None, index=0, delta=Delta(provider_specific_fields=None, content=' Your Current Work', role=None, function_call=None, tool_calls=None, audio=None), logprobs=None)], provider_specific_fields=None, usage=None), 'usage': None}
choice_json: {'index': 0, 'delta': {'provider_specific_fields': None, 'content': ' Your Current Work', 'role': None, 'function_call': None, 'tool_calls': None, 'audio': None}, 'logprobs': None}
choices in streaming: [StreamingChoices(finish_reason=None, index=0, delta=Delta(provider_specific_fields=None, content=' Your Current Work', role=None, function_call=None, tool_calls=None, audio=None), logprobs=None)]
final returned processed chunk: ModelResponseStream(id='chatcmpl-1e246dec-1357-4ceb-948f-03d49e55b5f9', created=1762261907, model='claude-sonnet-4-5-20250929', object='chat.completion.chunk', system_fingerprint=None, choices=[StreamingChoices(finish_reason=None, index=0, delta=Delta(provider_specific_fields=None, content=' Your Current Work', role=None, function_call=None, tool_calls=None, audio=None), logprobs=None)], provider_specific_fields=None, citations=None)
model_response finish reason 3: None; response_obj={'text': '', 'is_finished': False, 'finish_reason': '', 'usage': None, 'index': 0, 'tool_use': None}
model_response.choices[0].delta: Delta(provider_specific_fields=None, content=None, role=None, function_call=None, tool_calls=None, audio=None); completion_obj: {'content': ''}
self.sent_first_chunk: True
completion_obj: {'content': ''}, model_response.choices[0]: StreamingChoices(finish_reason=None, index=0, delta=Delta(provider_specific_fields=None, content=None, role=None, function_call=None, tool_calls=None, audio=None), logprobs=None), response_obj: {'text': '', 'is_finished': False, 'finish_reason': '', 'usage': None, 'index': 0, 'tool_use': None}
model_response finish reason 3: None; response_obj={'text': '', 'is_finished': False, 'finish_reason': '', 'usage': None, 'index': 0, 'tool_use': None}
model_response.choices[0].delta: Delta(provider_specific_fields=None, content=None, role=None, function_call=None, tool_calls=None, audio=None); completion_obj: {'content': ''}
self.sent_first_chunk: True
completion_obj: {'content': ''}, model_response.choices[0]: StreamingChoices(finish_reason=None, index=0, delta=Delta(provider_specific_fields=None, content=None, role=None, function_call=None, tool_calls=None, audio=None), logprobs=None), response_obj: {'text': '', 'is_finished': False, 'finish_reason': '', 'usage': None, 'index': 0, 'tool_use': None}

Raw OpenAI Chunk
ModelResponseStream(id='chatcmpl-1e246dec-1357-4ceb-948f-03d49e55b5f9', created=1762261913, model=None, object='chat.completion.chunk', system_fingerprint=None, choices=[StreamingChoices(finish_reason=None, index=0, delta=Delta(provider_specific_fields=None, content=':\n\nYou mentione', role=None, function_call=None, tool_calls=None, audio=None), logprobs=None)], provider_specific_fields=None, usage=None)

model_response finish reason 3: None; response_obj={'text': ':\n\nYou mentione', 'is_finished': False, 'finish_reason': None, 'logprobs': None, 'original_chunk': ModelResponseStream(id='chatcmpl-1e246dec-1357-4ceb-948f-03d49e55b5f9', created=1762261913, model=None, object='chat.completion.chunk', system_fingerprint=None, choices=[StreamingChoices(finish_reason=None, index=0, delta=Delta(provider_specific_fields=None, content=':\n\nYou mentione', role=None, function_call=None, tool_calls=None, audio=None), logprobs=None)], provider_specific_fields=None, usage=None), 'usage': None}
original delta: {'provider_specific_fields': None, 'content': ':\n\nYou mentione', 'role': None, 'function_call': None, 'tool_calls': None, 'audio': None}
new delta: Delta(provider_specific_fields=None, content=':\n\nYou mentione', role=None, function_call=None, tool_calls=None, audio=None)
model_response.choices[0].delta: Delta(provider_specific_fields=None, content=':\n\nYou mentione', role=None, function_call=None, tool_calls=None, audio=None); completion_obj: {'content': ':\n\nYou mentione'}
self.sent_first_chunk: True
completion_obj: {'content': ':\n\nYou mentione'}, model_response.choices[0]: StreamingChoices(finish_reason=None, index=0, delta=Delta(provider_specific_fields=None, content=':\n\nYou mentione', role=None, function_call=None, tool_calls=None, audio=None), logprobs=None), response_obj: {'text': ':\n\nYou mentione', 'is_finished': False, 'finish_reason': None, 'logprobs': None, 'original_chunk': ModelResponseStream(id='chatcmpl-1e246dec-1357-4ceb-948f-03d49e55b5f9', created=1762261913, model=None, object='chat.completion.chunk', system_fingerprint=None, choices=[StreamingChoices(finish_reason=None, index=0, delta=Delta(provider_specific_fields=None, content=':\n\nYou mentione', role=None, function_call=None, tool_calls=None, audio=None), logprobs=None)], provider_specific_fields=None, usage=None), 'usage': None}
choice_json: {'index': 0, 'delta': {'provider_specific_fields': None, 'content': ':\n\nYou mentione', 'role': None, 'function_call': None, 'tool_calls': None, 'audio': None}, 'logprobs': None}
choices in streaming: [StreamingChoices(finish_reason=None, index=0, delta=Delta(provider_specific_fields=None, content=':\n\nYou mentione', role=None, function_call=None, tool_calls=None, audio=None), logprobs=None)]
final returned processed chunk: ModelResponseStream(id='chatcmpl-1e246dec-1357-4ceb-948f-03d49e55b5f9', created=1762261907, model='claude-sonnet-4-5-20250929', object='chat.completion.chunk', system_fingerprint=None, choices=[StreamingChoices(finish_reason=None, index=0, delta=Delta(provider_specific_fields=None, content=':\n\nYou mentione', role=None, function_call=None, tool_calls=None, audio=None), logprobs=None)], provider_specific_fields=None, citations=None)
model_response finish reason 3: None; response_obj={'text': '', 'is_finished': False, 'finish_reason': '', 'usage': None, 'index': 0, 'tool_use': None}
model_response.choices[0].delta: Delta(provider_specific_fields=None, content=None, role=None, function_call=None, tool_calls=None, audio=None); completion_obj: {'content': ''}
self.sent_first_chunk: True
completion_obj: {'content': ''}, model_response.choices[0]: StreamingChoices(finish_reason=None, index=0, delta=Delta(provider_specific_fields=None, content=None, role=None, function_call=None, tool_calls=None, audio=None), logprobs=None), response_obj: {'text': '', 'is_finished': False, 'finish_reason': '', 'usage': None, 'index': 0, 'tool_use': None}
model_response finish reason 3: None; response_obj={'text': '', 'is_finished': False, 'finish_reason': '', 'usage': None, 'index': 0, 'tool_use': None}
model_response.choices[0].delta: Delta(provider_specific_fields=None, content=None, role=None, function_call=None, tool_calls=None, audio=None); completion_obj: {'content': ''}
self.sent_first_chunk: True
completion_obj: {'content': ''}, model_response.choices[0]: StreamingChoices(finish_reason=None, index=0, delta=Delta(provider_specific_fields=None, content=None, role=None, function_call=None, tool_calls=None, audio=None), logprobs=None), response_obj: {'text': '', 'is_finished': False, 'finish_reason': '', 'usage': None, 'index': 0, 'tool_use': None}

Raw OpenAI Chunk
ModelResponseStream(id='chatcmpl-1e246dec-1357-4ceb-948f-03d49e55b5f9', created=1762261913, model=None, object='chat.completion.chunk', system_fingerprint=None, choices=[StreamingChoices(finish_reason=None, index=0, delta=Delta(provider_specific_fields=None, content='d you nee', role=None, function_call=None, tool_calls=None, audio=None), logprobs=None)], provider_specific_fields=None, usage=None)

model_response finish reason 3: None; response_obj={'text': 'd you nee', 'is_finished': False, 'finish_reason': None, 'logprobs': None, 'original_chunk': ModelResponseStream(id='chatcmpl-1e246dec-1357-4ceb-948f-03d49e55b5f9', created=1762261913, model=None, object='chat.completion.chunk', system_fingerprint=None, choices=[StreamingChoices(finish_reason=None, index=0, delta=Delta(provider_specific_fields=None, content='d you nee', role=None, function_call=None, tool_calls=None, audio=None), logprobs=None)], provider_specific_fields=None, usage=None), 'usage': None}
original delta: {'provider_specific_fields': None, 'content': 'd you nee', 'role': None, 'function_call': None, 'tool_calls': None, 'audio': None}
new delta: Delta(provider_specific_fields=None, content='d you nee', role=None, function_call=None, tool_calls=None, audio=None)
model_response.choices[0].delta: Delta(provider_specific_fields=None, content='d you nee', role=None, function_call=None, tool_calls=None, audio=None); completion_obj: {'content': 'd you nee'}
self.sent_first_chunk: True
completion_obj: {'content': 'd you nee'}, model_response.choices[0]: StreamingChoices(finish_reason=None, index=0, delta=Delta(provider_specific_fields=None, content='d you nee', role=None, function_call=None, tool_calls=None, audio=None), logprobs=None), response_obj: {'text': 'd you nee', 'is_finished': False, 'finish_reason': None, 'logprobs': None, 'original_chunk': ModelResponseStream(id='chatcmpl-1e246dec-1357-4ceb-948f-03d49e55b5f9', created=1762261913, model=None, object='chat.completion.chunk', system_fingerprint=None, choices=[StreamingChoices(finish_reason=None, index=0, delta=Delta(provider_specific_fields=None, content='d you nee', role=None, function_call=None, tool_calls=None, audio=None), logprobs=None)], provider_specific_fields=None, usage=None), 'usage': None}
choice_json: {'index': 0, 'delta': {'provider_specific_fields': None, 'content': 'd you nee', 'role': None, 'function_call': None, 'tool_calls': None, 'audio': None}, 'logprobs': None}
choices in streaming: [StreamingChoices(finish_reason=None, index=0, delta=Delta(provider_specific_fields=None, content='d you nee', role=None, function_call=None, tool_calls=None, audio=None), logprobs=None)]
final returned processed chunk: ModelResponseStream(id='chatcmpl-1e246dec-1357-4ceb-948f-03d49e55b5f9', created=1762261907, model='claude-sonnet-4-5-20250929', object='chat.completion.chunk', system_fingerprint=None, choices=[StreamingChoices(finish_reason=None, index=0, delta=Delta(provider_specific_fields=None, content='d you nee', role=None, function_call=None, tool_calls=None, audio=None), logprobs=None)], provider_specific_fields=None, citations=None)
model_response finish reason 3: None; response_obj={'text': '', 'is_finished': False, 'finish_reason': '', 'usage': None, 'index': 0, 'tool_use': None}
model_response.choices[0].delta: Delta(provider_specific_fields=None, content=None, role=None, function_call=None, tool_calls=None, audio=None); completion_obj: {'content': ''}
self.sent_first_chunk: True
completion_obj: {'content': ''}, model_response.choices[0]: StreamingChoices(finish_reason=None, index=0, delta=Delta(provider_specific_fields=None, content=None, role=None, function_call=None, tool_calls=None, audio=None), logprobs=None), response_obj: {'text': '', 'is_finished': False, 'finish_reason': '', 'usage': None, 'index': 0, 'tool_use': None}
model_response finish reason 3: None; response_obj={'text': '', 'is_finished': False, 'finish_reason': '', 'usage': None, 'index': 0, 'tool_use': None}
model_response.choices[0].delta: Delta(provider_specific_fields=None, content=None, role=None, function_call=None, tool_calls=None, audio=None); completion_obj: {'content': ''}
self.sent_first_chunk: True
completion_obj: {'content': ''}, model_response.choices[0]: StreamingChoices(finish_reason=None, index=0, delta=Delta(provider_specific_fields=None, content=None, role=None, function_call=None, tool_calls=None, audio=None), logprobs=None), response_obj: {'text': '', 'is_finished': False, 'finish_reason': '', 'usage': None, 'index': 0, 'tool_use': None}

Raw OpenAI Chunk
ModelResponseStream(id='chatcmpl-1e246dec-1357-4ceb-948f-03d49e55b5f9', created=1762261913, model=None, object='chat.completion.chunk', system_fingerprint=None, choices=[StreamingChoices(finish_reason=None, index=0, delta=Delta(provider_specific_fields=None, content='d to review', role=None, function_call=None, tool_calls=None, audio=None), logprobs=None)], provider_specific_fields=None, usage=None)

model_response finish reason 3: None; response_obj={'text': 'd to review', 'is_finished': False, 'finish_reason': None, 'logprobs': None, 'original_chunk': ModelResponseStream(id='chatcmpl-1e246dec-1357-4ceb-948f-03d49e55b5f9', created=1762261913, model=None, object='chat.completion.chunk', system_fingerprint=None, choices=[StreamingChoices(finish_reason=None, index=0, delta=Delta(provider_specific_fields=None, content='d to review', role=None, function_call=None, tool_calls=None, audio=None), logprobs=None)], provider_specific_fields=None, usage=None), 'usage': None}
original delta: {'provider_specific_fields': None, 'content': 'd to review', 'role': None, 'function_call': None, 'tool_calls': None, 'audio': None}
new delta: Delta(provider_specific_fields=None, content='d to review', role=None, function_call=None, tool_calls=None, audio=None)
model_response.choices[0].delta: Delta(provider_specific_fields=None, content='d to review', role=None, function_call=None, tool_calls=None, audio=None); completion_obj: {'content': 'd to review'}
self.sent_first_chunk: True
completion_obj: {'content': 'd to review'}, model_response.choices[0]: StreamingChoices(finish_reason=None, index=0, delta=Delta(provider_specific_fields=None, content='d to review', role=None, function_call=None, tool_calls=None, audio=None), logprobs=None), response_obj: {'text': 'd to review', 'is_finished': False, 'finish_reason': None, 'logprobs': None, 'original_chunk': ModelResponseStream(id='chatcmpl-1e246dec-1357-4ceb-948f-03d49e55b5f9', created=1762261913, model=None, object='chat.completion.chunk', system_fingerprint=None, choices=[StreamingChoices(finish_reason=None, index=0, delta=Delta(provider_specific_fields=None, content='d to review', role=None, function_call=None, tool_calls=None, audio=None), logprobs=None)], provider_specific_fields=None, usage=None), 'usage': None}
choice_json: {'index': 0, 'delta': {'provider_specific_fields': None, 'content': 'd to review', 'role': None, 'function_call': None, 'tool_calls': None, 'audio': None}, 'logprobs': None}
choices in streaming: [StreamingChoices(finish_reason=None, index=0, delta=Delta(provider_specific_fields=None, content='d to review', role=None, function_call=None, tool_calls=None, audio=None), logprobs=None)]
final returned processed chunk: ModelResponseStream(id='chatcmpl-1e246dec-1357-4ceb-948f-03d49e55b5f9', created=1762261907, model='claude-sonnet-4-5-20250929', object='chat.completion.chunk', system_fingerprint=None, choices=[StreamingChoices(finish_reason=None, index=0, delta=Delta(provider_specific_fields=None, content='d to review', role=None, function_call=None, tool_calls=None, audio=None), logprobs=None)], provider_specific_fields=None, citations=None)
model_response finish reason 3: None; response_obj={'text': '', 'is_finished': False, 'finish_reason': '', 'usage': None, 'index': 0, 'tool_use': None}
model_response.choices[0].delta: Delta(provider_specific_fields=None, content=None, role=None, function_call=None, tool_calls=None, audio=None); completion_obj: {'content': ''}
self.sent_first_chunk: True
completion_obj: {'content': ''}, model_response.choices[0]: StreamingChoices(finish_reason=None, index=0, delta=Delta(provider_specific_fields=None, content=None, role=None, function_call=None, tool_calls=None, audio=None), logprobs=None), response_obj: {'text': '', 'is_finished': False, 'finish_reason': '', 'usage': None, 'index': 0, 'tool_use': None}
model_response finish reason 3: None; response_obj={'text': '', 'is_finished': False, 'finish_reason': '', 'usage': None, 'index': 0, 'tool_use': None}
model_response.choices[0].delta: Delta(provider_specific_fields=None, content=None, role=None, function_call=None, tool_calls=None, audio=None); completion_obj: {'content': ''}
self.sent_first_chunk: True
completion_obj: {'content': ''}, model_response.choices[0]: StreamingChoices(finish_reason=None, index=0, delta=Delta(provider_specific_fields=None, content=None, role=None, function_call=None, tool_calls=None, audio=None), logprobs=None), response_obj: {'text': '', 'is_finished': False, 'finish_reason': '', 'usage': None, 'index': 0, 'tool_use': None}

Raw OpenAI Chunk
ModelResponseStream(id='chatcmpl-1e246dec-1357-4ceb-948f-03d49e55b5f9', created=1762261913, model=None, object='chat.completion.chunk', system_fingerprint=None, choices=[StreamingChoices(finish_reason=None, index=0, delta=Delta(provider_specific_fields=None, content=' newly', role=None, function_call=None, tool_calls=None, audio=None), logprobs=None)], provider_specific_fields=None, usage=None)

model_response finish reason 3: None; response_obj={'text': ' newly', 'is_finished': False, 'finish_reason': None, 'logprobs': None, 'original_chunk': ModelResponseStream(id='chatcmpl-1e246dec-1357-4ceb-948f-03d49e55b5f9', created=1762261913, model=None, object='chat.completion.chunk', system_fingerprint=None, choices=[StreamingChoices(finish_reason=None, index=0, delta=Delta(provider_specific_fields=None, content=' newly', role=None, function_call=None, tool_calls=None, audio=None), logprobs=None)], provider_specific_fields=None, usage=None), 'usage': None}
original delta: {'provider_specific_fields': None, 'content': ' newly', 'role': None, 'function_call': None, 'tool_calls': None, 'audio': None}
new delta: Delta(provider_specific_fields=None, content=' newly', role=None, function_call=None, tool_calls=None, audio=None)
model_response.choices[0].delta: Delta(provider_specific_fields=None, content=' newly', role=None, function_call=None, tool_calls=None, audio=None); completion_obj: {'content': ' newly'}
self.sent_first_chunk: True
completion_obj: {'content': ' newly'}, model_response.choices[0]: StreamingChoices(finish_reason=None, index=0, delta=Delta(provider_specific_fields=None, content=' newly', role=None, function_call=None, tool_calls=None, audio=None), logprobs=None), response_obj: {'text': ' newly', 'is_finished': False, 'finish_reason': None, 'logprobs': None, 'original_chunk': ModelResponseStream(id='chatcmpl-1e246dec-1357-4ceb-948f-03d49e55b5f9', created=1762261913, model=None, object='chat.completion.chunk', system_fingerprint=None, choices=[StreamingChoices(finish_reason=None, index=0, delta=Delta(provider_specific_fields=None, content=' newly', role=None, function_call=None, tool_calls=None, audio=None), logprobs=None)], provider_specific_fields=None, usage=None), 'usage': None}
choice_json: {'index': 0, 'delta': {'provider_specific_fields': None, 'content': ' newly', 'role': None, 'function_call': None, 'tool_calls': None, 'audio': None}, 'logprobs': None}
choices in streaming: [StreamingChoices(finish_reason=None, index=0, delta=Delta(provider_specific_fields=None, content=' newly', role=None, function_call=None, tool_calls=None, audio=None), logprobs=None)]
final returned processed chunk: ModelResponseStream(id='chatcmpl-1e246dec-1357-4ceb-948f-03d49e55b5f9', created=1762261907, model='claude-sonnet-4-5-20250929', object='chat.completion.chunk', system_fingerprint=None, choices=[StreamingChoices(finish_reason=None, index=0, delta=Delta(provider_specific_fields=None, content=' newly', role=None, function_call=None, tool_calls=None, audio=None), logprobs=None)], provider_specific_fields=None, citations=None)
model_response finish reason 3: None; response_obj={'text': '', 'is_finished': False, 'finish_reason': '', 'usage': None, 'index': 0, 'tool_use': None}
model_response.choices[0].delta: Delta(provider_specific_fields=None, content=None, role=None, function_call=None, tool_calls=None, audio=None); completion_obj: {'content': ''}
self.sent_first_chunk: True
completion_obj: {'content': ''}, model_response.choices[0]: StreamingChoices(finish_reason=None, index=0, delta=Delta(provider_specific_fields=None, content=None, role=None, function_call=None, tool_calls=None, audio=None), logprobs=None), response_obj: {'text': '', 'is_finished': False, 'finish_reason': '', 'usage': None, 'index': 0, 'tool_use': None}
model_response finish reason 3: None; response_obj={'text': '', 'is_finished': False, 'finish_reason': '', 'usage': None, 'index': 0, 'tool_use': None}
model_response.choices[0].delta: Delta(provider_specific_fields=None, content=None, role=None, function_call=None, tool_calls=None, audio=None); completion_obj: {'content': ''}
self.sent_first_chunk: True
completion_obj: {'content': ''}, model_response.choices[0]: StreamingChoices(finish_reason=None, index=0, delta=Delta(provider_specific_fields=None, content=None, role=None, function_call=None, tool_calls=None, audio=None), logprobs=None), response_obj: {'text': '', 'is_finished': False, 'finish_reason': '', 'usage': None, 'index': 0, 'tool_use': None}

Raw OpenAI Chunk
ModelResponseStream(id='chatcmpl-1e246dec-1357-4ceb-948f-03d49e55b5f9', created=1762261913, model=None, object='chat.completion.chunk', system_fingerprint=None, choices=[StreamingChoices(finish_reason=None, index=0, delta=Delta(provider_specific_fields=None, content=' adde', role=None, function_call=None, tool_calls=None, audio=None), logprobs=None)], provider_specific_fields=None, usage=None)

model_response finish reason 3: None; response_obj={'text': ' adde', 'is_finished': False, 'finish_reason': None, 'logprobs': None, 'original_chunk': ModelResponseStream(id='chatcmpl-1e246dec-1357-4ceb-948f-03d49e55b5f9', created=1762261913, model=None, object='chat.completion.chunk', system_fingerprint=None, choices=[StreamingChoices(finish_reason=None, index=0, delta=Delta(provider_specific_fields=None, content=' adde', role=None, function_call=None, tool_calls=None, audio=None), logprobs=None)], provider_specific_fields=None, usage=None), 'usage': None}
original delta: {'provider_specific_fields': None, 'content': ' adde', 'role': None, 'function_call': None, 'tool_calls': None, 'audio': None}
new delta: Delta(provider_specific_fields=None, content=' adde', role=None, function_call=None, tool_calls=None, audio=None)
model_response.choices[0].delta: Delta(provider_specific_fields=None, content=' adde', role=None, function_call=None, tool_calls=None, audio=None); completion_obj: {'content': ' adde'}
self.sent_first_chunk: True
completion_obj: {'content': ' adde'}, model_response.choices[0]: StreamingChoices(finish_reason=None, index=0, delta=Delta(provider_specific_fields=None, content=' adde', role=None, function_call=None, tool_calls=None, audio=None), logprobs=None), response_obj: {'text': ' adde', 'is_finished': False, 'finish_reason': None, 'logprobs': None, 'original_chunk': ModelResponseStream(id='chatcmpl-1e246dec-1357-4ceb-948f-03d49e55b5f9', created=1762261913, model=None, object='chat.completion.chunk', system_fingerprint=None, choices=[StreamingChoices(finish_reason=None, index=0, delta=Delta(provider_specific_fields=None, content=' adde', role=None, function_call=None, tool_calls=None, audio=None), logprobs=None)], provider_specific_fields=None, usage=None), 'usage': None}
choice_json: {'index': 0, 'delta': {'provider_specific_fields': None, 'content': ' adde', 'role': None, 'function_call': None, 'tool_calls': None, 'audio': None}, 'logprobs': None}
choices in streaming: [StreamingChoices(finish_reason=None, index=0, delta=Delta(provider_specific_fields=None, content=' adde', role=None, function_call=None, tool_calls=None, audio=None), logprobs=None)]
final returned processed chunk: ModelResponseStream(id='chatcmpl-1e246dec-1357-4ceb-948f-03d49e55b5f9', created=1762261907, model='claude-sonnet-4-5-20250929', object='chat.completion.chunk', system_fingerprint=None, choices=[StreamingChoices(finish_reason=None, index=0, delta=Delta(provider_specific_fields=None, content=' adde', role=None, function_call=None, tool_calls=None, audio=None), logprobs=None)], provider_specific_fields=None, citations=None)
model_response finish reason 3: None; response_obj={'text': '', 'is_finished': False, 'finish_reason': '', 'usage': None, 'index': 0, 'tool_use': None}
model_response.choices[0].delta: Delta(provider_specific_fields=None, content=None, role=None, function_call=None, tool_calls=None, audio=None); completion_obj: {'content': ''}
self.sent_first_chunk: True
completion_obj: {'content': ''}, model_response.choices[0]: StreamingChoices(finish_reason=None, index=0, delta=Delta(provider_specific_fields=None, content=None, role=None, function_call=None, tool_calls=None, audio=None), logprobs=None), response_obj: {'text': '', 'is_finished': False, 'finish_reason': '', 'usage': None, 'index': 0, 'tool_use': None}
model_response finish reason 3: None; response_obj={'text': '', 'is_finished': False, 'finish_reason': '', 'usage': None, 'index': 0, 'tool_use': None}
model_response.choices[0].delta: Delta(provider_specific_fields=None, content=None, role=None, function_call=None, tool_calls=None, audio=None); completion_obj: {'content': ''}
self.sent_first_chunk: True
completion_obj: {'content': ''}, model_response.choices[0]: StreamingChoices(finish_reason=None, index=0, delta=Delta(provider_specific_fields=None, content=None, role=None, function_call=None, tool_calls=None, audio=None), logprobs=None), response_obj: {'text': '', 'is_finished': False, 'finish_reason': '', 'usage': None, 'index': 0, 'tool_use': None}

Raw OpenAI Chunk
ModelResponseStream(id='chatcmpl-1e246dec-1357-4ceb-948f-03d49e55b5f9', created=1762261913, model=None, object='chat.completion.chunk', system_fingerprint=None, choices=[StreamingChoices(finish_reason=None, index=0, delta=Delta(provider_specific_fields=None, content='d changes', role=None, function_call=None, tool_calls=None, audio=None), logprobs=None)], provider_specific_fields=None, usage=None)

model_response finish reason 3: None; response_obj={'text': 'd changes', 'is_finished': False, 'finish_reason': None, 'logprobs': None, 'original_chunk': ModelResponseStream(id='chatcmpl-1e246dec-1357-4ceb-948f-03d49e55b5f9', created=1762261913, model=None, object='chat.completion.chunk', system_fingerprint=None, choices=[StreamingChoices(finish_reason=None, index=0, delta=Delta(provider_specific_fields=None, content='d changes', role=None, function_call=None, tool_calls=None, audio=None), logprobs=None)], provider_specific_fields=None, usage=None), 'usage': None}
original delta: {'provider_specific_fields': None, 'content': 'd changes', 'role': None, 'function_call': None, 'tool_calls': None, 'audio': None}
new delta: Delta(provider_specific_fields=None, content='d changes', role=None, function_call=None, tool_calls=None, audio=None)
model_response.choices[0].delta: Delta(provider_specific_fields=None, content='d changes', role=None, function_call=None, tool_calls=None, audio=None); completion_obj: {'content': 'd changes'}
self.sent_first_chunk: True
completion_obj: {'content': 'd changes'}, model_response.choices[0]: StreamingChoices(finish_reason=None, index=0, delta=Delta(provider_specific_fields=None, content='d changes', role=None, function_call=None, tool_calls=None, audio=None), logprobs=None), response_obj: {'text': 'd changes', 'is_finished': False, 'finish_reason': None, 'logprobs': None, 'original_chunk': ModelResponseStream(id='chatcmpl-1e246dec-1357-4ceb-948f-03d49e55b5f9', created=1762261913, model=None, object='chat.completion.chunk', system_fingerprint=None, choices=[StreamingChoices(finish_reason=None, index=0, delta=Delta(provider_specific_fields=None, content='d changes', role=None, function_call=None, tool_calls=None, audio=None), logprobs=None)], provider_specific_fields=None, usage=None), 'usage': None}
choice_json: {'index': 0, 'delta': {'provider_specific_fields': None, 'content': 'd changes', 'role': None, 'function_call': None, 'tool_calls': None, 'audio': None}, 'logprobs': None}
choices in streaming: [StreamingChoices(finish_reason=None, index=0, delta=Delta(provider_specific_fields=None, content='d changes', role=None, function_call=None, tool_calls=None, audio=None), logprobs=None)]
final returned processed chunk: ModelResponseStream(id='chatcmpl-1e246dec-1357-4ceb-948f-03d49e55b5f9', created=1762261907, model='claude-sonnet-4-5-20250929', object='chat.completion.chunk', system_fingerprint=None, choices=[StreamingChoices(finish_reason=None, index=0, delta=Delta(provider_specific_fields=None, content='d changes', role=None, function_call=None, tool_calls=None, audio=None), logprobs=None)], provider_specific_fields=None, citations=None)
model_response finish reason 3: None; response_obj={'text': '', 'is_finished': False, 'finish_reason': '', 'usage': None, 'index': 0, 'tool_use': None}
model_response.choices[0].delta: Delta(provider_specific_fields=None, content=None, role=None, function_call=None, tool_calls=None, audio=None); completion_obj: {'content': ''}
self.sent_first_chunk: True
completion_obj: {'content': ''}, model_response.choices[0]: StreamingChoices(finish_reason=None, index=0, delta=Delta(provider_specific_fields=None, content=None, role=None, function_call=None, tool_calls=None, audio=None), logprobs=None), response_obj: {'text': '', 'is_finished': False, 'finish_reason': '', 'usage': None, 'index': 0, 'tool_use': None}
model_response finish reason 3: None; response_obj={'text': '', 'is_finished': False, 'finish_reason': '', 'usage': None, 'index': 0, 'tool_use': None}
model_response.choices[0].delta: Delta(provider_specific_fields=None, content=None, role=None, function_call=None, tool_calls=None, audio=None); completion_obj: {'content': ''}
self.sent_first_chunk: True
completion_obj: {'content': ''}, model_response.choices[0]: StreamingChoices(finish_reason=None, index=0, delta=Delta(provider_specific_fields=None, content=None, role=None, function_call=None, tool_calls=None, audio=None), logprobs=None), response_obj: {'text': '', 'is_finished': False, 'finish_reason': '', 'usage': None, 'index': 0, 'tool_use': None}

Raw OpenAI Chunk
ModelResponseStream(id='chatcmpl-1e246dec-1357-4ceb-948f-03d49e55b5f9', created=1762261913, model=None, object='chat.completion.chunk', system_fingerprint=None, choices=[StreamingChoices(finish_reason=None, index=0, delta=Delta(provider_specific_fields=None, content=' (', role=None, function_call=None, tool_calls=None, audio=None), logprobs=None)], provider_specific_fields=None, usage=None)

model_response finish reason 3: None; response_obj={'text': ' (', 'is_finished': False, 'finish_reason': None, 'logprobs': None, 'original_chunk': ModelResponseStream(id='chatcmpl-1e246dec-1357-4ceb-948f-03d49e55b5f9', created=1762261913, model=None, object='chat.completion.chunk', system_fingerprint=None, choices=[StreamingChoices(finish_reason=None, index=0, delta=Delta(provider_specific_fields=None, content=' (', role=None, function_call=None, tool_calls=None, audio=None), logprobs=None)], provider_specific_fields=None, usage=None), 'usage': None}
original delta: {'provider_specific_fields': None, 'content': ' (', 'role': None, 'function_call': None, 'tool_calls': None, 'audio': None}
new delta: Delta(provider_specific_fields=None, content=' (', role=None, function_call=None, tool_calls=None, audio=None)
model_response.choices[0].delta: Delta(provider_specific_fields=None, content=' (', role=None, function_call=None, tool_calls=None, audio=None); completion_obj: {'content': ' ('}
self.sent_first_chunk: True
completion_obj: {'content': ' ('}, model_response.choices[0]: StreamingChoices(finish_reason=None, index=0, delta=Delta(provider_specific_fields=None, content=' (', role=None, function_call=None, tool_calls=None, audio=None), logprobs=None), response_obj: {'text': ' (', 'is_finished': False, 'finish_reason': None, 'logprobs': None, 'original_chunk': ModelResponseStream(id='chatcmpl-1e246dec-1357-4ceb-948f-03d49e55b5f9', created=1762261913, model=None, object='chat.completion.chunk', system_fingerprint=None, choices=[StreamingChoices(finish_reason=None, index=0, delta=Delta(provider_specific_fields=None, content=' (', role=None, function_call=None, tool_calls=None, audio=None), logprobs=None)], provider_specific_fields=None, usage=None), 'usage': None}
choice_json: {'index': 0, 'delta': {'provider_specific_fields': None, 'content': ' (', 'role': None, 'function_call': None, 'tool_calls': None, 'audio': None}, 'logprobs': None}
choices in streaming: [StreamingChoices(finish_reason=None, index=0, delta=Delta(provider_specific_fields=None, content=' (', role=None, function_call=None, tool_calls=None, audio=None), logprobs=None)]
final returned processed chunk: ModelResponseStream(id='chatcmpl-1e246dec-1357-4ceb-948f-03d49e55b5f9', created=1762261907, model='claude-sonnet-4-5-20250929', object='chat.completion.chunk', system_fingerprint=None, choices=[StreamingChoices(finish_reason=None, index=0, delta=Delta(provider_specific_fields=None, content=' (', role=None, function_call=None, tool_calls=None, audio=None), logprobs=None)], provider_specific_fields=None, citations=None)
model_response finish reason 3: None; response_obj={'text': '', 'is_finished': False, 'finish_reason': '', 'usage': None, 'index': 0, 'tool_use': None}
model_response.choices[0].delta: Delta(provider_specific_fields=None, content=None, role=None, function_call=None, tool_calls=None, audio=None); completion_obj: {'content': ''}
self.sent_first_chunk: True
completion_obj: {'content': ''}, model_response.choices[0]: StreamingChoices(finish_reason=None, index=0, delta=Delta(provider_specific_fields=None, content=None, role=None, function_call=None, tool_calls=None, audio=None), logprobs=None), response_obj: {'text': '', 'is_finished': False, 'finish_reason': '', 'usage': None, 'index': 0, 'tool_use': None}
model_response finish reason 3: None; response_obj={'text': '', 'is_finished': False, 'finish_reason': '', 'usage': None, 'index': 0, 'tool_use': None}
model_response.choices[0].delta: Delta(provider_specific_fields=None, content=None, role=None, function_call=None, tool_calls=None, audio=None); completion_obj: {'content': ''}
self.sent_first_chunk: True
completion_obj: {'content': ''}, model_response.choices[0]: StreamingChoices(finish_reason=None, index=0, delta=Delta(provider_specific_fields=None, content=None, role=None, function_call=None, tool_calls=None, audio=None), logprobs=None), response_obj: {'text': '', 'is_finished': False, 'finish_reason': '', 'usage': None, 'index': 0, 'tool_use': None}

Raw OpenAI Chunk
ModelResponseStream(id='chatcmpl-1e246dec-1357-4ceb-948f-03d49e55b5f9', created=1762261913, model=None, object='chat.completion.chunk', system_fingerprint=None, choices=[StreamingChoices(finish_reason=None, index=0, delta=Delta(provider_specific_fields=None, content='via', role=None, function_call=None, tool_calls=None, audio=None), logprobs=None)], provider_specific_fields=None, usage=None)

model_response finish reason 3: None; response_obj={'text': 'via', 'is_finished': False, 'finish_reason': None, 'logprobs': None, 'original_chunk': ModelResponseStream(id='chatcmpl-1e246dec-1357-4ceb-948f-03d49e55b5f9', created=1762261913, model=None, object='chat.completion.chunk', system_fingerprint=None, choices=[StreamingChoices(finish_reason=None, index=0, delta=Delta(provider_specific_fields=None, content='via', role=None, function_call=None, tool_calls=None, audio=None), logprobs=None)], provider_specific_fields=None, usage=None), 'usage': None}
original delta: {'provider_specific_fields': None, 'content': 'via', 'role': None, 'function_call': None, 'tool_calls': None, 'audio': None}
new delta: Delta(provider_specific_fields=None, content='via', role=None, function_call=None, tool_calls=None, audio=None)
model_response.choices[0].delta: Delta(provider_specific_fields=None, content='via', role=None, function_call=None, tool_calls=None, audio=None); completion_obj: {'content': 'via'}
self.sent_first_chunk: True
completion_obj: {'content': 'via'}, model_response.choices[0]: StreamingChoices(finish_reason=None, index=0, delta=Delta(provider_specific_fields=None, content='via', role=None, function_call=None, tool_calls=None, audio=None), logprobs=None), response_obj: {'text': 'via', 'is_finished': False, 'finish_reason': None, 'logprobs': None, 'original_chunk': ModelResponseStream(id='chatcmpl-1e246dec-1357-4ceb-948f-03d49e55b5f9', created=1762261913, model=None, object='chat.completion.chunk', system_fingerprint=None, choices=[StreamingChoices(finish_reason=None, index=0, delta=Delta(provider_specific_fields=None, content='via', role=None, function_call=None, tool_calls=None, audio=None), logprobs=None)], provider_specific_fields=None, usage=None), 'usage': None}
choice_json: {'index': 0, 'delta': {'provider_specific_fields': None, 'content': 'via', 'role': None, 'function_call': None, 'tool_calls': None, 'audio': None}, 'logprobs': None}
choices in streaming: [StreamingChoices(finish_reason=None, index=0, delta=Delta(provider_specific_fields=None, content='via', role=None, function_call=None, tool_calls=None, audio=None), logprobs=None)]
final returned processed chunk: ModelResponseStream(id='chatcmpl-1e246dec-1357-4ceb-948f-03d49e55b5f9', created=1762261907, model='claude-sonnet-4-5-20250929', object='chat.completion.chunk', system_fingerprint=None, choices=[StreamingChoices(finish_reason=None, index=0, delta=Delta(provider_specific_fields=None, content='via', role=None, function_call=None, tool_calls=None, audio=None), logprobs=None)], provider_specific_fields=None, citations=None)
model_response finish reason 3: None; response_obj={'text': '', 'is_finished': False, 'finish_reason': '', 'usage': None, 'index': 0, 'tool_use': None}
model_response.choices[0].delta: Delta(provider_specific_fields=None, content=None, role=None, function_call=None, tool_calls=None, audio=None); completion_obj: {'content': ''}
self.sent_first_chunk: True
completion_obj: {'content': ''}, model_response.choices[0]: StreamingChoices(finish_reason=None, index=0, delta=Delta(provider_specific_fields=None, content=None, role=None, function_call=None, tool_calls=None, audio=None), logprobs=None), response_obj: {'text': '', 'is_finished': False, 'finish_reason': '', 'usage': None, 'index': 0, 'tool_use': None}
model_response finish reason 3: None; response_obj={'text': '', 'is_finished': False, 'finish_reason': '', 'usage': None, 'index': 0, 'tool_use': None}
model_response.choices[0].delta: Delta(provider_specific_fields=None, content=None, role=None, function_call=None, tool_calls=None, audio=None); completion_obj: {'content': ''}
self.sent_first_chunk: True
completion_obj: {'content': ''}, model_response.choices[0]: StreamingChoices(finish_reason=None, index=0, delta=Delta(provider_specific_fields=None, content=None, role=None, function_call=None, tool_calls=None, audio=None), logprobs=None), response_obj: {'text': '', 'is_finished': False, 'finish_reason': '', 'usage': None, 'index': 0, 'tool_use': None}

Raw OpenAI Chunk
ModelResponseStream(id='chatcmpl-1e246dec-1357-4ceb-948f-03d49e55b5f9', created=1762261913, model=None, object='chat.completion.chunk', system_fingerprint=None, choices=[StreamingChoices(finish_reason=None, index=0, delta=Delta(provider_specific_fields=None, content=' `j', role=None, function_call=None, tool_calls=None, audio=None), logprobs=None)], provider_specific_fields=None, usage=None)

model_response finish reason 3: None; response_obj={'text': ' `j', 'is_finished': False, 'finish_reason': None, 'logprobs': None, 'original_chunk': ModelResponseStream(id='chatcmpl-1e246dec-1357-4ceb-948f-03d49e55b5f9', created=1762261913, model=None, object='chat.completion.chunk', system_fingerprint=None, choices=[StreamingChoices(finish_reason=None, index=0, delta=Delta(provider_specific_fields=None, content=' `j', role=None, function_call=None, tool_calls=None, audio=None), logprobs=None)], provider_specific_fields=None, usage=None), 'usage': None}
original delta: {'provider_specific_fields': None, 'content': ' `j', 'role': None, 'function_call': None, 'tool_calls': None, 'audio': None}
new delta: Delta(provider_specific_fields=None, content=' `j', role=None, function_call=None, tool_calls=None, audio=None)
model_response.choices[0].delta: Delta(provider_specific_fields=None, content=' `j', role=None, function_call=None, tool_calls=None, audio=None); completion_obj: {'content': ' `j'}
self.sent_first_chunk: True
completion_obj: {'content': ' `j'}, model_response.choices[0]: StreamingChoices(finish_reason=None, index=0, delta=Delta(provider_specific_fields=None, content=' `j', role=None, function_call=None, tool_calls=None, audio=None), logprobs=None), response_obj: {'text': ' `j', 'is_finished': False, 'finish_reason': None, 'logprobs': None, 'original_chunk': ModelResponseStream(id='chatcmpl-1e246dec-1357-4ceb-948f-03d49e55b5f9', created=1762261913, model=None, object='chat.completion.chunk', system_fingerprint=None, choices=[StreamingChoices(finish_reason=None, index=0, delta=Delta(provider_specific_fields=None, content=' `j', role=None, function_call=None, tool_calls=None, audio=None), logprobs=None)], provider_specific_fields=None, usage=None), 'usage': None}
choice_json: {'index': 0, 'delta': {'provider_specific_fields': None, 'content': ' `j', 'role': None, 'function_call': None, 'tool_calls': None, 'audio': None}, 'logprobs': None}
choices in streaming: [StreamingChoices(finish_reason=None, index=0, delta=Delta(provider_specific_fields=None, content=' `j', role=None, function_call=None, tool_calls=None, audio=None), logprobs=None)]
final returned processed chunk: ModelResponseStream(id='chatcmpl-1e246dec-1357-4ceb-948f-03d49e55b5f9', created=1762261907, model='claude-sonnet-4-5-20250929', object='chat.completion.chunk', system_fingerprint=None, choices=[StreamingChoices(finish_reason=None, index=0, delta=Delta(provider_specific_fields=None, content=' `j', role=None, function_call=None, tool_calls=None, audio=None), logprobs=None)], provider_specific_fields=None, citations=None)
model_response finish reason 3: None; response_obj={'text': '', 'is_finished': False, 'finish_reason': '', 'usage': None, 'index': 0, 'tool_use': None}
model_response.choices[0].delta: Delta(provider_specific_fields=None, content=None, role=None, function_call=None, tool_calls=None, audio=None); completion_obj: {'content': ''}
self.sent_first_chunk: True
completion_obj: {'content': ''}, model_response.choices[0]: StreamingChoices(finish_reason=None, index=0, delta=Delta(provider_specific_fields=None, content=None, role=None, function_call=None, tool_calls=None, audio=None), logprobs=None), response_obj: {'text': '', 'is_finished': False, 'finish_reason': '', 'usage': None, 'index': 0, 'tool_use': None}
model_response finish reason 3: None; response_obj={'text': '', 'is_finished': False, 'finish_reason': '', 'usage': None, 'index': 0, 'tool_use': None}
model_response.choices[0].delta: Delta(provider_specific_fields=None, content=None, role=None, function_call=None, tool_calls=None, audio=None); completion_obj: {'content': ''}
self.sent_first_chunk: True
completion_obj: {'content': ''}, model_response.choices[0]: StreamingChoices(finish_reason=None, index=0, delta=Delta(provider_specific_fields=None, content=None, role=None, function_call=None, tool_calls=None, audio=None), logprobs=None), response_obj: {'text': '', 'is_finished': False, 'finish_reason': '', 'usage': None, 'index': 0, 'tool_use': None}

Raw OpenAI Chunk
ModelResponseStream(id='chatcmpl-1e246dec-1357-4ceb-948f-03d49e55b5f9', created=1762261913, model=None, object='chat.completion.chunk', system_fingerprint=None, choices=[StreamingChoices(finish_reason=None, index=0, delta=Delta(provider_specific_fields=None, content='j', role=None, function_call=None, tool_calls=None, audio=None), logprobs=None)], provider_specific_fields=None, usage=None)

model_response finish reason 3: None; response_obj={'text': 'j', 'is_finished': False, 'finish_reason': None, 'logprobs': None, 'original_chunk': ModelResponseStream(id='chatcmpl-1e246dec-1357-4ceb-948f-03d49e55b5f9', created=1762261913, model=None, object='chat.completion.chunk', system_fingerprint=None, choices=[StreamingChoices(finish_reason=None, index=0, delta=Delta(provider_specific_fields=None, content='j', role=None, function_call=None, tool_calls=None, audio=None), logprobs=None)], provider_specific_fields=None, usage=None), 'usage': None}
original delta: {'provider_specific_fields': None, 'content': 'j', 'role': None, 'function_call': None, 'tool_calls': None, 'audio': None}
new delta: Delta(provider_specific_fields=None, content='j', role=None, function_call=None, tool_calls=None, audio=None)
model_response.choices[0].delta: Delta(provider_specific_fields=None, content='j', role=None, function_call=None, tool_calls=None, audio=None); completion_obj: {'content': 'j'}
self.sent_first_chunk: True
completion_obj: {'content': 'j'}, model_response.choices[0]: StreamingChoices(finish_reason=None, index=0, delta=Delta(provider_specific_fields=None, content='j', role=None, function_call=None, tool_calls=None, audio=None), logprobs=None), response_obj: {'text': 'j', 'is_finished': False, 'finish_reason': None, 'logprobs': None, 'original_chunk': ModelResponseStream(id='chatcmpl-1e246dec-1357-4ceb-948f-03d49e55b5f9', created=1762261913, model=None, object='chat.completion.chunk', system_fingerprint=None, choices=[StreamingChoices(finish_reason=None, index=0, delta=Delta(provider_specific_fields=None, content='j', role=None, function_call=None, tool_calls=None, audio=None), logprobs=None)], provider_specific_fields=None, usage=None), 'usage': None}
choice_json: {'index': 0, 'delta': {'provider_specific_fields': None, 'content': 'j', 'role': None, 'function_call': None, 'tool_calls': None, 'audio': None}, 'logprobs': None}
choices in streaming: [StreamingChoices(finish_reason=None, index=0, delta=Delta(provider_specific_fields=None, content='j', role=None, function_call=None, tool_calls=None, audio=None), logprobs=None)]
final returned processed chunk: ModelResponseStream(id='chatcmpl-1e246dec-1357-4ceb-948f-03d49e55b5f9', created=1762261907, model='claude-sonnet-4-5-20250929', object='chat.completion.chunk', system_fingerprint=None, choices=[StreamingChoices(finish_reason=None, index=0, delta=Delta(provider_specific_fields=None, content='j', role=None, function_call=None, tool_calls=None, audio=None), logprobs=None)], provider_specific_fields=None, citations=None)
model_response finish reason 3: None; response_obj={'text': '', 'is_finished': False, 'finish_reason': '', 'usage': None, 'index': 0, 'tool_use': None}
model_response.choices[0].delta: Delta(provider_specific_fields=None, content=None, role=None, function_call=None, tool_calls=None, audio=None); completion_obj: {'content': ''}
self.sent_first_chunk: True
completion_obj: {'content': ''}, model_response.choices[0]: StreamingChoices(finish_reason=None, index=0, delta=Delta(provider_specific_fields=None, content=None, role=None, function_call=None, tool_calls=None, audio=None), logprobs=None), response_obj: {'text': '', 'is_finished': False, 'finish_reason': '', 'usage': None, 'index': 0, 'tool_use': None}
model_response finish reason 3: None; response_obj={'text': '', 'is_finished': False, 'finish_reason': '', 'usage': None, 'index': 0, 'tool_use': None}
model_response.choices[0].delta: Delta(provider_specific_fields=None, content=None, role=None, function_call=None, tool_calls=None, audio=None); completion_obj: {'content': ''}
self.sent_first_chunk: True
completion_obj: {'content': ''}, model_response.choices[0]: StreamingChoices(finish_reason=None, index=0, delta=Delta(provider_specific_fields=None, content=None, role=None, function_call=None, tool_calls=None, audio=None), logprobs=None), response_obj: {'text': '', 'is_finished': False, 'finish_reason': '', 'usage': None, 'index': 0, 'tool_use': None}

Raw OpenAI Chunk
ModelResponseStream(id='chatcmpl-1e246dec-1357-4ceb-948f-03d49e55b5f9', created=1762261913, model=None, object='chat.completion.chunk', system_fingerprint=None, choices=[StreamingChoices(finish_reason=None, index=0, delta=Delta(provider_specific_fields=None, content=' status', role=None, function_call=None, tool_calls=None, audio=None), logprobs=None)], provider_specific_fields=None, usage=None)

model_response finish reason 3: None; response_obj={'text': ' status', 'is_finished': False, 'finish_reason': None, 'logprobs': None, 'original_chunk': ModelResponseStream(id='chatcmpl-1e246dec-1357-4ceb-948f-03d49e55b5f9', created=1762261913, model=None, object='chat.completion.chunk', system_fingerprint=None, choices=[StreamingChoices(finish_reason=None, index=0, delta=Delta(provider_specific_fields=None, content=' status', role=None, function_call=None, tool_calls=None, audio=None), logprobs=None)], provider_specific_fields=None, usage=None), 'usage': None}
original delta: {'provider_specific_fields': None, 'content': ' status', 'role': None, 'function_call': None, 'tool_calls': None, 'audio': None}
new delta: Delta(provider_specific_fields=None, content=' status', role=None, function_call=None, tool_calls=None, audio=None)
model_response.choices[0].delta: Delta(provider_specific_fields=None, content=' status', role=None, function_call=None, tool_calls=None, audio=None); completion_obj: {'content': ' status'}
self.sent_first_chunk: True
completion_obj: {'content': ' status'}, model_response.choices[0]: StreamingChoices(finish_reason=None, index=0, delta=Delta(provider_specific_fields=None, content=' status', role=None, function_call=None, tool_calls=None, audio=None), logprobs=None), response_obj: {'text': ' status', 'is_finished': False, 'finish_reason': None, 'logprobs': None, 'original_chunk': ModelResponseStream(id='chatcmpl-1e246dec-1357-4ceb-948f-03d49e55b5f9', created=1762261913, model=None, object='chat.completion.chunk', system_fingerprint=None, choices=[StreamingChoices(finish_reason=None, index=0, delta=Delta(provider_specific_fields=None, content=' status', role=None, function_call=None, tool_calls=None, audio=None), logprobs=None)], provider_specific_fields=None, usage=None), 'usage': None}
choice_json: {'index': 0, 'delta': {'provider_specific_fields': None, 'content': ' status', 'role': None, 'function_call': None, 'tool_calls': None, 'audio': None}, 'logprobs': None}
choices in streaming: [StreamingChoices(finish_reason=None, index=0, delta=Delta(provider_specific_fields=None, content=' status', role=None, function_call=None, tool_calls=None, audio=None), logprobs=None)]
final returned processed chunk: ModelResponseStream(id='chatcmpl-1e246dec-1357-4ceb-948f-03d49e55b5f9', created=1762261907, model='claude-sonnet-4-5-20250929', object='chat.completion.chunk', system_fingerprint=None, choices=[StreamingChoices(finish_reason=None, index=0, delta=Delta(provider_specific_fields=None, content=' status', role=None, function_call=None, tool_calls=None, audio=None), logprobs=None)], provider_specific_fields=None, citations=None)
model_response finish reason 3: None; response_obj={'text': '', 'is_finished': False, 'finish_reason': '', 'usage': None, 'index': 0, 'tool_use': None}
model_response.choices[0].delta: Delta(provider_specific_fields=None, content=None, role=None, function_call=None, tool_calls=None, audio=None); completion_obj: {'content': ''}
self.sent_first_chunk: True
completion_obj: {'content': ''}, model_response.choices[0]: StreamingChoices(finish_reason=None, index=0, delta=Delta(provider_specific_fields=None, content=None, role=None, function_call=None, tool_calls=None, audio=None), logprobs=None), response_obj: {'text': '', 'is_finished': False, 'finish_reason': '', 'usage': None, 'index': 0, 'tool_use': None}
model_response finish reason 3: None; response_obj={'text': '', 'is_finished': False, 'finish_reason': '', 'usage': None, 'index': 0, 'tool_use': None}
model_response.choices[0].delta: Delta(provider_specific_fields=None, content=None, role=None, function_call=None, tool_calls=None, audio=None); completion_obj: {'content': ''}
self.sent_first_chunk: True
completion_obj: {'content': ''}, model_response.choices[0]: StreamingChoices(finish_reason=None, index=0, delta=Delta(provider_specific_fields=None, content=None, role=None, function_call=None, tool_calls=None, audio=None), logprobs=None), response_obj: {'text': '', 'is_finished': False, 'finish_reason': '', 'usage': None, 'index': 0, 'tool_use': None}

Raw OpenAI Chunk
ModelResponseStream(id='chatcmpl-1e246dec-1357-4ceb-948f-03d49e55b5f9', created=1762261914, model=None, object='chat.completion.chunk', system_fingerprint=None, choices=[StreamingChoices(finish_reason=None, index=0, delta=Delta(provider_specific_fields=None, content='`), which', role=None, function_call=None, tool_calls=None, audio=None), logprobs=None)], provider_specific_fields=None, usage=None)

model_response finish reason 3: None; response_obj={'text': '`), which', 'is_finished': False, 'finish_reason': None, 'logprobs': None, 'original_chunk': ModelResponseStream(id='chatcmpl-1e246dec-1357-4ceb-948f-03d49e55b5f9', created=1762261914, model=None, object='chat.completion.chunk', system_fingerprint=None, choices=[StreamingChoices(finish_reason=None, index=0, delta=Delta(provider_specific_fields=None, content='`), which', role=None, function_call=None, tool_calls=None, audio=None), logprobs=None)], provider_specific_fields=None, usage=None), 'usage': None}
original delta: {'provider_specific_fields': None, 'content': '`), which', 'role': None, 'function_call': None, 'tool_calls': None, 'audio': None}
new delta: Delta(provider_specific_fields=None, content='`), which', role=None, function_call=None, tool_calls=None, audio=None)
model_response.choices[0].delta: Delta(provider_specific_fields=None, content='`), which', role=None, function_call=None, tool_calls=None, audio=None); completion_obj: {'content': '`), which'}
self.sent_first_chunk: True
completion_obj: {'content': '`), which'}, model_response.choices[0]: StreamingChoices(finish_reason=None, index=0, delta=Delta(provider_specific_fields=None, content='`), which', role=None, function_call=None, tool_calls=None, audio=None), logprobs=None), response_obj: {'text': '`), which', 'is_finished': False, 'finish_reason': None, 'logprobs': None, 'original_chunk': ModelResponseStream(id='chatcmpl-1e246dec-1357-4ceb-948f-03d49e55b5f9', created=1762261914, model=None, object='chat.completion.chunk', system_fingerprint=None, choices=[StreamingChoices(finish_reason=None, index=0, delta=Delta(provider_specific_fields=None, content='`), which', role=None, function_call=None, tool_calls=None, audio=None), logprobs=None)], provider_specific_fields=None, usage=None), 'usage': None}
choice_json: {'index': 0, 'delta': {'provider_specific_fields': None, 'content': '`), which', 'role': None, 'function_call': None, 'tool_calls': None, 'audio': None}, 'logprobs': None}
choices in streaming: [StreamingChoices(finish_reason=None, index=0, delta=Delta(provider_specific_fields=None, content='`), which', role=None, function_call=None, tool_calls=None, audio=None), logprobs=None)]
final returned processed chunk: ModelResponseStream(id='chatcmpl-1e246dec-1357-4ceb-948f-03d49e55b5f9', created=1762261907, model='claude-sonnet-4-5-20250929', object='chat.completion.chunk', system_fingerprint=None, choices=[StreamingChoices(finish_reason=None, index=0, delta=Delta(provider_specific_fields=None, content='`), which', role=None, function_call=None, tool_calls=None, audio=None), logprobs=None)], provider_specific_fields=None, citations=None)
model_response finish reason 3: None; response_obj={'text': '', 'is_finished': False, 'finish_reason': '', 'usage': None, 'index': 0, 'tool_use': None}
model_response.choices[0].delta: Delta(provider_specific_fields=None, content=None, role=None, function_call=None, tool_calls=None, audio=None); completion_obj: {'content': ''}
self.sent_first_chunk: True
completion_obj: {'content': ''}, model_response.choices[0]: StreamingChoices(finish_reason=None, index=0, delta=Delta(provider_specific_fields=None, content=None, role=None, function_call=None, tool_calls=None, audio=None), logprobs=None), response_obj: {'text': '', 'is_finished': False, 'finish_reason': '', 'usage': None, 'index': 0, 'tool_use': None}
model_response finish reason 3: None; response_obj={'text': '', 'is_finished': False, 'finish_reason': '', 'usage': None, 'index': 0, 'tool_use': None}
model_response.choices[0].delta: Delta(provider_specific_fields=None, content=None, role=None, function_call=None, tool_calls=None, audio=None); completion_obj: {'content': ''}
self.sent_first_chunk: True
completion_obj: {'content': ''}, model_response.choices[0]: StreamingChoices(finish_reason=None, index=0, delta=Delta(provider_specific_fields=None, content=None, role=None, function_call=None, tool_calls=None, audio=None), logprobs=None), response_obj: {'text': '', 'is_finished': False, 'finish_reason': '', 'usage': None, 'index': 0, 'tool_use': None}

Raw OpenAI Chunk
ModelResponseStream(id='chatcmpl-1e246dec-1357-4ceb-948f-03d49e55b5f9', created=1762261914, model=None, object='chat.completion.chunk', system_fingerprint=None, choices=[StreamingChoices(finish_reason=None, index=0, delta=Delta(provider_specific_fields=None, content=" suggests you're using", role=None, function_call=None, tool_calls=None, audio=None), logprobs=None)], provider_specific_fields=None, usage=None)

model_response finish reason 3: None; response_obj={'text': " suggests you're using", 'is_finished': False, 'finish_reason': None, 'logprobs': None, 'original_chunk': ModelResponseStream(id='chatcmpl-1e246dec-1357-4ceb-948f-03d49e55b5f9', created=1762261914, model=None, object='chat.completion.chunk', system_fingerprint=None, choices=[StreamingChoices(finish_reason=None, index=0, delta=Delta(provider_specific_fields=None, content=" suggests you're using", role=None, function_call=None, tool_calls=None, audio=None), logprobs=None)], provider_specific_fields=None, usage=None), 'usage': None}
original delta: {'provider_specific_fields': None, 'content': " suggests you're using", 'role': None, 'function_call': None, 'tool_calls': None, 'audio': None}
new delta: Delta(provider_specific_fields=None, content=" suggests you're using", role=None, function_call=None, tool_calls=None, audio=None)
model_response.choices[0].delta: Delta(provider_specific_fields=None, content=" suggests you're using", role=None, function_call=None, tool_calls=None, audio=None); completion_obj: {'content': " suggests you're using"}
self.sent_first_chunk: True
completion_obj: {'content': " suggests you're using"}, model_response.choices[0]: StreamingChoices(finish_reason=None, index=0, delta=Delta(provider_specific_fields=None, content=" suggests you're using", role=None, function_call=None, tool_calls=None, audio=None), logprobs=None), response_obj: {'text': " suggests you're using", 'is_finished': False, 'finish_reason': None, 'logprobs': None, 'original_chunk': ModelResponseStream(id='chatcmpl-1e246dec-1357-4ceb-948f-03d49e55b5f9', created=1762261914, model=None, object='chat.completion.chunk', system_fingerprint=None, choices=[StreamingChoices(finish_reason=None, index=0, delta=Delta(provider_specific_fields=None, content=" suggests you're using", role=None, function_call=None, tool_calls=None, audio=None), logprobs=None)], provider_specific_fields=None, usage=None), 'usage': None}
choice_json: {'index': 0, 'delta': {'provider_specific_fields': None, 'content': " suggests you're using", 'role': None, 'function_call': None, 'tool_calls': None, 'audio': None}, 'logprobs': None}
choices in streaming: [StreamingChoices(finish_reason=None, index=0, delta=Delta(provider_specific_fields=None, content=" suggests you're using", role=None, function_call=None, tool_calls=None, audio=None), logprobs=None)]
final returned processed chunk: ModelResponseStream(id='chatcmpl-1e246dec-1357-4ceb-948f-03d49e55b5f9', created=1762261907, model='claude-sonnet-4-5-20250929', object='chat.completion.chunk', system_fingerprint=None, choices=[StreamingChoices(finish_reason=None, index=0, delta=Delta(provider_specific_fields=None, content=" suggests you're using", role=None, function_call=None, tool_calls=None, audio=None), logprobs=None)], provider_specific_fields=None, citations=None)
model_response finish reason 3: None; response_obj={'text': '', 'is_finished': False, 'finish_reason': '', 'usage': None, 'index': 0, 'tool_use': None}
model_response.choices[0].delta: Delta(provider_specific_fields=None, content=None, role=None, function_call=None, tool_calls=None, audio=None); completion_obj: {'content': ''}
self.sent_first_chunk: True
completion_obj: {'content': ''}, model_response.choices[0]: StreamingChoices(finish_reason=None, index=0, delta=Delta(provider_specific_fields=None, content=None, role=None, function_call=None, tool_calls=None, audio=None), logprobs=None), response_obj: {'text': '', 'is_finished': False, 'finish_reason': '', 'usage': None, 'index': 0, 'tool_use': None}
model_response finish reason 3: None; response_obj={'text': '', 'is_finished': False, 'finish_reason': '', 'usage': None, 'index': 0, 'tool_use': None}
model_response.choices[0].delta: Delta(provider_specific_fields=None, content=None, role=None, function_call=None, tool_calls=None, audio=None); completion_obj: {'content': ''}
self.sent_first_chunk: True
completion_obj: {'content': ''}, model_response.choices[0]: StreamingChoices(finish_reason=None, index=0, delta=Delta(provider_specific_fields=None, content=None, role=None, function_call=None, tool_calls=None, audio=None), logprobs=None), response_obj: {'text': '', 'is_finished': False, 'finish_reason': '', 'usage': None, 'index': 0, 'tool_use': None}

Raw OpenAI Chunk
ModelResponseStream(id='chatcmpl-1e246dec-1357-4ceb-948f-03d49e55b5f9', created=1762261914, model=None, object='chat.completion.chunk', system_fingerprint=None, choices=[StreamingChoices(finish_reason=None, index=0, delta=Delta(provider_specific_fields=None, content=' **', role=None, function_call=None, tool_calls=None, audio=None), logprobs=None)], provider_specific_fields=None, usage=None)

model_response finish reason 3: None; response_obj={'text': ' **', 'is_finished': False, 'finish_reason': None, 'logprobs': None, 'original_chunk': ModelResponseStream(id='chatcmpl-1e246dec-1357-4ceb-948f-03d49e55b5f9', created=1762261914, model=None, object='chat.completion.chunk', system_fingerprint=None, choices=[StreamingChoices(finish_reason=None, index=0, delta=Delta(provider_specific_fields=None, content=' **', role=None, function_call=None, tool_calls=None, audio=None), logprobs=None)], provider_specific_fields=None, usage=None), 'usage': None}
original delta: {'provider_specific_fields': None, 'content': ' **', 'role': None, 'function_call': None, 'tool_calls': None, 'audio': None}
new delta: Delta(provider_specific_fields=None, content=' **', role=None, function_call=None, tool_calls=None, audio=None)
model_response.choices[0].delta: Delta(provider_specific_fields=None, content=' **', role=None, function_call=None, tool_calls=None, audio=None); completion_obj: {'content': ' **'}
self.sent_first_chunk: True
completion_obj: {'content': ' **'}, model_response.choices[0]: StreamingChoices(finish_reason=None, index=0, delta=Delta(provider_specific_fields=None, content=' **', role=None, function_call=None, tool_calls=None, audio=None), logprobs=None), response_obj: {'text': ' **', 'is_finished': False, 'finish_reason': None, 'logprobs': None, 'original_chunk': ModelResponseStream(id='chatcmpl-1e246dec-1357-4ceb-948f-03d49e55b5f9', created=1762261914, model=None, object='chat.completion.chunk', system_fingerprint=None, choices=[StreamingChoices(finish_reason=None, index=0, delta=Delta(provider_specific_fields=None, content=' **', role=None, function_call=None, tool_calls=None, audio=None), logprobs=None)], provider_specific_fields=None, usage=None), 'usage': None}
choice_json: {'index': 0, 'delta': {'provider_specific_fields': None, 'content': ' **', 'role': None, 'function_call': None, 'tool_calls': None, 'audio': None}, 'logprobs': None}
choices in streaming: [StreamingChoices(finish_reason=None, index=0, delta=Delta(provider_specific_fields=None, content=' **', role=None, function_call=None, tool_calls=None, audio=None), logprobs=None)]
final returned processed chunk: ModelResponseStream(id='chatcmpl-1e246dec-1357-4ceb-948f-03d49e55b5f9', created=1762261907, model='claude-sonnet-4-5-20250929', object='chat.completion.chunk', system_fingerprint=None, choices=[StreamingChoices(finish_reason=None, index=0, delta=Delta(provider_specific_fields=None, content=' **', role=None, function_call=None, tool_calls=None, audio=None), logprobs=None)], provider_specific_fields=None, citations=None)
model_response finish reason 3: None; response_obj={'text': '', 'is_finished': False, 'finish_reason': '', 'usage': None, 'index': 0, 'tool_use': None}
model_response.choices[0].delta: Delta(provider_specific_fields=None, content=None, role=None, function_call=None, tool_calls=None, audio=None); completion_obj: {'content': ''}
self.sent_first_chunk: True
completion_obj: {'content': ''}, model_response.choices[0]: StreamingChoices(finish_reason=None, index=0, delta=Delta(provider_specific_fields=None, content=None, role=None, function_call=None, tool_calls=None, audio=None), logprobs=None), response_obj: {'text': '', 'is_finished': False, 'finish_reason': '', 'usage': None, 'index': 0, 'tool_use': None}
model_response finish reason 3: None; response_obj={'text': '', 'is_finished': False, 'finish_reason': '', 'usage': None, 'index': 0, 'tool_use': None}
model_response.choices[0].delta: Delta(provider_specific_fields=None, content=None, role=None, function_call=None, tool_calls=None, audio=None); completion_obj: {'content': ''}
self.sent_first_chunk: True
completion_obj: {'content': ''}, model_response.choices[0]: StreamingChoices(finish_reason=None, index=0, delta=Delta(provider_specific_fields=None, content=None, role=None, function_call=None, tool_calls=None, audio=None), logprobs=None), response_obj: {'text': '', 'is_finished': False, 'finish_reason': '', 'usage': None, 'index': 0, 'tool_use': None}

Raw OpenAI Chunk
ModelResponseStream(id='chatcmpl-1e246dec-1357-4ceb-948f-03d49e55b5f9', created=1762261914, model=None, object='chat.completion.chunk', system_fingerprint=None, choices=[StreamingChoices(finish_reason=None, index=0, delta=Delta(provider_specific_fields=None, content='Jujutsu (', role=None, function_call=None, tool_calls=None, audio=None), logprobs=None)], provider_specific_fields=None, usage=None)

model_response finish reason 3: None; response_obj={'text': 'Jujutsu (', 'is_finished': False, 'finish_reason': None, 'logprobs': None, 'original_chunk': ModelResponseStream(id='chatcmpl-1e246dec-1357-4ceb-948f-03d49e55b5f9', created=1762261914, model=None, object='chat.completion.chunk', system_fingerprint=None, choices=[StreamingChoices(finish_reason=None, index=0, delta=Delta(provider_specific_fields=None, content='Jujutsu (', role=None, function_call=None, tool_calls=None, audio=None), logprobs=None)], provider_specific_fields=None, usage=None), 'usage': None}
original delta: {'provider_specific_fields': None, 'content': 'Jujutsu (', 'role': None, 'function_call': None, 'tool_calls': None, 'audio': None}
new delta: Delta(provider_specific_fields=None, content='Jujutsu (', role=None, function_call=None, tool_calls=None, audio=None)
model_response.choices[0].delta: Delta(provider_specific_fields=None, content='Jujutsu (', role=None, function_call=None, tool_calls=None, audio=None); completion_obj: {'content': 'Jujutsu ('}
self.sent_first_chunk: True
completion_obj: {'content': 'Jujutsu ('}, model_response.choices[0]: StreamingChoices(finish_reason=None, index=0, delta=Delta(provider_specific_fields=None, content='Jujutsu (', role=None, function_call=None, tool_calls=None, audio=None), logprobs=None), response_obj: {'text': 'Jujutsu (', 'is_finished': False, 'finish_reason': None, 'logprobs': None, 'original_chunk': ModelResponseStream(id='chatcmpl-1e246dec-1357-4ceb-948f-03d49e55b5f9', created=1762261914, model=None, object='chat.completion.chunk', system_fingerprint=None, choices=[StreamingChoices(finish_reason=None, index=0, delta=Delta(provider_specific_fields=None, content='Jujutsu (', role=None, function_call=None, tool_calls=None, audio=None), logprobs=None)], provider_specific_fields=None, usage=None), 'usage': None}
choice_json: {'index': 0, 'delta': {'provider_specific_fields': None, 'content': 'Jujutsu (', 'role': None, 'function_call': None, 'tool_calls': None, 'audio': None}, 'logprobs': None}
choices in streaming: [StreamingChoices(finish_reason=None, index=0, delta=Delta(provider_specific_fields=None, content='Jujutsu (', role=None, function_call=None, tool_calls=None, audio=None), logprobs=None)]
final returned processed chunk: ModelResponseStream(id='chatcmpl-1e246dec-1357-4ceb-948f-03d49e55b5f9', created=1762261907, model='claude-sonnet-4-5-20250929', object='chat.completion.chunk', system_fingerprint=None, choices=[StreamingChoices(finish_reason=None, index=0, delta=Delta(provider_specific_fields=None, content='Jujutsu (', role=None, function_call=None, tool_calls=None, audio=None), logprobs=None)], provider_specific_fields=None, citations=None)
model_response finish reason 3: None; response_obj={'text': '', 'is_finished': False, 'finish_reason': '', 'usage': None, 'index': 0, 'tool_use': None}
model_response.choices[0].delta: Delta(provider_specific_fields=None, content=None, role=None, function_call=None, tool_calls=None, audio=None); completion_obj: {'content': ''}
self.sent_first_chunk: True
completion_obj: {'content': ''}, model_response.choices[0]: StreamingChoices(finish_reason=None, index=0, delta=Delta(provider_specific_fields=None, content=None, role=None, function_call=None, tool_calls=None, audio=None), logprobs=None), response_obj: {'text': '', 'is_finished': False, 'finish_reason': '', 'usage': None, 'index': 0, 'tool_use': None}
model_response finish reason 3: None; response_obj={'text': '', 'is_finished': False, 'finish_reason': '', 'usage': None, 'index': 0, 'tool_use': None}
model_response.choices[0].delta: Delta(provider_specific_fields=None, content=None, role=None, function_call=None, tool_calls=None, audio=None); completion_obj: {'content': ''}
self.sent_first_chunk: True
completion_obj: {'content': ''}, model_response.choices[0]: StreamingChoices(finish_reason=None, index=0, delta=Delta(provider_specific_fields=None, content=None, role=None, function_call=None, tool_calls=None, audio=None), logprobs=None), response_obj: {'text': '', 'is_finished': False, 'finish_reason': '', 'usage': None, 'index': 0, 'tool_use': None}

Raw OpenAI Chunk
ModelResponseStream(id='chatcmpl-1e246dec-1357-4ceb-948f-03d49e55b5f9', created=1762261914, model=None, object='chat.completion.chunk', system_fingerprint=None, choices=[StreamingChoices(finish_reason=None, index=0, delta=Delta(provider_specific_fields=None, content='j', role=None, function_call=None, tool_calls=None, audio=None), logprobs=None)], provider_specific_fields=None, usage=None)

model_response finish reason 3: None; response_obj={'text': 'j', 'is_finished': False, 'finish_reason': None, 'logprobs': None, 'original_chunk': ModelResponseStream(id='chatcmpl-1e246dec-1357-4ceb-948f-03d49e55b5f9', created=1762261914, model=None, object='chat.completion.chunk', system_fingerprint=None, choices=[StreamingChoices(finish_reason=None, index=0, delta=Delta(provider_specific_fields=None, content='j', role=None, function_call=None, tool_calls=None, audio=None), logprobs=None)], provider_specific_fields=None, usage=None), 'usage': None}
original delta: {'provider_specific_fields': None, 'content': 'j', 'role': None, 'function_call': None, 'tool_calls': None, 'audio': None}
new delta: Delta(provider_specific_fields=None, content='j', role=None, function_call=None, tool_calls=None, audio=None)
model_response.choices[0].delta: Delta(provider_specific_fields=None, content='j', role=None, function_call=None, tool_calls=None, audio=None); completion_obj: {'content': 'j'}
self.sent_first_chunk: True
completion_obj: {'content': 'j'}, model_response.choices[0]: StreamingChoices(finish_reason=None, index=0, delta=Delta(provider_specific_fields=None, content='j', role=None, function_call=None, tool_calls=None, audio=None), logprobs=None), response_obj: {'text': 'j', 'is_finished': False, 'finish_reason': None, 'logprobs': None, 'original_chunk': ModelResponseStream(id='chatcmpl-1e246dec-1357-4ceb-948f-03d49e55b5f9', created=1762261914, model=None, object='chat.completion.chunk', system_fingerprint=None, choices=[StreamingChoices(finish_reason=None, index=0, delta=Delta(provider_specific_fields=None, content='j', role=None, function_call=None, tool_calls=None, audio=None), logprobs=None)], provider_specific_fields=None, usage=None), 'usage': None}
choice_json: {'index': 0, 'delta': {'provider_specific_fields': None, 'content': 'j', 'role': None, 'function_call': None, 'tool_calls': None, 'audio': None}, 'logprobs': None}
choices in streaming: [StreamingChoices(finish_reason=None, index=0, delta=Delta(provider_specific_fields=None, content='j', role=None, function_call=None, tool_calls=None, audio=None), logprobs=None)]
final returned processed chunk: ModelResponseStream(id='chatcmpl-1e246dec-1357-4ceb-948f-03d49e55b5f9', created=1762261907, model='claude-sonnet-4-5-20250929', object='chat.completion.chunk', system_fingerprint=None, choices=[StreamingChoices(finish_reason=None, index=0, delta=Delta(provider_specific_fields=None, content='j', role=None, function_call=None, tool_calls=None, audio=None), logprobs=None)], provider_specific_fields=None, citations=None)
model_response finish reason 3: None; response_obj={'text': '', 'is_finished': False, 'finish_reason': '', 'usage': None, 'index': 0, 'tool_use': None}
model_response.choices[0].delta: Delta(provider_specific_fields=None, content=None, role=None, function_call=None, tool_calls=None, audio=None); completion_obj: {'content': ''}
self.sent_first_chunk: True
completion_obj: {'content': ''}, model_response.choices[0]: StreamingChoices(finish_reason=None, index=0, delta=Delta(provider_specific_fields=None, content=None, role=None, function_call=None, tool_calls=None, audio=None), logprobs=None), response_obj: {'text': '', 'is_finished': False, 'finish_reason': '', 'usage': None, 'index': 0, 'tool_use': None}
model_response finish reason 3: None; response_obj={'text': '', 'is_finished': False, 'finish_reason': '', 'usage': None, 'index': 0, 'tool_use': None}
model_response.choices[0].delta: Delta(provider_specific_fields=None, content=None, role=None, function_call=None, tool_calls=None, audio=None); completion_obj: {'content': ''}
self.sent_first_chunk: True
completion_obj: {'content': ''}, model_response.choices[0]: StreamingChoices(finish_reason=None, index=0, delta=Delta(provider_specific_fields=None, content=None, role=None, function_call=None, tool_calls=None, audio=None), logprobs=None), response_obj: {'text': '', 'is_finished': False, 'finish_reason': '', 'usage': None, 'index': 0, 'tool_use': None}

Raw OpenAI Chunk
ModelResponseStream(id='chatcmpl-1e246dec-1357-4ceb-948f-03d49e55b5f9', created=1762261914, model=None, object='chat.completion.chunk', system_fingerprint=None, choices=[StreamingChoices(finish_reason=None, index=0, delta=Delta(provider_specific_fields=None, content='j)** for version control.', role=None, function_call=None, tool_calls=None, audio=None), logprobs=None)], provider_specific_fields=None, usage=None)

model_response finish reason 3: None; response_obj={'text': 'j)** for version control.', 'is_finished': False, 'finish_reason': None, 'logprobs': None, 'original_chunk': ModelResponseStream(id='chatcmpl-1e246dec-1357-4ceb-948f-03d49e55b5f9', created=1762261914, model=None, object='chat.completion.chunk', system_fingerprint=None, choices=[StreamingChoices(finish_reason=None, index=0, delta=Delta(provider_specific_fields=None, content='j)** for version control.', role=None, function_call=None, tool_calls=None, audio=None), logprobs=None)], provider_specific_fields=None, usage=None), 'usage': None}
original delta: {'provider_specific_fields': None, 'content': 'j)** for version control.', 'role': None, 'function_call': None, 'tool_calls': None, 'audio': None}
new delta: Delta(provider_specific_fields=None, content='j)** for version control.', role=None, function_call=None, tool_calls=None, audio=None)
model_response.choices[0].delta: Delta(provider_specific_fields=None, content='j)** for version control.', role=None, function_call=None, tool_calls=None, audio=None); completion_obj: {'content': 'j)** for version control.'}
self.sent_first_chunk: True
completion_obj: {'content': 'j)** for version control.'}, model_response.choices[0]: StreamingChoices(finish_reason=None, index=0, delta=Delta(provider_specific_fields=None, content='j)** for version control.', role=None, function_call=None, tool_calls=None, audio=None), logprobs=None), response_obj: {'text': 'j)** for version control.', 'is_finished': False, 'finish_reason': None, 'logprobs': None, 'original_chunk': ModelResponseStream(id='chatcmpl-1e246dec-1357-4ceb-948f-03d49e55b5f9', created=1762261914, model=None, object='chat.completion.chunk', system_fingerprint=None, choices=[StreamingChoices(finish_reason=None, index=0, delta=Delta(provider_specific_fields=None, content='j)** for version control.', role=None, function_call=None, tool_calls=None, audio=None), logprobs=None)], provider_specific_fields=None, usage=None), 'usage': None}
choice_json: {'index': 0, 'delta': {'provider_specific_fields': None, 'content': 'j)** for version control.', 'role': None, 'function_call': None, 'tool_calls': None, 'audio': None}, 'logprobs': None}
choices in streaming: [StreamingChoices(finish_reason=None, index=0, delta=Delta(provider_specific_fields=None, content='j)** for version control.', role=None, function_call=None, tool_calls=None, audio=None), logprobs=None)]
final returned processed chunk: ModelResponseStream(id='chatcmpl-1e246dec-1357-4ceb-948f-03d49e55b5f9', created=1762261907, model='claude-sonnet-4-5-20250929', object='chat.completion.chunk', system_fingerprint=None, choices=[StreamingChoices(finish_reason=None, index=0, delta=Delta(provider_specific_fields=None, content='j)** for version control.', role=None, function_call=None, tool_calls=None, audio=None), logprobs=None)], provider_specific_fields=None, citations=None)
model_response finish reason 3: None; response_obj={'text': '', 'is_finished': False, 'finish_reason': '', 'usage': None, 'index': 0, 'tool_use': None}
model_response.choices[0].delta: Delta(provider_specific_fields=None, content=None, role=None, function_call=None, tool_calls=None, audio=None); completion_obj: {'content': ''}
self.sent_first_chunk: True
completion_obj: {'content': ''}, model_response.choices[0]: StreamingChoices(finish_reason=None, index=0, delta=Delta(provider_specific_fields=None, content=None, role=None, function_call=None, tool_calls=None, audio=None), logprobs=None), response_obj: {'text': '', 'is_finished': False, 'finish_reason': '', 'usage': None, 'index': 0, 'tool_use': None}
model_response finish reason 3: None; response_obj={'text': '', 'is_finished': False, 'finish_reason': '', 'usage': None, 'index': 0, 'tool_use': None}
model_response.choices[0].delta: Delta(provider_specific_fields=None, content=None, role=None, function_call=None, tool_calls=None, audio=None); completion_obj: {'content': ''}
self.sent_first_chunk: True
completion_obj: {'content': ''}, model_response.choices[0]: StreamingChoices(finish_reason=None, index=0, delta=Delta(provider_specific_fields=None, content=None, role=None, function_call=None, tool_calls=None, audio=None), logprobs=None), response_obj: {'text': '', 'is_finished': False, 'finish_reason': '', 'usage': None, 'index': 0, 'tool_use': None}

Raw OpenAI Chunk
ModelResponseStream(id='chatcmpl-1e246dec-1357-4ceb-948f-03d49e55b5f9', created=1762261914, model=None, object='chat.completion.chunk', system_fingerprint=None, choices=[StreamingChoices(finish_reason=None, index=0, delta=Delta(provider_specific_fields=None, content='\n\n---', role=None, function_call=None, tool_calls=None, audio=None), logprobs=None)], provider_specific_fields=None, usage=None)

model_response finish reason 3: None; response_obj={'text': '\n\n---', 'is_finished': False, 'finish_reason': None, 'logprobs': None, 'original_chunk': ModelResponseStream(id='chatcmpl-1e246dec-1357-4ceb-948f-03d49e55b5f9', created=1762261914, model=None, object='chat.completion.chunk', system_fingerprint=None, choices=[StreamingChoices(finish_reason=None, index=0, delta=Delta(provider_specific_fields=None, content='\n\n---', role=None, function_call=None, tool_calls=None, audio=None), logprobs=None)], provider_specific_fields=None, usage=None), 'usage': None}
original delta: {'provider_specific_fields': None, 'content': '\n\n---', 'role': None, 'function_call': None, 'tool_calls': None, 'audio': None}
new delta: Delta(provider_specific_fields=None, content='\n\n---', role=None, function_call=None, tool_calls=None, audio=None)
model_response.choices[0].delta: Delta(provider_specific_fields=None, content='\n\n---', role=None, function_call=None, tool_calls=None, audio=None); completion_obj: {'content': '\n\n---'}
self.sent_first_chunk: True
completion_obj: {'content': '\n\n---'}, model_response.choices[0]: StreamingChoices(finish_reason=None, index=0, delta=Delta(provider_specific_fields=None, content='\n\n---', role=None, function_call=None, tool_calls=None, audio=None), logprobs=None), response_obj: {'text': '\n\n---', 'is_finished': False, 'finish_reason': None, 'logprobs': None, 'original_chunk': ModelResponseStream(id='chatcmpl-1e246dec-1357-4ceb-948f-03d49e55b5f9', created=1762261914, model=None, object='chat.completion.chunk', system_fingerprint=None, choices=[StreamingChoices(finish_reason=None, index=0, delta=Delta(provider_specific_fields=None, content='\n\n---', role=None, function_call=None, tool_calls=None, audio=None), logprobs=None)], provider_specific_fields=None, usage=None), 'usage': None}
choice_json: {'index': 0, 'delta': {'provider_specific_fields': None, 'content': '\n\n---', 'role': None, 'function_call': None, 'tool_calls': None, 'audio': None}, 'logprobs': None}
choices in streaming: [StreamingChoices(finish_reason=None, index=0, delta=Delta(provider_specific_fields=None, content='\n\n---', role=None, function_call=None, tool_calls=None, audio=None), logprobs=None)]
final returned processed chunk: ModelResponseStream(id='chatcmpl-1e246dec-1357-4ceb-948f-03d49e55b5f9', created=1762261907, model='claude-sonnet-4-5-20250929', object='chat.completion.chunk', system_fingerprint=None, choices=[StreamingChoices(finish_reason=None, index=0, delta=Delta(provider_specific_fields=None, content='\n\n---', role=None, function_call=None, tool_calls=None, audio=None), logprobs=None)], provider_specific_fields=None, citations=None)
model_response finish reason 3: None; response_obj={'text': '', 'is_finished': False, 'finish_reason': '', 'usage': None, 'index': 0, 'tool_use': None}
model_response.choices[0].delta: Delta(provider_specific_fields=None, content=None, role=None, function_call=None, tool_calls=None, audio=None); completion_obj: {'content': ''}
self.sent_first_chunk: True
completion_obj: {'content': ''}, model_response.choices[0]: StreamingChoices(finish_reason=None, index=0, delta=Delta(provider_specific_fields=None, content=None, role=None, function_call=None, tool_calls=None, audio=None), logprobs=None), response_obj: {'text': '', 'is_finished': False, 'finish_reason': '', 'usage': None, 'index': 0, 'tool_use': None}
model_response finish reason 3: None; response_obj={'text': '', 'is_finished': False, 'finish_reason': '', 'usage': None, 'index': 0, 'tool_use': None}
model_response.choices[0].delta: Delta(provider_specific_fields=None, content=None, role=None, function_call=None, tool_calls=None, audio=None); completion_obj: {'content': ''}
self.sent_first_chunk: True
completion_obj: {'content': ''}, model_response.choices[0]: StreamingChoices(finish_reason=None, index=0, delta=Delta(provider_specific_fields=None, content=None, role=None, function_call=None, tool_calls=None, audio=None), logprobs=None), response_obj: {'text': '', 'is_finished': False, 'finish_reason': '', 'usage': None, 'index': 0, 'tool_use': None}

Raw OpenAI Chunk
ModelResponseStream(id='chatcmpl-1e246dec-1357-4ceb-948f-03d49e55b5f9', created=1762261914, model=None, object='chat.completion.chunk', system_fingerprint=None, choices=[StreamingChoices(finish_reason=None, index=0, delta=Delta(provider_specific_fields=None, content='\n\n## Answer', role=None, function_call=None, tool_calls=None, audio=None), logprobs=None)], provider_specific_fields=None, usage=None)

model_response finish reason 3: None; response_obj={'text': '\n\n## Answer', 'is_finished': False, 'finish_reason': None, 'logprobs': None, 'original_chunk': ModelResponseStream(id='chatcmpl-1e246dec-1357-4ceb-948f-03d49e55b5f9', created=1762261914, model=None, object='chat.completion.chunk', system_fingerprint=None, choices=[StreamingChoices(finish_reason=None, index=0, delta=Delta(provider_specific_fields=None, content='\n\n## Answer', role=None, function_call=None, tool_calls=None, audio=None), logprobs=None)], provider_specific_fields=None, usage=None), 'usage': None}
original delta: {'provider_specific_fields': None, 'content': '\n\n## Answer', 'role': None, 'function_call': None, 'tool_calls': None, 'audio': None}
new delta: Delta(provider_specific_fields=None, content='\n\n## Answer', role=None, function_call=None, tool_calls=None, audio=None)
model_response.choices[0].delta: Delta(provider_specific_fields=None, content='\n\n## Answer', role=None, function_call=None, tool_calls=None, audio=None); completion_obj: {'content': '\n\n## Answer'}
self.sent_first_chunk: True
completion_obj: {'content': '\n\n## Answer'}, model_response.choices[0]: StreamingChoices(finish_reason=None, index=0, delta=Delta(provider_specific_fields=None, content='\n\n## Answer', role=None, function_call=None, tool_calls=None, audio=None), logprobs=None), response_obj: {'text': '\n\n## Answer', 'is_finished': False, 'finish_reason': None, 'logprobs': None, 'original_chunk': ModelResponseStream(id='chatcmpl-1e246dec-1357-4ceb-948f-03d49e55b5f9', created=1762261914, model=None, object='chat.completion.chunk', system_fingerprint=None, choices=[StreamingChoices(finish_reason=None, index=0, delta=Delta(provider_specific_fields=None, content='\n\n## Answer', role=None, function_call=None, tool_calls=None, audio=None), logprobs=None)], provider_specific_fields=None, usage=None), 'usage': None}
choice_json: {'index': 0, 'delta': {'provider_specific_fields': None, 'content': '\n\n## Answer', 'role': None, 'function_call': None, 'tool_calls': None, 'audio': None}, 'logprobs': None}
choices in streaming: [StreamingChoices(finish_reason=None, index=0, delta=Delta(provider_specific_fields=None, content='\n\n## Answer', role=None, function_call=None, tool_calls=None, audio=None), logprobs=None)]
final returned processed chunk: ModelResponseStream(id='chatcmpl-1e246dec-1357-4ceb-948f-03d49e55b5f9', created=1762261907, model='claude-sonnet-4-5-20250929', object='chat.completion.chunk', system_fingerprint=None, choices=[StreamingChoices(finish_reason=None, index=0, delta=Delta(provider_specific_fields=None, content='\n\n## Answer', role=None, function_call=None, tool_calls=None, audio=None), logprobs=None)], provider_specific_fields=None, citations=None)
model_response finish reason 3: None; response_obj={'text': '', 'is_finished': False, 'finish_reason': '', 'usage': None, 'index': 0, 'tool_use': None}
model_response.choices[0].delta: Delta(provider_specific_fields=None, content=None, role=None, function_call=None, tool_calls=None, audio=None); completion_obj: {'content': ''}
self.sent_first_chunk: True
completion_obj: {'content': ''}, model_response.choices[0]: StreamingChoices(finish_reason=None, index=0, delta=Delta(provider_specific_fields=None, content=None, role=None, function_call=None, tool_calls=None, audio=None), logprobs=None), response_obj: {'text': '', 'is_finished': False, 'finish_reason': '', 'usage': None, 'index': 0, 'tool_use': None}
model_response finish reason 3: None; response_obj={'text': '', 'is_finished': False, 'finish_reason': '', 'usage': None, 'index': 0, 'tool_use': None}
model_response.choices[0].delta: Delta(provider_specific_fields=None, content=None, role=None, function_call=None, tool_calls=None, audio=None); completion_obj: {'content': ''}
self.sent_first_chunk: True
completion_obj: {'content': ''}, model_response.choices[0]: StreamingChoices(finish_reason=None, index=0, delta=Delta(provider_specific_fields=None, content=None, role=None, function_call=None, tool_calls=None, audio=None), logprobs=None), response_obj: {'text': '', 'is_finished': False, 'finish_reason': '', 'usage': None, 'index': 0, 'tool_use': None}

Raw OpenAI Chunk
ModelResponseStream(id='chatcmpl-1e246dec-1357-4ceb-948f-03d49e55b5f9', created=1762261914, model=None, object='chat.completion.chunk', system_fingerprint=None, choices=[StreamingChoices(finish_reason=None, index=0, delta=Delta(provider_specific_fields=None, content=' to', role=None, function_call=None, tool_calls=None, audio=None), logprobs=None)], provider_specific_fields=None, usage=None)

model_response finish reason 3: None; response_obj={'text': ' to', 'is_finished': False, 'finish_reason': None, 'logprobs': None, 'original_chunk': ModelResponseStream(id='chatcmpl-1e246dec-1357-4ceb-948f-03d49e55b5f9', created=1762261914, model=None, object='chat.completion.chunk', system_fingerprint=None, choices=[StreamingChoices(finish_reason=None, index=0, delta=Delta(provider_specific_fields=None, content=' to', role=None, function_call=None, tool_calls=None, audio=None), logprobs=None)], provider_specific_fields=None, usage=None), 'usage': None}
original delta: {'provider_specific_fields': None, 'content': ' to', 'role': None, 'function_call': None, 'tool_calls': None, 'audio': None}
new delta: Delta(provider_specific_fields=None, content=' to', role=None, function_call=None, tool_calls=None, audio=None)
model_response.choices[0].delta: Delta(provider_specific_fields=None, content=' to', role=None, function_call=None, tool_calls=None, audio=None); completion_obj: {'content': ' to'}
self.sent_first_chunk: True
completion_obj: {'content': ' to'}, model_response.choices[0]: StreamingChoices(finish_reason=None, index=0, delta=Delta(provider_specific_fields=None, content=' to', role=None, function_call=None, tool_calls=None, audio=None), logprobs=None), response_obj: {'text': ' to', 'is_finished': False, 'finish_reason': None, 'logprobs': None, 'original_chunk': ModelResponseStream(id='chatcmpl-1e246dec-1357-4ceb-948f-03d49e55b5f9', created=1762261914, model=None, object='chat.completion.chunk', system_fingerprint=None, choices=[StreamingChoices(finish_reason=None, index=0, delta=Delta(provider_specific_fields=None, content=' to', role=None, function_call=None, tool_calls=None, audio=None), logprobs=None)], provider_specific_fields=None, usage=None), 'usage': None}
choice_json: {'index': 0, 'delta': {'provider_specific_fields': None, 'content': ' to', 'role': None, 'function_call': None, 'tool_calls': None, 'audio': None}, 'logprobs': None}
choices in streaming: [StreamingChoices(finish_reason=None, index=0, delta=Delta(provider_specific_fields=None, content=' to', role=None, function_call=None, tool_calls=None, audio=None), logprobs=None)]
final returned processed chunk: ModelResponseStream(id='chatcmpl-1e246dec-1357-4ceb-948f-03d49e55b5f9', created=1762261907, model='claude-sonnet-4-5-20250929', object='chat.completion.chunk', system_fingerprint=None, choices=[StreamingChoices(finish_reason=None, index=0, delta=Delta(provider_specific_fields=None, content=' to', role=None, function_call=None, tool_calls=None, audio=None), logprobs=None)], provider_specific_fields=None, citations=None)
model_response finish reason 3: None; response_obj={'text': '', 'is_finished': False, 'finish_reason': '', 'usage': None, 'index': 0, 'tool_use': None}
model_response.choices[0].delta: Delta(provider_specific_fields=None, content=None, role=None, function_call=None, tool_calls=None, audio=None); completion_obj: {'content': ''}
self.sent_first_chunk: True
completion_obj: {'content': ''}, model_response.choices[0]: StreamingChoices(finish_reason=None, index=0, delta=Delta(provider_specific_fields=None, content=None, role=None, function_call=None, tool_calls=None, audio=None), logprobs=None), response_obj: {'text': '', 'is_finished': False, 'finish_reason': '', 'usage': None, 'index': 0, 'tool_use': None}
model_response finish reason 3: None; response_obj={'text': '', 'is_finished': False, 'finish_reason': '', 'usage': None, 'index': 0, 'tool_use': None}
model_response.choices[0].delta: Delta(provider_specific_fields=None, content=None, role=None, function_call=None, tool_calls=None, audio=None); completion_obj: {'content': ''}
self.sent_first_chunk: True
completion_obj: {'content': ''}, model_response.choices[0]: StreamingChoices(finish_reason=None, index=0, delta=Delta(provider_specific_fields=None, content=None, role=None, function_call=None, tool_calls=None, audio=None), logprobs=None), response_obj: {'text': '', 'is_finished': False, 'finish_reason': '', 'usage': None, 'index': 0, 'tool_use': None}

Raw OpenAI Chunk
ModelResponseStream(id='chatcmpl-1e246dec-1357-4ceb-948f-03d49e55b5f9', created=1762261914, model=None, object='chat.completion.chunk', system_fingerprint=None, choices=[StreamingChoices(finish_reason=None, index=0, delta=Delta(provider_specific_fields=None, content=' Your Original', role=None, function_call=None, tool_calls=None, audio=None), logprobs=None)], provider_specific_fields=None, usage=None)

model_response finish reason 3: None; response_obj={'text': ' Your Original', 'is_finished': False, 'finish_reason': None, 'logprobs': None, 'original_chunk': ModelResponseStream(id='chatcmpl-1e246dec-1357-4ceb-948f-03d49e55b5f9', created=1762261914, model=None, object='chat.completion.chunk', system_fingerprint=None, choices=[StreamingChoices(finish_reason=None, index=0, delta=Delta(provider_specific_fields=None, content=' Your Original', role=None, function_call=None, tool_calls=None, audio=None), logprobs=None)], provider_specific_fields=None, usage=None), 'usage': None}
original delta: {'provider_specific_fields': None, 'content': ' Your Original', 'role': None, 'function_call': None, 'tool_calls': None, 'audio': None}
new delta: Delta(provider_specific_fields=None, content=' Your Original', role=None, function_call=None, tool_calls=None, audio=None)
model_response.choices[0].delta: Delta(provider_specific_fields=None, content=' Your Original', role=None, function_call=None, tool_calls=None, audio=None); completion_obj: {'content': ' Your Original'}
self.sent_first_chunk: True
completion_obj: {'content': ' Your Original'}, model_response.choices[0]: StreamingChoices(finish_reason=None, index=0, delta=Delta(provider_specific_fields=None, content=' Your Original', role=None, function_call=None, tool_calls=None, audio=None), logprobs=None), response_obj: {'text': ' Your Original', 'is_finished': False, 'finish_reason': None, 'logprobs': None, 'original_chunk': ModelResponseStream(id='chatcmpl-1e246dec-1357-4ceb-948f-03d49e55b5f9', created=1762261914, model=None, object='chat.completion.chunk', system_fingerprint=None, choices=[StreamingChoices(finish_reason=None, index=0, delta=Delta(provider_specific_fields=None, content=' Your Original', role=None, function_call=None, tool_calls=None, audio=None), logprobs=None)], provider_specific_fields=None, usage=None), 'usage': None}
choice_json: {'index': 0, 'delta': {'provider_specific_fields': None, 'content': ' Your Original', 'role': None, 'function_call': None, 'tool_calls': None, 'audio': None}, 'logprobs': None}
choices in streaming: [StreamingChoices(finish_reason=None, index=0, delta=Delta(provider_specific_fields=None, content=' Your Original', role=None, function_call=None, tool_calls=None, audio=None), logprobs=None)]
final returned processed chunk: ModelResponseStream(id='chatcmpl-1e246dec-1357-4ceb-948f-03d49e55b5f9', created=1762261907, model='claude-sonnet-4-5-20250929', object='chat.completion.chunk', system_fingerprint=None, choices=[StreamingChoices(finish_reason=None, index=0, delta=Delta(provider_specific_fields=None, content=' Your Original', role=None, function_call=None, tool_calls=None, audio=None), logprobs=None)], provider_specific_fields=None, citations=None)
model_response finish reason 3: None; response_obj={'text': '', 'is_finished': False, 'finish_reason': '', 'usage': None, 'index': 0, 'tool_use': None}
model_response.choices[0].delta: Delta(provider_specific_fields=None, content=None, role=None, function_call=None, tool_calls=None, audio=None); completion_obj: {'content': ''}
self.sent_first_chunk: True
completion_obj: {'content': ''}, model_response.choices[0]: StreamingChoices(finish_reason=None, index=0, delta=Delta(provider_specific_fields=None, content=None, role=None, function_call=None, tool_calls=None, audio=None), logprobs=None), response_obj: {'text': '', 'is_finished': False, 'finish_reason': '', 'usage': None, 'index': 0, 'tool_use': None}
model_response finish reason 3: None; response_obj={'text': '', 'is_finished': False, 'finish_reason': '', 'usage': None, 'index': 0, 'tool_use': None}
model_response.choices[0].delta: Delta(provider_specific_fields=None, content=None, role=None, function_call=None, tool_calls=None, audio=None); completion_obj: {'content': ''}
self.sent_first_chunk: True
completion_obj: {'content': ''}, model_response.choices[0]: StreamingChoices(finish_reason=None, index=0, delta=Delta(provider_specific_fields=None, content=None, role=None, function_call=None, tool_calls=None, audio=None), logprobs=None), response_obj: {'text': '', 'is_finished': False, 'finish_reason': '', 'usage': None, 'index': 0, 'tool_use': None}

Raw OpenAI Chunk
ModelResponseStream(id='chatcmpl-1e246dec-1357-4ceb-948f-03d49e55b5f9', created=1762261914, model=None, object='chat.completion.chunk', system_fingerprint=None, choices=[StreamingChoices(finish_reason=None, index=0, delta=Delta(provider_specific_fields=None, content=' Question:\n\n**', role=None, function_call=None, tool_calls=None, audio=None), logprobs=None)], provider_specific_fields=None, usage=None)

model_response finish reason 3: None; response_obj={'text': ' Question:\n\n**', 'is_finished': False, 'finish_reason': None, 'logprobs': None, 'original_chunk': ModelResponseStream(id='chatcmpl-1e246dec-1357-4ceb-948f-03d49e55b5f9', created=1762261914, model=None, object='chat.completion.chunk', system_fingerprint=None, choices=[StreamingChoices(finish_reason=None, index=0, delta=Delta(provider_specific_fields=None, content=' Question:\n\n**', role=None, function_call=None, tool_calls=None, audio=None), logprobs=None)], provider_specific_fields=None, usage=None), 'usage': None}
original delta: {'provider_specific_fields': None, 'content': ' Question:\n\n**', 'role': None, 'function_call': None, 'tool_calls': None, 'audio': None}
new delta: Delta(provider_specific_fields=None, content=' Question:\n\n**', role=None, function_call=None, tool_calls=None, audio=None)
model_response.choices[0].delta: Delta(provider_specific_fields=None, content=' Question:\n\n**', role=None, function_call=None, tool_calls=None, audio=None); completion_obj: {'content': ' Question:\n\n**'}
self.sent_first_chunk: True
completion_obj: {'content': ' Question:\n\n**'}, model_response.choices[0]: StreamingChoices(finish_reason=None, index=0, delta=Delta(provider_specific_fields=None, content=' Question:\n\n**', role=None, function_call=None, tool_calls=None, audio=None), logprobs=None), response_obj: {'text': ' Question:\n\n**', 'is_finished': False, 'finish_reason': None, 'logprobs': None, 'original_chunk': ModelResponseStream(id='chatcmpl-1e246dec-1357-4ceb-948f-03d49e55b5f9', created=1762261914, model=None, object='chat.completion.chunk', system_fingerprint=None, choices=[StreamingChoices(finish_reason=None, index=0, delta=Delta(provider_specific_fields=None, content=' Question:\n\n**', role=None, function_call=None, tool_calls=None, audio=None), logprobs=None)], provider_specific_fields=None, usage=None), 'usage': None}
choice_json: {'index': 0, 'delta': {'provider_specific_fields': None, 'content': ' Question:\n\n**', 'role': None, 'function_call': None, 'tool_calls': None, 'audio': None}, 'logprobs': None}
choices in streaming: [StreamingChoices(finish_reason=None, index=0, delta=Delta(provider_specific_fields=None, content=' Question:\n\n**', role=None, function_call=None, tool_calls=None, audio=None), logprobs=None)]
final returned processed chunk: ModelResponseStream(id='chatcmpl-1e246dec-1357-4ceb-948f-03d49e55b5f9', created=1762261907, model='claude-sonnet-4-5-20250929', object='chat.completion.chunk', system_fingerprint=None, choices=[StreamingChoices(finish_reason=None, index=0, delta=Delta(provider_specific_fields=None, content=' Question:\n\n**', role=None, function_call=None, tool_calls=None, audio=None), logprobs=None)], provider_specific_fields=None, citations=None)
model_response finish reason 3: None; response_obj={'text': '', 'is_finished': False, 'finish_reason': '', 'usage': None, 'index': 0, 'tool_use': None}
model_response.choices[0].delta: Delta(provider_specific_fields=None, content=None, role=None, function_call=None, tool_calls=None, audio=None); completion_obj: {'content': ''}
self.sent_first_chunk: True
completion_obj: {'content': ''}, model_response.choices[0]: StreamingChoices(finish_reason=None, index=0, delta=Delta(provider_specific_fields=None, content=None, role=None, function_call=None, tool_calls=None, audio=None), logprobs=None), response_obj: {'text': '', 'is_finished': False, 'finish_reason': '', 'usage': None, 'index': 0, 'tool_use': None}
model_response finish reason 3: None; response_obj={'text': '', 'is_finished': False, 'finish_reason': '', 'usage': None, 'index': 0, 'tool_use': None}
model_response.choices[0].delta: Delta(provider_specific_fields=None, content=None, role=None, function_call=None, tool_calls=None, audio=None); completion_obj: {'content': ''}
self.sent_first_chunk: True
completion_obj: {'content': ''}, model_response.choices[0]: StreamingChoices(finish_reason=None, index=0, delta=Delta(provider_specific_fields=None, content=None, role=None, function_call=None, tool_calls=None, audio=None), logprobs=None), response_obj: {'text': '', 'is_finished': False, 'finish_reason': '', 'usage': None, 'index': 0, 'tool_use': None}

Raw OpenAI Chunk
ModelResponseStream(id='chatcmpl-1e246dec-1357-4ceb-948f-03d49e55b5f9', created=1762261914, model=None, object='chat.completion.chunk', system_fingerprint=None, choices=[StreamingChoices(finish_reason=None, index=0, delta=Delta(provider_specific_fields=None, content='No', role=None, function_call=None, tool_calls=None, audio=None), logprobs=None)], provider_specific_fields=None, usage=None)

model_response finish reason 3: None; response_obj={'text': 'No', 'is_finished': False, 'finish_reason': None, 'logprobs': None, 'original_chunk': ModelResponseStream(id='chatcmpl-1e246dec-1357-4ceb-948f-03d49e55b5f9', created=1762261914, model=None, object='chat.completion.chunk', system_fingerprint=None, choices=[StreamingChoices(finish_reason=None, index=0, delta=Delta(provider_specific_fields=None, content='No', role=None, function_call=None, tool_calls=None, audio=None), logprobs=None)], provider_specific_fields=None, usage=None), 'usage': None}
original delta: {'provider_specific_fields': None, 'content': 'No', 'role': None, 'function_call': None, 'tool_calls': None, 'audio': None}
new delta: Delta(provider_specific_fields=None, content='No', role=None, function_call=None, tool_calls=None, audio=None)
model_response.choices[0].delta: Delta(provider_specific_fields=None, content='No', role=None, function_call=None, tool_calls=None, audio=None); completion_obj: {'content': 'No'}
self.sent_first_chunk: True
completion_obj: {'content': 'No'}, model_response.choices[0]: StreamingChoices(finish_reason=None, index=0, delta=Delta(provider_specific_fields=None, content='No', role=None, function_call=None, tool_calls=None, audio=None), logprobs=None), response_obj: {'text': 'No', 'is_finished': False, 'finish_reason': None, 'logprobs': None, 'original_chunk': ModelResponseStream(id='chatcmpl-1e246dec-1357-4ceb-948f-03d49e55b5f9', created=1762261914, model=None, object='chat.completion.chunk', system_fingerprint=None, choices=[StreamingChoices(finish_reason=None, index=0, delta=Delta(provider_specific_fields=None, content='No', role=None, function_call=None, tool_calls=None, audio=None), logprobs=None)], provider_specific_fields=None, usage=None), 'usage': None}
choice_json: {'index': 0, 'delta': {'provider_specific_fields': None, 'content': 'No', 'role': None, 'function_call': None, 'tool_calls': None, 'audio': None}, 'logprobs': None}
choices in streaming: [StreamingChoices(finish_reason=None, index=0, delta=Delta(provider_specific_fields=None, content='No', role=None, function_call=None, tool_calls=None, audio=None), logprobs=None)]
final returned processed chunk: ModelResponseStream(id='chatcmpl-1e246dec-1357-4ceb-948f-03d49e55b5f9', created=1762261907, model='claude-sonnet-4-5-20250929', object='chat.completion.chunk', system_fingerprint=None, choices=[StreamingChoices(finish_reason=None, index=0, delta=Delta(provider_specific_fields=None, content='No', role=None, function_call=None, tool_calls=None, audio=None), logprobs=None)], provider_specific_fields=None, citations=None)
model_response finish reason 3: None; response_obj={'text': '', 'is_finished': False, 'finish_reason': '', 'usage': None, 'index': 0, 'tool_use': None}
model_response.choices[0].delta: Delta(provider_specific_fields=None, content=None, role=None, function_call=None, tool_calls=None, audio=None); completion_obj: {'content': ''}
self.sent_first_chunk: True
completion_obj: {'content': ''}, model_response.choices[0]: StreamingChoices(finish_reason=None, index=0, delta=Delta(provider_specific_fields=None, content=None, role=None, function_call=None, tool_calls=None, audio=None), logprobs=None), response_obj: {'text': '', 'is_finished': False, 'finish_reason': '', 'usage': None, 'index': 0, 'tool_use': None}
model_response finish reason 3: None; response_obj={'text': '', 'is_finished': False, 'finish_reason': '', 'usage': None, 'index': 0, 'tool_use': None}
model_response.choices[0].delta: Delta(provider_specific_fields=None, content=None, role=None, function_call=None, tool_calls=None, audio=None); completion_obj: {'content': ''}
self.sent_first_chunk: True
completion_obj: {'content': ''}, model_response.choices[0]: StreamingChoices(finish_reason=None, index=0, delta=Delta(provider_specific_fields=None, content=None, role=None, function_call=None, tool_calls=None, audio=None), logprobs=None), response_obj: {'text': '', 'is_finished': False, 'finish_reason': '', 'usage': None, 'index': 0, 'tool_use': None}

Raw OpenAI Chunk
ModelResponseStream(id='chatcmpl-1e246dec-1357-4ceb-948f-03d49e55b5f9', created=1762261914, model=None, object='chat.completion.chunk', system_fingerprint=None, choices=[StreamingChoices(finish_reason=None, index=0, delta=Delta(provider_specific_fields=None, content=', I', role=None, function_call=None, tool_calls=None, audio=None), logprobs=None)], provider_specific_fields=None, usage=None)

model_response finish reason 3: None; response_obj={'text': ', I', 'is_finished': False, 'finish_reason': None, 'logprobs': None, 'original_chunk': ModelResponseStream(id='chatcmpl-1e246dec-1357-4ceb-948f-03d49e55b5f9', created=1762261914, model=None, object='chat.completion.chunk', system_fingerprint=None, choices=[StreamingChoices(finish_reason=None, index=0, delta=Delta(provider_specific_fields=None, content=', I', role=None, function_call=None, tool_calls=None, audio=None), logprobs=None)], provider_specific_fields=None, usage=None), 'usage': None}
original delta: {'provider_specific_fields': None, 'content': ', I', 'role': None, 'function_call': None, 'tool_calls': None, 'audio': None}
new delta: Delta(provider_specific_fields=None, content=', I', role=None, function_call=None, tool_calls=None, audio=None)
model_response.choices[0].delta: Delta(provider_specific_fields=None, content=', I', role=None, function_call=None, tool_calls=None, audio=None); completion_obj: {'content': ', I'}
self.sent_first_chunk: True
completion_obj: {'content': ', I'}, model_response.choices[0]: StreamingChoices(finish_reason=None, index=0, delta=Delta(provider_specific_fields=None, content=', I', role=None, function_call=None, tool_calls=None, audio=None), logprobs=None), response_obj: {'text': ', I', 'is_finished': False, 'finish_reason': None, 'logprobs': None, 'original_chunk': ModelResponseStream(id='chatcmpl-1e246dec-1357-4ceb-948f-03d49e55b5f9', created=1762261914, model=None, object='chat.completion.chunk', system_fingerprint=None, choices=[StreamingChoices(finish_reason=None, index=0, delta=Delta(provider_specific_fields=None, content=', I', role=None, function_call=None, tool_calls=None, audio=None), logprobs=None)], provider_specific_fields=None, usage=None), 'usage': None}
choice_json: {'index': 0, 'delta': {'provider_specific_fields': None, 'content': ', I', 'role': None, 'function_call': None, 'tool_calls': None, 'audio': None}, 'logprobs': None}
choices in streaming: [StreamingChoices(finish_reason=None, index=0, delta=Delta(provider_specific_fields=None, content=', I', role=None, function_call=None, tool_calls=None, audio=None), logprobs=None)]
final returned processed chunk: ModelResponseStream(id='chatcmpl-1e246dec-1357-4ceb-948f-03d49e55b5f9', created=1762261907, model='claude-sonnet-4-5-20250929', object='chat.completion.chunk', system_fingerprint=None, choices=[StreamingChoices(finish_reason=None, index=0, delta=Delta(provider_specific_fields=None, content=', I', role=None, function_call=None, tool_calls=None, audio=None), logprobs=None)], provider_specific_fields=None, citations=None)
model_response finish reason 3: None; response_obj={'text': '', 'is_finished': False, 'finish_reason': '', 'usage': None, 'index': 0, 'tool_use': None}
model_response.choices[0].delta: Delta(provider_specific_fields=None, content=None, role=None, function_call=None, tool_calls=None, audio=None); completion_obj: {'content': ''}
self.sent_first_chunk: True
completion_obj: {'content': ''}, model_response.choices[0]: StreamingChoices(finish_reason=None, index=0, delta=Delta(provider_specific_fields=None, content=None, role=None, function_call=None, tool_calls=None, audio=None), logprobs=None), response_obj: {'text': '', 'is_finished': False, 'finish_reason': '', 'usage': None, 'index': 0, 'tool_use': None}
model_response finish reason 3: None; response_obj={'text': '', 'is_finished': False, 'finish_reason': '', 'usage': None, 'index': 0, 'tool_use': None}
model_response.choices[0].delta: Delta(provider_specific_fields=None, content=None, role=None, function_call=None, tool_calls=None, audio=None); completion_obj: {'content': ''}
self.sent_first_chunk: True
completion_obj: {'content': ''}, model_response.choices[0]: StreamingChoices(finish_reason=None, index=0, delta=Delta(provider_specific_fields=None, content=None, role=None, function_call=None, tool_calls=None, audio=None), logprobs=None), response_obj: {'text': '', 'is_finished': False, 'finish_reason': '', 'usage': None, 'index': 0, 'tool_use': None}

Raw OpenAI Chunk
ModelResponseStream(id='chatcmpl-1e246dec-1357-4ceb-948f-03d49e55b5f9', created=1762261914, model=None, object='chat.completion.chunk', system_fingerprint=None, choices=[StreamingChoices(finish_reason=None, index=0, delta=Delta(provider_specific_fields=None, content=' cannot', role=None, function_call=None, tool_calls=None, audio=None), logprobs=None)], provider_specific_fields=None, usage=None)

model_response finish reason 3: None; response_obj={'text': ' cannot', 'is_finished': False, 'finish_reason': None, 'logprobs': None, 'original_chunk': ModelResponseStream(id='chatcmpl-1e246dec-1357-4ceb-948f-03d49e55b5f9', created=1762261914, model=None, object='chat.completion.chunk', system_fingerprint=None, choices=[StreamingChoices(finish_reason=None, index=0, delta=Delta(provider_specific_fields=None, content=' cannot', role=None, function_call=None, tool_calls=None, audio=None), logprobs=None)], provider_specific_fields=None, usage=None), 'usage': None}
original delta: {'provider_specific_fields': None, 'content': ' cannot', 'role': None, 'function_call': None, 'tool_calls': None, 'audio': None}
new delta: Delta(provider_specific_fields=None, content=' cannot', role=None, function_call=None, tool_calls=None, audio=None)
model_response.choices[0].delta: Delta(provider_specific_fields=None, content=' cannot', role=None, function_call=None, tool_calls=None, audio=None); completion_obj: {'content': ' cannot'}
self.sent_first_chunk: True
completion_obj: {'content': ' cannot'}, model_response.choices[0]: StreamingChoices(finish_reason=None, index=0, delta=Delta(provider_specific_fields=None, content=' cannot', role=None, function_call=None, tool_calls=None, audio=None), logprobs=None), response_obj: {'text': ' cannot', 'is_finished': False, 'finish_reason': None, 'logprobs': None, 'original_chunk': ModelResponseStream(id='chatcmpl-1e246dec-1357-4ceb-948f-03d49e55b5f9', created=1762261914, model=None, object='chat.completion.chunk', system_fingerprint=None, choices=[StreamingChoices(finish_reason=None, index=0, delta=Delta(provider_specific_fields=None, content=' cannot', role=None, function_call=None, tool_calls=None, audio=None), logprobs=None)], provider_specific_fields=None, usage=None), 'usage': None}
choice_json: {'index': 0, 'delta': {'provider_specific_fields': None, 'content': ' cannot', 'role': None, 'function_call': None, 'tool_calls': None, 'audio': None}, 'logprobs': None}
choices in streaming: [StreamingChoices(finish_reason=None, index=0, delta=Delta(provider_specific_fields=None, content=' cannot', role=None, function_call=None, tool_calls=None, audio=None), logprobs=None)]
final returned processed chunk: ModelResponseStream(id='chatcmpl-1e246dec-1357-4ceb-948f-03d49e55b5f9', created=1762261907, model='claude-sonnet-4-5-20250929', object='chat.completion.chunk', system_fingerprint=None, choices=[StreamingChoices(finish_reason=None, index=0, delta=Delta(provider_specific_fields=None, content=' cannot', role=None, function_call=None, tool_calls=None, audio=None), logprobs=None)], provider_specific_fields=None, citations=None)
model_response finish reason 3: None; response_obj={'text': '', 'is_finished': False, 'finish_reason': '', 'usage': None, 'index': 0, 'tool_use': None}
model_response.choices[0].delta: Delta(provider_specific_fields=None, content=None, role=None, function_call=None, tool_calls=None, audio=None); completion_obj: {'content': ''}
self.sent_first_chunk: True
completion_obj: {'content': ''}, model_response.choices[0]: StreamingChoices(finish_reason=None, index=0, delta=Delta(provider_specific_fields=None, content=None, role=None, function_call=None, tool_calls=None, audio=None), logprobs=None), response_obj: {'text': '', 'is_finished': False, 'finish_reason': '', 'usage': None, 'index': 0, 'tool_use': None}
model_response finish reason 3: None; response_obj={'text': '', 'is_finished': False, 'finish_reason': '', 'usage': None, 'index': 0, 'tool_use': None}
model_response.choices[0].delta: Delta(provider_specific_fields=None, content=None, role=None, function_call=None, tool_calls=None, audio=None); completion_obj: {'content': ''}
self.sent_first_chunk: True
completion_obj: {'content': ''}, model_response.choices[0]: StreamingChoices(finish_reason=None, index=0, delta=Delta(provider_specific_fields=None, content=None, role=None, function_call=None, tool_calls=None, audio=None), logprobs=None), response_obj: {'text': '', 'is_finished': False, 'finish_reason': '', 'usage': None, 'index': 0, 'tool_use': None}

Raw OpenAI Chunk
ModelResponseStream(id='chatcmpl-1e246dec-1357-4ceb-948f-03d49e55b5f9', created=1762261915, model=None, object='chat.completion.chunk', system_fingerprint=None, choices=[StreamingChoices(finish_reason=None, index=0, delta=Delta(provider_specific_fields=None, content=' tell', role=None, function_call=None, tool_calls=None, audio=None), logprobs=None)], provider_specific_fields=None, usage=None)

model_response finish reason 3: None; response_obj={'text': ' tell', 'is_finished': False, 'finish_reason': None, 'logprobs': None, 'original_chunk': ModelResponseStream(id='chatcmpl-1e246dec-1357-4ceb-948f-03d49e55b5f9', created=1762261915, model=None, object='chat.completion.chunk', system_fingerprint=None, choices=[StreamingChoices(finish_reason=None, index=0, delta=Delta(provider_specific_fields=None, content=' tell', role=None, function_call=None, tool_calls=None, audio=None), logprobs=None)], provider_specific_fields=None, usage=None), 'usage': None}
original delta: {'provider_specific_fields': None, 'content': ' tell', 'role': None, 'function_call': None, 'tool_calls': None, 'audio': None}
new delta: Delta(provider_specific_fields=None, content=' tell', role=None, function_call=None, tool_calls=None, audio=None)
model_response.choices[0].delta: Delta(provider_specific_fields=None, content=' tell', role=None, function_call=None, tool_calls=None, audio=None); completion_obj: {'content': ' tell'}
self.sent_first_chunk: True
completion_obj: {'content': ' tell'}, model_response.choices[0]: StreamingChoices(finish_reason=None, index=0, delta=Delta(provider_specific_fields=None, content=' tell', role=None, function_call=None, tool_calls=None, audio=None), logprobs=None), response_obj: {'text': ' tell', 'is_finished': False, 'finish_reason': None, 'logprobs': None, 'original_chunk': ModelResponseStream(id='chatcmpl-1e246dec-1357-4ceb-948f-03d49e55b5f9', created=1762261915, model=None, object='chat.completion.chunk', system_fingerprint=None, choices=[StreamingChoices(finish_reason=None, index=0, delta=Delta(provider_specific_fields=None, content=' tell', role=None, function_call=None, tool_calls=None, audio=None), logprobs=None)], provider_specific_fields=None, usage=None), 'usage': None}
choice_json: {'index': 0, 'delta': {'provider_specific_fields': None, 'content': ' tell', 'role': None, 'function_call': None, 'tool_calls': None, 'audio': None}, 'logprobs': None}
choices in streaming: [StreamingChoices(finish_reason=None, index=0, delta=Delta(provider_specific_fields=None, content=' tell', role=None, function_call=None, tool_calls=None, audio=None), logprobs=None)]
final returned processed chunk: ModelResponseStream(id='chatcmpl-1e246dec-1357-4ceb-948f-03d49e55b5f9', created=1762261907, model='claude-sonnet-4-5-20250929', object='chat.completion.chunk', system_fingerprint=None, choices=[StreamingChoices(finish_reason=None, index=0, delta=Delta(provider_specific_fields=None, content=' tell', role=None, function_call=None, tool_calls=None, audio=None), logprobs=None)], provider_specific_fields=None, citations=None)
model_response finish reason 3: None; response_obj={'text': '', 'is_finished': False, 'finish_reason': '', 'usage': None, 'index': 0, 'tool_use': None}
model_response.choices[0].delta: Delta(provider_specific_fields=None, content=None, role=None, function_call=None, tool_calls=None, audio=None); completion_obj: {'content': ''}
self.sent_first_chunk: True
completion_obj: {'content': ''}, model_response.choices[0]: StreamingChoices(finish_reason=None, index=0, delta=Delta(provider_specific_fields=None, content=None, role=None, function_call=None, tool_calls=None, audio=None), logprobs=None), response_obj: {'text': '', 'is_finished': False, 'finish_reason': '', 'usage': None, 'index': 0, 'tool_use': None}
model_response finish reason 3: None; response_obj={'text': '', 'is_finished': False, 'finish_reason': '', 'usage': None, 'index': 0, 'tool_use': None}
model_response.choices[0].delta: Delta(provider_specific_fields=None, content=None, role=None, function_call=None, tool_calls=None, audio=None); completion_obj: {'content': ''}
self.sent_first_chunk: True
completion_obj: {'content': ''}, model_response.choices[0]: StreamingChoices(finish_reason=None, index=0, delta=Delta(provider_specific_fields=None, content=None, role=None, function_call=None, tool_calls=None, audio=None), logprobs=None), response_obj: {'text': '', 'is_finished': False, 'finish_reason': '', 'usage': None, 'index': 0, 'tool_use': None}

Raw OpenAI Chunk
ModelResponseStream(id='chatcmpl-1e246dec-1357-4ceb-948f-03d49e55b5f9', created=1762261915, model=None, object='chat.completion.chunk', system_fingerprint=None, choices=[StreamingChoices(finish_reason=None, index=0, delta=Delta(provider_specific_fields=None, content=' you about', role=None, function_call=None, tool_calls=None, audio=None), logprobs=None)], provider_specific_fields=None, usage=None)

model_response finish reason 3: None; response_obj={'text': ' you about', 'is_finished': False, 'finish_reason': None, 'logprobs': None, 'original_chunk': ModelResponseStream(id='chatcmpl-1e246dec-1357-4ceb-948f-03d49e55b5f9', created=1762261915, model=None, object='chat.completion.chunk', system_fingerprint=None, choices=[StreamingChoices(finish_reason=None, index=0, delta=Delta(provider_specific_fields=None, content=' you about', role=None, function_call=None, tool_calls=None, audio=None), logprobs=None)], provider_specific_fields=None, usage=None), 'usage': None}
original delta: {'provider_specific_fields': None, 'content': ' you about', 'role': None, 'function_call': None, 'tool_calls': None, 'audio': None}
new delta: Delta(provider_specific_fields=None, content=' you about', role=None, function_call=None, tool_calls=None, audio=None)
model_response.choices[0].delta: Delta(provider_specific_fields=None, content=' you about', role=None, function_call=None, tool_calls=None, audio=None); completion_obj: {'content': ' you about'}
self.sent_first_chunk: True
completion_obj: {'content': ' you about'}, model_response.choices[0]: StreamingChoices(finish_reason=None, index=0, delta=Delta(provider_specific_fields=None, content=' you about', role=None, function_call=None, tool_calls=None, audio=None), logprobs=None), response_obj: {'text': ' you about', 'is_finished': False, 'finish_reason': None, 'logprobs': None, 'original_chunk': ModelResponseStream(id='chatcmpl-1e246dec-1357-4ceb-948f-03d49e55b5f9', created=1762261915, model=None, object='chat.completion.chunk', system_fingerprint=None, choices=[StreamingChoices(finish_reason=None, index=0, delta=Delta(provider_specific_fields=None, content=' you about', role=None, function_call=None, tool_calls=None, audio=None), logprobs=None)], provider_specific_fields=None, usage=None), 'usage': None}
choice_json: {'index': 0, 'delta': {'provider_specific_fields': None, 'content': ' you about', 'role': None, 'function_call': None, 'tool_calls': None, 'audio': None}, 'logprobs': None}
choices in streaming: [StreamingChoices(finish_reason=None, index=0, delta=Delta(provider_specific_fields=None, content=' you about', role=None, function_call=None, tool_calls=None, audio=None), logprobs=None)]
final returned processed chunk: ModelResponseStream(id='chatcmpl-1e246dec-1357-4ceb-948f-03d49e55b5f9', created=1762261907, model='claude-sonnet-4-5-20250929', object='chat.completion.chunk', system_fingerprint=None, choices=[StreamingChoices(finish_reason=None, index=0, delta=Delta(provider_specific_fields=None, content=' you about', role=None, function_call=None, tool_calls=None, audio=None), logprobs=None)], provider_specific_fields=None, citations=None)
model_response finish reason 3: None; response_obj={'text': '', 'is_finished': False, 'finish_reason': '', 'usage': None, 'index': 0, 'tool_use': None}
model_response.choices[0].delta: Delta(provider_specific_fields=None, content=None, role=None, function_call=None, tool_calls=None, audio=None); completion_obj: {'content': ''}
self.sent_first_chunk: True
completion_obj: {'content': ''}, model_response.choices[0]: StreamingChoices(finish_reason=None, index=0, delta=Delta(provider_specific_fields=None, content=None, role=None, function_call=None, tool_calls=None, audio=None), logprobs=None), response_obj: {'text': '', 'is_finished': False, 'finish_reason': '', 'usage': None, 'index': 0, 'tool_use': None}
model_response finish reason 3: None; response_obj={'text': '', 'is_finished': False, 'finish_reason': '', 'usage': None, 'index': 0, 'tool_use': None}
model_response.choices[0].delta: Delta(provider_specific_fields=None, content=None, role=None, function_call=None, tool_calls=None, audio=None); completion_obj: {'content': ''}
self.sent_first_chunk: True
completion_obj: {'content': ''}, model_response.choices[0]: StreamingChoices(finish_reason=None, index=0, delta=Delta(provider_specific_fields=None, content=None, role=None, function_call=None, tool_calls=None, audio=None), logprobs=None), response_obj: {'text': '', 'is_finished': False, 'finish_reason': '', 'usage': None, 'index': 0, 'tool_use': None}

Raw OpenAI Chunk
ModelResponseStream(id='chatcmpl-1e246dec-1357-4ceb-948f-03d49e55b5f9', created=1762261915, model=None, object='chat.completion.chunk', system_fingerprint=None, choices=[StreamingChoices(finish_reason=None, index=0, delta=Delta(provider_specific_fields=None, content=' your', role=None, function_call=None, tool_calls=None, audio=None), logprobs=None)], provider_specific_fields=None, usage=None)

model_response finish reason 3: None; response_obj={'text': ' your', 'is_finished': False, 'finish_reason': None, 'logprobs': None, 'original_chunk': ModelResponseStream(id='chatcmpl-1e246dec-1357-4ceb-948f-03d49e55b5f9', created=1762261915, model=None, object='chat.completion.chunk', system_fingerprint=None, choices=[StreamingChoices(finish_reason=None, index=0, delta=Delta(provider_specific_fields=None, content=' your', role=None, function_call=None, tool_calls=None, audio=None), logprobs=None)], provider_specific_fields=None, usage=None), 'usage': None}
original delta: {'provider_specific_fields': None, 'content': ' your', 'role': None, 'function_call': None, 'tool_calls': None, 'audio': None}
new delta: Delta(provider_specific_fields=None, content=' your', role=None, function_call=None, tool_calls=None, audio=None)
model_response.choices[0].delta: Delta(provider_specific_fields=None, content=' your', role=None, function_call=None, tool_calls=None, audio=None); completion_obj: {'content': ' your'}
self.sent_first_chunk: True
completion_obj: {'content': ' your'}, model_response.choices[0]: StreamingChoices(finish_reason=None, index=0, delta=Delta(provider_specific_fields=None, content=' your', role=None, function_call=None, tool_calls=None, audio=None), logprobs=None), response_obj: {'text': ' your', 'is_finished': False, 'finish_reason': None, 'logprobs': None, 'original_chunk': ModelResponseStream(id='chatcmpl-1e246dec-1357-4ceb-948f-03d49e55b5f9', created=1762261915, model=None, object='chat.completion.chunk', system_fingerprint=None, choices=[StreamingChoices(finish_reason=None, index=0, delta=Delta(provider_specific_fields=None, content=' your', role=None, function_call=None, tool_calls=None, audio=None), logprobs=None)], provider_specific_fields=None, usage=None), 'usage': None}
choice_json: {'index': 0, 'delta': {'provider_specific_fields': None, 'content': ' your', 'role': None, 'function_call': None, 'tool_calls': None, 'audio': None}, 'logprobs': None}
choices in streaming: [StreamingChoices(finish_reason=None, index=0, delta=Delta(provider_specific_fields=None, content=' your', role=None, function_call=None, tool_calls=None, audio=None), logprobs=None)]
final returned processed chunk: ModelResponseStream(id='chatcmpl-1e246dec-1357-4ceb-948f-03d49e55b5f9', created=1762261907, model='claude-sonnet-4-5-20250929', object='chat.completion.chunk', system_fingerprint=None, choices=[StreamingChoices(finish_reason=None, index=0, delta=Delta(provider_specific_fields=None, content=' your', role=None, function_call=None, tool_calls=None, audio=None), logprobs=None)], provider_specific_fields=None, citations=None)
model_response finish reason 3: None; response_obj={'text': '', 'is_finished': False, 'finish_reason': '', 'usage': None, 'index': 0, 'tool_use': None}
model_response.choices[0].delta: Delta(provider_specific_fields=None, content=None, role=None, function_call=None, tool_calls=None, audio=None); completion_obj: {'content': ''}
self.sent_first_chunk: True
completion_obj: {'content': ''}, model_response.choices[0]: StreamingChoices(finish_reason=None, index=0, delta=Delta(provider_specific_fields=None, content=None, role=None, function_call=None, tool_calls=None, audio=None), logprobs=None), response_obj: {'text': '', 'is_finished': False, 'finish_reason': '', 'usage': None, 'index': 0, 'tool_use': None}
model_response finish reason 3: None; response_obj={'text': '', 'is_finished': False, 'finish_reason': '', 'usage': None, 'index': 0, 'tool_use': None}
model_response.choices[0].delta: Delta(provider_specific_fields=None, content=None, role=None, function_call=None, tool_calls=None, audio=None); completion_obj: {'content': ''}
self.sent_first_chunk: True
completion_obj: {'content': ''}, model_response.choices[0]: StreamingChoices(finish_reason=None, index=0, delta=Delta(provider_specific_fields=None, content=None, role=None, function_call=None, tool_calls=None, audio=None), logprobs=None), response_obj: {'text': '', 'is_finished': False, 'finish_reason': '', 'usage': None, 'index': 0, 'tool_use': None}

Raw OpenAI Chunk
ModelResponseStream(id='chatcmpl-1e246dec-1357-4ceb-948f-03d49e55b5f9', created=1762261915, model=None, object='chat.completion.chunk', system_fingerprint=None, choices=[StreamingChoices(finish_reason=None, index=0, delta=Delta(provider_specific_fields=None, content=' past conversations**', role=None, function_call=None, tool_calls=None, audio=None), logprobs=None)], provider_specific_fields=None, usage=None)

model_response finish reason 3: None; response_obj={'text': ' past conversations**', 'is_finished': False, 'finish_reason': None, 'logprobs': None, 'original_chunk': ModelResponseStream(id='chatcmpl-1e246dec-1357-4ceb-948f-03d49e55b5f9', created=1762261915, model=None, object='chat.completion.chunk', system_fingerprint=None, choices=[StreamingChoices(finish_reason=None, index=0, delta=Delta(provider_specific_fields=None, content=' past conversations**', role=None, function_call=None, tool_calls=None, audio=None), logprobs=None)], provider_specific_fields=None, usage=None), 'usage': None}
original delta: {'provider_specific_fields': None, 'content': ' past conversations**', 'role': None, 'function_call': None, 'tool_calls': None, 'audio': None}
new delta: Delta(provider_specific_fields=None, content=' past conversations**', role=None, function_call=None, tool_calls=None, audio=None)
model_response.choices[0].delta: Delta(provider_specific_fields=None, content=' past conversations**', role=None, function_call=None, tool_calls=None, audio=None); completion_obj: {'content': ' past conversations**'}
self.sent_first_chunk: True
completion_obj: {'content': ' past conversations**'}, model_response.choices[0]: StreamingChoices(finish_reason=None, index=0, delta=Delta(provider_specific_fields=None, content=' past conversations**', role=None, function_call=None, tool_calls=None, audio=None), logprobs=None), response_obj: {'text': ' past conversations**', 'is_finished': False, 'finish_reason': None, 'logprobs': None, 'original_chunk': ModelResponseStream(id='chatcmpl-1e246dec-1357-4ceb-948f-03d49e55b5f9', created=1762261915, model=None, object='chat.completion.chunk', system_fingerprint=None, choices=[StreamingChoices(finish_reason=None, index=0, delta=Delta(provider_specific_fields=None, content=' past conversations**', role=None, function_call=None, tool_calls=None, audio=None), logprobs=None)], provider_specific_fields=None, usage=None), 'usage': None}
choice_json: {'index': 0, 'delta': {'provider_specific_fields': None, 'content': ' past conversations**', 'role': None, 'function_call': None, 'tool_calls': None, 'audio': None}, 'logprobs': None}
choices in streaming: [StreamingChoices(finish_reason=None, index=0, delta=Delta(provider_specific_fields=None, content=' past conversations**', role=None, function_call=None, tool_calls=None, audio=None), logprobs=None)]
final returned processed chunk: ModelResponseStream(id='chatcmpl-1e246dec-1357-4ceb-948f-03d49e55b5f9', created=1762261907, model='claude-sonnet-4-5-20250929', object='chat.completion.chunk', system_fingerprint=None, choices=[StreamingChoices(finish_reason=None, index=0, delta=Delta(provider_specific_fields=None, content=' past conversations**', role=None, function_call=None, tool_calls=None, audio=None), logprobs=None)], provider_specific_fields=None, citations=None)
model_response finish reason 3: None; response_obj={'text': '', 'is_finished': False, 'finish_reason': '', 'usage': None, 'index': 0, 'tool_use': None}
model_response.choices[0].delta: Delta(provider_specific_fields=None, content=None, role=None, function_call=None, tool_calls=None, audio=None); completion_obj: {'content': ''}
self.sent_first_chunk: True
completion_obj: {'content': ''}, model_response.choices[0]: StreamingChoices(finish_reason=None, index=0, delta=Delta(provider_specific_fields=None, content=None, role=None, function_call=None, tool_calls=None, audio=None), logprobs=None), response_obj: {'text': '', 'is_finished': False, 'finish_reason': '', 'usage': None, 'index': 0, 'tool_use': None}
model_response finish reason 3: None; response_obj={'text': '', 'is_finished': False, 'finish_reason': '', 'usage': None, 'index': 0, 'tool_use': None}
model_response.choices[0].delta: Delta(provider_specific_fields=None, content=None, role=None, function_call=None, tool_calls=None, audio=None); completion_obj: {'content': ''}
self.sent_first_chunk: True
completion_obj: {'content': ''}, model_response.choices[0]: StreamingChoices(finish_reason=None, index=0, delta=Delta(provider_specific_fields=None, content=None, role=None, function_call=None, tool_calls=None, audio=None), logprobs=None), response_obj: {'text': '', 'is_finished': False, 'finish_reason': '', 'usage': None, 'index': 0, 'tool_use': None}

Raw OpenAI Chunk
ModelResponseStream(id='chatcmpl-1e246dec-1357-4ceb-948f-03d49e55b5f9', created=1762261915, model=None, object='chat.completion.chunk', system_fingerprint=None, choices=[StreamingChoices(finish_reason=None, index=0, delta=Delta(provider_specific_fields=None, content=' because', role=None, function_call=None, tool_calls=None, audio=None), logprobs=None)], provider_specific_fields=None, usage=None)

model_response finish reason 3: None; response_obj={'text': ' because', 'is_finished': False, 'finish_reason': None, 'logprobs': None, 'original_chunk': ModelResponseStream(id='chatcmpl-1e246dec-1357-4ceb-948f-03d49e55b5f9', created=1762261915, model=None, object='chat.completion.chunk', system_fingerprint=None, choices=[StreamingChoices(finish_reason=None, index=0, delta=Delta(provider_specific_fields=None, content=' because', role=None, function_call=None, tool_calls=None, audio=None), logprobs=None)], provider_specific_fields=None, usage=None), 'usage': None}
original delta: {'provider_specific_fields': None, 'content': ' because', 'role': None, 'function_call': None, 'tool_calls': None, 'audio': None}
new delta: Delta(provider_specific_fields=None, content=' because', role=None, function_call=None, tool_calls=None, audio=None)
model_response.choices[0].delta: Delta(provider_specific_fields=None, content=' because', role=None, function_call=None, tool_calls=None, audio=None); completion_obj: {'content': ' because'}
self.sent_first_chunk: True
completion_obj: {'content': ' because'}, model_response.choices[0]: StreamingChoices(finish_reason=None, index=0, delta=Delta(provider_specific_fields=None, content=' because', role=None, function_call=None, tool_calls=None, audio=None), logprobs=None), response_obj: {'text': ' because', 'is_finished': False, 'finish_reason': None, 'logprobs': None, 'original_chunk': ModelResponseStream(id='chatcmpl-1e246dec-1357-4ceb-948f-03d49e55b5f9', created=1762261915, model=None, object='chat.completion.chunk', system_fingerprint=None, choices=[StreamingChoices(finish_reason=None, index=0, delta=Delta(provider_specific_fields=None, content=' because', role=None, function_call=None, tool_calls=None, audio=None), logprobs=None)], provider_specific_fields=None, usage=None), 'usage': None}
choice_json: {'index': 0, 'delta': {'provider_specific_fields': None, 'content': ' because', 'role': None, 'function_call': None, 'tool_calls': None, 'audio': None}, 'logprobs': None}
choices in streaming: [StreamingChoices(finish_reason=None, index=0, delta=Delta(provider_specific_fields=None, content=' because', role=None, function_call=None, tool_calls=None, audio=None), logprobs=None)]
final returned processed chunk: ModelResponseStream(id='chatcmpl-1e246dec-1357-4ceb-948f-03d49e55b5f9', created=1762261907, model='claude-sonnet-4-5-20250929', object='chat.completion.chunk', system_fingerprint=None, choices=[StreamingChoices(finish_reason=None, index=0, delta=Delta(provider_specific_fields=None, content=' because', role=None, function_call=None, tool_calls=None, audio=None), logprobs=None)], provider_specific_fields=None, citations=None)
model_response finish reason 3: None; response_obj={'text': '', 'is_finished': False, 'finish_reason': '', 'usage': None, 'index': 0, 'tool_use': None}
model_response.choices[0].delta: Delta(provider_specific_fields=None, content=None, role=None, function_call=None, tool_calls=None, audio=None); completion_obj: {'content': ''}
self.sent_first_chunk: True
completion_obj: {'content': ''}, model_response.choices[0]: StreamingChoices(finish_reason=None, index=0, delta=Delta(provider_specific_fields=None, content=None, role=None, function_call=None, tool_calls=None, audio=None), logprobs=None), response_obj: {'text': '', 'is_finished': False, 'finish_reason': '', 'usage': None, 'index': 0, 'tool_use': None}
model_response finish reason 3: None; response_obj={'text': '', 'is_finished': False, 'finish_reason': '', 'usage': None, 'index': 0, 'tool_use': None}
model_response.choices[0].delta: Delta(provider_specific_fields=None, content=None, role=None, function_call=None, tool_calls=None, audio=None); completion_obj: {'content': ''}
self.sent_first_chunk: True
completion_obj: {'content': ''}, model_response.choices[0]: StreamingChoices(finish_reason=None, index=0, delta=Delta(provider_specific_fields=None, content=None, role=None, function_call=None, tool_calls=None, audio=None), logprobs=None), response_obj: {'text': '', 'is_finished': False, 'finish_reason': '', 'usage': None, 'index': 0, 'tool_use': None}

Raw OpenAI Chunk
ModelResponseStream(id='chatcmpl-1e246dec-1357-4ceb-948f-03d49e55b5f9', created=1762261915, model=None, object='chat.completion.chunk', system_fingerprint=None, choices=[StreamingChoices(finish_reason=None, index=0, delta=Delta(provider_specific_fields=None, content=':', role=None, function_call=None, tool_calls=None, audio=None), logprobs=None)], provider_specific_fields=None, usage=None)

model_response finish reason 3: None; response_obj={'text': ':', 'is_finished': False, 'finish_reason': None, 'logprobs': None, 'original_chunk': ModelResponseStream(id='chatcmpl-1e246dec-1357-4ceb-948f-03d49e55b5f9', created=1762261915, model=None, object='chat.completion.chunk', system_fingerprint=None, choices=[StreamingChoices(finish_reason=None, index=0, delta=Delta(provider_specific_fields=None, content=':', role=None, function_call=None, tool_calls=None, audio=None), logprobs=None)], provider_specific_fields=None, usage=None), 'usage': None}
original delta: {'provider_specific_fields': None, 'content': ':', 'role': None, 'function_call': None, 'tool_calls': None, 'audio': None}
new delta: Delta(provider_specific_fields=None, content=':', role=None, function_call=None, tool_calls=None, audio=None)
model_response.choices[0].delta: Delta(provider_specific_fields=None, content=':', role=None, function_call=None, tool_calls=None, audio=None); completion_obj: {'content': ':'}
self.sent_first_chunk: True
completion_obj: {'content': ':'}, model_response.choices[0]: StreamingChoices(finish_reason=None, index=0, delta=Delta(provider_specific_fields=None, content=':', role=None, function_call=None, tool_calls=None, audio=None), logprobs=None), response_obj: {'text': ':', 'is_finished': False, 'finish_reason': None, 'logprobs': None, 'original_chunk': ModelResponseStream(id='chatcmpl-1e246dec-1357-4ceb-948f-03d49e55b5f9', created=1762261915, model=None, object='chat.completion.chunk', system_fingerprint=None, choices=[StreamingChoices(finish_reason=None, index=0, delta=Delta(provider_specific_fields=None, content=':', role=None, function_call=None, tool_calls=None, audio=None), logprobs=None)], provider_specific_fields=None, usage=None), 'usage': None}
choice_json: {'index': 0, 'delta': {'provider_specific_fields': None, 'content': ':', 'role': None, 'function_call': None, 'tool_calls': None, 'audio': None}, 'logprobs': None}
choices in streaming: [StreamingChoices(finish_reason=None, index=0, delta=Delta(provider_specific_fields=None, content=':', role=None, function_call=None, tool_calls=None, audio=None), logprobs=None)]
final returned processed chunk: ModelResponseStream(id='chatcmpl-1e246dec-1357-4ceb-948f-03d49e55b5f9', created=1762261907, model='claude-sonnet-4-5-20250929', object='chat.completion.chunk', system_fingerprint=None, choices=[StreamingChoices(finish_reason=None, index=0, delta=Delta(provider_specific_fields=None, content=':', role=None, function_call=None, tool_calls=None, audio=None), logprobs=None)], provider_specific_fields=None, citations=None)
model_response finish reason 3: None; response_obj={'text': '', 'is_finished': False, 'finish_reason': '', 'usage': None, 'index': 0, 'tool_use': None}
model_response.choices[0].delta: Delta(provider_specific_fields=None, content=None, role=None, function_call=None, tool_calls=None, audio=None); completion_obj: {'content': ''}
self.sent_first_chunk: True
completion_obj: {'content': ''}, model_response.choices[0]: StreamingChoices(finish_reason=None, index=0, delta=Delta(provider_specific_fields=None, content=None, role=None, function_call=None, tool_calls=None, audio=None), logprobs=None), response_obj: {'text': '', 'is_finished': False, 'finish_reason': '', 'usage': None, 'index': 0, 'tool_use': None}
model_response finish reason 3: None; response_obj={'text': '', 'is_finished': False, 'finish_reason': '', 'usage': None, 'index': 0, 'tool_use': None}
model_response.choices[0].delta: Delta(provider_specific_fields=None, content=None, role=None, function_call=None, tool_calls=None, audio=None); completion_obj: {'content': ''}
self.sent_first_chunk: True
completion_obj: {'content': ''}, model_response.choices[0]: StreamingChoices(finish_reason=None, index=0, delta=Delta(provider_specific_fields=None, content=None, role=None, function_call=None, tool_calls=None, audio=None), logprobs=None), response_obj: {'text': '', 'is_finished': False, 'finish_reason': '', 'usage': None, 'index': 0, 'tool_use': None}

Raw OpenAI Chunk
ModelResponseStream(id='chatcmpl-1e246dec-1357-4ceb-948f-03d49e55b5f9', created=1762261915, model=None, object='chat.completion.chunk', system_fingerprint=None, choices=[StreamingChoices(finish_reason=None, index=0, delta=Delta(provider_specific_fields=None, content='\n-', role=None, function_call=None, tool_calls=None, audio=None), logprobs=None)], provider_specific_fields=None, usage=None)

model_response finish reason 3: None; response_obj={'text': '\n-', 'is_finished': False, 'finish_reason': None, 'logprobs': None, 'original_chunk': ModelResponseStream(id='chatcmpl-1e246dec-1357-4ceb-948f-03d49e55b5f9', created=1762261915, model=None, object='chat.completion.chunk', system_fingerprint=None, choices=[StreamingChoices(finish_reason=None, index=0, delta=Delta(provider_specific_fields=None, content='\n-', role=None, function_call=None, tool_calls=None, audio=None), logprobs=None)], provider_specific_fields=None, usage=None), 'usage': None}
original delta: {'provider_specific_fields': None, 'content': '\n-', 'role': None, 'function_call': None, 'tool_calls': None, 'audio': None}
new delta: Delta(provider_specific_fields=None, content='\n-', role=None, function_call=None, tool_calls=None, audio=None)
model_response.choices[0].delta: Delta(provider_specific_fields=None, content='\n-', role=None, function_call=None, tool_calls=None, audio=None); completion_obj: {'content': '\n-'}
self.sent_first_chunk: True
completion_obj: {'content': '\n-'}, model_response.choices[0]: StreamingChoices(finish_reason=None, index=0, delta=Delta(provider_specific_fields=None, content='\n-', role=None, function_call=None, tool_calls=None, audio=None), logprobs=None), response_obj: {'text': '\n-', 'is_finished': False, 'finish_reason': None, 'logprobs': None, 'original_chunk': ModelResponseStream(id='chatcmpl-1e246dec-1357-4ceb-948f-03d49e55b5f9', created=1762261915, model=None, object='chat.completion.chunk', system_fingerprint=None, choices=[StreamingChoices(finish_reason=None, index=0, delta=Delta(provider_specific_fields=None, content='\n-', role=None, function_call=None, tool_calls=None, audio=None), logprobs=None)], provider_specific_fields=None, usage=None), 'usage': None}
choice_json: {'index': 0, 'delta': {'provider_specific_fields': None, 'content': '\n-', 'role': None, 'function_call': None, 'tool_calls': None, 'audio': None}, 'logprobs': None}
choices in streaming: [StreamingChoices(finish_reason=None, index=0, delta=Delta(provider_specific_fields=None, content='\n-', role=None, function_call=None, tool_calls=None, audio=None), logprobs=None)]
final returned processed chunk: ModelResponseStream(id='chatcmpl-1e246dec-1357-4ceb-948f-03d49e55b5f9', created=1762261907, model='claude-sonnet-4-5-20250929', object='chat.completion.chunk', system_fingerprint=None, choices=[StreamingChoices(finish_reason=None, index=0, delta=Delta(provider_specific_fields=None, content='\n-', role=None, function_call=None, tool_calls=None, audio=None), logprobs=None)], provider_specific_fields=None, citations=None)
model_response finish reason 3: None; response_obj={'text': '', 'is_finished': False, 'finish_reason': '', 'usage': None, 'index': 0, 'tool_use': None}
model_response.choices[0].delta: Delta(provider_specific_fields=None, content=None, role=None, function_call=None, tool_calls=None, audio=None); completion_obj: {'content': ''}
self.sent_first_chunk: True
completion_obj: {'content': ''}, model_response.choices[0]: StreamingChoices(finish_reason=None, index=0, delta=Delta(provider_specific_fields=None, content=None, role=None, function_call=None, tool_calls=None, audio=None), logprobs=None), response_obj: {'text': '', 'is_finished': False, 'finish_reason': '', 'usage': None, 'index': 0, 'tool_use': None}
model_response finish reason 3: None; response_obj={'text': '', 'is_finished': False, 'finish_reason': '', 'usage': None, 'index': 0, 'tool_use': None}
model_response.choices[0].delta: Delta(provider_specific_fields=None, content=None, role=None, function_call=None, tool_calls=None, audio=None); completion_obj: {'content': ''}
self.sent_first_chunk: True
completion_obj: {'content': ''}, model_response.choices[0]: StreamingChoices(finish_reason=None, index=0, delta=Delta(provider_specific_fields=None, content=None, role=None, function_call=None, tool_calls=None, audio=None), logprobs=None), response_obj: {'text': '', 'is_finished': False, 'finish_reason': '', 'usage': None, 'index': 0, 'tool_use': None}

Raw OpenAI Chunk
ModelResponseStream(id='chatcmpl-1e246dec-1357-4ceb-948f-03d49e55b5f9', created=1762261915, model=None, object='chat.completion.chunk', system_fingerprint=None, choices=[StreamingChoices(finish_reason=None, index=0, delta=Delta(provider_specific_fields=None, content=" I don't have access to previous", role=None, function_call=None, tool_calls=None, audio=None), logprobs=None)], provider_specific_fields=None, usage=None)

model_response finish reason 3: None; response_obj={'text': " I don't have access to previous", 'is_finished': False, 'finish_reason': None, 'logprobs': None, 'original_chunk': ModelResponseStream(id='chatcmpl-1e246dec-1357-4ceb-948f-03d49e55b5f9', created=1762261915, model=None, object='chat.completion.chunk', system_fingerprint=None, choices=[StreamingChoices(finish_reason=None, index=0, delta=Delta(provider_specific_fields=None, content=" I don't have access to previous", role=None, function_call=None, tool_calls=None, audio=None), logprobs=None)], provider_specific_fields=None, usage=None), 'usage': None}
original delta: {'provider_specific_fields': None, 'content': " I don't have access to previous", 'role': None, 'function_call': None, 'tool_calls': None, 'audio': None}
new delta: Delta(provider_specific_fields=None, content=" I don't have access to previous", role=None, function_call=None, tool_calls=None, audio=None)
model_response.choices[0].delta: Delta(provider_specific_fields=None, content=" I don't have access to previous", role=None, function_call=None, tool_calls=None, audio=None); completion_obj: {'content': " I don't have access to previous"}
self.sent_first_chunk: True
completion_obj: {'content': " I don't have access to previous"}, model_response.choices[0]: StreamingChoices(finish_reason=None, index=0, delta=Delta(provider_specific_fields=None, content=" I don't have access to previous", role=None, function_call=None, tool_calls=None, audio=None), logprobs=None), response_obj: {'text': " I don't have access to previous", 'is_finished': False, 'finish_reason': None, 'logprobs': None, 'original_chunk': ModelResponseStream(id='chatcmpl-1e246dec-1357-4ceb-948f-03d49e55b5f9', created=1762261915, model=None, object='chat.completion.chunk', system_fingerprint=None, choices=[StreamingChoices(finish_reason=None, index=0, delta=Delta(provider_specific_fields=None, content=" I don't have access to previous", role=None, function_call=None, tool_calls=None, audio=None), logprobs=None)], provider_specific_fields=None, usage=None), 'usage': None}
choice_json: {'index': 0, 'delta': {'provider_specific_fields': None, 'content': " I don't have access to previous", 'role': None, 'function_call': None, 'tool_calls': None, 'audio': None}, 'logprobs': None}
choices in streaming: [StreamingChoices(finish_reason=None, index=0, delta=Delta(provider_specific_fields=None, content=" I don't have access to previous", role=None, function_call=None, tool_calls=None, audio=None), logprobs=None)]
final returned processed chunk: ModelResponseStream(id='chatcmpl-1e246dec-1357-4ceb-948f-03d49e55b5f9', created=1762261907, model='claude-sonnet-4-5-20250929', object='chat.completion.chunk', system_fingerprint=None, choices=[StreamingChoices(finish_reason=None, index=0, delta=Delta(provider_specific_fields=None, content=" I don't have access to previous", role=None, function_call=None, tool_calls=None, audio=None), logprobs=None)], provider_specific_fields=None, citations=None)
model_response finish reason 3: None; response_obj={'text': '', 'is_finished': False, 'finish_reason': '', 'usage': None, 'index': 0, 'tool_use': None}
model_response.choices[0].delta: Delta(provider_specific_fields=None, content=None, role=None, function_call=None, tool_calls=None, audio=None); completion_obj: {'content': ''}
self.sent_first_chunk: True
completion_obj: {'content': ''}, model_response.choices[0]: StreamingChoices(finish_reason=None, index=0, delta=Delta(provider_specific_fields=None, content=None, role=None, function_call=None, tool_calls=None, audio=None), logprobs=None), response_obj: {'text': '', 'is_finished': False, 'finish_reason': '', 'usage': None, 'index': 0, 'tool_use': None}
model_response finish reason 3: None; response_obj={'text': '', 'is_finished': False, 'finish_reason': '', 'usage': None, 'index': 0, 'tool_use': None}
model_response.choices[0].delta: Delta(provider_specific_fields=None, content=None, role=None, function_call=None, tool_calls=None, audio=None); completion_obj: {'content': ''}
self.sent_first_chunk: True
completion_obj: {'content': ''}, model_response.choices[0]: StreamingChoices(finish_reason=None, index=0, delta=Delta(provider_specific_fields=None, content=None, role=None, function_call=None, tool_calls=None, audio=None), logprobs=None), response_obj: {'text': '', 'is_finished': False, 'finish_reason': '', 'usage': None, 'index': 0, 'tool_use': None}

Raw OpenAI Chunk
ModelResponseStream(id='chatcmpl-1e246dec-1357-4ceb-948f-03d49e55b5f9', created=1762261915, model=None, object='chat.completion.chunk', system_fingerprint=None, choices=[StreamingChoices(finish_reason=None, index=0, delta=Delta(provider_specific_fields=None, content=' conversation', role=None, function_call=None, tool_calls=None, audio=None), logprobs=None)], provider_specific_fields=None, usage=None)

model_response finish reason 3: None; response_obj={'text': ' conversation', 'is_finished': False, 'finish_reason': None, 'logprobs': None, 'original_chunk': ModelResponseStream(id='chatcmpl-1e246dec-1357-4ceb-948f-03d49e55b5f9', created=1762261915, model=None, object='chat.completion.chunk', system_fingerprint=None, choices=[StreamingChoices(finish_reason=None, index=0, delta=Delta(provider_specific_fields=None, content=' conversation', role=None, function_call=None, tool_calls=None, audio=None), logprobs=None)], provider_specific_fields=None, usage=None), 'usage': None}
original delta: {'provider_specific_fields': None, 'content': ' conversation', 'role': None, 'function_call': None, 'tool_calls': None, 'audio': None}
new delta: Delta(provider_specific_fields=None, content=' conversation', role=None, function_call=None, tool_calls=None, audio=None)
model_response.choices[0].delta: Delta(provider_specific_fields=None, content=' conversation', role=None, function_call=None, tool_calls=None, audio=None); completion_obj: {'content': ' conversation'}
self.sent_first_chunk: True
completion_obj: {'content': ' conversation'}, model_response.choices[0]: StreamingChoices(finish_reason=None, index=0, delta=Delta(provider_specific_fields=None, content=' conversation', role=None, function_call=None, tool_calls=None, audio=None), logprobs=None), response_obj: {'text': ' conversation', 'is_finished': False, 'finish_reason': None, 'logprobs': None, 'original_chunk': ModelResponseStream(id='chatcmpl-1e246dec-1357-4ceb-948f-03d49e55b5f9', created=1762261915, model=None, object='chat.completion.chunk', system_fingerprint=None, choices=[StreamingChoices(finish_reason=None, index=0, delta=Delta(provider_specific_fields=None, content=' conversation', role=None, function_call=None, tool_calls=None, audio=None), logprobs=None)], provider_specific_fields=None, usage=None), 'usage': None}
choice_json: {'index': 0, 'delta': {'provider_specific_fields': None, 'content': ' conversation', 'role': None, 'function_call': None, 'tool_calls': None, 'audio': None}, 'logprobs': None}
choices in streaming: [StreamingChoices(finish_reason=None, index=0, delta=Delta(provider_specific_fields=None, content=' conversation', role=None, function_call=None, tool_calls=None, audio=None), logprobs=None)]
final returned processed chunk: ModelResponseStream(id='chatcmpl-1e246dec-1357-4ceb-948f-03d49e55b5f9', created=1762261907, model='claude-sonnet-4-5-20250929', object='chat.completion.chunk', system_fingerprint=None, choices=[StreamingChoices(finish_reason=None, index=0, delta=Delta(provider_specific_fields=None, content=' conversation', role=None, function_call=None, tool_calls=None, audio=None), logprobs=None)], provider_specific_fields=None, citations=None)
model_response finish reason 3: None; response_obj={'text': '', 'is_finished': False, 'finish_reason': '', 'usage': None, 'index': 0, 'tool_use': None}
model_response.choices[0].delta: Delta(provider_specific_fields=None, content=None, role=None, function_call=None, tool_calls=None, audio=None); completion_obj: {'content': ''}
self.sent_first_chunk: True
completion_obj: {'content': ''}, model_response.choices[0]: StreamingChoices(finish_reason=None, index=0, delta=Delta(provider_specific_fields=None, content=None, role=None, function_call=None, tool_calls=None, audio=None), logprobs=None), response_obj: {'text': '', 'is_finished': False, 'finish_reason': '', 'usage': None, 'index': 0, 'tool_use': None}
model_response finish reason 3: None; response_obj={'text': '', 'is_finished': False, 'finish_reason': '', 'usage': None, 'index': 0, 'tool_use': None}
model_response.choices[0].delta: Delta(provider_specific_fields=None, content=None, role=None, function_call=None, tool_calls=None, audio=None); completion_obj: {'content': ''}
self.sent_first_chunk: True
completion_obj: {'content': ''}, model_response.choices[0]: StreamingChoices(finish_reason=None, index=0, delta=Delta(provider_specific_fields=None, content=None, role=None, function_call=None, tool_calls=None, audio=None), logprobs=None), response_obj: {'text': '', 'is_finished': False, 'finish_reason': '', 'usage': None, 'index': 0, 'tool_use': None}

Raw OpenAI Chunk
ModelResponseStream(id='chatcmpl-1e246dec-1357-4ceb-948f-03d49e55b5f9', created=1762261915, model=None, object='chat.completion.chunk', system_fingerprint=None, choices=[StreamingChoices(finish_reason=None, index=0, delta=Delta(provider_specific_fields=None, content=' history in', role=None, function_call=None, tool_calls=None, audio=None), logprobs=None)], provider_specific_fields=None, usage=None)

model_response finish reason 3: None; response_obj={'text': ' history in', 'is_finished': False, 'finish_reason': None, 'logprobs': None, 'original_chunk': ModelResponseStream(id='chatcmpl-1e246dec-1357-4ceb-948f-03d49e55b5f9', created=1762261915, model=None, object='chat.completion.chunk', system_fingerprint=None, choices=[StreamingChoices(finish_reason=None, index=0, delta=Delta(provider_specific_fields=None, content=' history in', role=None, function_call=None, tool_calls=None, audio=None), logprobs=None)], provider_specific_fields=None, usage=None), 'usage': None}
original delta: {'provider_specific_fields': None, 'content': ' history in', 'role': None, 'function_call': None, 'tool_calls': None, 'audio': None}
new delta: Delta(provider_specific_fields=None, content=' history in', role=None, function_call=None, tool_calls=None, audio=None)
model_response.choices[0].delta: Delta(provider_specific_fields=None, content=' history in', role=None, function_call=None, tool_calls=None, audio=None); completion_obj: {'content': ' history in'}
self.sent_first_chunk: True
completion_obj: {'content': ' history in'}, model_response.choices[0]: StreamingChoices(finish_reason=None, index=0, delta=Delta(provider_specific_fields=None, content=' history in', role=None, function_call=None, tool_calls=None, audio=None), logprobs=None), response_obj: {'text': ' history in', 'is_finished': False, 'finish_reason': None, 'logprobs': None, 'original_chunk': ModelResponseStream(id='chatcmpl-1e246dec-1357-4ceb-948f-03d49e55b5f9', created=1762261915, model=None, object='chat.completion.chunk', system_fingerprint=None, choices=[StreamingChoices(finish_reason=None, index=0, delta=Delta(provider_specific_fields=None, content=' history in', role=None, function_call=None, tool_calls=None, audio=None), logprobs=None)], provider_specific_fields=None, usage=None), 'usage': None}
choice_json: {'index': 0, 'delta': {'provider_specific_fields': None, 'content': ' history in', 'role': None, 'function_call': None, 'tool_calls': None, 'audio': None}, 'logprobs': None}
choices in streaming: [StreamingChoices(finish_reason=None, index=0, delta=Delta(provider_specific_fields=None, content=' history in', role=None, function_call=None, tool_calls=None, audio=None), logprobs=None)]
final returned processed chunk: ModelResponseStream(id='chatcmpl-1e246dec-1357-4ceb-948f-03d49e55b5f9', created=1762261907, model='claude-sonnet-4-5-20250929', object='chat.completion.chunk', system_fingerprint=None, choices=[StreamingChoices(finish_reason=None, index=0, delta=Delta(provider_specific_fields=None, content=' history in', role=None, function_call=None, tool_calls=None, audio=None), logprobs=None)], provider_specific_fields=None, citations=None)
model_response finish reason 3: None; response_obj={'text': '', 'is_finished': False, 'finish_reason': '', 'usage': None, 'index': 0, 'tool_use': None}
model_response.choices[0].delta: Delta(provider_specific_fields=None, content=None, role=None, function_call=None, tool_calls=None, audio=None); completion_obj: {'content': ''}
self.sent_first_chunk: True
completion_obj: {'content': ''}, model_response.choices[0]: StreamingChoices(finish_reason=None, index=0, delta=Delta(provider_specific_fields=None, content=None, role=None, function_call=None, tool_calls=None, audio=None), logprobs=None), response_obj: {'text': '', 'is_finished': False, 'finish_reason': '', 'usage': None, 'index': 0, 'tool_use': None}
model_response finish reason 3: None; response_obj={'text': '', 'is_finished': False, 'finish_reason': '', 'usage': None, 'index': 0, 'tool_use': None}
model_response.choices[0].delta: Delta(provider_specific_fields=None, content=None, role=None, function_call=None, tool_calls=None, audio=None); completion_obj: {'content': ''}
self.sent_first_chunk: True
completion_obj: {'content': ''}, model_response.choices[0]: StreamingChoices(finish_reason=None, index=0, delta=Delta(provider_specific_fields=None, content=None, role=None, function_call=None, tool_calls=None, audio=None), logprobs=None), response_obj: {'text': '', 'is_finished': False, 'finish_reason': '', 'usage': None, 'index': 0, 'tool_use': None}

Raw OpenAI Chunk
ModelResponseStream(id='chatcmpl-1e246dec-1357-4ceb-948f-03d49e55b5f9', created=1762261915, model=None, object='chat.completion.chunk', system_fingerprint=None, choices=[StreamingChoices(finish_reason=None, index=0, delta=Delta(provider_specific_fields=None, content=' this session', role=None, function_call=None, tool_calls=None, audio=None), logprobs=None)], provider_specific_fields=None, usage=None)

model_response finish reason 3: None; response_obj={'text': ' this session', 'is_finished': False, 'finish_reason': None, 'logprobs': None, 'original_chunk': ModelResponseStream(id='chatcmpl-1e246dec-1357-4ceb-948f-03d49e55b5f9', created=1762261915, model=None, object='chat.completion.chunk', system_fingerprint=None, choices=[StreamingChoices(finish_reason=None, index=0, delta=Delta(provider_specific_fields=None, content=' this session', role=None, function_call=None, tool_calls=None, audio=None), logprobs=None)], provider_specific_fields=None, usage=None), 'usage': None}
original delta: {'provider_specific_fields': None, 'content': ' this session', 'role': None, 'function_call': None, 'tool_calls': None, 'audio': None}
new delta: Delta(provider_specific_fields=None, content=' this session', role=None, function_call=None, tool_calls=None, audio=None)
model_response.choices[0].delta: Delta(provider_specific_fields=None, content=' this session', role=None, function_call=None, tool_calls=None, audio=None); completion_obj: {'content': ' this session'}
self.sent_first_chunk: True
completion_obj: {'content': ' this session'}, model_response.choices[0]: StreamingChoices(finish_reason=None, index=0, delta=Delta(provider_specific_fields=None, content=' this session', role=None, function_call=None, tool_calls=None, audio=None), logprobs=None), response_obj: {'text': ' this session', 'is_finished': False, 'finish_reason': None, 'logprobs': None, 'original_chunk': ModelResponseStream(id='chatcmpl-1e246dec-1357-4ceb-948f-03d49e55b5f9', created=1762261915, model=None, object='chat.completion.chunk', system_fingerprint=None, choices=[StreamingChoices(finish_reason=None, index=0, delta=Delta(provider_specific_fields=None, content=' this session', role=None, function_call=None, tool_calls=None, audio=None), logprobs=None)], provider_specific_fields=None, usage=None), 'usage': None}
choice_json: {'index': 0, 'delta': {'provider_specific_fields': None, 'content': ' this session', 'role': None, 'function_call': None, 'tool_calls': None, 'audio': None}, 'logprobs': None}
choices in streaming: [StreamingChoices(finish_reason=None, index=0, delta=Delta(provider_specific_fields=None, content=' this session', role=None, function_call=None, tool_calls=None, audio=None), logprobs=None)]
final returned processed chunk: ModelResponseStream(id='chatcmpl-1e246dec-1357-4ceb-948f-03d49e55b5f9', created=1762261907, model='claude-sonnet-4-5-20250929', object='chat.completion.chunk', system_fingerprint=None, choices=[StreamingChoices(finish_reason=None, index=0, delta=Delta(provider_specific_fields=None, content=' this session', role=None, function_call=None, tool_calls=None, audio=None), logprobs=None)], provider_specific_fields=None, citations=None)
model_response finish reason 3: None; response_obj={'text': '', 'is_finished': False, 'finish_reason': '', 'usage': None, 'index': 0, 'tool_use': None}
model_response.choices[0].delta: Delta(provider_specific_fields=None, content=None, role=None, function_call=None, tool_calls=None, audio=None); completion_obj: {'content': ''}
self.sent_first_chunk: True
completion_obj: {'content': ''}, model_response.choices[0]: StreamingChoices(finish_reason=None, index=0, delta=Delta(provider_specific_fields=None, content=None, role=None, function_call=None, tool_calls=None, audio=None), logprobs=None), response_obj: {'text': '', 'is_finished': False, 'finish_reason': '', 'usage': None, 'index': 0, 'tool_use': None}
model_response finish reason 3: None; response_obj={'text': '', 'is_finished': False, 'finish_reason': '', 'usage': None, 'index': 0, 'tool_use': None}
model_response.choices[0].delta: Delta(provider_specific_fields=None, content=None, role=None, function_call=None, tool_calls=None, audio=None); completion_obj: {'content': ''}
self.sent_first_chunk: True
completion_obj: {'content': ''}, model_response.choices[0]: StreamingChoices(finish_reason=None, index=0, delta=Delta(provider_specific_fields=None, content=None, role=None, function_call=None, tool_calls=None, audio=None), logprobs=None), response_obj: {'text': '', 'is_finished': False, 'finish_reason': '', 'usage': None, 'index': 0, 'tool_use': None}

Raw OpenAI Chunk
ModelResponseStream(id='chatcmpl-1e246dec-1357-4ceb-948f-03d49e55b5f9', created=1762261915, model=None, object='chat.completion.chunk', system_fingerprint=None, choices=[StreamingChoices(finish_reason=None, index=0, delta=Delta(provider_specific_fields=None, content='\n- Each', role=None, function_call=None, tool_calls=None, audio=None), logprobs=None)], provider_specific_fields=None, usage=None)

model_response finish reason 3: None; response_obj={'text': '\n- Each', 'is_finished': False, 'finish_reason': None, 'logprobs': None, 'original_chunk': ModelResponseStream(id='chatcmpl-1e246dec-1357-4ceb-948f-03d49e55b5f9', created=1762261915, model=None, object='chat.completion.chunk', system_fingerprint=None, choices=[StreamingChoices(finish_reason=None, index=0, delta=Delta(provider_specific_fields=None, content='\n- Each', role=None, function_call=None, tool_calls=None, audio=None), logprobs=None)], provider_specific_fields=None, usage=None), 'usage': None}
original delta: {'provider_specific_fields': None, 'content': '\n- Each', 'role': None, 'function_call': None, 'tool_calls': None, 'audio': None}
new delta: Delta(provider_specific_fields=None, content='\n- Each', role=None, function_call=None, tool_calls=None, audio=None)
model_response.choices[0].delta: Delta(provider_specific_fields=None, content='\n- Each', role=None, function_call=None, tool_calls=None, audio=None); completion_obj: {'content': '\n- Each'}
self.sent_first_chunk: True
completion_obj: {'content': '\n- Each'}, model_response.choices[0]: StreamingChoices(finish_reason=None, index=0, delta=Delta(provider_specific_fields=None, content='\n- Each', role=None, function_call=None, tool_calls=None, audio=None), logprobs=None), response_obj: {'text': '\n- Each', 'is_finished': False, 'finish_reason': None, 'logprobs': None, 'original_chunk': ModelResponseStream(id='chatcmpl-1e246dec-1357-4ceb-948f-03d49e55b5f9', created=1762261915, model=None, object='chat.completion.chunk', system_fingerprint=None, choices=[StreamingChoices(finish_reason=None, index=0, delta=Delta(provider_specific_fields=None, content='\n- Each', role=None, function_call=None, tool_calls=None, audio=None), logprobs=None)], provider_specific_fields=None, usage=None), 'usage': None}
choice_json: {'index': 0, 'delta': {'provider_specific_fields': None, 'content': '\n- Each', 'role': None, 'function_call': None, 'tool_calls': None, 'audio': None}, 'logprobs': None}
choices in streaming: [StreamingChoices(finish_reason=None, index=0, delta=Delta(provider_specific_fields=None, content='\n- Each', role=None, function_call=None, tool_calls=None, audio=None), logprobs=None)]
final returned processed chunk: ModelResponseStream(id='chatcmpl-1e246dec-1357-4ceb-948f-03d49e55b5f9', created=1762261907, model='claude-sonnet-4-5-20250929', object='chat.completion.chunk', system_fingerprint=None, choices=[StreamingChoices(finish_reason=None, index=0, delta=Delta(provider_specific_fields=None, content='\n- Each', role=None, function_call=None, tool_calls=None, audio=None), logprobs=None)], provider_specific_fields=None, citations=None)
model_response finish reason 3: None; response_obj={'text': '', 'is_finished': False, 'finish_reason': '', 'usage': None, 'index': 0, 'tool_use': None}
model_response.choices[0].delta: Delta(provider_specific_fields=None, content=None, role=None, function_call=None, tool_calls=None, audio=None); completion_obj: {'content': ''}
self.sent_first_chunk: True
completion_obj: {'content': ''}, model_response.choices[0]: StreamingChoices(finish_reason=None, index=0, delta=Delta(provider_specific_fields=None, content=None, role=None, function_call=None, tool_calls=None, audio=None), logprobs=None), response_obj: {'text': '', 'is_finished': False, 'finish_reason': '', 'usage': None, 'index': 0, 'tool_use': None}
model_response finish reason 3: None; response_obj={'text': '', 'is_finished': False, 'finish_reason': '', 'usage': None, 'index': 0, 'tool_use': None}
model_response.choices[0].delta: Delta(provider_specific_fields=None, content=None, role=None, function_call=None, tool_calls=None, audio=None); completion_obj: {'content': ''}
self.sent_first_chunk: True
completion_obj: {'content': ''}, model_response.choices[0]: StreamingChoices(finish_reason=None, index=0, delta=Delta(provider_specific_fields=None, content=None, role=None, function_call=None, tool_calls=None, audio=None), logprobs=None), response_obj: {'text': '', 'is_finished': False, 'finish_reason': '', 'usage': None, 'index': 0, 'tool_use': None}

Raw OpenAI Chunk
ModelResponseStream(id='chatcmpl-1e246dec-1357-4ceb-948f-03d49e55b5f9', created=1762261915, model=None, object='chat.completion.chunk', system_fingerprint=None, choices=[StreamingChoices(finish_reason=None, index=0, delta=Delta(provider_specific_fields=None, content=' conversation starts fresh without', role=None, function_call=None, tool_calls=None, audio=None), logprobs=None)], provider_specific_fields=None, usage=None)

model_response finish reason 3: None; response_obj={'text': ' conversation starts fresh without', 'is_finished': False, 'finish_reason': None, 'logprobs': None, 'original_chunk': ModelResponseStream(id='chatcmpl-1e246dec-1357-4ceb-948f-03d49e55b5f9', created=1762261915, model=None, object='chat.completion.chunk', system_fingerprint=None, choices=[StreamingChoices(finish_reason=None, index=0, delta=Delta(provider_specific_fields=None, content=' conversation starts fresh without', role=None, function_call=None, tool_calls=None, audio=None), logprobs=None)], provider_specific_fields=None, usage=None), 'usage': None}
original delta: {'provider_specific_fields': None, 'content': ' conversation starts fresh without', 'role': None, 'function_call': None, 'tool_calls': None, 'audio': None}
new delta: Delta(provider_specific_fields=None, content=' conversation starts fresh without', role=None, function_call=None, tool_calls=None, audio=None)
model_response.choices[0].delta: Delta(provider_specific_fields=None, content=' conversation starts fresh without', role=None, function_call=None, tool_calls=None, audio=None); completion_obj: {'content': ' conversation starts fresh without'}
self.sent_first_chunk: True
completion_obj: {'content': ' conversation starts fresh without'}, model_response.choices[0]: StreamingChoices(finish_reason=None, index=0, delta=Delta(provider_specific_fields=None, content=' conversation starts fresh without', role=None, function_call=None, tool_calls=None, audio=None), logprobs=None), response_obj: {'text': ' conversation starts fresh without', 'is_finished': False, 'finish_reason': None, 'logprobs': None, 'original_chunk': ModelResponseStream(id='chatcmpl-1e246dec-1357-4ceb-948f-03d49e55b5f9', created=1762261915, model=None, object='chat.completion.chunk', system_fingerprint=None, choices=[StreamingChoices(finish_reason=None, index=0, delta=Delta(provider_specific_fields=None, content=' conversation starts fresh without', role=None, function_call=None, tool_calls=None, audio=None), logprobs=None)], provider_specific_fields=None, usage=None), 'usage': None}
choice_json: {'index': 0, 'delta': {'provider_specific_fields': None, 'content': ' conversation starts fresh without', 'role': None, 'function_call': None, 'tool_calls': None, 'audio': None}, 'logprobs': None}
choices in streaming: [StreamingChoices(finish_reason=None, index=0, delta=Delta(provider_specific_fields=None, content=' conversation starts fresh without', role=None, function_call=None, tool_calls=None, audio=None), logprobs=None)]
final returned processed chunk: ModelResponseStream(id='chatcmpl-1e246dec-1357-4ceb-948f-03d49e55b5f9', created=1762261907, model='claude-sonnet-4-5-20250929', object='chat.completion.chunk', system_fingerprint=None, choices=[StreamingChoices(finish_reason=None, index=0, delta=Delta(provider_specific_fields=None, content=' conversation starts fresh without', role=None, function_call=None, tool_calls=None, audio=None), logprobs=None)], provider_specific_fields=None, citations=None)
model_response finish reason 3: None; response_obj={'text': '', 'is_finished': False, 'finish_reason': '', 'usage': None, 'index': 0, 'tool_use': None}
model_response.choices[0].delta: Delta(provider_specific_fields=None, content=None, role=None, function_call=None, tool_calls=None, audio=None); completion_obj: {'content': ''}
self.sent_first_chunk: True
completion_obj: {'content': ''}, model_response.choices[0]: StreamingChoices(finish_reason=None, index=0, delta=Delta(provider_specific_fields=None, content=None, role=None, function_call=None, tool_calls=None, audio=None), logprobs=None), response_obj: {'text': '', 'is_finished': False, 'finish_reason': '', 'usage': None, 'index': 0, 'tool_use': None}
model_response finish reason 3: None; response_obj={'text': '', 'is_finished': False, 'finish_reason': '', 'usage': None, 'index': 0, 'tool_use': None}
model_response.choices[0].delta: Delta(provider_specific_fields=None, content=None, role=None, function_call=None, tool_calls=None, audio=None); completion_obj: {'content': ''}
self.sent_first_chunk: True
completion_obj: {'content': ''}, model_response.choices[0]: StreamingChoices(finish_reason=None, index=0, delta=Delta(provider_specific_fields=None, content=None, role=None, function_call=None, tool_calls=None, audio=None), logprobs=None), response_obj: {'text': '', 'is_finished': False, 'finish_reason': '', 'usage': None, 'index': 0, 'tool_use': None}

Raw OpenAI Chunk
ModelResponseStream(id='chatcmpl-1e246dec-1357-4ceb-948f-03d49e55b5f9', created=1762261915, model=None, object='chat.completion.chunk', system_fingerprint=None, choices=[StreamingChoices(finish_reason=None, index=0, delta=Delta(provider_specific_fields=None, content=' memory', role=None, function_call=None, tool_calls=None, audio=None), logprobs=None)], provider_specific_fields=None, usage=None)

model_response finish reason 3: None; response_obj={'text': ' memory', 'is_finished': False, 'finish_reason': None, 'logprobs': None, 'original_chunk': ModelResponseStream(id='chatcmpl-1e246dec-1357-4ceb-948f-03d49e55b5f9', created=1762261915, model=None, object='chat.completion.chunk', system_fingerprint=None, choices=[StreamingChoices(finish_reason=None, index=0, delta=Delta(provider_specific_fields=None, content=' memory', role=None, function_call=None, tool_calls=None, audio=None), logprobs=None)], provider_specific_fields=None, usage=None), 'usage': None}
original delta: {'provider_specific_fields': None, 'content': ' memory', 'role': None, 'function_call': None, 'tool_calls': None, 'audio': None}
new delta: Delta(provider_specific_fields=None, content=' memory', role=None, function_call=None, tool_calls=None, audio=None)
model_response.choices[0].delta: Delta(provider_specific_fields=None, content=' memory', role=None, function_call=None, tool_calls=None, audio=None); completion_obj: {'content': ' memory'}
self.sent_first_chunk: True
completion_obj: {'content': ' memory'}, model_response.choices[0]: StreamingChoices(finish_reason=None, index=0, delta=Delta(provider_specific_fields=None, content=' memory', role=None, function_call=None, tool_calls=None, audio=None), logprobs=None), response_obj: {'text': ' memory', 'is_finished': False, 'finish_reason': None, 'logprobs': None, 'original_chunk': ModelResponseStream(id='chatcmpl-1e246dec-1357-4ceb-948f-03d49e55b5f9', created=1762261915, model=None, object='chat.completion.chunk', system_fingerprint=None, choices=[StreamingChoices(finish_reason=None, index=0, delta=Delta(provider_specific_fields=None, content=' memory', role=None, function_call=None, tool_calls=None, audio=None), logprobs=None)], provider_specific_fields=None, usage=None), 'usage': None}
choice_json: {'index': 0, 'delta': {'provider_specific_fields': None, 'content': ' memory', 'role': None, 'function_call': None, 'tool_calls': None, 'audio': None}, 'logprobs': None}
choices in streaming: [StreamingChoices(finish_reason=None, index=0, delta=Delta(provider_specific_fields=None, content=' memory', role=None, function_call=None, tool_calls=None, audio=None), logprobs=None)]
final returned processed chunk: ModelResponseStream(id='chatcmpl-1e246dec-1357-4ceb-948f-03d49e55b5f9', created=1762261907, model='claude-sonnet-4-5-20250929', object='chat.completion.chunk', system_fingerprint=None, choices=[StreamingChoices(finish_reason=None, index=0, delta=Delta(provider_specific_fields=None, content=' memory', role=None, function_call=None, tool_calls=None, audio=None), logprobs=None)], provider_specific_fields=None, citations=None)
model_response finish reason 3: None; response_obj={'text': '', 'is_finished': False, 'finish_reason': '', 'usage': None, 'index': 0, 'tool_use': None}
model_response.choices[0].delta: Delta(provider_specific_fields=None, content=None, role=None, function_call=None, tool_calls=None, audio=None); completion_obj: {'content': ''}
self.sent_first_chunk: True
completion_obj: {'content': ''}, model_response.choices[0]: StreamingChoices(finish_reason=None, index=0, delta=Delta(provider_specific_fields=None, content=None, role=None, function_call=None, tool_calls=None, audio=None), logprobs=None), response_obj: {'text': '', 'is_finished': False, 'finish_reason': '', 'usage': None, 'index': 0, 'tool_use': None}
model_response finish reason 3: None; response_obj={'text': '', 'is_finished': False, 'finish_reason': '', 'usage': None, 'index': 0, 'tool_use': None}
model_response.choices[0].delta: Delta(provider_specific_fields=None, content=None, role=None, function_call=None, tool_calls=None, audio=None); completion_obj: {'content': ''}
self.sent_first_chunk: True
completion_obj: {'content': ''}, model_response.choices[0]: StreamingChoices(finish_reason=None, index=0, delta=Delta(provider_specific_fields=None, content=None, role=None, function_call=None, tool_calls=None, audio=None), logprobs=None), response_obj: {'text': '', 'is_finished': False, 'finish_reason': '', 'usage': None, 'index': 0, 'tool_use': None}

Raw OpenAI Chunk
ModelResponseStream(id='chatcmpl-1e246dec-1357-4ceb-948f-03d49e55b5f9', created=1762261916, model=None, object='chat.completion.chunk', system_fingerprint=None, choices=[StreamingChoices(finish_reason=None, index=0, delta=Delta(provider_specific_fields=None, content='\n- **', role=None, function_call=None, tool_calls=None, audio=None), logprobs=None)], provider_specific_fields=None, usage=None)

model_response finish reason 3: None; response_obj={'text': '\n- **', 'is_finished': False, 'finish_reason': None, 'logprobs': None, 'original_chunk': ModelResponseStream(id='chatcmpl-1e246dec-1357-4ceb-948f-03d49e55b5f9', created=1762261916, model=None, object='chat.completion.chunk', system_fingerprint=None, choices=[StreamingChoices(finish_reason=None, index=0, delta=Delta(provider_specific_fields=None, content='\n- **', role=None, function_call=None, tool_calls=None, audio=None), logprobs=None)], provider_specific_fields=None, usage=None), 'usage': None}
original delta: {'provider_specific_fields': None, 'content': '\n- **', 'role': None, 'function_call': None, 'tool_calls': None, 'audio': None}
new delta: Delta(provider_specific_fields=None, content='\n- **', role=None, function_call=None, tool_calls=None, audio=None)
model_response.choices[0].delta: Delta(provider_specific_fields=None, content='\n- **', role=None, function_call=None, tool_calls=None, audio=None); completion_obj: {'content': '\n- **'}
self.sent_first_chunk: True
completion_obj: {'content': '\n- **'}, model_response.choices[0]: StreamingChoices(finish_reason=None, index=0, delta=Delta(provider_specific_fields=None, content='\n- **', role=None, function_call=None, tool_calls=None, audio=None), logprobs=None), response_obj: {'text': '\n- **', 'is_finished': False, 'finish_reason': None, 'logprobs': None, 'original_chunk': ModelResponseStream(id='chatcmpl-1e246dec-1357-4ceb-948f-03d49e55b5f9', created=1762261916, model=None, object='chat.completion.chunk', system_fingerprint=None, choices=[StreamingChoices(finish_reason=None, index=0, delta=Delta(provider_specific_fields=None, content='\n- **', role=None, function_call=None, tool_calls=None, audio=None), logprobs=None)], provider_specific_fields=None, usage=None), 'usage': None}
choice_json: {'index': 0, 'delta': {'provider_specific_fields': None, 'content': '\n- **', 'role': None, 'function_call': None, 'tool_calls': None, 'audio': None}, 'logprobs': None}
choices in streaming: [StreamingChoices(finish_reason=None, index=0, delta=Delta(provider_specific_fields=None, content='\n- **', role=None, function_call=None, tool_calls=None, audio=None), logprobs=None)]
final returned processed chunk: ModelResponseStream(id='chatcmpl-1e246dec-1357-4ceb-948f-03d49e55b5f9', created=1762261907, model='claude-sonnet-4-5-20250929', object='chat.completion.chunk', system_fingerprint=None, choices=[StreamingChoices(finish_reason=None, index=0, delta=Delta(provider_specific_fields=None, content='\n- **', role=None, function_call=None, tool_calls=None, audio=None), logprobs=None)], provider_specific_fields=None, citations=None)
model_response finish reason 3: None; response_obj={'text': '', 'is_finished': False, 'finish_reason': '', 'usage': None, 'index': 0, 'tool_use': None}
model_response.choices[0].delta: Delta(provider_specific_fields=None, content=None, role=None, function_call=None, tool_calls=None, audio=None); completion_obj: {'content': ''}
self.sent_first_chunk: True
completion_obj: {'content': ''}, model_response.choices[0]: StreamingChoices(finish_reason=None, index=0, delta=Delta(provider_specific_fields=None, content=None, role=None, function_call=None, tool_calls=None, audio=None), logprobs=None), response_obj: {'text': '', 'is_finished': False, 'finish_reason': '', 'usage': None, 'index': 0, 'tool_use': None}
model_response finish reason 3: None; response_obj={'text': '', 'is_finished': False, 'finish_reason': '', 'usage': None, 'index': 0, 'tool_use': None}
model_response.choices[0].delta: Delta(provider_specific_fields=None, content=None, role=None, function_call=None, tool_calls=None, audio=None); completion_obj: {'content': ''}
self.sent_first_chunk: True
completion_obj: {'content': ''}, model_response.choices[0]: StreamingChoices(finish_reason=None, index=0, delta=Delta(provider_specific_fields=None, content=None, role=None, function_call=None, tool_calls=None, audio=None), logprobs=None), response_obj: {'text': '', 'is_finished': False, 'finish_reason': '', 'usage': None, 'index': 0, 'tool_use': None}

Raw OpenAI Chunk
ModelResponseStream(id='chatcmpl-1e246dec-1357-4ceb-948f-03d49e55b5f9', created=1762261916, model=None, object='chat.completion.chunk', system_fingerprint=None, choices=[StreamingChoices(finish_reason=None, index=0, delta=Delta(provider_specific_fields=None, content='However', role=None, function_call=None, tool_calls=None, audio=None), logprobs=None)], provider_specific_fields=None, usage=None)

model_response finish reason 3: None; response_obj={'text': 'However', 'is_finished': False, 'finish_reason': None, 'logprobs': None, 'original_chunk': ModelResponseStream(id='chatcmpl-1e246dec-1357-4ceb-948f-03d49e55b5f9', created=1762261916, model=None, object='chat.completion.chunk', system_fingerprint=None, choices=[StreamingChoices(finish_reason=None, index=0, delta=Delta(provider_specific_fields=None, content='However', role=None, function_call=None, tool_calls=None, audio=None), logprobs=None)], provider_specific_fields=None, usage=None), 'usage': None}
original delta: {'provider_specific_fields': None, 'content': 'However', 'role': None, 'function_call': None, 'tool_calls': None, 'audio': None}
new delta: Delta(provider_specific_fields=None, content='However', role=None, function_call=None, tool_calls=None, audio=None)
model_response.choices[0].delta: Delta(provider_specific_fields=None, content='However', role=None, function_call=None, tool_calls=None, audio=None); completion_obj: {'content': 'However'}
self.sent_first_chunk: True
completion_obj: {'content': 'However'}, model_response.choices[0]: StreamingChoices(finish_reason=None, index=0, delta=Delta(provider_specific_fields=None, content='However', role=None, function_call=None, tool_calls=None, audio=None), logprobs=None), response_obj: {'text': 'However', 'is_finished': False, 'finish_reason': None, 'logprobs': None, 'original_chunk': ModelResponseStream(id='chatcmpl-1e246dec-1357-4ceb-948f-03d49e55b5f9', created=1762261916, model=None, object='chat.completion.chunk', system_fingerprint=None, choices=[StreamingChoices(finish_reason=None, index=0, delta=Delta(provider_specific_fields=None, content='However', role=None, function_call=None, tool_calls=None, audio=None), logprobs=None)], provider_specific_fields=None, usage=None), 'usage': None}
choice_json: {'index': 0, 'delta': {'provider_specific_fields': None, 'content': 'However', 'role': None, 'function_call': None, 'tool_calls': None, 'audio': None}, 'logprobs': None}
choices in streaming: [StreamingChoices(finish_reason=None, index=0, delta=Delta(provider_specific_fields=None, content='However', role=None, function_call=None, tool_calls=None, audio=None), logprobs=None)]
final returned processed chunk: ModelResponseStream(id='chatcmpl-1e246dec-1357-4ceb-948f-03d49e55b5f9', created=1762261907, model='claude-sonnet-4-5-20250929', object='chat.completion.chunk', system_fingerprint=None, choices=[StreamingChoices(finish_reason=None, index=0, delta=Delta(provider_specific_fields=None, content='However', role=None, function_call=None, tool_calls=None, audio=None), logprobs=None)], provider_specific_fields=None, citations=None)
model_response finish reason 3: None; response_obj={'text': '', 'is_finished': False, 'finish_reason': '', 'usage': None, 'index': 0, 'tool_use': None}
model_response.choices[0].delta: Delta(provider_specific_fields=None, content=None, role=None, function_call=None, tool_calls=None, audio=None); completion_obj: {'content': ''}
self.sent_first_chunk: True
completion_obj: {'content': ''}, model_response.choices[0]: StreamingChoices(finish_reason=None, index=0, delta=Delta(provider_specific_fields=None, content=None, role=None, function_call=None, tool_calls=None, audio=None), logprobs=None), response_obj: {'text': '', 'is_finished': False, 'finish_reason': '', 'usage': None, 'index': 0, 'tool_use': None}
model_response finish reason 3: None; response_obj={'text': '', 'is_finished': False, 'finish_reason': '', 'usage': None, 'index': 0, 'tool_use': None}
model_response.choices[0].delta: Delta(provider_specific_fields=None, content=None, role=None, function_call=None, tool_calls=None, audio=None); completion_obj: {'content': ''}
self.sent_first_chunk: True
completion_obj: {'content': ''}, model_response.choices[0]: StreamingChoices(finish_reason=None, index=0, delta=Delta(provider_specific_fields=None, content=None, role=None, function_call=None, tool_calls=None, audio=None), logprobs=None), response_obj: {'text': '', 'is_finished': False, 'finish_reason': '', 'usage': None, 'index': 0, 'tool_use': None}

Raw OpenAI Chunk
ModelResponseStream(id='chatcmpl-1e246dec-1357-4ceb-948f-03d49e55b5f9', created=1762261916, model=None, object='chat.completion.chunk', system_fingerprint=None, choices=[StreamingChoices(finish_reason=None, index=0, delta=Delta(provider_specific_fields=None, content='**, your', role=None, function_call=None, tool_calls=None, audio=None), logprobs=None)], provider_specific_fields=None, usage=None)

model_response finish reason 3: None; response_obj={'text': '**, your', 'is_finished': False, 'finish_reason': None, 'logprobs': None, 'original_chunk': ModelResponseStream(id='chatcmpl-1e246dec-1357-4ceb-948f-03d49e55b5f9', created=1762261916, model=None, object='chat.completion.chunk', system_fingerprint=None, choices=[StreamingChoices(finish_reason=None, index=0, delta=Delta(provider_specific_fields=None, content='**, your', role=None, function_call=None, tool_calls=None, audio=None), logprobs=None)], provider_specific_fields=None, usage=None), 'usage': None}
original delta: {'provider_specific_fields': None, 'content': '**, your', 'role': None, 'function_call': None, 'tool_calls': None, 'audio': None}
new delta: Delta(provider_specific_fields=None, content='**, your', role=None, function_call=None, tool_calls=None, audio=None)
model_response.choices[0].delta: Delta(provider_specific_fields=None, content='**, your', role=None, function_call=None, tool_calls=None, audio=None); completion_obj: {'content': '**, your'}
self.sent_first_chunk: True
completion_obj: {'content': '**, your'}, model_response.choices[0]: StreamingChoices(finish_reason=None, index=0, delta=Delta(provider_specific_fields=None, content='**, your', role=None, function_call=None, tool_calls=None, audio=None), logprobs=None), response_obj: {'text': '**, your', 'is_finished': False, 'finish_reason': None, 'logprobs': None, 'original_chunk': ModelResponseStream(id='chatcmpl-1e246dec-1357-4ceb-948f-03d49e55b5f9', created=1762261916, model=None, object='chat.completion.chunk', system_fingerprint=None, choices=[StreamingChoices(finish_reason=None, index=0, delta=Delta(provider_specific_fields=None, content='**, your', role=None, function_call=None, tool_calls=None, audio=None), logprobs=None)], provider_specific_fields=None, usage=None), 'usage': None}
choice_json: {'index': 0, 'delta': {'provider_specific_fields': None, 'content': '**, your', 'role': None, 'function_call': None, 'tool_calls': None, 'audio': None}, 'logprobs': None}
choices in streaming: [StreamingChoices(finish_reason=None, index=0, delta=Delta(provider_specific_fields=None, content='**, your', role=None, function_call=None, tool_calls=None, audio=None), logprobs=None)]
final returned processed chunk: ModelResponseStream(id='chatcmpl-1e246dec-1357-4ceb-948f-03d49e55b5f9', created=1762261907, model='claude-sonnet-4-5-20250929', object='chat.completion.chunk', system_fingerprint=None, choices=[StreamingChoices(finish_reason=None, index=0, delta=Delta(provider_specific_fields=None, content='**, your', role=None, function_call=None, tool_calls=None, audio=None), logprobs=None)], provider_specific_fields=None, citations=None)
model_response finish reason 3: None; response_obj={'text': '', 'is_finished': False, 'finish_reason': '', 'usage': None, 'index': 0, 'tool_use': None}
model_response.choices[0].delta: Delta(provider_specific_fields=None, content=None, role=None, function_call=None, tool_calls=None, audio=None); completion_obj: {'content': ''}
self.sent_first_chunk: True
completion_obj: {'content': ''}, model_response.choices[0]: StreamingChoices(finish_reason=None, index=0, delta=Delta(provider_specific_fields=None, content=None, role=None, function_call=None, tool_calls=None, audio=None), logprobs=None), response_obj: {'text': '', 'is_finished': False, 'finish_reason': '', 'usage': None, 'index': 0, 'tool_use': None}
model_response finish reason 3: None; response_obj={'text': '', 'is_finished': False, 'finish_reason': '', 'usage': None, 'index': 0, 'tool_use': None}
model_response.choices[0].delta: Delta(provider_specific_fields=None, content=None, role=None, function_call=None, tool_calls=None, audio=None); completion_obj: {'content': ''}
self.sent_first_chunk: True
completion_obj: {'content': ''}, model_response.choices[0]: StreamingChoices(finish_reason=None, index=0, delta=Delta(provider_specific_fields=None, content=None, role=None, function_call=None, tool_calls=None, audio=None), logprobs=None), response_obj: {'text': '', 'is_finished': False, 'finish_reason': '', 'usage': None, 'index': 0, 'tool_use': None}

Raw OpenAI Chunk
ModelResponseStream(id='chatcmpl-1e246dec-1357-4ceb-948f-03d49e55b5f9', created=1762261916, model=None, object='chat.completion.chunk', system_fingerprint=None, choices=[StreamingChoices(finish_reason=None, index=0, delta=Delta(provider_specific_fields=None, content=' Supermemory integration is designe', role=None, function_call=None, tool_calls=None, audio=None), logprobs=None)], provider_specific_fields=None, usage=None)

model_response finish reason 3: None; response_obj={'text': ' Supermemory integration is designe', 'is_finished': False, 'finish_reason': None, 'logprobs': None, 'original_chunk': ModelResponseStream(id='chatcmpl-1e246dec-1357-4ceb-948f-03d49e55b5f9', created=1762261916, model=None, object='chat.completion.chunk', system_fingerprint=None, choices=[StreamingChoices(finish_reason=None, index=0, delta=Delta(provider_specific_fields=None, content=' Supermemory integration is designe', role=None, function_call=None, tool_calls=None, audio=None), logprobs=None)], provider_specific_fields=None, usage=None), 'usage': None}
original delta: {'provider_specific_fields': None, 'content': ' Supermemory integration is designe', 'role': None, 'function_call': None, 'tool_calls': None, 'audio': None}
new delta: Delta(provider_specific_fields=None, content=' Supermemory integration is designe', role=None, function_call=None, tool_calls=None, audio=None)
model_response.choices[0].delta: Delta(provider_specific_fields=None, content=' Supermemory integration is designe', role=None, function_call=None, tool_calls=None, audio=None); completion_obj: {'content': ' Supermemory integration is designe'}
self.sent_first_chunk: True
completion_obj: {'content': ' Supermemory integration is designe'}, model_response.choices[0]: StreamingChoices(finish_reason=None, index=0, delta=Delta(provider_specific_fields=None, content=' Supermemory integration is designe', role=None, function_call=None, tool_calls=None, audio=None), logprobs=None), response_obj: {'text': ' Supermemory integration is designe', 'is_finished': False, 'finish_reason': None, 'logprobs': None, 'original_chunk': ModelResponseStream(id='chatcmpl-1e246dec-1357-4ceb-948f-03d49e55b5f9', created=1762261916, model=None, object='chat.completion.chunk', system_fingerprint=None, choices=[StreamingChoices(finish_reason=None, index=0, delta=Delta(provider_specific_fields=None, content=' Supermemory integration is designe', role=None, function_call=None, tool_calls=None, audio=None), logprobs=None)], provider_specific_fields=None, usage=None), 'usage': None}
choice_json: {'index': 0, 'delta': {'provider_specific_fields': None, 'content': ' Supermemory integration is designe', 'role': None, 'function_call': None, 'tool_calls': None, 'audio': None}, 'logprobs': None}
choices in streaming: [StreamingChoices(finish_reason=None, index=0, delta=Delta(provider_specific_fields=None, content=' Supermemory integration is designe', role=None, function_call=None, tool_calls=None, audio=None), logprobs=None)]
final returned processed chunk: ModelResponseStream(id='chatcmpl-1e246dec-1357-4ceb-948f-03d49e55b5f9', created=1762261907, model='claude-sonnet-4-5-20250929', object='chat.completion.chunk', system_fingerprint=None, choices=[StreamingChoices(finish_reason=None, index=0, delta=Delta(provider_specific_fields=None, content=' Supermemory integration is designe', role=None, function_call=None, tool_calls=None, audio=None), logprobs=None)], provider_specific_fields=None, citations=None)
model_response finish reason 3: None; response_obj={'text': '', 'is_finished': False, 'finish_reason': '', 'usage': None, 'index': 0, 'tool_use': None}
model_response.choices[0].delta: Delta(provider_specific_fields=None, content=None, role=None, function_call=None, tool_calls=None, audio=None); completion_obj: {'content': ''}
self.sent_first_chunk: True
completion_obj: {'content': ''}, model_response.choices[0]: StreamingChoices(finish_reason=None, index=0, delta=Delta(provider_specific_fields=None, content=None, role=None, function_call=None, tool_calls=None, audio=None), logprobs=None), response_obj: {'text': '', 'is_finished': False, 'finish_reason': '', 'usage': None, 'index': 0, 'tool_use': None}
model_response finish reason 3: None; response_obj={'text': '', 'is_finished': False, 'finish_reason': '', 'usage': None, 'index': 0, 'tool_use': None}
model_response.choices[0].delta: Delta(provider_specific_fields=None, content=None, role=None, function_call=None, tool_calls=None, audio=None); completion_obj: {'content': ''}
self.sent_first_chunk: True
completion_obj: {'content': ''}, model_response.choices[0]: StreamingChoices(finish_reason=None, index=0, delta=Delta(provider_specific_fields=None, content=None, role=None, function_call=None, tool_calls=None, audio=None), logprobs=None), response_obj: {'text': '', 'is_finished': False, 'finish_reason': '', 'usage': None, 'index': 0, 'tool_use': None}

Raw OpenAI Chunk
ModelResponseStream(id='chatcmpl-1e246dec-1357-4ceb-948f-03d49e55b5f9', created=1762261916, model=None, object='chat.completion.chunk', system_fingerprint=None, choices=[StreamingChoices(finish_reason=None, index=0, delta=Delta(provider_specific_fields=None, content='d to solve', role=None, function_call=None, tool_calls=None, audio=None), logprobs=None)], provider_specific_fields=None, usage=None)

model_response finish reason 3: None; response_obj={'text': 'd to solve', 'is_finished': False, 'finish_reason': None, 'logprobs': None, 'original_chunk': ModelResponseStream(id='chatcmpl-1e246dec-1357-4ceb-948f-03d49e55b5f9', created=1762261916, model=None, object='chat.completion.chunk', system_fingerprint=None, choices=[StreamingChoices(finish_reason=None, index=0, delta=Delta(provider_specific_fields=None, content='d to solve', role=None, function_call=None, tool_calls=None, audio=None), logprobs=None)], provider_specific_fields=None, usage=None), 'usage': None}
original delta: {'provider_specific_fields': None, 'content': 'd to solve', 'role': None, 'function_call': None, 'tool_calls': None, 'audio': None}
new delta: Delta(provider_specific_fields=None, content='d to solve', role=None, function_call=None, tool_calls=None, audio=None)
model_response.choices[0].delta: Delta(provider_specific_fields=None, content='d to solve', role=None, function_call=None, tool_calls=None, audio=None); completion_obj: {'content': 'd to solve'}
self.sent_first_chunk: True
completion_obj: {'content': 'd to solve'}, model_response.choices[0]: StreamingChoices(finish_reason=None, index=0, delta=Delta(provider_specific_fields=None, content='d to solve', role=None, function_call=None, tool_calls=None, audio=None), logprobs=None), response_obj: {'text': 'd to solve', 'is_finished': False, 'finish_reason': None, 'logprobs': None, 'original_chunk': ModelResponseStream(id='chatcmpl-1e246dec-1357-4ceb-948f-03d49e55b5f9', created=1762261916, model=None, object='chat.completion.chunk', system_fingerprint=None, choices=[StreamingChoices(finish_reason=None, index=0, delta=Delta(provider_specific_fields=None, content='d to solve', role=None, function_call=None, tool_calls=None, audio=None), logprobs=None)], provider_specific_fields=None, usage=None), 'usage': None}
choice_json: {'index': 0, 'delta': {'provider_specific_fields': None, 'content': 'd to solve', 'role': None, 'function_call': None, 'tool_calls': None, 'audio': None}, 'logprobs': None}
choices in streaming: [StreamingChoices(finish_reason=None, index=0, delta=Delta(provider_specific_fields=None, content='d to solve', role=None, function_call=None, tool_calls=None, audio=None), logprobs=None)]
final returned processed chunk: ModelResponseStream(id='chatcmpl-1e246dec-1357-4ceb-948f-03d49e55b5f9', created=1762261907, model='claude-sonnet-4-5-20250929', object='chat.completion.chunk', system_fingerprint=None, choices=[StreamingChoices(finish_reason=None, index=0, delta=Delta(provider_specific_fields=None, content='d to solve', role=None, function_call=None, tool_calls=None, audio=None), logprobs=None)], provider_specific_fields=None, citations=None)
model_response finish reason 3: None; response_obj={'text': '', 'is_finished': False, 'finish_reason': '', 'usage': None, 'index': 0, 'tool_use': None}
model_response.choices[0].delta: Delta(provider_specific_fields=None, content=None, role=None, function_call=None, tool_calls=None, audio=None); completion_obj: {'content': ''}
self.sent_first_chunk: True
completion_obj: {'content': ''}, model_response.choices[0]: StreamingChoices(finish_reason=None, index=0, delta=Delta(provider_specific_fields=None, content=None, role=None, function_call=None, tool_calls=None, audio=None), logprobs=None), response_obj: {'text': '', 'is_finished': False, 'finish_reason': '', 'usage': None, 'index': 0, 'tool_use': None}
model_response finish reason 3: None; response_obj={'text': '', 'is_finished': False, 'finish_reason': '', 'usage': None, 'index': 0, 'tool_use': None}
model_response.choices[0].delta: Delta(provider_specific_fields=None, content=None, role=None, function_call=None, tool_calls=None, audio=None); completion_obj: {'content': ''}
self.sent_first_chunk: True
completion_obj: {'content': ''}, model_response.choices[0]: StreamingChoices(finish_reason=None, index=0, delta=Delta(provider_specific_fields=None, content=None, role=None, function_call=None, tool_calls=None, audio=None), logprobs=None), response_obj: {'text': '', 'is_finished': False, 'finish_reason': '', 'usage': None, 'index': 0, 'tool_use': None}

Raw OpenAI Chunk
ModelResponseStream(id='chatcmpl-1e246dec-1357-4ceb-948f-03d49e55b5f9', created=1762261916, model=None, object='chat.completion.chunk', system_fingerprint=None, choices=[StreamingChoices(finish_reason=None, index=0, delta=Delta(provider_specific_fields=None, content=' exactly', role=None, function_call=None, tool_calls=None, audio=None), logprobs=None)], provider_specific_fields=None, usage=None)

model_response finish reason 3: None; response_obj={'text': ' exactly', 'is_finished': False, 'finish_reason': None, 'logprobs': None, 'original_chunk': ModelResponseStream(id='chatcmpl-1e246dec-1357-4ceb-948f-03d49e55b5f9', created=1762261916, model=None, object='chat.completion.chunk', system_fingerprint=None, choices=[StreamingChoices(finish_reason=None, index=0, delta=Delta(provider_specific_fields=None, content=' exactly', role=None, function_call=None, tool_calls=None, audio=None), logprobs=None)], provider_specific_fields=None, usage=None), 'usage': None}
original delta: {'provider_specific_fields': None, 'content': ' exactly', 'role': None, 'function_call': None, 'tool_calls': None, 'audio': None}
new delta: Delta(provider_specific_fields=None, content=' exactly', role=None, function_call=None, tool_calls=None, audio=None)
model_response.choices[0].delta: Delta(provider_specific_fields=None, content=' exactly', role=None, function_call=None, tool_calls=None, audio=None); completion_obj: {'content': ' exactly'}
self.sent_first_chunk: True
completion_obj: {'content': ' exactly'}, model_response.choices[0]: StreamingChoices(finish_reason=None, index=0, delta=Delta(provider_specific_fields=None, content=' exactly', role=None, function_call=None, tool_calls=None, audio=None), logprobs=None), response_obj: {'text': ' exactly', 'is_finished': False, 'finish_reason': None, 'logprobs': None, 'original_chunk': ModelResponseStream(id='chatcmpl-1e246dec-1357-4ceb-948f-03d49e55b5f9', created=1762261916, model=None, object='chat.completion.chunk', system_fingerprint=None, choices=[StreamingChoices(finish_reason=None, index=0, delta=Delta(provider_specific_fields=None, content=' exactly', role=None, function_call=None, tool_calls=None, audio=None), logprobs=None)], provider_specific_fields=None, usage=None), 'usage': None}
choice_json: {'index': 0, 'delta': {'provider_specific_fields': None, 'content': ' exactly', 'role': None, 'function_call': None, 'tool_calls': None, 'audio': None}, 'logprobs': None}
choices in streaming: [StreamingChoices(finish_reason=None, index=0, delta=Delta(provider_specific_fields=None, content=' exactly', role=None, function_call=None, tool_calls=None, audio=None), logprobs=None)]
final returned processed chunk: ModelResponseStream(id='chatcmpl-1e246dec-1357-4ceb-948f-03d49e55b5f9', created=1762261907, model='claude-sonnet-4-5-20250929', object='chat.completion.chunk', system_fingerprint=None, choices=[StreamingChoices(finish_reason=None, index=0, delta=Delta(provider_specific_fields=None, content=' exactly', role=None, function_call=None, tool_calls=None, audio=None), logprobs=None)], provider_specific_fields=None, citations=None)
model_response finish reason 3: None; response_obj={'text': '', 'is_finished': False, 'finish_reason': '', 'usage': None, 'index': 0, 'tool_use': None}
model_response.choices[0].delta: Delta(provider_specific_fields=None, content=None, role=None, function_call=None, tool_calls=None, audio=None); completion_obj: {'content': ''}
self.sent_first_chunk: True
completion_obj: {'content': ''}, model_response.choices[0]: StreamingChoices(finish_reason=None, index=0, delta=Delta(provider_specific_fields=None, content=None, role=None, function_call=None, tool_calls=None, audio=None), logprobs=None), response_obj: {'text': '', 'is_finished': False, 'finish_reason': '', 'usage': None, 'index': 0, 'tool_use': None}
model_response finish reason 3: None; response_obj={'text': '', 'is_finished': False, 'finish_reason': '', 'usage': None, 'index': 0, 'tool_use': None}
model_response.choices[0].delta: Delta(provider_specific_fields=None, content=None, role=None, function_call=None, tool_calls=None, audio=None); completion_obj: {'content': ''}
self.sent_first_chunk: True
completion_obj: {'content': ''}, model_response.choices[0]: StreamingChoices(finish_reason=None, index=0, delta=Delta(provider_specific_fields=None, content=None, role=None, function_call=None, tool_calls=None, audio=None), logprobs=None), response_obj: {'text': '', 'is_finished': False, 'finish_reason': '', 'usage': None, 'index': 0, 'tool_use': None}

Raw OpenAI Chunk
ModelResponseStream(id='chatcmpl-1e246dec-1357-4ceb-948f-03d49e55b5f9', created=1762261916, model=None, object='chat.completion.chunk', system_fingerprint=None, choices=[StreamingChoices(finish_reason=None, index=0, delta=Delta(provider_specific_fields=None, content=' this problem!', role=None, function_call=None, tool_calls=None, audio=None), logprobs=None)], provider_specific_fields=None, usage=None)

model_response finish reason 3: None; response_obj={'text': ' this problem!', 'is_finished': False, 'finish_reason': None, 'logprobs': None, 'original_chunk': ModelResponseStream(id='chatcmpl-1e246dec-1357-4ceb-948f-03d49e55b5f9', created=1762261916, model=None, object='chat.completion.chunk', system_fingerprint=None, choices=[StreamingChoices(finish_reason=None, index=0, delta=Delta(provider_specific_fields=None, content=' this problem!', role=None, function_call=None, tool_calls=None, audio=None), logprobs=None)], provider_specific_fields=None, usage=None), 'usage': None}
original delta: {'provider_specific_fields': None, 'content': ' this problem!', 'role': None, 'function_call': None, 'tool_calls': None, 'audio': None}
new delta: Delta(provider_specific_fields=None, content=' this problem!', role=None, function_call=None, tool_calls=None, audio=None)
model_response.choices[0].delta: Delta(provider_specific_fields=None, content=' this problem!', role=None, function_call=None, tool_calls=None, audio=None); completion_obj: {'content': ' this problem!'}
self.sent_first_chunk: True
completion_obj: {'content': ' this problem!'}, model_response.choices[0]: StreamingChoices(finish_reason=None, index=0, delta=Delta(provider_specific_fields=None, content=' this problem!', role=None, function_call=None, tool_calls=None, audio=None), logprobs=None), response_obj: {'text': ' this problem!', 'is_finished': False, 'finish_reason': None, 'logprobs': None, 'original_chunk': ModelResponseStream(id='chatcmpl-1e246dec-1357-4ceb-948f-03d49e55b5f9', created=1762261916, model=None, object='chat.completion.chunk', system_fingerprint=None, choices=[StreamingChoices(finish_reason=None, index=0, delta=Delta(provider_specific_fields=None, content=' this problem!', role=None, function_call=None, tool_calls=None, audio=None), logprobs=None)], provider_specific_fields=None, usage=None), 'usage': None}
choice_json: {'index': 0, 'delta': {'provider_specific_fields': None, 'content': ' this problem!', 'role': None, 'function_call': None, 'tool_calls': None, 'audio': None}, 'logprobs': None}
choices in streaming: [StreamingChoices(finish_reason=None, index=0, delta=Delta(provider_specific_fields=None, content=' this problem!', role=None, function_call=None, tool_calls=None, audio=None), logprobs=None)]
final returned processed chunk: ModelResponseStream(id='chatcmpl-1e246dec-1357-4ceb-948f-03d49e55b5f9', created=1762261907, model='claude-sonnet-4-5-20250929', object='chat.completion.chunk', system_fingerprint=None, choices=[StreamingChoices(finish_reason=None, index=0, delta=Delta(provider_specific_fields=None, content=' this problem!', role=None, function_call=None, tool_calls=None, audio=None), logprobs=None)], provider_specific_fields=None, citations=None)
model_response finish reason 3: None; response_obj={'text': '', 'is_finished': False, 'finish_reason': '', 'usage': None, 'index': 0, 'tool_use': None}
model_response.choices[0].delta: Delta(provider_specific_fields=None, content=None, role=None, function_call=None, tool_calls=None, audio=None); completion_obj: {'content': ''}
self.sent_first_chunk: True
completion_obj: {'content': ''}, model_response.choices[0]: StreamingChoices(finish_reason=None, index=0, delta=Delta(provider_specific_fields=None, content=None, role=None, function_call=None, tool_calls=None, audio=None), logprobs=None), response_obj: {'text': '', 'is_finished': False, 'finish_reason': '', 'usage': None, 'index': 0, 'tool_use': None}
model_response finish reason 3: None; response_obj={'text': '', 'is_finished': False, 'finish_reason': '', 'usage': None, 'index': 0, 'tool_use': None}
model_response.choices[0].delta: Delta(provider_specific_fields=None, content=None, role=None, function_call=None, tool_calls=None, audio=None); completion_obj: {'content': ''}
self.sent_first_chunk: True
completion_obj: {'content': ''}, model_response.choices[0]: StreamingChoices(finish_reason=None, index=0, delta=Delta(provider_specific_fields=None, content=None, role=None, function_call=None, tool_calls=None, audio=None), logprobs=None), response_obj: {'text': '', 'is_finished': False, 'finish_reason': '', 'usage': None, 'index': 0, 'tool_use': None}

Raw OpenAI Chunk
ModelResponseStream(id='chatcmpl-1e246dec-1357-4ceb-948f-03d49e55b5f9', created=1762261916, model=None, object='chat.completion.chunk', system_fingerprint=None, choices=[StreamingChoices(finish_reason=None, index=0, delta=Delta(provider_specific_fields=None, content='\n\nOnce', role=None, function_call=None, tool_calls=None, audio=None), logprobs=None)], provider_specific_fields=None, usage=None)

model_response finish reason 3: None; response_obj={'text': '\n\nOnce', 'is_finished': False, 'finish_reason': None, 'logprobs': None, 'original_chunk': ModelResponseStream(id='chatcmpl-1e246dec-1357-4ceb-948f-03d49e55b5f9', created=1762261916, model=None, object='chat.completion.chunk', system_fingerprint=None, choices=[StreamingChoices(finish_reason=None, index=0, delta=Delta(provider_specific_fields=None, content='\n\nOnce', role=None, function_call=None, tool_calls=None, audio=None), logprobs=None)], provider_specific_fields=None, usage=None), 'usage': None}
original delta: {'provider_specific_fields': None, 'content': '\n\nOnce', 'role': None, 'function_call': None, 'tool_calls': None, 'audio': None}
new delta: Delta(provider_specific_fields=None, content='\n\nOnce', role=None, function_call=None, tool_calls=None, audio=None)
model_response.choices[0].delta: Delta(provider_specific_fields=None, content='\n\nOnce', role=None, function_call=None, tool_calls=None, audio=None); completion_obj: {'content': '\n\nOnce'}
self.sent_first_chunk: True
completion_obj: {'content': '\n\nOnce'}, model_response.choices[0]: StreamingChoices(finish_reason=None, index=0, delta=Delta(provider_specific_fields=None, content='\n\nOnce', role=None, function_call=None, tool_calls=None, audio=None), logprobs=None), response_obj: {'text': '\n\nOnce', 'is_finished': False, 'finish_reason': None, 'logprobs': None, 'original_chunk': ModelResponseStream(id='chatcmpl-1e246dec-1357-4ceb-948f-03d49e55b5f9', created=1762261916, model=None, object='chat.completion.chunk', system_fingerprint=None, choices=[StreamingChoices(finish_reason=None, index=0, delta=Delta(provider_specific_fields=None, content='\n\nOnce', role=None, function_call=None, tool_calls=None, audio=None), logprobs=None)], provider_specific_fields=None, usage=None), 'usage': None}
choice_json: {'index': 0, 'delta': {'provider_specific_fields': None, 'content': '\n\nOnce', 'role': None, 'function_call': None, 'tool_calls': None, 'audio': None}, 'logprobs': None}
choices in streaming: [StreamingChoices(finish_reason=None, index=0, delta=Delta(provider_specific_fields=None, content='\n\nOnce', role=None, function_call=None, tool_calls=None, audio=None), logprobs=None)]
final returned processed chunk: ModelResponseStream(id='chatcmpl-1e246dec-1357-4ceb-948f-03d49e55b5f9', created=1762261907, model='claude-sonnet-4-5-20250929', object='chat.completion.chunk', system_fingerprint=None, choices=[StreamingChoices(finish_reason=None, index=0, delta=Delta(provider_specific_fields=None, content='\n\nOnce', role=None, function_call=None, tool_calls=None, audio=None), logprobs=None)], provider_specific_fields=None, citations=None)
model_response finish reason 3: None; response_obj={'text': '', 'is_finished': False, 'finish_reason': '', 'usage': None, 'index': 0, 'tool_use': None}
model_response.choices[0].delta: Delta(provider_specific_fields=None, content=None, role=None, function_call=None, tool_calls=None, audio=None); completion_obj: {'content': ''}
self.sent_first_chunk: True
completion_obj: {'content': ''}, model_response.choices[0]: StreamingChoices(finish_reason=None, index=0, delta=Delta(provider_specific_fields=None, content=None, role=None, function_call=None, tool_calls=None, audio=None), logprobs=None), response_obj: {'text': '', 'is_finished': False, 'finish_reason': '', 'usage': None, 'index': 0, 'tool_use': None}
model_response finish reason 3: None; response_obj={'text': '', 'is_finished': False, 'finish_reason': '', 'usage': None, 'index': 0, 'tool_use': None}
model_response.choices[0].delta: Delta(provider_specific_fields=None, content=None, role=None, function_call=None, tool_calls=None, audio=None); completion_obj: {'content': ''}
self.sent_first_chunk: True
completion_obj: {'content': ''}, model_response.choices[0]: StreamingChoices(finish_reason=None, index=0, delta=Delta(provider_specific_fields=None, content=None, role=None, function_call=None, tool_calls=None, audio=None), logprobs=None), response_obj: {'text': '', 'is_finished': False, 'finish_reason': '', 'usage': None, 'index': 0, 'tool_use': None}

Raw OpenAI Chunk
ModelResponseStream(id='chatcmpl-1e246dec-1357-4ceb-948f-03d49e55b5f9', created=1762261916, model=None, object='chat.completion.chunk', system_fingerprint=None, choices=[StreamingChoices(finish_reason=None, index=0, delta=Delta(provider_specific_fields=None, content=' you integrate', role=None, function_call=None, tool_calls=None, audio=None), logprobs=None)], provider_specific_fields=None, usage=None)

model_response finish reason 3: None; response_obj={'text': ' you integrate', 'is_finished': False, 'finish_reason': None, 'logprobs': None, 'original_chunk': ModelResponseStream(id='chatcmpl-1e246dec-1357-4ceb-948f-03d49e55b5f9', created=1762261916, model=None, object='chat.completion.chunk', system_fingerprint=None, choices=[StreamingChoices(finish_reason=None, index=0, delta=Delta(provider_specific_fields=None, content=' you integrate', role=None, function_call=None, tool_calls=None, audio=None), logprobs=None)], provider_specific_fields=None, usage=None), 'usage': None}
original delta: {'provider_specific_fields': None, 'content': ' you integrate', 'role': None, 'function_call': None, 'tool_calls': None, 'audio': None}
new delta: Delta(provider_specific_fields=None, content=' you integrate', role=None, function_call=None, tool_calls=None, audio=None)
model_response.choices[0].delta: Delta(provider_specific_fields=None, content=' you integrate', role=None, function_call=None, tool_calls=None, audio=None); completion_obj: {'content': ' you integrate'}
self.sent_first_chunk: True
completion_obj: {'content': ' you integrate'}, model_response.choices[0]: StreamingChoices(finish_reason=None, index=0, delta=Delta(provider_specific_fields=None, content=' you integrate', role=None, function_call=None, tool_calls=None, audio=None), logprobs=None), response_obj: {'text': ' you integrate', 'is_finished': False, 'finish_reason': None, 'logprobs': None, 'original_chunk': ModelResponseStream(id='chatcmpl-1e246dec-1357-4ceb-948f-03d49e55b5f9', created=1762261916, model=None, object='chat.completion.chunk', system_fingerprint=None, choices=[StreamingChoices(finish_reason=None, index=0, delta=Delta(provider_specific_fields=None, content=' you integrate', role=None, function_call=None, tool_calls=None, audio=None), logprobs=None)], provider_specific_fields=None, usage=None), 'usage': None}
choice_json: {'index': 0, 'delta': {'provider_specific_fields': None, 'content': ' you integrate', 'role': None, 'function_call': None, 'tool_calls': None, 'audio': None}, 'logprobs': None}
choices in streaming: [StreamingChoices(finish_reason=None, index=0, delta=Delta(provider_specific_fields=None, content=' you integrate', role=None, function_call=None, tool_calls=None, audio=None), logprobs=None)]
final returned processed chunk: ModelResponseStream(id='chatcmpl-1e246dec-1357-4ceb-948f-03d49e55b5f9', created=1762261907, model='claude-sonnet-4-5-20250929', object='chat.completion.chunk', system_fingerprint=None, choices=[StreamingChoices(finish_reason=None, index=0, delta=Delta(provider_specific_fields=None, content=' you integrate', role=None, function_call=None, tool_calls=None, audio=None), logprobs=None)], provider_specific_fields=None, citations=None)
model_response finish reason 3: None; response_obj={'text': '', 'is_finished': False, 'finish_reason': '', 'usage': None, 'index': 0, 'tool_use': None}
model_response.choices[0].delta: Delta(provider_specific_fields=None, content=None, role=None, function_call=None, tool_calls=None, audio=None); completion_obj: {'content': ''}
self.sent_first_chunk: True
completion_obj: {'content': ''}, model_response.choices[0]: StreamingChoices(finish_reason=None, index=0, delta=Delta(provider_specific_fields=None, content=None, role=None, function_call=None, tool_calls=None, audio=None), logprobs=None), response_obj: {'text': '', 'is_finished': False, 'finish_reason': '', 'usage': None, 'index': 0, 'tool_use': None}
model_response finish reason 3: None; response_obj={'text': '', 'is_finished': False, 'finish_reason': '', 'usage': None, 'index': 0, 'tool_use': None}
model_response.choices[0].delta: Delta(provider_specific_fields=None, content=None, role=None, function_call=None, tool_calls=None, audio=None); completion_obj: {'content': ''}
self.sent_first_chunk: True
completion_obj: {'content': ''}, model_response.choices[0]: StreamingChoices(finish_reason=None, index=0, delta=Delta(provider_specific_fields=None, content=None, role=None, function_call=None, tool_calls=None, audio=None), logprobs=None), response_obj: {'text': '', 'is_finished': False, 'finish_reason': '', 'usage': None, 'index': 0, 'tool_use': None}

Raw OpenAI Chunk
ModelResponseStream(id='chatcmpl-1e246dec-1357-4ceb-948f-03d49e55b5f9', created=1762261916, model=None, object='chat.completion.chunk', system_fingerprint=None, choices=[StreamingChoices(finish_reason=None, index=0, delta=Delta(provider_specific_fields=None, content=' the', role=None, function_call=None, tool_calls=None, audio=None), logprobs=None)], provider_specific_fields=None, usage=None)

model_response finish reason 3: None; response_obj={'text': ' the', 'is_finished': False, 'finish_reason': None, 'logprobs': None, 'original_chunk': ModelResponseStream(id='chatcmpl-1e246dec-1357-4ceb-948f-03d49e55b5f9', created=1762261916, model=None, object='chat.completion.chunk', system_fingerprint=None, choices=[StreamingChoices(finish_reason=None, index=0, delta=Delta(provider_specific_fields=None, content=' the', role=None, function_call=None, tool_calls=None, audio=None), logprobs=None)], provider_specific_fields=None, usage=None), 'usage': None}
original delta: {'provider_specific_fields': None, 'content': ' the', 'role': None, 'function_call': None, 'tool_calls': None, 'audio': None}
new delta: Delta(provider_specific_fields=None, content=' the', role=None, function_call=None, tool_calls=None, audio=None)
model_response.choices[0].delta: Delta(provider_specific_fields=None, content=' the', role=None, function_call=None, tool_calls=None, audio=None); completion_obj: {'content': ' the'}
self.sent_first_chunk: True
completion_obj: {'content': ' the'}, model_response.choices[0]: StreamingChoices(finish_reason=None, index=0, delta=Delta(provider_specific_fields=None, content=' the', role=None, function_call=None, tool_calls=None, audio=None), logprobs=None), response_obj: {'text': ' the', 'is_finished': False, 'finish_reason': None, 'logprobs': None, 'original_chunk': ModelResponseStream(id='chatcmpl-1e246dec-1357-4ceb-948f-03d49e55b5f9', created=1762261916, model=None, object='chat.completion.chunk', system_fingerprint=None, choices=[StreamingChoices(finish_reason=None, index=0, delta=Delta(provider_specific_fields=None, content=' the', role=None, function_call=None, tool_calls=None, audio=None), logprobs=None)], provider_specific_fields=None, usage=None), 'usage': None}
choice_json: {'index': 0, 'delta': {'provider_specific_fields': None, 'content': ' the', 'role': None, 'function_call': None, 'tool_calls': None, 'audio': None}, 'logprobs': None}
choices in streaming: [StreamingChoices(finish_reason=None, index=0, delta=Delta(provider_specific_fields=None, content=' the', role=None, function_call=None, tool_calls=None, audio=None), logprobs=None)]
final returned processed chunk: ModelResponseStream(id='chatcmpl-1e246dec-1357-4ceb-948f-03d49e55b5f9', created=1762261907, model='claude-sonnet-4-5-20250929', object='chat.completion.chunk', system_fingerprint=None, choices=[StreamingChoices(finish_reason=None, index=0, delta=Delta(provider_specific_fields=None, content=' the', role=None, function_call=None, tool_calls=None, audio=None), logprobs=None)], provider_specific_fields=None, citations=None)
model_response finish reason 3: None; response_obj={'text': '', 'is_finished': False, 'finish_reason': '', 'usage': None, 'index': 0, 'tool_use': None}
model_response.choices[0].delta: Delta(provider_specific_fields=None, content=None, role=None, function_call=None, tool_calls=None, audio=None); completion_obj: {'content': ''}
self.sent_first_chunk: True
completion_obj: {'content': ''}, model_response.choices[0]: StreamingChoices(finish_reason=None, index=0, delta=Delta(provider_specific_fields=None, content=None, role=None, function_call=None, tool_calls=None, audio=None), logprobs=None), response_obj: {'text': '', 'is_finished': False, 'finish_reason': '', 'usage': None, 'index': 0, 'tool_use': None}
model_response finish reason 3: None; response_obj={'text': '', 'is_finished': False, 'finish_reason': '', 'usage': None, 'index': 0, 'tool_use': None}
model_response.choices[0].delta: Delta(provider_specific_fields=None, content=None, role=None, function_call=None, tool_calls=None, audio=None); completion_obj: {'content': ''}
self.sent_first_chunk: True
completion_obj: {'content': ''}, model_response.choices[0]: StreamingChoices(finish_reason=None, index=0, delta=Delta(provider_specific_fields=None, content=None, role=None, function_call=None, tool_calls=None, audio=None), logprobs=None), response_obj: {'text': '', 'is_finished': False, 'finish_reason': '', 'usage': None, 'index': 0, 'tool_use': None}

Raw OpenAI Chunk
ModelResponseStream(id='chatcmpl-1e246dec-1357-4ceb-948f-03d49e55b5f9', created=1762261916, model=None, object='chat.completion.chunk', system_fingerprint=None, choices=[StreamingChoices(finish_reason=None, index=0, delta=Delta(provider_specific_fields=None, content=' `', role=None, function_call=None, tool_calls=None, audio=None), logprobs=None)], provider_specific_fields=None, usage=None)

model_response finish reason 3: None; response_obj={'text': ' `', 'is_finished': False, 'finish_reason': None, 'logprobs': None, 'original_chunk': ModelResponseStream(id='chatcmpl-1e246dec-1357-4ceb-948f-03d49e55b5f9', created=1762261916, model=None, object='chat.completion.chunk', system_fingerprint=None, choices=[StreamingChoices(finish_reason=None, index=0, delta=Delta(provider_specific_fields=None, content=' `', role=None, function_call=None, tool_calls=None, audio=None), logprobs=None)], provider_specific_fields=None, usage=None), 'usage': None}
original delta: {'provider_specific_fields': None, 'content': ' `', 'role': None, 'function_call': None, 'tool_calls': None, 'audio': None}
new delta: Delta(provider_specific_fields=None, content=' `', role=None, function_call=None, tool_calls=None, audio=None)
model_response.choices[0].delta: Delta(provider_specific_fields=None, content=' `', role=None, function_call=None, tool_calls=None, audio=None); completion_obj: {'content': ' `'}
self.sent_first_chunk: True
completion_obj: {'content': ' `'}, model_response.choices[0]: StreamingChoices(finish_reason=None, index=0, delta=Delta(provider_specific_fields=None, content=' `', role=None, function_call=None, tool_calls=None, audio=None), logprobs=None), response_obj: {'text': ' `', 'is_finished': False, 'finish_reason': None, 'logprobs': None, 'original_chunk': ModelResponseStream(id='chatcmpl-1e246dec-1357-4ceb-948f-03d49e55b5f9', created=1762261916, model=None, object='chat.completion.chunk', system_fingerprint=None, choices=[StreamingChoices(finish_reason=None, index=0, delta=Delta(provider_specific_fields=None, content=' `', role=None, function_call=None, tool_calls=None, audio=None), logprobs=None)], provider_specific_fields=None, usage=None), 'usage': None}
choice_json: {'index': 0, 'delta': {'provider_specific_fields': None, 'content': ' `', 'role': None, 'function_call': None, 'tool_calls': None, 'audio': None}, 'logprobs': None}
choices in streaming: [StreamingChoices(finish_reason=None, index=0, delta=Delta(provider_specific_fields=None, content=' `', role=None, function_call=None, tool_calls=None, audio=None), logprobs=None)]
final returned processed chunk: ModelResponseStream(id='chatcmpl-1e246dec-1357-4ceb-948f-03d49e55b5f9', created=1762261907, model='claude-sonnet-4-5-20250929', object='chat.completion.chunk', system_fingerprint=None, choices=[StreamingChoices(finish_reason=None, index=0, delta=Delta(provider_specific_fields=None, content=' `', role=None, function_call=None, tool_calls=None, audio=None), logprobs=None)], provider_specific_fields=None, citations=None)
model_response finish reason 3: None; response_obj={'text': '', 'is_finished': False, 'finish_reason': '', 'usage': None, 'index': 0, 'tool_use': None}
model_response.choices[0].delta: Delta(provider_specific_fields=None, content=None, role=None, function_call=None, tool_calls=None, audio=None); completion_obj: {'content': ''}
self.sent_first_chunk: True
completion_obj: {'content': ''}, model_response.choices[0]: StreamingChoices(finish_reason=None, index=0, delta=Delta(provider_specific_fields=None, content=None, role=None, function_call=None, tool_calls=None, audio=None), logprobs=None), response_obj: {'text': '', 'is_finished': False, 'finish_reason': '', 'usage': None, 'index': 0, 'tool_use': None}
model_response finish reason 3: None; response_obj={'text': '', 'is_finished': False, 'finish_reason': '', 'usage': None, 'index': 0, 'tool_use': None}
model_response.choices[0].delta: Delta(provider_specific_fields=None, content=None, role=None, function_call=None, tool_calls=None, audio=None); completion_obj: {'content': ''}
self.sent_first_chunk: True
completion_obj: {'content': ''}, model_response.choices[0]: StreamingChoices(finish_reason=None, index=0, delta=Delta(provider_specific_fields=None, content=None, role=None, function_call=None, tool_calls=None, audio=None), logprobs=None), response_obj: {'text': '', 'is_finished': False, 'finish_reason': '', 'usage': None, 'index': 0, 'tool_use': None}

Raw OpenAI Chunk
ModelResponseStream(id='chatcmpl-1e246dec-1357-4ceb-948f-03d49e55b5f9', created=1762261916, model=None, object='chat.completion.chunk', system_fingerprint=None, choices=[StreamingChoices(finish_reason=None, index=0, delta=Delta(provider_specific_fields=None, content='ContextRetriever` into', role=None, function_call=None, tool_calls=None, audio=None), logprobs=None)], provider_specific_fields=None, usage=None)

model_response finish reason 3: None; response_obj={'text': 'ContextRetriever` into', 'is_finished': False, 'finish_reason': None, 'logprobs': None, 'original_chunk': ModelResponseStream(id='chatcmpl-1e246dec-1357-4ceb-948f-03d49e55b5f9', created=1762261916, model=None, object='chat.completion.chunk', system_fingerprint=None, choices=[StreamingChoices(finish_reason=None, index=0, delta=Delta(provider_specific_fields=None, content='ContextRetriever` into', role=None, function_call=None, tool_calls=None, audio=None), logprobs=None)], provider_specific_fields=None, usage=None), 'usage': None}
original delta: {'provider_specific_fields': None, 'content': 'ContextRetriever` into', 'role': None, 'function_call': None, 'tool_calls': None, 'audio': None}
new delta: Delta(provider_specific_fields=None, content='ContextRetriever` into', role=None, function_call=None, tool_calls=None, audio=None)
model_response.choices[0].delta: Delta(provider_specific_fields=None, content='ContextRetriever` into', role=None, function_call=None, tool_calls=None, audio=None); completion_obj: {'content': 'ContextRetriever` into'}
self.sent_first_chunk: True
completion_obj: {'content': 'ContextRetriever` into'}, model_response.choices[0]: StreamingChoices(finish_reason=None, index=0, delta=Delta(provider_specific_fields=None, content='ContextRetriever` into', role=None, function_call=None, tool_calls=None, audio=None), logprobs=None), response_obj: {'text': 'ContextRetriever` into', 'is_finished': False, 'finish_reason': None, 'logprobs': None, 'original_chunk': ModelResponseStream(id='chatcmpl-1e246dec-1357-4ceb-948f-03d49e55b5f9', created=1762261916, model=None, object='chat.completion.chunk', system_fingerprint=None, choices=[StreamingChoices(finish_reason=None, index=0, delta=Delta(provider_specific_fields=None, content='ContextRetriever` into', role=None, function_call=None, tool_calls=None, audio=None), logprobs=None)], provider_specific_fields=None, usage=None), 'usage': None}
choice_json: {'index': 0, 'delta': {'provider_specific_fields': None, 'content': 'ContextRetriever` into', 'role': None, 'function_call': None, 'tool_calls': None, 'audio': None}, 'logprobs': None}
choices in streaming: [StreamingChoices(finish_reason=None, index=0, delta=Delta(provider_specific_fields=None, content='ContextRetriever` into', role=None, function_call=None, tool_calls=None, audio=None), logprobs=None)]
final returned processed chunk: ModelResponseStream(id='chatcmpl-1e246dec-1357-4ceb-948f-03d49e55b5f9', created=1762261907, model='claude-sonnet-4-5-20250929', object='chat.completion.chunk', system_fingerprint=None, choices=[StreamingChoices(finish_reason=None, index=0, delta=Delta(provider_specific_fields=None, content='ContextRetriever` into', role=None, function_call=None, tool_calls=None, audio=None), logprobs=None)], provider_specific_fields=None, citations=None)
model_response finish reason 3: None; response_obj={'text': '', 'is_finished': False, 'finish_reason': '', 'usage': None, 'index': 0, 'tool_use': None}
model_response.choices[0].delta: Delta(provider_specific_fields=None, content=None, role=None, function_call=None, tool_calls=None, audio=None); completion_obj: {'content': ''}
self.sent_first_chunk: True
completion_obj: {'content': ''}, model_response.choices[0]: StreamingChoices(finish_reason=None, index=0, delta=Delta(provider_specific_fields=None, content=None, role=None, function_call=None, tool_calls=None, audio=None), logprobs=None), response_obj: {'text': '', 'is_finished': False, 'finish_reason': '', 'usage': None, 'index': 0, 'tool_use': None}
model_response finish reason 3: None; response_obj={'text': '', 'is_finished': False, 'finish_reason': '', 'usage': None, 'index': 0, 'tool_use': None}
model_response.choices[0].delta: Delta(provider_specific_fields=None, content=None, role=None, function_call=None, tool_calls=None, audio=None); completion_obj: {'content': ''}
self.sent_first_chunk: True
completion_obj: {'content': ''}, model_response.choices[0]: StreamingChoices(finish_reason=None, index=0, delta=Delta(provider_specific_fields=None, content=None, role=None, function_call=None, tool_calls=None, audio=None), logprobs=None), response_obj: {'text': '', 'is_finished': False, 'finish_reason': '', 'usage': None, 'index': 0, 'tool_use': None}

Raw OpenAI Chunk
ModelResponseStream(id='chatcmpl-1e246dec-1357-4ceb-948f-03d49e55b5f9', created=1762261916, model=None, object='chat.completion.chunk', system_fingerprint=None, choices=[StreamingChoices(finish_reason=None, index=0, delta=Delta(provider_specific_fields=None, content=' your proxy', role=None, function_call=None, tool_calls=None, audio=None), logprobs=None)], provider_specific_fields=None, usage=None)

model_response finish reason 3: None; response_obj={'text': ' your proxy', 'is_finished': False, 'finish_reason': None, 'logprobs': None, 'original_chunk': ModelResponseStream(id='chatcmpl-1e246dec-1357-4ceb-948f-03d49e55b5f9', created=1762261916, model=None, object='chat.completion.chunk', system_fingerprint=None, choices=[StreamingChoices(finish_reason=None, index=0, delta=Delta(provider_specific_fields=None, content=' your proxy', role=None, function_call=None, tool_calls=None, audio=None), logprobs=None)], provider_specific_fields=None, usage=None), 'usage': None}
original delta: {'provider_specific_fields': None, 'content': ' your proxy', 'role': None, 'function_call': None, 'tool_calls': None, 'audio': None}
new delta: Delta(provider_specific_fields=None, content=' your proxy', role=None, function_call=None, tool_calls=None, audio=None)
model_response.choices[0].delta: Delta(provider_specific_fields=None, content=' your proxy', role=None, function_call=None, tool_calls=None, audio=None); completion_obj: {'content': ' your proxy'}
self.sent_first_chunk: True
completion_obj: {'content': ' your proxy'}, model_response.choices[0]: StreamingChoices(finish_reason=None, index=0, delta=Delta(provider_specific_fields=None, content=' your proxy', role=None, function_call=None, tool_calls=None, audio=None), logprobs=None), response_obj: {'text': ' your proxy', 'is_finished': False, 'finish_reason': None, 'logprobs': None, 'original_chunk': ModelResponseStream(id='chatcmpl-1e246dec-1357-4ceb-948f-03d49e55b5f9', created=1762261916, model=None, object='chat.completion.chunk', system_fingerprint=None, choices=[StreamingChoices(finish_reason=None, index=0, delta=Delta(provider_specific_fields=None, content=' your proxy', role=None, function_call=None, tool_calls=None, audio=None), logprobs=None)], provider_specific_fields=None, usage=None), 'usage': None}
choice_json: {'index': 0, 'delta': {'provider_specific_fields': None, 'content': ' your proxy', 'role': None, 'function_call': None, 'tool_calls': None, 'audio': None}, 'logprobs': None}
choices in streaming: [StreamingChoices(finish_reason=None, index=0, delta=Delta(provider_specific_fields=None, content=' your proxy', role=None, function_call=None, tool_calls=None, audio=None), logprobs=None)]
final returned processed chunk: ModelResponseStream(id='chatcmpl-1e246dec-1357-4ceb-948f-03d49e55b5f9', created=1762261907, model='claude-sonnet-4-5-20250929', object='chat.completion.chunk', system_fingerprint=None, choices=[StreamingChoices(finish_reason=None, index=0, delta=Delta(provider_specific_fields=None, content=' your proxy', role=None, function_call=None, tool_calls=None, audio=None), logprobs=None)], provider_specific_fields=None, citations=None)
model_response finish reason 3: None; response_obj={'text': '', 'is_finished': False, 'finish_reason': '', 'usage': None, 'index': 0, 'tool_use': None}
model_response.choices[0].delta: Delta(provider_specific_fields=None, content=None, role=None, function_call=None, tool_calls=None, audio=None); completion_obj: {'content': ''}
self.sent_first_chunk: True
completion_obj: {'content': ''}, model_response.choices[0]: StreamingChoices(finish_reason=None, index=0, delta=Delta(provider_specific_fields=None, content=None, role=None, function_call=None, tool_calls=None, audio=None), logprobs=None), response_obj: {'text': '', 'is_finished': False, 'finish_reason': '', 'usage': None, 'index': 0, 'tool_use': None}
model_response finish reason 3: None; response_obj={'text': '', 'is_finished': False, 'finish_reason': '', 'usage': None, 'index': 0, 'tool_use': None}
model_response.choices[0].delta: Delta(provider_specific_fields=None, content=None, role=None, function_call=None, tool_calls=None, audio=None); completion_obj: {'content': ''}
self.sent_first_chunk: True
completion_obj: {'content': ''}, model_response.choices[0]: StreamingChoices(finish_reason=None, index=0, delta=Delta(provider_specific_fields=None, content=None, role=None, function_call=None, tool_calls=None, audio=None), logprobs=None), response_obj: {'text': '', 'is_finished': False, 'finish_reason': '', 'usage': None, 'index': 0, 'tool_use': None}

Raw OpenAI Chunk
ModelResponseStream(id='chatcmpl-1e246dec-1357-4ceb-948f-03d49e55b5f9', created=1762261916, model=None, object='chat.completion.chunk', system_fingerprint=None, choices=[StreamingChoices(finish_reason=None, index=0, delta=Delta(provider_specific_fields=None, content=', **', role=None, function_call=None, tool_calls=None, audio=None), logprobs=None)], provider_specific_fields=None, usage=None)

model_response finish reason 3: None; response_obj={'text': ', **', 'is_finished': False, 'finish_reason': None, 'logprobs': None, 'original_chunk': ModelResponseStream(id='chatcmpl-1e246dec-1357-4ceb-948f-03d49e55b5f9', created=1762261916, model=None, object='chat.completion.chunk', system_fingerprint=None, choices=[StreamingChoices(finish_reason=None, index=0, delta=Delta(provider_specific_fields=None, content=', **', role=None, function_call=None, tool_calls=None, audio=None), logprobs=None)], provider_specific_fields=None, usage=None), 'usage': None}
original delta: {'provider_specific_fields': None, 'content': ', **', 'role': None, 'function_call': None, 'tool_calls': None, 'audio': None}
new delta: Delta(provider_specific_fields=None, content=', **', role=None, function_call=None, tool_calls=None, audio=None)
model_response.choices[0].delta: Delta(provider_specific_fields=None, content=', **', role=None, function_call=None, tool_calls=None, audio=None); completion_obj: {'content': ', **'}
self.sent_first_chunk: True
completion_obj: {'content': ', **'}, model_response.choices[0]: StreamingChoices(finish_reason=None, index=0, delta=Delta(provider_specific_fields=None, content=', **', role=None, function_call=None, tool_calls=None, audio=None), logprobs=None), response_obj: {'text': ', **', 'is_finished': False, 'finish_reason': None, 'logprobs': None, 'original_chunk': ModelResponseStream(id='chatcmpl-1e246dec-1357-4ceb-948f-03d49e55b5f9', created=1762261916, model=None, object='chat.completion.chunk', system_fingerprint=None, choices=[StreamingChoices(finish_reason=None, index=0, delta=Delta(provider_specific_fields=None, content=', **', role=None, function_call=None, tool_calls=None, audio=None), logprobs=None)], provider_specific_fields=None, usage=None), 'usage': None}
choice_json: {'index': 0, 'delta': {'provider_specific_fields': None, 'content': ', **', 'role': None, 'function_call': None, 'tool_calls': None, 'audio': None}, 'logprobs': None}
choices in streaming: [StreamingChoices(finish_reason=None, index=0, delta=Delta(provider_specific_fields=None, content=', **', role=None, function_call=None, tool_calls=None, audio=None), logprobs=None)]
final returned processed chunk: ModelResponseStream(id='chatcmpl-1e246dec-1357-4ceb-948f-03d49e55b5f9', created=1762261907, model='claude-sonnet-4-5-20250929', object='chat.completion.chunk', system_fingerprint=None, choices=[StreamingChoices(finish_reason=None, index=0, delta=Delta(provider_specific_fields=None, content=', **', role=None, function_call=None, tool_calls=None, audio=None), logprobs=None)], provider_specific_fields=None, citations=None)
model_response finish reason 3: None; response_obj={'text': '', 'is_finished': False, 'finish_reason': '', 'usage': None, 'index': 0, 'tool_use': None}
model_response.choices[0].delta: Delta(provider_specific_fields=None, content=None, role=None, function_call=None, tool_calls=None, audio=None); completion_obj: {'content': ''}
self.sent_first_chunk: True
completion_obj: {'content': ''}, model_response.choices[0]: StreamingChoices(finish_reason=None, index=0, delta=Delta(provider_specific_fields=None, content=None, role=None, function_call=None, tool_calls=None, audio=None), logprobs=None), response_obj: {'text': '', 'is_finished': False, 'finish_reason': '', 'usage': None, 'index': 0, 'tool_use': None}
model_response finish reason 3: None; response_obj={'text': '', 'is_finished': False, 'finish_reason': '', 'usage': None, 'index': 0, 'tool_use': None}
model_response.choices[0].delta: Delta(provider_specific_fields=None, content=None, role=None, function_call=None, tool_calls=None, audio=None); completion_obj: {'content': ''}
self.sent_first_chunk: True
completion_obj: {'content': ''}, model_response.choices[0]: StreamingChoices(finish_reason=None, index=0, delta=Delta(provider_specific_fields=None, content=None, role=None, function_call=None, tool_calls=None, audio=None), logprobs=None), response_obj: {'text': '', 'is_finished': False, 'finish_reason': '', 'usage': None, 'index': 0, 'tool_use': None}

Raw OpenAI Chunk
ModelResponseStream(id='chatcmpl-1e246dec-1357-4ceb-948f-03d49e55b5f9', created=1762261916, model=None, object='chat.completion.chunk', system_fingerprint=None, choices=[StreamingChoices(finish_reason=None, index=0, delta=Delta(provider_specific_fields=None, content='Supermemory will remember', role=None, function_call=None, tool_calls=None, audio=None), logprobs=None)], provider_specific_fields=None, usage=None)

model_response finish reason 3: None; response_obj={'text': 'Supermemory will remember', 'is_finished': False, 'finish_reason': None, 'logprobs': None, 'original_chunk': ModelResponseStream(id='chatcmpl-1e246dec-1357-4ceb-948f-03d49e55b5f9', created=1762261916, model=None, object='chat.completion.chunk', system_fingerprint=None, choices=[StreamingChoices(finish_reason=None, index=0, delta=Delta(provider_specific_fields=None, content='Supermemory will remember', role=None, function_call=None, tool_calls=None, audio=None), logprobs=None)], provider_specific_fields=None, usage=None), 'usage': None}
original delta: {'provider_specific_fields': None, 'content': 'Supermemory will remember', 'role': None, 'function_call': None, 'tool_calls': None, 'audio': None}
new delta: Delta(provider_specific_fields=None, content='Supermemory will remember', role=None, function_call=None, tool_calls=None, audio=None)
model_response.choices[0].delta: Delta(provider_specific_fields=None, content='Supermemory will remember', role=None, function_call=None, tool_calls=None, audio=None); completion_obj: {'content': 'Supermemory will remember'}
self.sent_first_chunk: True
completion_obj: {'content': 'Supermemory will remember'}, model_response.choices[0]: StreamingChoices(finish_reason=None, index=0, delta=Delta(provider_specific_fields=None, content='Supermemory will remember', role=None, function_call=None, tool_calls=None, audio=None), logprobs=None), response_obj: {'text': 'Supermemory will remember', 'is_finished': False, 'finish_reason': None, 'logprobs': None, 'original_chunk': ModelResponseStream(id='chatcmpl-1e246dec-1357-4ceb-948f-03d49e55b5f9', created=1762261916, model=None, object='chat.completion.chunk', system_fingerprint=None, choices=[StreamingChoices(finish_reason=None, index=0, delta=Delta(provider_specific_fields=None, content='Supermemory will remember', role=None, function_call=None, tool_calls=None, audio=None), logprobs=None)], provider_specific_fields=None, usage=None), 'usage': None}
choice_json: {'index': 0, 'delta': {'provider_specific_fields': None, 'content': 'Supermemory will remember', 'role': None, 'function_call': None, 'tool_calls': None, 'audio': None}, 'logprobs': None}
choices in streaming: [StreamingChoices(finish_reason=None, index=0, delta=Delta(provider_specific_fields=None, content='Supermemory will remember', role=None, function_call=None, tool_calls=None, audio=None), logprobs=None)]
final returned processed chunk: ModelResponseStream(id='chatcmpl-1e246dec-1357-4ceb-948f-03d49e55b5f9', created=1762261907, model='claude-sonnet-4-5-20250929', object='chat.completion.chunk', system_fingerprint=None, choices=[StreamingChoices(finish_reason=None, index=0, delta=Delta(provider_specific_fields=None, content='Supermemory will remember', role=None, function_call=None, tool_calls=None, audio=None), logprobs=None)], provider_specific_fields=None, citations=None)
model_response finish reason 3: None; response_obj={'text': '', 'is_finished': False, 'finish_reason': '', 'usage': None, 'index': 0, 'tool_use': None}
model_response.choices[0].delta: Delta(provider_specific_fields=None, content=None, role=None, function_call=None, tool_calls=None, audio=None); completion_obj: {'content': ''}
self.sent_first_chunk: True
completion_obj: {'content': ''}, model_response.choices[0]: StreamingChoices(finish_reason=None, index=0, delta=Delta(provider_specific_fields=None, content=None, role=None, function_call=None, tool_calls=None, audio=None), logprobs=None), response_obj: {'text': '', 'is_finished': False, 'finish_reason': '', 'usage': None, 'index': 0, 'tool_use': None}
model_response finish reason 3: None; response_obj={'text': '', 'is_finished': False, 'finish_reason': '', 'usage': None, 'index': 0, 'tool_use': None}
model_response.choices[0].delta: Delta(provider_specific_fields=None, content=None, role=None, function_call=None, tool_calls=None, audio=None); completion_obj: {'content': ''}
self.sent_first_chunk: True
completion_obj: {'content': ''}, model_response.choices[0]: StreamingChoices(finish_reason=None, index=0, delta=Delta(provider_specific_fields=None, content=None, role=None, function_call=None, tool_calls=None, audio=None), logprobs=None), response_obj: {'text': '', 'is_finished': False, 'finish_reason': '', 'usage': None, 'index': 0, 'tool_use': None}

Raw OpenAI Chunk
ModelResponseStream(id='chatcmpl-1e246dec-1357-4ceb-948f-03d49e55b5f9', created=1762261916, model=None, object='chat.completion.chunk', system_fingerprint=None, choices=[StreamingChoices(finish_reason=None, index=0, delta=Delta(provider_specific_fields=None, content=' your conversations', role=None, function_call=None, tool_calls=None, audio=None), logprobs=None)], provider_specific_fields=None, usage=None)

model_response finish reason 3: None; response_obj={'text': ' your conversations', 'is_finished': False, 'finish_reason': None, 'logprobs': None, 'original_chunk': ModelResponseStream(id='chatcmpl-1e246dec-1357-4ceb-948f-03d49e55b5f9', created=1762261916, model=None, object='chat.completion.chunk', system_fingerprint=None, choices=[StreamingChoices(finish_reason=None, index=0, delta=Delta(provider_specific_fields=None, content=' your conversations', role=None, function_call=None, tool_calls=None, audio=None), logprobs=None)], provider_specific_fields=None, usage=None), 'usage': None}
original delta: {'provider_specific_fields': None, 'content': ' your conversations', 'role': None, 'function_call': None, 'tool_calls': None, 'audio': None}
new delta: Delta(provider_specific_fields=None, content=' your conversations', role=None, function_call=None, tool_calls=None, audio=None)
model_response.choices[0].delta: Delta(provider_specific_fields=None, content=' your conversations', role=None, function_call=None, tool_calls=None, audio=None); completion_obj: {'content': ' your conversations'}
self.sent_first_chunk: True
completion_obj: {'content': ' your conversations'}, model_response.choices[0]: StreamingChoices(finish_reason=None, index=0, delta=Delta(provider_specific_fields=None, content=' your conversations', role=None, function_call=None, tool_calls=None, audio=None), logprobs=None), response_obj: {'text': ' your conversations', 'is_finished': False, 'finish_reason': None, 'logprobs': None, 'original_chunk': ModelResponseStream(id='chatcmpl-1e246dec-1357-4ceb-948f-03d49e55b5f9', created=1762261916, model=None, object='chat.completion.chunk', system_fingerprint=None, choices=[StreamingChoices(finish_reason=None, index=0, delta=Delta(provider_specific_fields=None, content=' your conversations', role=None, function_call=None, tool_calls=None, audio=None), logprobs=None)], provider_specific_fields=None, usage=None), 'usage': None}
choice_json: {'index': 0, 'delta': {'provider_specific_fields': None, 'content': ' your conversations', 'role': None, 'function_call': None, 'tool_calls': None, 'audio': None}, 'logprobs': None}
choices in streaming: [StreamingChoices(finish_reason=None, index=0, delta=Delta(provider_specific_fields=None, content=' your conversations', role=None, function_call=None, tool_calls=None, audio=None), logprobs=None)]
final returned processed chunk: ModelResponseStream(id='chatcmpl-1e246dec-1357-4ceb-948f-03d49e55b5f9', created=1762261907, model='claude-sonnet-4-5-20250929', object='chat.completion.chunk', system_fingerprint=None, choices=[StreamingChoices(finish_reason=None, index=0, delta=Delta(provider_specific_fields=None, content=' your conversations', role=None, function_call=None, tool_calls=None, audio=None), logprobs=None)], provider_specific_fields=None, citations=None)
model_response finish reason 3: None; response_obj={'text': '', 'is_finished': False, 'finish_reason': '', 'usage': None, 'index': 0, 'tool_use': None}
model_response.choices[0].delta: Delta(provider_specific_fields=None, content=None, role=None, function_call=None, tool_calls=None, audio=None); completion_obj: {'content': ''}
self.sent_first_chunk: True
completion_obj: {'content': ''}, model_response.choices[0]: StreamingChoices(finish_reason=None, index=0, delta=Delta(provider_specific_fields=None, content=None, role=None, function_call=None, tool_calls=None, audio=None), logprobs=None), response_obj: {'text': '', 'is_finished': False, 'finish_reason': '', 'usage': None, 'index': 0, 'tool_use': None}
model_response finish reason 3: None; response_obj={'text': '', 'is_finished': False, 'finish_reason': '', 'usage': None, 'index': 0, 'tool_use': None}
model_response.choices[0].delta: Delta(provider_specific_fields=None, content=None, role=None, function_call=None, tool_calls=None, audio=None); completion_obj: {'content': ''}
self.sent_first_chunk: True
completion_obj: {'content': ''}, model_response.choices[0]: StreamingChoices(finish_reason=None, index=0, delta=Delta(provider_specific_fields=None, content=None, role=None, function_call=None, tool_calls=None, audio=None), logprobs=None), response_obj: {'text': '', 'is_finished': False, 'finish_reason': '', 'usage': None, 'index': 0, 'tool_use': None}

Raw OpenAI Chunk
ModelResponseStream(id='chatcmpl-1e246dec-1357-4ceb-948f-03d49e55b5f9', created=1762261916, model=None, object='chat.completion.chunk', system_fingerprint=None, choices=[StreamingChoices(finish_reason=None, index=0, delta=Delta(provider_specific_fields=None, content='**', role=None, function_call=None, tool_calls=None, audio=None), logprobs=None)], provider_specific_fields=None, usage=None)

model_response finish reason 3: None; response_obj={'text': '**', 'is_finished': False, 'finish_reason': None, 'logprobs': None, 'original_chunk': ModelResponseStream(id='chatcmpl-1e246dec-1357-4ceb-948f-03d49e55b5f9', created=1762261916, model=None, object='chat.completion.chunk', system_fingerprint=None, choices=[StreamingChoices(finish_reason=None, index=0, delta=Delta(provider_specific_fields=None, content='**', role=None, function_call=None, tool_calls=None, audio=None), logprobs=None)], provider_specific_fields=None, usage=None), 'usage': None}
original delta: {'provider_specific_fields': None, 'content': '**', 'role': None, 'function_call': None, 'tool_calls': None, 'audio': None}
new delta: Delta(provider_specific_fields=None, content='**', role=None, function_call=None, tool_calls=None, audio=None)
model_response.choices[0].delta: Delta(provider_specific_fields=None, content='**', role=None, function_call=None, tool_calls=None, audio=None); completion_obj: {'content': '**'}
self.sent_first_chunk: True
completion_obj: {'content': '**'}, model_response.choices[0]: StreamingChoices(finish_reason=None, index=0, delta=Delta(provider_specific_fields=None, content='**', role=None, function_call=None, tool_calls=None, audio=None), logprobs=None), response_obj: {'text': '**', 'is_finished': False, 'finish_reason': None, 'logprobs': None, 'original_chunk': ModelResponseStream(id='chatcmpl-1e246dec-1357-4ceb-948f-03d49e55b5f9', created=1762261916, model=None, object='chat.completion.chunk', system_fingerprint=None, choices=[StreamingChoices(finish_reason=None, index=0, delta=Delta(provider_specific_fields=None, content='**', role=None, function_call=None, tool_calls=None, audio=None), logprobs=None)], provider_specific_fields=None, usage=None), 'usage': None}
choice_json: {'index': 0, 'delta': {'provider_specific_fields': None, 'content': '**', 'role': None, 'function_call': None, 'tool_calls': None, 'audio': None}, 'logprobs': None}
choices in streaming: [StreamingChoices(finish_reason=None, index=0, delta=Delta(provider_specific_fields=None, content='**', role=None, function_call=None, tool_calls=None, audio=None), logprobs=None)]
final returned processed chunk: ModelResponseStream(id='chatcmpl-1e246dec-1357-4ceb-948f-03d49e55b5f9', created=1762261907, model='claude-sonnet-4-5-20250929', object='chat.completion.chunk', system_fingerprint=None, choices=[StreamingChoices(finish_reason=None, index=0, delta=Delta(provider_specific_fields=None, content='**', role=None, function_call=None, tool_calls=None, audio=None), logprobs=None)], provider_specific_fields=None, citations=None)
model_response finish reason 3: None; response_obj={'text': '', 'is_finished': False, 'finish_reason': '', 'usage': None, 'index': 0, 'tool_use': None}
model_response.choices[0].delta: Delta(provider_specific_fields=None, content=None, role=None, function_call=None, tool_calls=None, audio=None); completion_obj: {'content': ''}
self.sent_first_chunk: True
completion_obj: {'content': ''}, model_response.choices[0]: StreamingChoices(finish_reason=None, index=0, delta=Delta(provider_specific_fields=None, content=None, role=None, function_call=None, tool_calls=None, audio=None), logprobs=None), response_obj: {'text': '', 'is_finished': False, 'finish_reason': '', 'usage': None, 'index': 0, 'tool_use': None}
model_response finish reason 3: None; response_obj={'text': '', 'is_finished': False, 'finish_reason': '', 'usage': None, 'index': 0, 'tool_use': None}
model_response.choices[0].delta: Delta(provider_specific_fields=None, content=None, role=None, function_call=None, tool_calls=None, audio=None); completion_obj: {'content': ''}
self.sent_first_chunk: True
completion_obj: {'content': ''}, model_response.choices[0]: StreamingChoices(finish_reason=None, index=0, delta=Delta(provider_specific_fields=None, content=None, role=None, function_call=None, tool_calls=None, audio=None), logprobs=None), response_obj: {'text': '', 'is_finished': False, 'finish_reason': '', 'usage': None, 'index': 0, 'tool_use': None}

Raw OpenAI Chunk
ModelResponseStream(id='chatcmpl-1e246dec-1357-4ceb-948f-03d49e55b5f9', created=1762261917, model=None, object='chat.completion.chunk', system_fingerprint=None, choices=[StreamingChoices(finish_reason=None, index=0, delta=Delta(provider_specific_fields=None, content=' and provide', role=None, function_call=None, tool_calls=None, audio=None), logprobs=None)], provider_specific_fields=None, usage=None)

model_response finish reason 3: None; response_obj={'text': ' and provide', 'is_finished': False, 'finish_reason': None, 'logprobs': None, 'original_chunk': ModelResponseStream(id='chatcmpl-1e246dec-1357-4ceb-948f-03d49e55b5f9', created=1762261917, model=None, object='chat.completion.chunk', system_fingerprint=None, choices=[StreamingChoices(finish_reason=None, index=0, delta=Delta(provider_specific_fields=None, content=' and provide', role=None, function_call=None, tool_calls=None, audio=None), logprobs=None)], provider_specific_fields=None, usage=None), 'usage': None}
original delta: {'provider_specific_fields': None, 'content': ' and provide', 'role': None, 'function_call': None, 'tool_calls': None, 'audio': None}
new delta: Delta(provider_specific_fields=None, content=' and provide', role=None, function_call=None, tool_calls=None, audio=None)
model_response.choices[0].delta: Delta(provider_specific_fields=None, content=' and provide', role=None, function_call=None, tool_calls=None, audio=None); completion_obj: {'content': ' and provide'}
self.sent_first_chunk: True
completion_obj: {'content': ' and provide'}, model_response.choices[0]: StreamingChoices(finish_reason=None, index=0, delta=Delta(provider_specific_fields=None, content=' and provide', role=None, function_call=None, tool_calls=None, audio=None), logprobs=None), response_obj: {'text': ' and provide', 'is_finished': False, 'finish_reason': None, 'logprobs': None, 'original_chunk': ModelResponseStream(id='chatcmpl-1e246dec-1357-4ceb-948f-03d49e55b5f9', created=1762261917, model=None, object='chat.completion.chunk', system_fingerprint=None, choices=[StreamingChoices(finish_reason=None, index=0, delta=Delta(provider_specific_fields=None, content=' and provide', role=None, function_call=None, tool_calls=None, audio=None), logprobs=None)], provider_specific_fields=None, usage=None), 'usage': None}
choice_json: {'index': 0, 'delta': {'provider_specific_fields': None, 'content': ' and provide', 'role': None, 'function_call': None, 'tool_calls': None, 'audio': None}, 'logprobs': None}
choices in streaming: [StreamingChoices(finish_reason=None, index=0, delta=Delta(provider_specific_fields=None, content=' and provide', role=None, function_call=None, tool_calls=None, audio=None), logprobs=None)]
final returned processed chunk: ModelResponseStream(id='chatcmpl-1e246dec-1357-4ceb-948f-03d49e55b5f9', created=1762261907, model='claude-sonnet-4-5-20250929', object='chat.completion.chunk', system_fingerprint=None, choices=[StreamingChoices(finish_reason=None, index=0, delta=Delta(provider_specific_fields=None, content=' and provide', role=None, function_call=None, tool_calls=None, audio=None), logprobs=None)], provider_specific_fields=None, citations=None)
model_response finish reason 3: None; response_obj={'text': '', 'is_finished': False, 'finish_reason': '', 'usage': None, 'index': 0, 'tool_use': None}
model_response.choices[0].delta: Delta(provider_specific_fields=None, content=None, role=None, function_call=None, tool_calls=None, audio=None); completion_obj: {'content': ''}
self.sent_first_chunk: True
completion_obj: {'content': ''}, model_response.choices[0]: StreamingChoices(finish_reason=None, index=0, delta=Delta(provider_specific_fields=None, content=None, role=None, function_call=None, tool_calls=None, audio=None), logprobs=None), response_obj: {'text': '', 'is_finished': False, 'finish_reason': '', 'usage': None, 'index': 0, 'tool_use': None}
model_response finish reason 3: None; response_obj={'text': '', 'is_finished': False, 'finish_reason': '', 'usage': None, 'index': 0, 'tool_use': None}
model_response.choices[0].delta: Delta(provider_specific_fields=None, content=None, role=None, function_call=None, tool_calls=None, audio=None); completion_obj: {'content': ''}
self.sent_first_chunk: True
completion_obj: {'content': ''}, model_response.choices[0]: StreamingChoices(finish_reason=None, index=0, delta=Delta(provider_specific_fields=None, content=None, role=None, function_call=None, tool_calls=None, audio=None), logprobs=None), response_obj: {'text': '', 'is_finished': False, 'finish_reason': '', 'usage': None, 'index': 0, 'tool_use': None}

Raw OpenAI Chunk
ModelResponseStream(id='chatcmpl-1e246dec-1357-4ceb-948f-03d49e55b5f9', created=1762261917, model=None, object='chat.completion.chunk', system_fingerprint=None, choices=[StreamingChoices(finish_reason=None, index=0, delta=Delta(provider_specific_fields=None, content=' relevant', role=None, function_call=None, tool_calls=None, audio=None), logprobs=None)], provider_specific_fields=None, usage=None)

model_response finish reason 3: None; response_obj={'text': ' relevant', 'is_finished': False, 'finish_reason': None, 'logprobs': None, 'original_chunk': ModelResponseStream(id='chatcmpl-1e246dec-1357-4ceb-948f-03d49e55b5f9', created=1762261917, model=None, object='chat.completion.chunk', system_fingerprint=None, choices=[StreamingChoices(finish_reason=None, index=0, delta=Delta(provider_specific_fields=None, content=' relevant', role=None, function_call=None, tool_calls=None, audio=None), logprobs=None)], provider_specific_fields=None, usage=None), 'usage': None}
original delta: {'provider_specific_fields': None, 'content': ' relevant', 'role': None, 'function_call': None, 'tool_calls': None, 'audio': None}
new delta: Delta(provider_specific_fields=None, content=' relevant', role=None, function_call=None, tool_calls=None, audio=None)
model_response.choices[0].delta: Delta(provider_specific_fields=None, content=' relevant', role=None, function_call=None, tool_calls=None, audio=None); completion_obj: {'content': ' relevant'}
self.sent_first_chunk: True
completion_obj: {'content': ' relevant'}, model_response.choices[0]: StreamingChoices(finish_reason=None, index=0, delta=Delta(provider_specific_fields=None, content=' relevant', role=None, function_call=None, tool_calls=None, audio=None), logprobs=None), response_obj: {'text': ' relevant', 'is_finished': False, 'finish_reason': None, 'logprobs': None, 'original_chunk': ModelResponseStream(id='chatcmpl-1e246dec-1357-4ceb-948f-03d49e55b5f9', created=1762261917, model=None, object='chat.completion.chunk', system_fingerprint=None, choices=[StreamingChoices(finish_reason=None, index=0, delta=Delta(provider_specific_fields=None, content=' relevant', role=None, function_call=None, tool_calls=None, audio=None), logprobs=None)], provider_specific_fields=None, usage=None), 'usage': None}
choice_json: {'index': 0, 'delta': {'provider_specific_fields': None, 'content': ' relevant', 'role': None, 'function_call': None, 'tool_calls': None, 'audio': None}, 'logprobs': None}
choices in streaming: [StreamingChoices(finish_reason=None, index=0, delta=Delta(provider_specific_fields=None, content=' relevant', role=None, function_call=None, tool_calls=None, audio=None), logprobs=None)]
final returned processed chunk: ModelResponseStream(id='chatcmpl-1e246dec-1357-4ceb-948f-03d49e55b5f9', created=1762261907, model='claude-sonnet-4-5-20250929', object='chat.completion.chunk', system_fingerprint=None, choices=[StreamingChoices(finish_reason=None, index=0, delta=Delta(provider_specific_fields=None, content=' relevant', role=None, function_call=None, tool_calls=None, audio=None), logprobs=None)], provider_specific_fields=None, citations=None)
model_response finish reason 3: None; response_obj={'text': '', 'is_finished': False, 'finish_reason': '', 'usage': None, 'index': 0, 'tool_use': None}
model_response.choices[0].delta: Delta(provider_specific_fields=None, content=None, role=None, function_call=None, tool_calls=None, audio=None); completion_obj: {'content': ''}
self.sent_first_chunk: True
completion_obj: {'content': ''}, model_response.choices[0]: StreamingChoices(finish_reason=None, index=0, delta=Delta(provider_specific_fields=None, content=None, role=None, function_call=None, tool_calls=None, audio=None), logprobs=None), response_obj: {'text': '', 'is_finished': False, 'finish_reason': '', 'usage': None, 'index': 0, 'tool_use': None}
model_response finish reason 3: None; response_obj={'text': '', 'is_finished': False, 'finish_reason': '', 'usage': None, 'index': 0, 'tool_use': None}
model_response.choices[0].delta: Delta(provider_specific_fields=None, content=None, role=None, function_call=None, tool_calls=None, audio=None); completion_obj: {'content': ''}
self.sent_first_chunk: True
completion_obj: {'content': ''}, model_response.choices[0]: StreamingChoices(finish_reason=None, index=0, delta=Delta(provider_specific_fields=None, content=None, role=None, function_call=None, tool_calls=None, audio=None), logprobs=None), response_obj: {'text': '', 'is_finished': False, 'finish_reason': '', 'usage': None, 'index': 0, 'tool_use': None}

Raw OpenAI Chunk
ModelResponseStream(id='chatcmpl-1e246dec-1357-4ceb-948f-03d49e55b5f9', created=1762261917, model=None, object='chat.completion.chunk', system_fingerprint=None, choices=[StreamingChoices(finish_reason=None, index=0, delta=Delta(provider_specific_fields=None, content=' context automatically', role=None, function_call=None, tool_calls=None, audio=None), logprobs=None)], provider_specific_fields=None, usage=None)

model_response finish reason 3: None; response_obj={'text': ' context automatically', 'is_finished': False, 'finish_reason': None, 'logprobs': None, 'original_chunk': ModelResponseStream(id='chatcmpl-1e246dec-1357-4ceb-948f-03d49e55b5f9', created=1762261917, model=None, object='chat.completion.chunk', system_fingerprint=None, choices=[StreamingChoices(finish_reason=None, index=0, delta=Delta(provider_specific_fields=None, content=' context automatically', role=None, function_call=None, tool_calls=None, audio=None), logprobs=None)], provider_specific_fields=None, usage=None), 'usage': None}
original delta: {'provider_specific_fields': None, 'content': ' context automatically', 'role': None, 'function_call': None, 'tool_calls': None, 'audio': None}
new delta: Delta(provider_specific_fields=None, content=' context automatically', role=None, function_call=None, tool_calls=None, audio=None)
model_response.choices[0].delta: Delta(provider_specific_fields=None, content=' context automatically', role=None, function_call=None, tool_calls=None, audio=None); completion_obj: {'content': ' context automatically'}
self.sent_first_chunk: True
completion_obj: {'content': ' context automatically'}, model_response.choices[0]: StreamingChoices(finish_reason=None, index=0, delta=Delta(provider_specific_fields=None, content=' context automatically', role=None, function_call=None, tool_calls=None, audio=None), logprobs=None), response_obj: {'text': ' context automatically', 'is_finished': False, 'finish_reason': None, 'logprobs': None, 'original_chunk': ModelResponseStream(id='chatcmpl-1e246dec-1357-4ceb-948f-03d49e55b5f9', created=1762261917, model=None, object='chat.completion.chunk', system_fingerprint=None, choices=[StreamingChoices(finish_reason=None, index=0, delta=Delta(provider_specific_fields=None, content=' context automatically', role=None, function_call=None, tool_calls=None, audio=None), logprobs=None)], provider_specific_fields=None, usage=None), 'usage': None}
choice_json: {'index': 0, 'delta': {'provider_specific_fields': None, 'content': ' context automatically', 'role': None, 'function_call': None, 'tool_calls': None, 'audio': None}, 'logprobs': None}
choices in streaming: [StreamingChoices(finish_reason=None, index=0, delta=Delta(provider_specific_fields=None, content=' context automatically', role=None, function_call=None, tool_calls=None, audio=None), logprobs=None)]
final returned processed chunk: ModelResponseStream(id='chatcmpl-1e246dec-1357-4ceb-948f-03d49e55b5f9', created=1762261907, model='claude-sonnet-4-5-20250929', object='chat.completion.chunk', system_fingerprint=None, choices=[StreamingChoices(finish_reason=None, index=0, delta=Delta(provider_specific_fields=None, content=' context automatically', role=None, function_call=None, tool_calls=None, audio=None), logprobs=None)], provider_specific_fields=None, citations=None)
model_response finish reason 3: None; response_obj={'text': '', 'is_finished': False, 'finish_reason': '', 'usage': None, 'index': 0, 'tool_use': None}
model_response.choices[0].delta: Delta(provider_specific_fields=None, content=None, role=None, function_call=None, tool_calls=None, audio=None); completion_obj: {'content': ''}
self.sent_first_chunk: True
completion_obj: {'content': ''}, model_response.choices[0]: StreamingChoices(finish_reason=None, index=0, delta=Delta(provider_specific_fields=None, content=None, role=None, function_call=None, tool_calls=None, audio=None), logprobs=None), response_obj: {'text': '', 'is_finished': False, 'finish_reason': '', 'usage': None, 'index': 0, 'tool_use': None}
model_response finish reason 3: None; response_obj={'text': '', 'is_finished': False, 'finish_reason': '', 'usage': None, 'index': 0, 'tool_use': None}
model_response.choices[0].delta: Delta(provider_specific_fields=None, content=None, role=None, function_call=None, tool_calls=None, audio=None); completion_obj: {'content': ''}
self.sent_first_chunk: True
completion_obj: {'content': ''}, model_response.choices[0]: StreamingChoices(finish_reason=None, index=0, delta=Delta(provider_specific_fields=None, content=None, role=None, function_call=None, tool_calls=None, audio=None), logprobs=None), response_obj: {'text': '', 'is_finished': False, 'finish_reason': '', 'usage': None, 'index': 0, 'tool_use': None}

Raw OpenAI Chunk
ModelResponseStream(id='chatcmpl-1e246dec-1357-4ceb-948f-03d49e55b5f9', created=1762261917, model=None, object='chat.completion.chunk', system_fingerprint=None, choices=[StreamingChoices(finish_reason=None, index=0, delta=Delta(provider_specific_fields=None, content='.', role=None, function_call=None, tool_calls=None, audio=None), logprobs=None)], provider_specific_fields=None, usage=None)

model_response finish reason 3: None; response_obj={'text': '.', 'is_finished': False, 'finish_reason': None, 'logprobs': None, 'original_chunk': ModelResponseStream(id='chatcmpl-1e246dec-1357-4ceb-948f-03d49e55b5f9', created=1762261917, model=None, object='chat.completion.chunk', system_fingerprint=None, choices=[StreamingChoices(finish_reason=None, index=0, delta=Delta(provider_specific_fields=None, content='.', role=None, function_call=None, tool_calls=None, audio=None), logprobs=None)], provider_specific_fields=None, usage=None), 'usage': None}
original delta: {'provider_specific_fields': None, 'content': '.', 'role': None, 'function_call': None, 'tool_calls': None, 'audio': None}
new delta: Delta(provider_specific_fields=None, content='.', role=None, function_call=None, tool_calls=None, audio=None)
model_response.choices[0].delta: Delta(provider_specific_fields=None, content='.', role=None, function_call=None, tool_calls=None, audio=None); completion_obj: {'content': '.'}
self.sent_first_chunk: True
completion_obj: {'content': '.'}, model_response.choices[0]: StreamingChoices(finish_reason=None, index=0, delta=Delta(provider_specific_fields=None, content='.', role=None, function_call=None, tool_calls=None, audio=None), logprobs=None), response_obj: {'text': '.', 'is_finished': False, 'finish_reason': None, 'logprobs': None, 'original_chunk': ModelResponseStream(id='chatcmpl-1e246dec-1357-4ceb-948f-03d49e55b5f9', created=1762261917, model=None, object='chat.completion.chunk', system_fingerprint=None, choices=[StreamingChoices(finish_reason=None, index=0, delta=Delta(provider_specific_fields=None, content='.', role=None, function_call=None, tool_calls=None, audio=None), logprobs=None)], provider_specific_fields=None, usage=None), 'usage': None}
choice_json: {'index': 0, 'delta': {'provider_specific_fields': None, 'content': '.', 'role': None, 'function_call': None, 'tool_calls': None, 'audio': None}, 'logprobs': None}
choices in streaming: [StreamingChoices(finish_reason=None, index=0, delta=Delta(provider_specific_fields=None, content='.', role=None, function_call=None, tool_calls=None, audio=None), logprobs=None)]
final returned processed chunk: ModelResponseStream(id='chatcmpl-1e246dec-1357-4ceb-948f-03d49e55b5f9', created=1762261907, model='claude-sonnet-4-5-20250929', object='chat.completion.chunk', system_fingerprint=None, choices=[StreamingChoices(finish_reason=None, index=0, delta=Delta(provider_specific_fields=None, content='.', role=None, function_call=None, tool_calls=None, audio=None), logprobs=None)], provider_specific_fields=None, citations=None)
model_response finish reason 3: None; response_obj={'text': '', 'is_finished': False, 'finish_reason': '', 'usage': None, 'index': 0, 'tool_use': None}
model_response.choices[0].delta: Delta(provider_specific_fields=None, content=None, role=None, function_call=None, tool_calls=None, audio=None); completion_obj: {'content': ''}
self.sent_first_chunk: True
completion_obj: {'content': ''}, model_response.choices[0]: StreamingChoices(finish_reason=None, index=0, delta=Delta(provider_specific_fields=None, content=None, role=None, function_call=None, tool_calls=None, audio=None), logprobs=None), response_obj: {'text': '', 'is_finished': False, 'finish_reason': '', 'usage': None, 'index': 0, 'tool_use': None}
model_response finish reason 3: None; response_obj={'text': '', 'is_finished': False, 'finish_reason': '', 'usage': None, 'index': 0, 'tool_use': None}
model_response.choices[0].delta: Delta(provider_specific_fields=None, content=None, role=None, function_call=None, tool_calls=None, audio=None); completion_obj: {'content': ''}
self.sent_first_chunk: True
completion_obj: {'content': ''}, model_response.choices[0]: StreamingChoices(finish_reason=None, index=0, delta=Delta(provider_specific_fields=None, content=None, role=None, function_call=None, tool_calls=None, audio=None), logprobs=None), response_obj: {'text': '', 'is_finished': False, 'finish_reason': '', 'usage': None, 'index': 0, 'tool_use': None}

Raw OpenAI Chunk
ModelResponseStream(id='chatcmpl-1e246dec-1357-4ceb-948f-03d49e55b5f9', created=1762261917, model=None, object='chat.completion.chunk', system_fingerprint=None, choices=[StreamingChoices(finish_reason=None, index=0, delta=Delta(provider_specific_fields=None, content='\n\n---', role=None, function_call=None, tool_calls=None, audio=None), logprobs=None)], provider_specific_fields=None, usage=None)

model_response finish reason 3: None; response_obj={'text': '\n\n---', 'is_finished': False, 'finish_reason': None, 'logprobs': None, 'original_chunk': ModelResponseStream(id='chatcmpl-1e246dec-1357-4ceb-948f-03d49e55b5f9', created=1762261917, model=None, object='chat.completion.chunk', system_fingerprint=None, choices=[StreamingChoices(finish_reason=None, index=0, delta=Delta(provider_specific_fields=None, content='\n\n---', role=None, function_call=None, tool_calls=None, audio=None), logprobs=None)], provider_specific_fields=None, usage=None), 'usage': None}
original delta: {'provider_specific_fields': None, 'content': '\n\n---', 'role': None, 'function_call': None, 'tool_calls': None, 'audio': None}
new delta: Delta(provider_specific_fields=None, content='\n\n---', role=None, function_call=None, tool_calls=None, audio=None)
model_response.choices[0].delta: Delta(provider_specific_fields=None, content='\n\n---', role=None, function_call=None, tool_calls=None, audio=None); completion_obj: {'content': '\n\n---'}
self.sent_first_chunk: True
completion_obj: {'content': '\n\n---'}, model_response.choices[0]: StreamingChoices(finish_reason=None, index=0, delta=Delta(provider_specific_fields=None, content='\n\n---', role=None, function_call=None, tool_calls=None, audio=None), logprobs=None), response_obj: {'text': '\n\n---', 'is_finished': False, 'finish_reason': None, 'logprobs': None, 'original_chunk': ModelResponseStream(id='chatcmpl-1e246dec-1357-4ceb-948f-03d49e55b5f9', created=1762261917, model=None, object='chat.completion.chunk', system_fingerprint=None, choices=[StreamingChoices(finish_reason=None, index=0, delta=Delta(provider_specific_fields=None, content='\n\n---', role=None, function_call=None, tool_calls=None, audio=None), logprobs=None)], provider_specific_fields=None, usage=None), 'usage': None}
choice_json: {'index': 0, 'delta': {'provider_specific_fields': None, 'content': '\n\n---', 'role': None, 'function_call': None, 'tool_calls': None, 'audio': None}, 'logprobs': None}
choices in streaming: [StreamingChoices(finish_reason=None, index=0, delta=Delta(provider_specific_fields=None, content='\n\n---', role=None, function_call=None, tool_calls=None, audio=None), logprobs=None)]
final returned processed chunk: ModelResponseStream(id='chatcmpl-1e246dec-1357-4ceb-948f-03d49e55b5f9', created=1762261907, model='claude-sonnet-4-5-20250929', object='chat.completion.chunk', system_fingerprint=None, choices=[StreamingChoices(finish_reason=None, index=0, delta=Delta(provider_specific_fields=None, content='\n\n---', role=None, function_call=None, tool_calls=None, audio=None), logprobs=None)], provider_specific_fields=None, citations=None)
model_response finish reason 3: None; response_obj={'text': '', 'is_finished': False, 'finish_reason': '', 'usage': None, 'index': 0, 'tool_use': None}
model_response.choices[0].delta: Delta(provider_specific_fields=None, content=None, role=None, function_call=None, tool_calls=None, audio=None); completion_obj: {'content': ''}
self.sent_first_chunk: True
completion_obj: {'content': ''}, model_response.choices[0]: StreamingChoices(finish_reason=None, index=0, delta=Delta(provider_specific_fields=None, content=None, role=None, function_call=None, tool_calls=None, audio=None), logprobs=None), response_obj: {'text': '', 'is_finished': False, 'finish_reason': '', 'usage': None, 'index': 0, 'tool_use': None}
model_response finish reason 3: None; response_obj={'text': '', 'is_finished': False, 'finish_reason': '', 'usage': None, 'index': 0, 'tool_use': None}
model_response.choices[0].delta: Delta(provider_specific_fields=None, content=None, role=None, function_call=None, tool_calls=None, audio=None); completion_obj: {'content': ''}
self.sent_first_chunk: True
completion_obj: {'content': ''}, model_response.choices[0]: StreamingChoices(finish_reason=None, index=0, delta=Delta(provider_specific_fields=None, content=None, role=None, function_call=None, tool_calls=None, audio=None), logprobs=None), response_obj: {'text': '', 'is_finished': False, 'finish_reason': '', 'usage': None, 'index': 0, 'tool_use': None}

Raw OpenAI Chunk
ModelResponseStream(id='chatcmpl-1e246dec-1357-4ceb-948f-03d49e55b5f9', created=1762261917, model=None, object='chat.completion.chunk', system_fingerprint=None, choices=[StreamingChoices(finish_reason=None, index=0, delta=Delta(provider_specific_fields=None, content='\n\nWoul', role=None, function_call=None, tool_calls=None, audio=None), logprobs=None)], provider_specific_fields=None, usage=None)

model_response finish reason 3: None; response_obj={'text': '\n\nWoul', 'is_finished': False, 'finish_reason': None, 'logprobs': None, 'original_chunk': ModelResponseStream(id='chatcmpl-1e246dec-1357-4ceb-948f-03d49e55b5f9', created=1762261917, model=None, object='chat.completion.chunk', system_fingerprint=None, choices=[StreamingChoices(finish_reason=None, index=0, delta=Delta(provider_specific_fields=None, content='\n\nWoul', role=None, function_call=None, tool_calls=None, audio=None), logprobs=None)], provider_specific_fields=None, usage=None), 'usage': None}
original delta: {'provider_specific_fields': None, 'content': '\n\nWoul', 'role': None, 'function_call': None, 'tool_calls': None, 'audio': None}
new delta: Delta(provider_specific_fields=None, content='\n\nWoul', role=None, function_call=None, tool_calls=None, audio=None)
model_response.choices[0].delta: Delta(provider_specific_fields=None, content='\n\nWoul', role=None, function_call=None, tool_calls=None, audio=None); completion_obj: {'content': '\n\nWoul'}
self.sent_first_chunk: True
completion_obj: {'content': '\n\nWoul'}, model_response.choices[0]: StreamingChoices(finish_reason=None, index=0, delta=Delta(provider_specific_fields=None, content='\n\nWoul', role=None, function_call=None, tool_calls=None, audio=None), logprobs=None), response_obj: {'text': '\n\nWoul', 'is_finished': False, 'finish_reason': None, 'logprobs': None, 'original_chunk': ModelResponseStream(id='chatcmpl-1e246dec-1357-4ceb-948f-03d49e55b5f9', created=1762261917, model=None, object='chat.completion.chunk', system_fingerprint=None, choices=[StreamingChoices(finish_reason=None, index=0, delta=Delta(provider_specific_fields=None, content='\n\nWoul', role=None, function_call=None, tool_calls=None, audio=None), logprobs=None)], provider_specific_fields=None, usage=None), 'usage': None}
choice_json: {'index': 0, 'delta': {'provider_specific_fields': None, 'content': '\n\nWoul', 'role': None, 'function_call': None, 'tool_calls': None, 'audio': None}, 'logprobs': None}
choices in streaming: [StreamingChoices(finish_reason=None, index=0, delta=Delta(provider_specific_fields=None, content='\n\nWoul', role=None, function_call=None, tool_calls=None, audio=None), logprobs=None)]
final returned processed chunk: ModelResponseStream(id='chatcmpl-1e246dec-1357-4ceb-948f-03d49e55b5f9', created=1762261907, model='claude-sonnet-4-5-20250929', object='chat.completion.chunk', system_fingerprint=None, choices=[StreamingChoices(finish_reason=None, index=0, delta=Delta(provider_specific_fields=None, content='\n\nWoul', role=None, function_call=None, tool_calls=None, audio=None), logprobs=None)], provider_specific_fields=None, citations=None)
model_response finish reason 3: None; response_obj={'text': '', 'is_finished': False, 'finish_reason': '', 'usage': None, 'index': 0, 'tool_use': None}
model_response.choices[0].delta: Delta(provider_specific_fields=None, content=None, role=None, function_call=None, tool_calls=None, audio=None); completion_obj: {'content': ''}
self.sent_first_chunk: True
completion_obj: {'content': ''}, model_response.choices[0]: StreamingChoices(finish_reason=None, index=0, delta=Delta(provider_specific_fields=None, content=None, role=None, function_call=None, tool_calls=None, audio=None), logprobs=None), response_obj: {'text': '', 'is_finished': False, 'finish_reason': '', 'usage': None, 'index': 0, 'tool_use': None}
model_response finish reason 3: None; response_obj={'text': '', 'is_finished': False, 'finish_reason': '', 'usage': None, 'index': 0, 'tool_use': None}
model_response.choices[0].delta: Delta(provider_specific_fields=None, content=None, role=None, function_call=None, tool_calls=None, audio=None); completion_obj: {'content': ''}
self.sent_first_chunk: True
completion_obj: {'content': ''}, model_response.choices[0]: StreamingChoices(finish_reason=None, index=0, delta=Delta(provider_specific_fields=None, content=None, role=None, function_call=None, tool_calls=None, audio=None), logprobs=None), response_obj: {'text': '', 'is_finished': False, 'finish_reason': '', 'usage': None, 'index': 0, 'tool_use': None}

Raw OpenAI Chunk
ModelResponseStream(id='chatcmpl-1e246dec-1357-4ceb-948f-03d49e55b5f9', created=1762261917, model=None, object='chat.completion.chunk', system_fingerprint=None, choices=[StreamingChoices(finish_reason=None, index=0, delta=Delta(provider_specific_fields=None, content='d you like me to help', role=None, function_call=None, tool_calls=None, audio=None), logprobs=None)], provider_specific_fields=None, usage=None)

model_response finish reason 3: None; response_obj={'text': 'd you like me to help', 'is_finished': False, 'finish_reason': None, 'logprobs': None, 'original_chunk': ModelResponseStream(id='chatcmpl-1e246dec-1357-4ceb-948f-03d49e55b5f9', created=1762261917, model=None, object='chat.completion.chunk', system_fingerprint=None, choices=[StreamingChoices(finish_reason=None, index=0, delta=Delta(provider_specific_fields=None, content='d you like me to help', role=None, function_call=None, tool_calls=None, audio=None), logprobs=None)], provider_specific_fields=None, usage=None), 'usage': None}
original delta: {'provider_specific_fields': None, 'content': 'd you like me to help', 'role': None, 'function_call': None, 'tool_calls': None, 'audio': None}
new delta: Delta(provider_specific_fields=None, content='d you like me to help', role=None, function_call=None, tool_calls=None, audio=None)
model_response.choices[0].delta: Delta(provider_specific_fields=None, content='d you like me to help', role=None, function_call=None, tool_calls=None, audio=None); completion_obj: {'content': 'd you like me to help'}
self.sent_first_chunk: True
completion_obj: {'content': 'd you like me to help'}, model_response.choices[0]: StreamingChoices(finish_reason=None, index=0, delta=Delta(provider_specific_fields=None, content='d you like me to help', role=None, function_call=None, tool_calls=None, audio=None), logprobs=None), response_obj: {'text': 'd you like me to help', 'is_finished': False, 'finish_reason': None, 'logprobs': None, 'original_chunk': ModelResponseStream(id='chatcmpl-1e246dec-1357-4ceb-948f-03d49e55b5f9', created=1762261917, model=None, object='chat.completion.chunk', system_fingerprint=None, choices=[StreamingChoices(finish_reason=None, index=0, delta=Delta(provider_specific_fields=None, content='d you like me to help', role=None, function_call=None, tool_calls=None, audio=None), logprobs=None)], provider_specific_fields=None, usage=None), 'usage': None}
choice_json: {'index': 0, 'delta': {'provider_specific_fields': None, 'content': 'd you like me to help', 'role': None, 'function_call': None, 'tool_calls': None, 'audio': None}, 'logprobs': None}
choices in streaming: [StreamingChoices(finish_reason=None, index=0, delta=Delta(provider_specific_fields=None, content='d you like me to help', role=None, function_call=None, tool_calls=None, audio=None), logprobs=None)]
final returned processed chunk: ModelResponseStream(id='chatcmpl-1e246dec-1357-4ceb-948f-03d49e55b5f9', created=1762261907, model='claude-sonnet-4-5-20250929', object='chat.completion.chunk', system_fingerprint=None, choices=[StreamingChoices(finish_reason=None, index=0, delta=Delta(provider_specific_fields=None, content='d you like me to help', role=None, function_call=None, tool_calls=None, audio=None), logprobs=None)], provider_specific_fields=None, citations=None)
model_response finish reason 3: None; response_obj={'text': '', 'is_finished': False, 'finish_reason': '', 'usage': None, 'index': 0, 'tool_use': None}
model_response.choices[0].delta: Delta(provider_specific_fields=None, content=None, role=None, function_call=None, tool_calls=None, audio=None); completion_obj: {'content': ''}
self.sent_first_chunk: True
completion_obj: {'content': ''}, model_response.choices[0]: StreamingChoices(finish_reason=None, index=0, delta=Delta(provider_specific_fields=None, content=None, role=None, function_call=None, tool_calls=None, audio=None), logprobs=None), response_obj: {'text': '', 'is_finished': False, 'finish_reason': '', 'usage': None, 'index': 0, 'tool_use': None}
model_response finish reason 3: None; response_obj={'text': '', 'is_finished': False, 'finish_reason': '', 'usage': None, 'index': 0, 'tool_use': None}
model_response.choices[0].delta: Delta(provider_specific_fields=None, content=None, role=None, function_call=None, tool_calls=None, audio=None); completion_obj: {'content': ''}
self.sent_first_chunk: True
completion_obj: {'content': ''}, model_response.choices[0]: StreamingChoices(finish_reason=None, index=0, delta=Delta(provider_specific_fields=None, content=None, role=None, function_call=None, tool_calls=None, audio=None), logprobs=None), response_obj: {'text': '', 'is_finished': False, 'finish_reason': '', 'usage': None, 'index': 0, 'tool_use': None}

Raw OpenAI Chunk
ModelResponseStream(id='chatcmpl-1e246dec-1357-4ceb-948f-03d49e55b5f9', created=1762261917, model=None, object='chat.completion.chunk', system_fingerprint=None, choices=[StreamingChoices(finish_reason=None, index=0, delta=Delta(provider_specific_fields=None, content=' you:', role=None, function_call=None, tool_calls=None, audio=None), logprobs=None)], provider_specific_fields=None, usage=None)

model_response finish reason 3: None; response_obj={'text': ' you:', 'is_finished': False, 'finish_reason': None, 'logprobs': None, 'original_chunk': ModelResponseStream(id='chatcmpl-1e246dec-1357-4ceb-948f-03d49e55b5f9', created=1762261917, model=None, object='chat.completion.chunk', system_fingerprint=None, choices=[StreamingChoices(finish_reason=None, index=0, delta=Delta(provider_specific_fields=None, content=' you:', role=None, function_call=None, tool_calls=None, audio=None), logprobs=None)], provider_specific_fields=None, usage=None), 'usage': None}
original delta: {'provider_specific_fields': None, 'content': ' you:', 'role': None, 'function_call': None, 'tool_calls': None, 'audio': None}
new delta: Delta(provider_specific_fields=None, content=' you:', role=None, function_call=None, tool_calls=None, audio=None)
model_response.choices[0].delta: Delta(provider_specific_fields=None, content=' you:', role=None, function_call=None, tool_calls=None, audio=None); completion_obj: {'content': ' you:'}
self.sent_first_chunk: True
completion_obj: {'content': ' you:'}, model_response.choices[0]: StreamingChoices(finish_reason=None, index=0, delta=Delta(provider_specific_fields=None, content=' you:', role=None, function_call=None, tool_calls=None, audio=None), logprobs=None), response_obj: {'text': ' you:', 'is_finished': False, 'finish_reason': None, 'logprobs': None, 'original_chunk': ModelResponseStream(id='chatcmpl-1e246dec-1357-4ceb-948f-03d49e55b5f9', created=1762261917, model=None, object='chat.completion.chunk', system_fingerprint=None, choices=[StreamingChoices(finish_reason=None, index=0, delta=Delta(provider_specific_fields=None, content=' you:', role=None, function_call=None, tool_calls=None, audio=None), logprobs=None)], provider_specific_fields=None, usage=None), 'usage': None}
choice_json: {'index': 0, 'delta': {'provider_specific_fields': None, 'content': ' you:', 'role': None, 'function_call': None, 'tool_calls': None, 'audio': None}, 'logprobs': None}
choices in streaming: [StreamingChoices(finish_reason=None, index=0, delta=Delta(provider_specific_fields=None, content=' you:', role=None, function_call=None, tool_calls=None, audio=None), logprobs=None)]
final returned processed chunk: ModelResponseStream(id='chatcmpl-1e246dec-1357-4ceb-948f-03d49e55b5f9', created=1762261907, model='claude-sonnet-4-5-20250929', object='chat.completion.chunk', system_fingerprint=None, choices=[StreamingChoices(finish_reason=None, index=0, delta=Delta(provider_specific_fields=None, content=' you:', role=None, function_call=None, tool_calls=None, audio=None), logprobs=None)], provider_specific_fields=None, citations=None)
model_response finish reason 3: None; response_obj={'text': '', 'is_finished': False, 'finish_reason': '', 'usage': None, 'index': 0, 'tool_use': None}
model_response.choices[0].delta: Delta(provider_specific_fields=None, content=None, role=None, function_call=None, tool_calls=None, audio=None); completion_obj: {'content': ''}
self.sent_first_chunk: True
completion_obj: {'content': ''}, model_response.choices[0]: StreamingChoices(finish_reason=None, index=0, delta=Delta(provider_specific_fields=None, content=None, role=None, function_call=None, tool_calls=None, audio=None), logprobs=None), response_obj: {'text': '', 'is_finished': False, 'finish_reason': '', 'usage': None, 'index': 0, 'tool_use': None}
model_response finish reason 3: None; response_obj={'text': '', 'is_finished': False, 'finish_reason': '', 'usage': None, 'index': 0, 'tool_use': None}
model_response.choices[0].delta: Delta(provider_specific_fields=None, content=None, role=None, function_call=None, tool_calls=None, audio=None); completion_obj: {'content': ''}
self.sent_first_chunk: True
completion_obj: {'content': ''}, model_response.choices[0]: StreamingChoices(finish_reason=None, index=0, delta=Delta(provider_specific_fields=None, content=None, role=None, function_call=None, tool_calls=None, audio=None), logprobs=None), response_obj: {'text': '', 'is_finished': False, 'finish_reason': '', 'usage': None, 'index': 0, 'tool_use': None}

Raw OpenAI Chunk
ModelResponseStream(id='chatcmpl-1e246dec-1357-4ceb-948f-03d49e55b5f9', created=1762261917, model=None, object='chat.completion.chunk', system_fingerprint=None, choices=[StreamingChoices(finish_reason=None, index=0, delta=Delta(provider_specific_fields=None, content='\n1. **Integrate the `', role=None, function_call=None, tool_calls=None, audio=None), logprobs=None)], provider_specific_fields=None, usage=None)

model_response finish reason 3: None; response_obj={'text': '\n1. **Integrate the `', 'is_finished': False, 'finish_reason': None, 'logprobs': None, 'original_chunk': ModelResponseStream(id='chatcmpl-1e246dec-1357-4ceb-948f-03d49e55b5f9', created=1762261917, model=None, object='chat.completion.chunk', system_fingerprint=None, choices=[StreamingChoices(finish_reason=None, index=0, delta=Delta(provider_specific_fields=None, content='\n1. **Integrate the `', role=None, function_call=None, tool_calls=None, audio=None), logprobs=None)], provider_specific_fields=None, usage=None), 'usage': None}
original delta: {'provider_specific_fields': None, 'content': '\n1. **Integrate the `', 'role': None, 'function_call': None, 'tool_calls': None, 'audio': None}
new delta: Delta(provider_specific_fields=None, content='\n1. **Integrate the `', role=None, function_call=None, tool_calls=None, audio=None)
model_response.choices[0].delta: Delta(provider_specific_fields=None, content='\n1. **Integrate the `', role=None, function_call=None, tool_calls=None, audio=None); completion_obj: {'content': '\n1. **Integrate the `'}
self.sent_first_chunk: True
completion_obj: {'content': '\n1. **Integrate the `'}, model_response.choices[0]: StreamingChoices(finish_reason=None, index=0, delta=Delta(provider_specific_fields=None, content='\n1. **Integrate the `', role=None, function_call=None, tool_calls=None, audio=None), logprobs=None), response_obj: {'text': '\n1. **Integrate the `', 'is_finished': False, 'finish_reason': None, 'logprobs': None, 'original_chunk': ModelResponseStream(id='chatcmpl-1e246dec-1357-4ceb-948f-03d49e55b5f9', created=1762261917, model=None, object='chat.completion.chunk', system_fingerprint=None, choices=[StreamingChoices(finish_reason=None, index=0, delta=Delta(provider_specific_fields=None, content='\n1. **Integrate the `', role=None, function_call=None, tool_calls=None, audio=None), logprobs=None)], provider_specific_fields=None, usage=None), 'usage': None}
choice_json: {'index': 0, 'delta': {'provider_specific_fields': None, 'content': '\n1. **Integrate the `', 'role': None, 'function_call': None, 'tool_calls': None, 'audio': None}, 'logprobs': None}
choices in streaming: [StreamingChoices(finish_reason=None, index=0, delta=Delta(provider_specific_fields=None, content='\n1. **Integrate the `', role=None, function_call=None, tool_calls=None, audio=None), logprobs=None)]
final returned processed chunk: ModelResponseStream(id='chatcmpl-1e246dec-1357-4ceb-948f-03d49e55b5f9', created=1762261907, model='claude-sonnet-4-5-20250929', object='chat.completion.chunk', system_fingerprint=None, choices=[StreamingChoices(finish_reason=None, index=0, delta=Delta(provider_specific_fields=None, content='\n1. **Integrate the `', role=None, function_call=None, tool_calls=None, audio=None), logprobs=None)], provider_specific_fields=None, citations=None)
model_response finish reason 3: None; response_obj={'text': '', 'is_finished': False, 'finish_reason': '', 'usage': None, 'index': 0, 'tool_use': None}
model_response.choices[0].delta: Delta(provider_specific_fields=None, content=None, role=None, function_call=None, tool_calls=None, audio=None); completion_obj: {'content': ''}
self.sent_first_chunk: True
completion_obj: {'content': ''}, model_response.choices[0]: StreamingChoices(finish_reason=None, index=0, delta=Delta(provider_specific_fields=None, content=None, role=None, function_call=None, tool_calls=None, audio=None), logprobs=None), response_obj: {'text': '', 'is_finished': False, 'finish_reason': '', 'usage': None, 'index': 0, 'tool_use': None}
model_response finish reason 3: None; response_obj={'text': '', 'is_finished': False, 'finish_reason': '', 'usage': None, 'index': 0, 'tool_use': None}
model_response.choices[0].delta: Delta(provider_specific_fields=None, content=None, role=None, function_call=None, tool_calls=None, audio=None); completion_obj: {'content': ''}
self.sent_first_chunk: True
completion_obj: {'content': ''}, model_response.choices[0]: StreamingChoices(finish_reason=None, index=0, delta=Delta(provider_specific_fields=None, content=None, role=None, function_call=None, tool_calls=None, audio=None), logprobs=None), response_obj: {'text': '', 'is_finished': False, 'finish_reason': '', 'usage': None, 'index': 0, 'tool_use': None}

Raw OpenAI Chunk
ModelResponseStream(id='chatcmpl-1e246dec-1357-4ceb-948f-03d49e55b5f9', created=1762261917, model=None, object='chat.completion.chunk', system_fingerprint=None, choices=[StreamingChoices(finish_reason=None, index=0, delta=Delta(provider_specific_fields=None, content='ContextRetriever` into your', role=None, function_call=None, tool_calls=None, audio=None), logprobs=None)], provider_specific_fields=None, usage=None)

model_response finish reason 3: None; response_obj={'text': 'ContextRetriever` into your', 'is_finished': False, 'finish_reason': None, 'logprobs': None, 'original_chunk': ModelResponseStream(id='chatcmpl-1e246dec-1357-4ceb-948f-03d49e55b5f9', created=1762261917, model=None, object='chat.completion.chunk', system_fingerprint=None, choices=[StreamingChoices(finish_reason=None, index=0, delta=Delta(provider_specific_fields=None, content='ContextRetriever` into your', role=None, function_call=None, tool_calls=None, audio=None), logprobs=None)], provider_specific_fields=None, usage=None), 'usage': None}
original delta: {'provider_specific_fields': None, 'content': 'ContextRetriever` into your', 'role': None, 'function_call': None, 'tool_calls': None, 'audio': None}
new delta: Delta(provider_specific_fields=None, content='ContextRetriever` into your', role=None, function_call=None, tool_calls=None, audio=None)
model_response.choices[0].delta: Delta(provider_specific_fields=None, content='ContextRetriever` into your', role=None, function_call=None, tool_calls=None, audio=None); completion_obj: {'content': 'ContextRetriever` into your'}
self.sent_first_chunk: True
completion_obj: {'content': 'ContextRetriever` into your'}, model_response.choices[0]: StreamingChoices(finish_reason=None, index=0, delta=Delta(provider_specific_fields=None, content='ContextRetriever` into your', role=None, function_call=None, tool_calls=None, audio=None), logprobs=None), response_obj: {'text': 'ContextRetriever` into your', 'is_finished': False, 'finish_reason': None, 'logprobs': None, 'original_chunk': ModelResponseStream(id='chatcmpl-1e246dec-1357-4ceb-948f-03d49e55b5f9', created=1762261917, model=None, object='chat.completion.chunk', system_fingerprint=None, choices=[StreamingChoices(finish_reason=None, index=0, delta=Delta(provider_specific_fields=None, content='ContextRetriever` into your', role=None, function_call=None, tool_calls=None, audio=None), logprobs=None)], provider_specific_fields=None, usage=None), 'usage': None}
choice_json: {'index': 0, 'delta': {'provider_specific_fields': None, 'content': 'ContextRetriever` into your', 'role': None, 'function_call': None, 'tool_calls': None, 'audio': None}, 'logprobs': None}
choices in streaming: [StreamingChoices(finish_reason=None, index=0, delta=Delta(provider_specific_fields=None, content='ContextRetriever` into your', role=None, function_call=None, tool_calls=None, audio=None), logprobs=None)]
final returned processed chunk: ModelResponseStream(id='chatcmpl-1e246dec-1357-4ceb-948f-03d49e55b5f9', created=1762261907, model='claude-sonnet-4-5-20250929', object='chat.completion.chunk', system_fingerprint=None, choices=[StreamingChoices(finish_reason=None, index=0, delta=Delta(provider_specific_fields=None, content='ContextRetriever` into your', role=None, function_call=None, tool_calls=None, audio=None), logprobs=None)], provider_specific_fields=None, citations=None)
model_response finish reason 3: None; response_obj={'text': '', 'is_finished': False, 'finish_reason': '', 'usage': None, 'index': 0, 'tool_use': None}
model_response.choices[0].delta: Delta(provider_specific_fields=None, content=None, role=None, function_call=None, tool_calls=None, audio=None); completion_obj: {'content': ''}
self.sent_first_chunk: True
completion_obj: {'content': ''}, model_response.choices[0]: StreamingChoices(finish_reason=None, index=0, delta=Delta(provider_specific_fields=None, content=None, role=None, function_call=None, tool_calls=None, audio=None), logprobs=None), response_obj: {'text': '', 'is_finished': False, 'finish_reason': '', 'usage': None, 'index': 0, 'tool_use': None}
model_response finish reason 3: None; response_obj={'text': '', 'is_finished': False, 'finish_reason': '', 'usage': None, 'index': 0, 'tool_use': None}
model_response.choices[0].delta: Delta(provider_specific_fields=None, content=None, role=None, function_call=None, tool_calls=None, audio=None); completion_obj: {'content': ''}
self.sent_first_chunk: True
completion_obj: {'content': ''}, model_response.choices[0]: StreamingChoices(finish_reason=None, index=0, delta=Delta(provider_specific_fields=None, content=None, role=None, function_call=None, tool_calls=None, audio=None), logprobs=None), response_obj: {'text': '', 'is_finished': False, 'finish_reason': '', 'usage': None, 'index': 0, 'tool_use': None}

Raw OpenAI Chunk
ModelResponseStream(id='chatcmpl-1e246dec-1357-4ceb-948f-03d49e55b5f9', created=1762261917, model=None, object='chat.completion.chunk', system_fingerprint=None, choices=[StreamingChoices(finish_reason=None, index=0, delta=Delta(provider_specific_fields=None, content=' proxy**', role=None, function_call=None, tool_calls=None, audio=None), logprobs=None)], provider_specific_fields=None, usage=None)

model_response finish reason 3: None; response_obj={'text': ' proxy**', 'is_finished': False, 'finish_reason': None, 'logprobs': None, 'original_chunk': ModelResponseStream(id='chatcmpl-1e246dec-1357-4ceb-948f-03d49e55b5f9', created=1762261917, model=None, object='chat.completion.chunk', system_fingerprint=None, choices=[StreamingChoices(finish_reason=None, index=0, delta=Delta(provider_specific_fields=None, content=' proxy**', role=None, function_call=None, tool_calls=None, audio=None), logprobs=None)], provider_specific_fields=None, usage=None), 'usage': None}
original delta: {'provider_specific_fields': None, 'content': ' proxy**', 'role': None, 'function_call': None, 'tool_calls': None, 'audio': None}
new delta: Delta(provider_specific_fields=None, content=' proxy**', role=None, function_call=None, tool_calls=None, audio=None)
model_response.choices[0].delta: Delta(provider_specific_fields=None, content=' proxy**', role=None, function_call=None, tool_calls=None, audio=None); completion_obj: {'content': ' proxy**'}
self.sent_first_chunk: True
completion_obj: {'content': ' proxy**'}, model_response.choices[0]: StreamingChoices(finish_reason=None, index=0, delta=Delta(provider_specific_fields=None, content=' proxy**', role=None, function_call=None, tool_calls=None, audio=None), logprobs=None), response_obj: {'text': ' proxy**', 'is_finished': False, 'finish_reason': None, 'logprobs': None, 'original_chunk': ModelResponseStream(id='chatcmpl-1e246dec-1357-4ceb-948f-03d49e55b5f9', created=1762261917, model=None, object='chat.completion.chunk', system_fingerprint=None, choices=[StreamingChoices(finish_reason=None, index=0, delta=Delta(provider_specific_fields=None, content=' proxy**', role=None, function_call=None, tool_calls=None, audio=None), logprobs=None)], provider_specific_fields=None, usage=None), 'usage': None}
choice_json: {'index': 0, 'delta': {'provider_specific_fields': None, 'content': ' proxy**', 'role': None, 'function_call': None, 'tool_calls': None, 'audio': None}, 'logprobs': None}
choices in streaming: [StreamingChoices(finish_reason=None, index=0, delta=Delta(provider_specific_fields=None, content=' proxy**', role=None, function_call=None, tool_calls=None, audio=None), logprobs=None)]
final returned processed chunk: ModelResponseStream(id='chatcmpl-1e246dec-1357-4ceb-948f-03d49e55b5f9', created=1762261907, model='claude-sonnet-4-5-20250929', object='chat.completion.chunk', system_fingerprint=None, choices=[StreamingChoices(finish_reason=None, index=0, delta=Delta(provider_specific_fields=None, content=' proxy**', role=None, function_call=None, tool_calls=None, audio=None), logprobs=None)], provider_specific_fields=None, citations=None)
model_response finish reason 3: None; response_obj={'text': '', 'is_finished': False, 'finish_reason': '', 'usage': None, 'index': 0, 'tool_use': None}
model_response.choices[0].delta: Delta(provider_specific_fields=None, content=None, role=None, function_call=None, tool_calls=None, audio=None); completion_obj: {'content': ''}
self.sent_first_chunk: True
completion_obj: {'content': ''}, model_response.choices[0]: StreamingChoices(finish_reason=None, index=0, delta=Delta(provider_specific_fields=None, content=None, role=None, function_call=None, tool_calls=None, audio=None), logprobs=None), response_obj: {'text': '', 'is_finished': False, 'finish_reason': '', 'usage': None, 'index': 0, 'tool_use': None}
model_response finish reason 3: None; response_obj={'text': '', 'is_finished': False, 'finish_reason': '', 'usage': None, 'index': 0, 'tool_use': None}
model_response.choices[0].delta: Delta(provider_specific_fields=None, content=None, role=None, function_call=None, tool_calls=None, audio=None); completion_obj: {'content': ''}
self.sent_first_chunk: True
completion_obj: {'content': ''}, model_response.choices[0]: StreamingChoices(finish_reason=None, index=0, delta=Delta(provider_specific_fields=None, content=None, role=None, function_call=None, tool_calls=None, audio=None), logprobs=None), response_obj: {'text': '', 'is_finished': False, 'finish_reason': '', 'usage': None, 'index': 0, 'tool_use': None}

Raw OpenAI Chunk
ModelResponseStream(id='chatcmpl-1e246dec-1357-4ceb-948f-03d49e55b5f9', created=1762261917, model=None, object='chat.completion.chunk', system_fingerprint=None, choices=[StreamingChoices(finish_reason=None, index=0, delta=Delta(provider_specific_fields=None, content=' (`', role=None, function_call=None, tool_calls=None, audio=None), logprobs=None)], provider_specific_fields=None, usage=None)

model_response finish reason 3: None; response_obj={'text': ' (`', 'is_finished': False, 'finish_reason': None, 'logprobs': None, 'original_chunk': ModelResponseStream(id='chatcmpl-1e246dec-1357-4ceb-948f-03d49e55b5f9', created=1762261917, model=None, object='chat.completion.chunk', system_fingerprint=None, choices=[StreamingChoices(finish_reason=None, index=0, delta=Delta(provider_specific_fields=None, content=' (`', role=None, function_call=None, tool_calls=None, audio=None), logprobs=None)], provider_specific_fields=None, usage=None), 'usage': None}
original delta: {'provider_specific_fields': None, 'content': ' (`', 'role': None, 'function_call': None, 'tool_calls': None, 'audio': None}
new delta: Delta(provider_specific_fields=None, content=' (`', role=None, function_call=None, tool_calls=None, audio=None)
model_response.choices[0].delta: Delta(provider_specific_fields=None, content=' (`', role=None, function_call=None, tool_calls=None, audio=None); completion_obj: {'content': ' (`'}
self.sent_first_chunk: True
completion_obj: {'content': ' (`'}, model_response.choices[0]: StreamingChoices(finish_reason=None, index=0, delta=Delta(provider_specific_fields=None, content=' (`', role=None, function_call=None, tool_calls=None, audio=None), logprobs=None), response_obj: {'text': ' (`', 'is_finished': False, 'finish_reason': None, 'logprobs': None, 'original_chunk': ModelResponseStream(id='chatcmpl-1e246dec-1357-4ceb-948f-03d49e55b5f9', created=1762261917, model=None, object='chat.completion.chunk', system_fingerprint=None, choices=[StreamingChoices(finish_reason=None, index=0, delta=Delta(provider_specific_fields=None, content=' (`', role=None, function_call=None, tool_calls=None, audio=None), logprobs=None)], provider_specific_fields=None, usage=None), 'usage': None}
choice_json: {'index': 0, 'delta': {'provider_specific_fields': None, 'content': ' (`', 'role': None, 'function_call': None, 'tool_calls': None, 'audio': None}, 'logprobs': None}
choices in streaming: [StreamingChoices(finish_reason=None, index=0, delta=Delta(provider_specific_fields=None, content=' (`', role=None, function_call=None, tool_calls=None, audio=None), logprobs=None)]
final returned processed chunk: ModelResponseStream(id='chatcmpl-1e246dec-1357-4ceb-948f-03d49e55b5f9', created=1762261907, model='claude-sonnet-4-5-20250929', object='chat.completion.chunk', system_fingerprint=None, choices=[StreamingChoices(finish_reason=None, index=0, delta=Delta(provider_specific_fields=None, content=' (`', role=None, function_call=None, tool_calls=None, audio=None), logprobs=None)], provider_specific_fields=None, citations=None)
model_response finish reason 3: None; response_obj={'text': '', 'is_finished': False, 'finish_reason': '', 'usage': None, 'index': 0, 'tool_use': None}
model_response.choices[0].delta: Delta(provider_specific_fields=None, content=None, role=None, function_call=None, tool_calls=None, audio=None); completion_obj: {'content': ''}
self.sent_first_chunk: True
completion_obj: {'content': ''}, model_response.choices[0]: StreamingChoices(finish_reason=None, index=0, delta=Delta(provider_specific_fields=None, content=None, role=None, function_call=None, tool_calls=None, audio=None), logprobs=None), response_obj: {'text': '', 'is_finished': False, 'finish_reason': '', 'usage': None, 'index': 0, 'tool_use': None}
model_response finish reason 3: None; response_obj={'text': '', 'is_finished': False, 'finish_reason': '', 'usage': None, 'index': 0, 'tool_use': None}
model_response.choices[0].delta: Delta(provider_specific_fields=None, content=None, role=None, function_call=None, tool_calls=None, audio=None); completion_obj: {'content': ''}
self.sent_first_chunk: True
completion_obj: {'content': ''}, model_response.choices[0]: StreamingChoices(finish_reason=None, index=0, delta=Delta(provider_specific_fields=None, content=None, role=None, function_call=None, tool_calls=None, audio=None), logprobs=None), response_obj: {'text': '', 'is_finished': False, 'finish_reason': '', 'usage': None, 'index': 0, 'tool_use': None}

Raw OpenAI Chunk
ModelResponseStream(id='chatcmpl-1e246dec-1357-4ceb-948f-03d49e55b5f9', created=1762261917, model=None, object='chat.completion.chunk', system_fingerprint=None, choices=[StreamingChoices(finish_reason=None, index=0, delta=Delta(provider_specific_fields=None, content='lit', role=None, function_call=None, tool_calls=None, audio=None), logprobs=None)], provider_specific_fields=None, usage=None)

model_response finish reason 3: None; response_obj={'text': 'lit', 'is_finished': False, 'finish_reason': None, 'logprobs': None, 'original_chunk': ModelResponseStream(id='chatcmpl-1e246dec-1357-4ceb-948f-03d49e55b5f9', created=1762261917, model=None, object='chat.completion.chunk', system_fingerprint=None, choices=[StreamingChoices(finish_reason=None, index=0, delta=Delta(provider_specific_fields=None, content='lit', role=None, function_call=None, tool_calls=None, audio=None), logprobs=None)], provider_specific_fields=None, usage=None), 'usage': None}
original delta: {'provider_specific_fields': None, 'content': 'lit', 'role': None, 'function_call': None, 'tool_calls': None, 'audio': None}
new delta: Delta(provider_specific_fields=None, content='lit', role=None, function_call=None, tool_calls=None, audio=None)
model_response.choices[0].delta: Delta(provider_specific_fields=None, content='lit', role=None, function_call=None, tool_calls=None, audio=None); completion_obj: {'content': 'lit'}
self.sent_first_chunk: True
completion_obj: {'content': 'lit'}, model_response.choices[0]: StreamingChoices(finish_reason=None, index=0, delta=Delta(provider_specific_fields=None, content='lit', role=None, function_call=None, tool_calls=None, audio=None), logprobs=None), response_obj: {'text': 'lit', 'is_finished': False, 'finish_reason': None, 'logprobs': None, 'original_chunk': ModelResponseStream(id='chatcmpl-1e246dec-1357-4ceb-948f-03d49e55b5f9', created=1762261917, model=None, object='chat.completion.chunk', system_fingerprint=None, choices=[StreamingChoices(finish_reason=None, index=0, delta=Delta(provider_specific_fields=None, content='lit', role=None, function_call=None, tool_calls=None, audio=None), logprobs=None)], provider_specific_fields=None, usage=None), 'usage': None}
choice_json: {'index': 0, 'delta': {'provider_specific_fields': None, 'content': 'lit', 'role': None, 'function_call': None, 'tool_calls': None, 'audio': None}, 'logprobs': None}
choices in streaming: [StreamingChoices(finish_reason=None, index=0, delta=Delta(provider_specific_fields=None, content='lit', role=None, function_call=None, tool_calls=None, audio=None), logprobs=None)]
final returned processed chunk: ModelResponseStream(id='chatcmpl-1e246dec-1357-4ceb-948f-03d49e55b5f9', created=1762261907, model='claude-sonnet-4-5-20250929', object='chat.completion.chunk', system_fingerprint=None, choices=[StreamingChoices(finish_reason=None, index=0, delta=Delta(provider_specific_fields=None, content='lit', role=None, function_call=None, tool_calls=None, audio=None), logprobs=None)], provider_specific_fields=None, citations=None)
model_response finish reason 3: None; response_obj={'text': '', 'is_finished': False, 'finish_reason': '', 'usage': None, 'index': 0, 'tool_use': None}
model_response.choices[0].delta: Delta(provider_specific_fields=None, content=None, role=None, function_call=None, tool_calls=None, audio=None); completion_obj: {'content': ''}
self.sent_first_chunk: True
completion_obj: {'content': ''}, model_response.choices[0]: StreamingChoices(finish_reason=None, index=0, delta=Delta(provider_specific_fields=None, content=None, role=None, function_call=None, tool_calls=None, audio=None), logprobs=None), response_obj: {'text': '', 'is_finished': False, 'finish_reason': '', 'usage': None, 'index': 0, 'tool_use': None}
model_response finish reason 3: None; response_obj={'text': '', 'is_finished': False, 'finish_reason': '', 'usage': None, 'index': 0, 'tool_use': None}
model_response.choices[0].delta: Delta(provider_specific_fields=None, content=None, role=None, function_call=None, tool_calls=None, audio=None); completion_obj: {'content': ''}
self.sent_first_chunk: True
completion_obj: {'content': ''}, model_response.choices[0]: StreamingChoices(finish_reason=None, index=0, delta=Delta(provider_specific_fields=None, content=None, role=None, function_call=None, tool_calls=None, audio=None), logprobs=None), response_obj: {'text': '', 'is_finished': False, 'finish_reason': '', 'usage': None, 'index': 0, 'tool_use': None}

Raw OpenAI Chunk
ModelResponseStream(id='chatcmpl-1e246dec-1357-4ceb-948f-03d49e55b5f9', created=1762261918, model=None, object='chat.completion.chunk', system_fingerprint=None, choices=[StreamingChoices(finish_reason=None, index=0, delta=Delta(provider_specific_fields=None, content='ellm_', role=None, function_call=None, tool_calls=None, audio=None), logprobs=None)], provider_specific_fields=None, usage=None)

model_response finish reason 3: None; response_obj={'text': 'ellm_', 'is_finished': False, 'finish_reason': None, 'logprobs': None, 'original_chunk': ModelResponseStream(id='chatcmpl-1e246dec-1357-4ceb-948f-03d49e55b5f9', created=1762261918, model=None, object='chat.completion.chunk', system_fingerprint=None, choices=[StreamingChoices(finish_reason=None, index=0, delta=Delta(provider_specific_fields=None, content='ellm_', role=None, function_call=None, tool_calls=None, audio=None), logprobs=None)], provider_specific_fields=None, usage=None), 'usage': None}
original delta: {'provider_specific_fields': None, 'content': 'ellm_', 'role': None, 'function_call': None, 'tool_calls': None, 'audio': None}
new delta: Delta(provider_specific_fields=None, content='ellm_', role=None, function_call=None, tool_calls=None, audio=None)
model_response.choices[0].delta: Delta(provider_specific_fields=None, content='ellm_', role=None, function_call=None, tool_calls=None, audio=None); completion_obj: {'content': 'ellm_'}
self.sent_first_chunk: True
completion_obj: {'content': 'ellm_'}, model_response.choices[0]: StreamingChoices(finish_reason=None, index=0, delta=Delta(provider_specific_fields=None, content='ellm_', role=None, function_call=None, tool_calls=None, audio=None), logprobs=None), response_obj: {'text': 'ellm_', 'is_finished': False, 'finish_reason': None, 'logprobs': None, 'original_chunk': ModelResponseStream(id='chatcmpl-1e246dec-1357-4ceb-948f-03d49e55b5f9', created=1762261918, model=None, object='chat.completion.chunk', system_fingerprint=None, choices=[StreamingChoices(finish_reason=None, index=0, delta=Delta(provider_specific_fields=None, content='ellm_', role=None, function_call=None, tool_calls=None, audio=None), logprobs=None)], provider_specific_fields=None, usage=None), 'usage': None}
choice_json: {'index': 0, 'delta': {'provider_specific_fields': None, 'content': 'ellm_', 'role': None, 'function_call': None, 'tool_calls': None, 'audio': None}, 'logprobs': None}
choices in streaming: [StreamingChoices(finish_reason=None, index=0, delta=Delta(provider_specific_fields=None, content='ellm_', role=None, function_call=None, tool_calls=None, audio=None), logprobs=None)]
final returned processed chunk: ModelResponseStream(id='chatcmpl-1e246dec-1357-4ceb-948f-03d49e55b5f9', created=1762261907, model='claude-sonnet-4-5-20250929', object='chat.completion.chunk', system_fingerprint=None, choices=[StreamingChoices(finish_reason=None, index=0, delta=Delta(provider_specific_fields=None, content='ellm_', role=None, function_call=None, tool_calls=None, audio=None), logprobs=None)], provider_specific_fields=None, citations=None)
model_response finish reason 3: None; response_obj={'text': '', 'is_finished': False, 'finish_reason': '', 'usage': None, 'index': 0, 'tool_use': None}
model_response.choices[0].delta: Delta(provider_specific_fields=None, content=None, role=None, function_call=None, tool_calls=None, audio=None); completion_obj: {'content': ''}
self.sent_first_chunk: True
completion_obj: {'content': ''}, model_response.choices[0]: StreamingChoices(finish_reason=None, index=0, delta=Delta(provider_specific_fields=None, content=None, role=None, function_call=None, tool_calls=None, audio=None), logprobs=None), response_obj: {'text': '', 'is_finished': False, 'finish_reason': '', 'usage': None, 'index': 0, 'tool_use': None}
model_response finish reason 3: None; response_obj={'text': '', 'is_finished': False, 'finish_reason': '', 'usage': None, 'index': 0, 'tool_use': None}
model_response.choices[0].delta: Delta(provider_specific_fields=None, content=None, role=None, function_call=None, tool_calls=None, audio=None); completion_obj: {'content': ''}
self.sent_first_chunk: True
completion_obj: {'content': ''}, model_response.choices[0]: StreamingChoices(finish_reason=None, index=0, delta=Delta(provider_specific_fields=None, content=None, role=None, function_call=None, tool_calls=None, audio=None), logprobs=None), response_obj: {'text': '', 'is_finished': False, 'finish_reason': '', 'usage': None, 'index': 0, 'tool_use': None}

Raw OpenAI Chunk
ModelResponseStream(id='chatcmpl-1e246dec-1357-4ceb-948f-03d49e55b5f9', created=1762261918, model=None, object='chat.completion.chunk', system_fingerprint=None, choices=[StreamingChoices(finish_reason=None, index=0, delta=Delta(provider_specific_fields=None, content='proxy_', role=None, function_call=None, tool_calls=None, audio=None), logprobs=None)], provider_specific_fields=None, usage=None)

model_response finish reason 3: None; response_obj={'text': 'proxy_', 'is_finished': False, 'finish_reason': None, 'logprobs': None, 'original_chunk': ModelResponseStream(id='chatcmpl-1e246dec-1357-4ceb-948f-03d49e55b5f9', created=1762261918, model=None, object='chat.completion.chunk', system_fingerprint=None, choices=[StreamingChoices(finish_reason=None, index=0, delta=Delta(provider_specific_fields=None, content='proxy_', role=None, function_call=None, tool_calls=None, audio=None), logprobs=None)], provider_specific_fields=None, usage=None), 'usage': None}
original delta: {'provider_specific_fields': None, 'content': 'proxy_', 'role': None, 'function_call': None, 'tool_calls': None, 'audio': None}
new delta: Delta(provider_specific_fields=None, content='proxy_', role=None, function_call=None, tool_calls=None, audio=None)
model_response.choices[0].delta: Delta(provider_specific_fields=None, content='proxy_', role=None, function_call=None, tool_calls=None, audio=None); completion_obj: {'content': 'proxy_'}
self.sent_first_chunk: True
completion_obj: {'content': 'proxy_'}, model_response.choices[0]: StreamingChoices(finish_reason=None, index=0, delta=Delta(provider_specific_fields=None, content='proxy_', role=None, function_call=None, tool_calls=None, audio=None), logprobs=None), response_obj: {'text': 'proxy_', 'is_finished': False, 'finish_reason': None, 'logprobs': None, 'original_chunk': ModelResponseStream(id='chatcmpl-1e246dec-1357-4ceb-948f-03d49e55b5f9', created=1762261918, model=None, object='chat.completion.chunk', system_fingerprint=None, choices=[StreamingChoices(finish_reason=None, index=0, delta=Delta(provider_specific_fields=None, content='proxy_', role=None, function_call=None, tool_calls=None, audio=None), logprobs=None)], provider_specific_fields=None, usage=None), 'usage': None}
choice_json: {'index': 0, 'delta': {'provider_specific_fields': None, 'content': 'proxy_', 'role': None, 'function_call': None, 'tool_calls': None, 'audio': None}, 'logprobs': None}
choices in streaming: [StreamingChoices(finish_reason=None, index=0, delta=Delta(provider_specific_fields=None, content='proxy_', role=None, function_call=None, tool_calls=None, audio=None), logprobs=None)]
final returned processed chunk: ModelResponseStream(id='chatcmpl-1e246dec-1357-4ceb-948f-03d49e55b5f9', created=1762261907, model='claude-sonnet-4-5-20250929', object='chat.completion.chunk', system_fingerprint=None, choices=[StreamingChoices(finish_reason=None, index=0, delta=Delta(provider_specific_fields=None, content='proxy_', role=None, function_call=None, tool_calls=None, audio=None), logprobs=None)], provider_specific_fields=None, citations=None)
model_response finish reason 3: None; response_obj={'text': '', 'is_finished': False, 'finish_reason': '', 'usage': None, 'index': 0, 'tool_use': None}
model_response.choices[0].delta: Delta(provider_specific_fields=None, content=None, role=None, function_call=None, tool_calls=None, audio=None); completion_obj: {'content': ''}
self.sent_first_chunk: True
completion_obj: {'content': ''}, model_response.choices[0]: StreamingChoices(finish_reason=None, index=0, delta=Delta(provider_specific_fields=None, content=None, role=None, function_call=None, tool_calls=None, audio=None), logprobs=None), response_obj: {'text': '', 'is_finished': False, 'finish_reason': '', 'usage': None, 'index': 0, 'tool_use': None}
model_response finish reason 3: None; response_obj={'text': '', 'is_finished': False, 'finish_reason': '', 'usage': None, 'index': 0, 'tool_use': None}
model_response.choices[0].delta: Delta(provider_specific_fields=None, content=None, role=None, function_call=None, tool_calls=None, audio=None); completion_obj: {'content': ''}
self.sent_first_chunk: True
completion_obj: {'content': ''}, model_response.choices[0]: StreamingChoices(finish_reason=None, index=0, delta=Delta(provider_specific_fields=None, content=None, role=None, function_call=None, tool_calls=None, audio=None), logprobs=None), response_obj: {'text': '', 'is_finished': False, 'finish_reason': '', 'usage': None, 'index': 0, 'tool_use': None}

Raw OpenAI Chunk
ModelResponseStream(id='chatcmpl-1e246dec-1357-4ceb-948f-03d49e55b5f9', created=1762261918, model=None, object='chat.completion.chunk', system_fingerprint=None, choices=[StreamingChoices(finish_reason=None, index=0, delta=Delta(provider_specific_fields=None, content='sdk', role=None, function_call=None, tool_calls=None, audio=None), logprobs=None)], provider_specific_fields=None, usage=None)

model_response finish reason 3: None; response_obj={'text': 'sdk', 'is_finished': False, 'finish_reason': None, 'logprobs': None, 'original_chunk': ModelResponseStream(id='chatcmpl-1e246dec-1357-4ceb-948f-03d49e55b5f9', created=1762261918, model=None, object='chat.completion.chunk', system_fingerprint=None, choices=[StreamingChoices(finish_reason=None, index=0, delta=Delta(provider_specific_fields=None, content='sdk', role=None, function_call=None, tool_calls=None, audio=None), logprobs=None)], provider_specific_fields=None, usage=None), 'usage': None}
original delta: {'provider_specific_fields': None, 'content': 'sdk', 'role': None, 'function_call': None, 'tool_calls': None, 'audio': None}
new delta: Delta(provider_specific_fields=None, content='sdk', role=None, function_call=None, tool_calls=None, audio=None)
model_response.choices[0].delta: Delta(provider_specific_fields=None, content='sdk', role=None, function_call=None, tool_calls=None, audio=None); completion_obj: {'content': 'sdk'}
self.sent_first_chunk: True
completion_obj: {'content': 'sdk'}, model_response.choices[0]: StreamingChoices(finish_reason=None, index=0, delta=Delta(provider_specific_fields=None, content='sdk', role=None, function_call=None, tool_calls=None, audio=None), logprobs=None), response_obj: {'text': 'sdk', 'is_finished': False, 'finish_reason': None, 'logprobs': None, 'original_chunk': ModelResponseStream(id='chatcmpl-1e246dec-1357-4ceb-948f-03d49e55b5f9', created=1762261918, model=None, object='chat.completion.chunk', system_fingerprint=None, choices=[StreamingChoices(finish_reason=None, index=0, delta=Delta(provider_specific_fields=None, content='sdk', role=None, function_call=None, tool_calls=None, audio=None), logprobs=None)], provider_specific_fields=None, usage=None), 'usage': None}
choice_json: {'index': 0, 'delta': {'provider_specific_fields': None, 'content': 'sdk', 'role': None, 'function_call': None, 'tool_calls': None, 'audio': None}, 'logprobs': None}
choices in streaming: [StreamingChoices(finish_reason=None, index=0, delta=Delta(provider_specific_fields=None, content='sdk', role=None, function_call=None, tool_calls=None, audio=None), logprobs=None)]
final returned processed chunk: ModelResponseStream(id='chatcmpl-1e246dec-1357-4ceb-948f-03d49e55b5f9', created=1762261907, model='claude-sonnet-4-5-20250929', object='chat.completion.chunk', system_fingerprint=None, choices=[StreamingChoices(finish_reason=None, index=0, delta=Delta(provider_specific_fields=None, content='sdk', role=None, function_call=None, tool_calls=None, audio=None), logprobs=None)], provider_specific_fields=None, citations=None)
model_response finish reason 3: None; response_obj={'text': '', 'is_finished': False, 'finish_reason': '', 'usage': None, 'index': 0, 'tool_use': None}
model_response.choices[0].delta: Delta(provider_specific_fields=None, content=None, role=None, function_call=None, tool_calls=None, audio=None); completion_obj: {'content': ''}
self.sent_first_chunk: True
completion_obj: {'content': ''}, model_response.choices[0]: StreamingChoices(finish_reason=None, index=0, delta=Delta(provider_specific_fields=None, content=None, role=None, function_call=None, tool_calls=None, audio=None), logprobs=None), response_obj: {'text': '', 'is_finished': False, 'finish_reason': '', 'usage': None, 'index': 0, 'tool_use': None}
model_response finish reason 3: None; response_obj={'text': '', 'is_finished': False, 'finish_reason': '', 'usage': None, 'index': 0, 'tool_use': None}
model_response.choices[0].delta: Delta(provider_specific_fields=None, content=None, role=None, function_call=None, tool_calls=None, audio=None); completion_obj: {'content': ''}
self.sent_first_chunk: True
completion_obj: {'content': ''}, model_response.choices[0]: StreamingChoices(finish_reason=None, index=0, delta=Delta(provider_specific_fields=None, content=None, role=None, function_call=None, tool_calls=None, audio=None), logprobs=None), response_obj: {'text': '', 'is_finished': False, 'finish_reason': '', 'usage': None, 'index': 0, 'tool_use': None}

Raw OpenAI Chunk
ModelResponseStream(id='chatcmpl-1e246dec-1357-4ceb-948f-03d49e55b5f9', created=1762261918, model=None, object='chat.completion.chunk', system_fingerprint=None, choices=[StreamingChoices(finish_reason=None, index=0, delta=Delta(provider_specific_fields=None, content='.', role=None, function_call=None, tool_calls=None, audio=None), logprobs=None)], provider_specific_fields=None, usage=None)

model_response finish reason 3: None; response_obj={'text': '.', 'is_finished': False, 'finish_reason': None, 'logprobs': None, 'original_chunk': ModelResponseStream(id='chatcmpl-1e246dec-1357-4ceb-948f-03d49e55b5f9', created=1762261918, model=None, object='chat.completion.chunk', system_fingerprint=None, choices=[StreamingChoices(finish_reason=None, index=0, delta=Delta(provider_specific_fields=None, content='.', role=None, function_call=None, tool_calls=None, audio=None), logprobs=None)], provider_specific_fields=None, usage=None), 'usage': None}
original delta: {'provider_specific_fields': None, 'content': '.', 'role': None, 'function_call': None, 'tool_calls': None, 'audio': None}
new delta: Delta(provider_specific_fields=None, content='.', role=None, function_call=None, tool_calls=None, audio=None)
model_response.choices[0].delta: Delta(provider_specific_fields=None, content='.', role=None, function_call=None, tool_calls=None, audio=None); completion_obj: {'content': '.'}
self.sent_first_chunk: True
completion_obj: {'content': '.'}, model_response.choices[0]: StreamingChoices(finish_reason=None, index=0, delta=Delta(provider_specific_fields=None, content='.', role=None, function_call=None, tool_calls=None, audio=None), logprobs=None), response_obj: {'text': '.', 'is_finished': False, 'finish_reason': None, 'logprobs': None, 'original_chunk': ModelResponseStream(id='chatcmpl-1e246dec-1357-4ceb-948f-03d49e55b5f9', created=1762261918, model=None, object='chat.completion.chunk', system_fingerprint=None, choices=[StreamingChoices(finish_reason=None, index=0, delta=Delta(provider_specific_fields=None, content='.', role=None, function_call=None, tool_calls=None, audio=None), logprobs=None)], provider_specific_fields=None, usage=None), 'usage': None}
choice_json: {'index': 0, 'delta': {'provider_specific_fields': None, 'content': '.', 'role': None, 'function_call': None, 'tool_calls': None, 'audio': None}, 'logprobs': None}
choices in streaming: [StreamingChoices(finish_reason=None, index=0, delta=Delta(provider_specific_fields=None, content='.', role=None, function_call=None, tool_calls=None, audio=None), logprobs=None)]
final returned processed chunk: ModelResponseStream(id='chatcmpl-1e246dec-1357-4ceb-948f-03d49e55b5f9', created=1762261907, model='claude-sonnet-4-5-20250929', object='chat.completion.chunk', system_fingerprint=None, choices=[StreamingChoices(finish_reason=None, index=0, delta=Delta(provider_specific_fields=None, content='.', role=None, function_call=None, tool_calls=None, audio=None), logprobs=None)], provider_specific_fields=None, citations=None)
model_response finish reason 3: None; response_obj={'text': '', 'is_finished': False, 'finish_reason': '', 'usage': None, 'index': 0, 'tool_use': None}
model_response.choices[0].delta: Delta(provider_specific_fields=None, content=None, role=None, function_call=None, tool_calls=None, audio=None); completion_obj: {'content': ''}
self.sent_first_chunk: True
completion_obj: {'content': ''}, model_response.choices[0]: StreamingChoices(finish_reason=None, index=0, delta=Delta(provider_specific_fields=None, content=None, role=None, function_call=None, tool_calls=None, audio=None), logprobs=None), response_obj: {'text': '', 'is_finished': False, 'finish_reason': '', 'usage': None, 'index': 0, 'tool_use': None}
model_response finish reason 3: None; response_obj={'text': '', 'is_finished': False, 'finish_reason': '', 'usage': None, 'index': 0, 'tool_use': None}
model_response.choices[0].delta: Delta(provider_specific_fields=None, content=None, role=None, function_call=None, tool_calls=None, audio=None); completion_obj: {'content': ''}
self.sent_first_chunk: True
completion_obj: {'content': ''}, model_response.choices[0]: StreamingChoices(finish_reason=None, index=0, delta=Delta(provider_specific_fields=None, content=None, role=None, function_call=None, tool_calls=None, audio=None), logprobs=None), response_obj: {'text': '', 'is_finished': False, 'finish_reason': '', 'usage': None, 'index': 0, 'tool_use': None}

Raw OpenAI Chunk
ModelResponseStream(id='chatcmpl-1e246dec-1357-4ceb-948f-03d49e55b5f9', created=1762261918, model=None, object='chat.completion.chunk', system_fingerprint=None, choices=[StreamingChoices(finish_reason=None, index=0, delta=Delta(provider_specific_fields=None, content='py`', role=None, function_call=None, tool_calls=None, audio=None), logprobs=None)], provider_specific_fields=None, usage=None)

model_response finish reason 3: None; response_obj={'text': 'py`', 'is_finished': False, 'finish_reason': None, 'logprobs': None, 'original_chunk': ModelResponseStream(id='chatcmpl-1e246dec-1357-4ceb-948f-03d49e55b5f9', created=1762261918, model=None, object='chat.completion.chunk', system_fingerprint=None, choices=[StreamingChoices(finish_reason=None, index=0, delta=Delta(provider_specific_fields=None, content='py`', role=None, function_call=None, tool_calls=None, audio=None), logprobs=None)], provider_specific_fields=None, usage=None), 'usage': None}
original delta: {'provider_specific_fields': None, 'content': 'py`', 'role': None, 'function_call': None, 'tool_calls': None, 'audio': None}
new delta: Delta(provider_specific_fields=None, content='py`', role=None, function_call=None, tool_calls=None, audio=None)
model_response.choices[0].delta: Delta(provider_specific_fields=None, content='py`', role=None, function_call=None, tool_calls=None, audio=None); completion_obj: {'content': 'py`'}
self.sent_first_chunk: True
completion_obj: {'content': 'py`'}, model_response.choices[0]: StreamingChoices(finish_reason=None, index=0, delta=Delta(provider_specific_fields=None, content='py`', role=None, function_call=None, tool_calls=None, audio=None), logprobs=None), response_obj: {'text': 'py`', 'is_finished': False, 'finish_reason': None, 'logprobs': None, 'original_chunk': ModelResponseStream(id='chatcmpl-1e246dec-1357-4ceb-948f-03d49e55b5f9', created=1762261918, model=None, object='chat.completion.chunk', system_fingerprint=None, choices=[StreamingChoices(finish_reason=None, index=0, delta=Delta(provider_specific_fields=None, content='py`', role=None, function_call=None, tool_calls=None, audio=None), logprobs=None)], provider_specific_fields=None, usage=None), 'usage': None}
choice_json: {'index': 0, 'delta': {'provider_specific_fields': None, 'content': 'py`', 'role': None, 'function_call': None, 'tool_calls': None, 'audio': None}, 'logprobs': None}
choices in streaming: [StreamingChoices(finish_reason=None, index=0, delta=Delta(provider_specific_fields=None, content='py`', role=None, function_call=None, tool_calls=None, audio=None), logprobs=None)]
final returned processed chunk: ModelResponseStream(id='chatcmpl-1e246dec-1357-4ceb-948f-03d49e55b5f9', created=1762261907, model='claude-sonnet-4-5-20250929', object='chat.completion.chunk', system_fingerprint=None, choices=[StreamingChoices(finish_reason=None, index=0, delta=Delta(provider_specific_fields=None, content='py`', role=None, function_call=None, tool_calls=None, audio=None), logprobs=None)], provider_specific_fields=None, citations=None)
model_response finish reason 3: None; response_obj={'text': '', 'is_finished': False, 'finish_reason': '', 'usage': None, 'index': 0, 'tool_use': None}
model_response.choices[0].delta: Delta(provider_specific_fields=None, content=None, role=None, function_call=None, tool_calls=None, audio=None); completion_obj: {'content': ''}
self.sent_first_chunk: True
completion_obj: {'content': ''}, model_response.choices[0]: StreamingChoices(finish_reason=None, index=0, delta=Delta(provider_specific_fields=None, content=None, role=None, function_call=None, tool_calls=None, audio=None), logprobs=None), response_obj: {'text': '', 'is_finished': False, 'finish_reason': '', 'usage': None, 'index': 0, 'tool_use': None}
model_response finish reason 3: None; response_obj={'text': '', 'is_finished': False, 'finish_reason': '', 'usage': None, 'index': 0, 'tool_use': None}
model_response.choices[0].delta: Delta(provider_specific_fields=None, content=None, role=None, function_call=None, tool_calls=None, audio=None); completion_obj: {'content': ''}
self.sent_first_chunk: True
completion_obj: {'content': ''}, model_response.choices[0]: StreamingChoices(finish_reason=None, index=0, delta=Delta(provider_specific_fields=None, content=None, role=None, function_call=None, tool_calls=None, audio=None), logprobs=None), response_obj: {'text': '', 'is_finished': False, 'finish_reason': '', 'usage': None, 'index': 0, 'tool_use': None}

Raw OpenAI Chunk
ModelResponseStream(id='chatcmpl-1e246dec-1357-4ceb-948f-03d49e55b5f9', created=1762261918, model=None, object='chat.completion.chunk', system_fingerprint=None, choices=[StreamingChoices(finish_reason=None, index=0, delta=Delta(provider_specific_fields=None, content=' or `litellm_proxy_', role=None, function_call=None, tool_calls=None, audio=None), logprobs=None)], provider_specific_fields=None, usage=None)

model_response finish reason 3: None; response_obj={'text': ' or `litellm_proxy_', 'is_finished': False, 'finish_reason': None, 'logprobs': None, 'original_chunk': ModelResponseStream(id='chatcmpl-1e246dec-1357-4ceb-948f-03d49e55b5f9', created=1762261918, model=None, object='chat.completion.chunk', system_fingerprint=None, choices=[StreamingChoices(finish_reason=None, index=0, delta=Delta(provider_specific_fields=None, content=' or `litellm_proxy_', role=None, function_call=None, tool_calls=None, audio=None), logprobs=None)], provider_specific_fields=None, usage=None), 'usage': None}
original delta: {'provider_specific_fields': None, 'content': ' or `litellm_proxy_', 'role': None, 'function_call': None, 'tool_calls': None, 'audio': None}
new delta: Delta(provider_specific_fields=None, content=' or `litellm_proxy_', role=None, function_call=None, tool_calls=None, audio=None)
model_response.choices[0].delta: Delta(provider_specific_fields=None, content=' or `litellm_proxy_', role=None, function_call=None, tool_calls=None, audio=None); completion_obj: {'content': ' or `litellm_proxy_'}
self.sent_first_chunk: True
completion_obj: {'content': ' or `litellm_proxy_'}, model_response.choices[0]: StreamingChoices(finish_reason=None, index=0, delta=Delta(provider_specific_fields=None, content=' or `litellm_proxy_', role=None, function_call=None, tool_calls=None, audio=None), logprobs=None), response_obj: {'text': ' or `litellm_proxy_', 'is_finished': False, 'finish_reason': None, 'logprobs': None, 'original_chunk': ModelResponseStream(id='chatcmpl-1e246dec-1357-4ceb-948f-03d49e55b5f9', created=1762261918, model=None, object='chat.completion.chunk', system_fingerprint=None, choices=[StreamingChoices(finish_reason=None, index=0, delta=Delta(provider_specific_fields=None, content=' or `litellm_proxy_', role=None, function_call=None, tool_calls=None, audio=None), logprobs=None)], provider_specific_fields=None, usage=None), 'usage': None}
choice_json: {'index': 0, 'delta': {'provider_specific_fields': None, 'content': ' or `litellm_proxy_', 'role': None, 'function_call': None, 'tool_calls': None, 'audio': None}, 'logprobs': None}
choices in streaming: [StreamingChoices(finish_reason=None, index=0, delta=Delta(provider_specific_fields=None, content=' or `litellm_proxy_', role=None, function_call=None, tool_calls=None, audio=None), logprobs=None)]
final returned processed chunk: ModelResponseStream(id='chatcmpl-1e246dec-1357-4ceb-948f-03d49e55b5f9', created=1762261907, model='claude-sonnet-4-5-20250929', object='chat.completion.chunk', system_fingerprint=None, choices=[StreamingChoices(finish_reason=None, index=0, delta=Delta(provider_specific_fields=None, content=' or `litellm_proxy_', role=None, function_call=None, tool_calls=None, audio=None), logprobs=None)], provider_specific_fields=None, citations=None)
model_response finish reason 3: None; response_obj={'text': '', 'is_finished': False, 'finish_reason': '', 'usage': None, 'index': 0, 'tool_use': None}
model_response.choices[0].delta: Delta(provider_specific_fields=None, content=None, role=None, function_call=None, tool_calls=None, audio=None); completion_obj: {'content': ''}
self.sent_first_chunk: True
completion_obj: {'content': ''}, model_response.choices[0]: StreamingChoices(finish_reason=None, index=0, delta=Delta(provider_specific_fields=None, content=None, role=None, function_call=None, tool_calls=None, audio=None), logprobs=None), response_obj: {'text': '', 'is_finished': False, 'finish_reason': '', 'usage': None, 'index': 0, 'tool_use': None}
model_response finish reason 3: None; response_obj={'text': '', 'is_finished': False, 'finish_reason': '', 'usage': None, 'index': 0, 'tool_use': None}
model_response.choices[0].delta: Delta(provider_specific_fields=None, content=None, role=None, function_call=None, tool_calls=None, audio=None); completion_obj: {'content': ''}
self.sent_first_chunk: True
completion_obj: {'content': ''}, model_response.choices[0]: StreamingChoices(finish_reason=None, index=0, delta=Delta(provider_specific_fields=None, content=None, role=None, function_call=None, tool_calls=None, audio=None), logprobs=None), response_obj: {'text': '', 'is_finished': False, 'finish_reason': '', 'usage': None, 'index': 0, 'tool_use': None}

Raw OpenAI Chunk
ModelResponseStream(id='chatcmpl-1e246dec-1357-4ceb-948f-03d49e55b5f9', created=1762261918, model=None, object='chat.completion.chunk', system_fingerprint=None, choices=[StreamingChoices(finish_reason=None, index=0, delta=Delta(provider_specific_fields=None, content='with', role=None, function_call=None, tool_calls=None, audio=None), logprobs=None)], provider_specific_fields=None, usage=None)

model_response finish reason 3: None; response_obj={'text': 'with', 'is_finished': False, 'finish_reason': None, 'logprobs': None, 'original_chunk': ModelResponseStream(id='chatcmpl-1e246dec-1357-4ceb-948f-03d49e55b5f9', created=1762261918, model=None, object='chat.completion.chunk', system_fingerprint=None, choices=[StreamingChoices(finish_reason=None, index=0, delta=Delta(provider_specific_fields=None, content='with', role=None, function_call=None, tool_calls=None, audio=None), logprobs=None)], provider_specific_fields=None, usage=None), 'usage': None}
original delta: {'provider_specific_fields': None, 'content': 'with', 'role': None, 'function_call': None, 'tool_calls': None, 'audio': None}
new delta: Delta(provider_specific_fields=None, content='with', role=None, function_call=None, tool_calls=None, audio=None)
model_response.choices[0].delta: Delta(provider_specific_fields=None, content='with', role=None, function_call=None, tool_calls=None, audio=None); completion_obj: {'content': 'with'}
self.sent_first_chunk: True
completion_obj: {'content': 'with'}, model_response.choices[0]: StreamingChoices(finish_reason=None, index=0, delta=Delta(provider_specific_fields=None, content='with', role=None, function_call=None, tool_calls=None, audio=None), logprobs=None), response_obj: {'text': 'with', 'is_finished': False, 'finish_reason': None, 'logprobs': None, 'original_chunk': ModelResponseStream(id='chatcmpl-1e246dec-1357-4ceb-948f-03d49e55b5f9', created=1762261918, model=None, object='chat.completion.chunk', system_fingerprint=None, choices=[StreamingChoices(finish_reason=None, index=0, delta=Delta(provider_specific_fields=None, content='with', role=None, function_call=None, tool_calls=None, audio=None), logprobs=None)], provider_specific_fields=None, usage=None), 'usage': None}
choice_json: {'index': 0, 'delta': {'provider_specific_fields': None, 'content': 'with', 'role': None, 'function_call': None, 'tool_calls': None, 'audio': None}, 'logprobs': None}
choices in streaming: [StreamingChoices(finish_reason=None, index=0, delta=Delta(provider_specific_fields=None, content='with', role=None, function_call=None, tool_calls=None, audio=None), logprobs=None)]
final returned processed chunk: ModelResponseStream(id='chatcmpl-1e246dec-1357-4ceb-948f-03d49e55b5f9', created=1762261907, model='claude-sonnet-4-5-20250929', object='chat.completion.chunk', system_fingerprint=None, choices=[StreamingChoices(finish_reason=None, index=0, delta=Delta(provider_specific_fields=None, content='with', role=None, function_call=None, tool_calls=None, audio=None), logprobs=None)], provider_specific_fields=None, citations=None)
model_response finish reason 3: None; response_obj={'text': '', 'is_finished': False, 'finish_reason': '', 'usage': None, 'index': 0, 'tool_use': None}
model_response.choices[0].delta: Delta(provider_specific_fields=None, content=None, role=None, function_call=None, tool_calls=None, audio=None); completion_obj: {'content': ''}
self.sent_first_chunk: True
completion_obj: {'content': ''}, model_response.choices[0]: StreamingChoices(finish_reason=None, index=0, delta=Delta(provider_specific_fields=None, content=None, role=None, function_call=None, tool_calls=None, audio=None), logprobs=None), response_obj: {'text': '', 'is_finished': False, 'finish_reason': '', 'usage': None, 'index': 0, 'tool_use': None}
model_response finish reason 3: None; response_obj={'text': '', 'is_finished': False, 'finish_reason': '', 'usage': None, 'index': 0, 'tool_use': None}
model_response.choices[0].delta: Delta(provider_specific_fields=None, content=None, role=None, function_call=None, tool_calls=None, audio=None); completion_obj: {'content': ''}
self.sent_first_chunk: True
completion_obj: {'content': ''}, model_response.choices[0]: StreamingChoices(finish_reason=None, index=0, delta=Delta(provider_specific_fields=None, content=None, role=None, function_call=None, tool_calls=None, audio=None), logprobs=None), response_obj: {'text': '', 'is_finished': False, 'finish_reason': '', 'usage': None, 'index': 0, 'tool_use': None}

Raw OpenAI Chunk
ModelResponseStream(id='chatcmpl-1e246dec-1357-4ceb-948f-03d49e55b5f9', created=1762261918, model=None, object='chat.completion.chunk', system_fingerprint=None, choices=[StreamingChoices(finish_reason=None, index=0, delta=Delta(provider_specific_fields=None, content='_memory', role=None, function_call=None, tool_calls=None, audio=None), logprobs=None)], provider_specific_fields=None, usage=None)

model_response finish reason 3: None; response_obj={'text': '_memory', 'is_finished': False, 'finish_reason': None, 'logprobs': None, 'original_chunk': ModelResponseStream(id='chatcmpl-1e246dec-1357-4ceb-948f-03d49e55b5f9', created=1762261918, model=None, object='chat.completion.chunk', system_fingerprint=None, choices=[StreamingChoices(finish_reason=None, index=0, delta=Delta(provider_specific_fields=None, content='_memory', role=None, function_call=None, tool_calls=None, audio=None), logprobs=None)], provider_specific_fields=None, usage=None), 'usage': None}
original delta: {'provider_specific_fields': None, 'content': '_memory', 'role': None, 'function_call': None, 'tool_calls': None, 'audio': None}
new delta: Delta(provider_specific_fields=None, content='_memory', role=None, function_call=None, tool_calls=None, audio=None)
model_response.choices[0].delta: Delta(provider_specific_fields=None, content='_memory', role=None, function_call=None, tool_calls=None, audio=None); completion_obj: {'content': '_memory'}
self.sent_first_chunk: True
completion_obj: {'content': '_memory'}, model_response.choices[0]: StreamingChoices(finish_reason=None, index=0, delta=Delta(provider_specific_fields=None, content='_memory', role=None, function_call=None, tool_calls=None, audio=None), logprobs=None), response_obj: {'text': '_memory', 'is_finished': False, 'finish_reason': None, 'logprobs': None, 'original_chunk': ModelResponseStream(id='chatcmpl-1e246dec-1357-4ceb-948f-03d49e55b5f9', created=1762261918, model=None, object='chat.completion.chunk', system_fingerprint=None, choices=[StreamingChoices(finish_reason=None, index=0, delta=Delta(provider_specific_fields=None, content='_memory', role=None, function_call=None, tool_calls=None, audio=None), logprobs=None)], provider_specific_fields=None, usage=None), 'usage': None}
choice_json: {'index': 0, 'delta': {'provider_specific_fields': None, 'content': '_memory', 'role': None, 'function_call': None, 'tool_calls': None, 'audio': None}, 'logprobs': None}
choices in streaming: [StreamingChoices(finish_reason=None, index=0, delta=Delta(provider_specific_fields=None, content='_memory', role=None, function_call=None, tool_calls=None, audio=None), logprobs=None)]
final returned processed chunk: ModelResponseStream(id='chatcmpl-1e246dec-1357-4ceb-948f-03d49e55b5f9', created=1762261907, model='claude-sonnet-4-5-20250929', object='chat.completion.chunk', system_fingerprint=None, choices=[StreamingChoices(finish_reason=None, index=0, delta=Delta(provider_specific_fields=None, content='_memory', role=None, function_call=None, tool_calls=None, audio=None), logprobs=None)], provider_specific_fields=None, citations=None)
model_response finish reason 3: None; response_obj={'text': '', 'is_finished': False, 'finish_reason': '', 'usage': None, 'index': 0, 'tool_use': None}
model_response.choices[0].delta: Delta(provider_specific_fields=None, content=None, role=None, function_call=None, tool_calls=None, audio=None); completion_obj: {'content': ''}
self.sent_first_chunk: True
completion_obj: {'content': ''}, model_response.choices[0]: StreamingChoices(finish_reason=None, index=0, delta=Delta(provider_specific_fields=None, content=None, role=None, function_call=None, tool_calls=None, audio=None), logprobs=None), response_obj: {'text': '', 'is_finished': False, 'finish_reason': '', 'usage': None, 'index': 0, 'tool_use': None}
model_response finish reason 3: None; response_obj={'text': '', 'is_finished': False, 'finish_reason': '', 'usage': None, 'index': 0, 'tool_use': None}
model_response.choices[0].delta: Delta(provider_specific_fields=None, content=None, role=None, function_call=None, tool_calls=None, audio=None); completion_obj: {'content': ''}
self.sent_first_chunk: True
completion_obj: {'content': ''}, model_response.choices[0]: StreamingChoices(finish_reason=None, index=0, delta=Delta(provider_specific_fields=None, content=None, role=None, function_call=None, tool_calls=None, audio=None), logprobs=None), response_obj: {'text': '', 'is_finished': False, 'finish_reason': '', 'usage': None, 'index': 0, 'tool_use': None}

Raw OpenAI Chunk
ModelResponseStream(id='chatcmpl-1e246dec-1357-4ceb-948f-03d49e55b5f9', created=1762261918, model=None, object='chat.completion.chunk', system_fingerprint=None, choices=[StreamingChoices(finish_reason=None, index=0, delta=Delta(provider_specific_fields=None, content='.py`', role=None, function_call=None, tool_calls=None, audio=None), logprobs=None)], provider_specific_fields=None, usage=None)

model_response finish reason 3: None; response_obj={'text': '.py`', 'is_finished': False, 'finish_reason': None, 'logprobs': None, 'original_chunk': ModelResponseStream(id='chatcmpl-1e246dec-1357-4ceb-948f-03d49e55b5f9', created=1762261918, model=None, object='chat.completion.chunk', system_fingerprint=None, choices=[StreamingChoices(finish_reason=None, index=0, delta=Delta(provider_specific_fields=None, content='.py`', role=None, function_call=None, tool_calls=None, audio=None), logprobs=None)], provider_specific_fields=None, usage=None), 'usage': None}
original delta: {'provider_specific_fields': None, 'content': '.py`', 'role': None, 'function_call': None, 'tool_calls': None, 'audio': None}
new delta: Delta(provider_specific_fields=None, content='.py`', role=None, function_call=None, tool_calls=None, audio=None)
model_response.choices[0].delta: Delta(provider_specific_fields=None, content='.py`', role=None, function_call=None, tool_calls=None, audio=None); completion_obj: {'content': '.py`'}
self.sent_first_chunk: True
completion_obj: {'content': '.py`'}, model_response.choices[0]: StreamingChoices(finish_reason=None, index=0, delta=Delta(provider_specific_fields=None, content='.py`', role=None, function_call=None, tool_calls=None, audio=None), logprobs=None), response_obj: {'text': '.py`', 'is_finished': False, 'finish_reason': None, 'logprobs': None, 'original_chunk': ModelResponseStream(id='chatcmpl-1e246dec-1357-4ceb-948f-03d49e55b5f9', created=1762261918, model=None, object='chat.completion.chunk', system_fingerprint=None, choices=[StreamingChoices(finish_reason=None, index=0, delta=Delta(provider_specific_fields=None, content='.py`', role=None, function_call=None, tool_calls=None, audio=None), logprobs=None)], provider_specific_fields=None, usage=None), 'usage': None}
choice_json: {'index': 0, 'delta': {'provider_specific_fields': None, 'content': '.py`', 'role': None, 'function_call': None, 'tool_calls': None, 'audio': None}, 'logprobs': None}
choices in streaming: [StreamingChoices(finish_reason=None, index=0, delta=Delta(provider_specific_fields=None, content='.py`', role=None, function_call=None, tool_calls=None, audio=None), logprobs=None)]
final returned processed chunk: ModelResponseStream(id='chatcmpl-1e246dec-1357-4ceb-948f-03d49e55b5f9', created=1762261907, model='claude-sonnet-4-5-20250929', object='chat.completion.chunk', system_fingerprint=None, choices=[StreamingChoices(finish_reason=None, index=0, delta=Delta(provider_specific_fields=None, content='.py`', role=None, function_call=None, tool_calls=None, audio=None), logprobs=None)], provider_specific_fields=None, citations=None)
model_response finish reason 3: None; response_obj={'text': '', 'is_finished': False, 'finish_reason': '', 'usage': None, 'index': 0, 'tool_use': None}
model_response.choices[0].delta: Delta(provider_specific_fields=None, content=None, role=None, function_call=None, tool_calls=None, audio=None); completion_obj: {'content': ''}
self.sent_first_chunk: True
completion_obj: {'content': ''}, model_response.choices[0]: StreamingChoices(finish_reason=None, index=0, delta=Delta(provider_specific_fields=None, content=None, role=None, function_call=None, tool_calls=None, audio=None), logprobs=None), response_obj: {'text': '', 'is_finished': False, 'finish_reason': '', 'usage': None, 'index': 0, 'tool_use': None}
model_response finish reason 3: None; response_obj={'text': '', 'is_finished': False, 'finish_reason': '', 'usage': None, 'index': 0, 'tool_use': None}
model_response.choices[0].delta: Delta(provider_specific_fields=None, content=None, role=None, function_call=None, tool_calls=None, audio=None); completion_obj: {'content': ''}
self.sent_first_chunk: True
completion_obj: {'content': ''}, model_response.choices[0]: StreamingChoices(finish_reason=None, index=0, delta=Delta(provider_specific_fields=None, content=None, role=None, function_call=None, tool_calls=None, audio=None), logprobs=None), response_obj: {'text': '', 'is_finished': False, 'finish_reason': '', 'usage': None, 'index': 0, 'tool_use': None}

Raw OpenAI Chunk
ModelResponseStream(id='chatcmpl-1e246dec-1357-4ceb-948f-03d49e55b5f9', created=1762261918, model=None, object='chat.completion.chunk', system_fingerprint=None, choices=[StreamingChoices(finish_reason=None, index=0, delta=Delta(provider_specific_fields=None, content=')?\n2. **Set', role=None, function_call=None, tool_calls=None, audio=None), logprobs=None)], provider_specific_fields=None, usage=None)

model_response finish reason 3: None; response_obj={'text': ')?\n2. **Set', 'is_finished': False, 'finish_reason': None, 'logprobs': None, 'original_chunk': ModelResponseStream(id='chatcmpl-1e246dec-1357-4ceb-948f-03d49e55b5f9', created=1762261918, model=None, object='chat.completion.chunk', system_fingerprint=None, choices=[StreamingChoices(finish_reason=None, index=0, delta=Delta(provider_specific_fields=None, content=')?\n2. **Set', role=None, function_call=None, tool_calls=None, audio=None), logprobs=None)], provider_specific_fields=None, usage=None), 'usage': None}
original delta: {'provider_specific_fields': None, 'content': ')?\n2. **Set', 'role': None, 'function_call': None, 'tool_calls': None, 'audio': None}
new delta: Delta(provider_specific_fields=None, content=')?\n2. **Set', role=None, function_call=None, tool_calls=None, audio=None)
model_response.choices[0].delta: Delta(provider_specific_fields=None, content=')?\n2. **Set', role=None, function_call=None, tool_calls=None, audio=None); completion_obj: {'content': ')?\n2. **Set'}
self.sent_first_chunk: True
completion_obj: {'content': ')?\n2. **Set'}, model_response.choices[0]: StreamingChoices(finish_reason=None, index=0, delta=Delta(provider_specific_fields=None, content=')?\n2. **Set', role=None, function_call=None, tool_calls=None, audio=None), logprobs=None), response_obj: {'text': ')?\n2. **Set', 'is_finished': False, 'finish_reason': None, 'logprobs': None, 'original_chunk': ModelResponseStream(id='chatcmpl-1e246dec-1357-4ceb-948f-03d49e55b5f9', created=1762261918, model=None, object='chat.completion.chunk', system_fingerprint=None, choices=[StreamingChoices(finish_reason=None, index=0, delta=Delta(provider_specific_fields=None, content=')?\n2. **Set', role=None, function_call=None, tool_calls=None, audio=None), logprobs=None)], provider_specific_fields=None, usage=None), 'usage': None}
choice_json: {'index': 0, 'delta': {'provider_specific_fields': None, 'content': ')?\n2. **Set', 'role': None, 'function_call': None, 'tool_calls': None, 'audio': None}, 'logprobs': None}
choices in streaming: [StreamingChoices(finish_reason=None, index=0, delta=Delta(provider_specific_fields=None, content=')?\n2. **Set', role=None, function_call=None, tool_calls=None, audio=None), logprobs=None)]
final returned processed chunk: ModelResponseStream(id='chatcmpl-1e246dec-1357-4ceb-948f-03d49e55b5f9', created=1762261907, model='claude-sonnet-4-5-20250929', object='chat.completion.chunk', system_fingerprint=None, choices=[StreamingChoices(finish_reason=None, index=0, delta=Delta(provider_specific_fields=None, content=')?\n2. **Set', role=None, function_call=None, tool_calls=None, audio=None), logprobs=None)], provider_specific_fields=None, citations=None)
model_response finish reason 3: None; response_obj={'text': '', 'is_finished': False, 'finish_reason': '', 'usage': None, 'index': 0, 'tool_use': None}
model_response.choices[0].delta: Delta(provider_specific_fields=None, content=None, role=None, function_call=None, tool_calls=None, audio=None); completion_obj: {'content': ''}
self.sent_first_chunk: True
completion_obj: {'content': ''}, model_response.choices[0]: StreamingChoices(finish_reason=None, index=0, delta=Delta(provider_specific_fields=None, content=None, role=None, function_call=None, tool_calls=None, audio=None), logprobs=None), response_obj: {'text': '', 'is_finished': False, 'finish_reason': '', 'usage': None, 'index': 0, 'tool_use': None}
model_response finish reason 3: None; response_obj={'text': '', 'is_finished': False, 'finish_reason': '', 'usage': None, 'index': 0, 'tool_use': None}
model_response.choices[0].delta: Delta(provider_specific_fields=None, content=None, role=None, function_call=None, tool_calls=None, audio=None); completion_obj: {'content': ''}
self.sent_first_chunk: True
completion_obj: {'content': ''}, model_response.choices[0]: StreamingChoices(finish_reason=None, index=0, delta=Delta(provider_specific_fields=None, content=None, role=None, function_call=None, tool_calls=None, audio=None), logprobs=None), response_obj: {'text': '', 'is_finished': False, 'finish_reason': '', 'usage': None, 'index': 0, 'tool_use': None}

Raw OpenAI Chunk
ModelResponseStream(id='chatcmpl-1e246dec-1357-4ceb-948f-03d49e55b5f9', created=1762261918, model=None, object='chat.completion.chunk', system_fingerprint=None, choices=[StreamingChoices(finish_reason=None, index=0, delta=Delta(provider_specific_fields=None, content=' up the', role=None, function_call=None, tool_calls=None, audio=None), logprobs=None)], provider_specific_fields=None, usage=None)

model_response finish reason 3: None; response_obj={'text': ' up the', 'is_finished': False, 'finish_reason': None, 'logprobs': None, 'original_chunk': ModelResponseStream(id='chatcmpl-1e246dec-1357-4ceb-948f-03d49e55b5f9', created=1762261918, model=None, object='chat.completion.chunk', system_fingerprint=None, choices=[StreamingChoices(finish_reason=None, index=0, delta=Delta(provider_specific_fields=None, content=' up the', role=None, function_call=None, tool_calls=None, audio=None), logprobs=None)], provider_specific_fields=None, usage=None), 'usage': None}
original delta: {'provider_specific_fields': None, 'content': ' up the', 'role': None, 'function_call': None, 'tool_calls': None, 'audio': None}
new delta: Delta(provider_specific_fields=None, content=' up the', role=None, function_call=None, tool_calls=None, audio=None)
model_response.choices[0].delta: Delta(provider_specific_fields=None, content=' up the', role=None, function_call=None, tool_calls=None, audio=None); completion_obj: {'content': ' up the'}
self.sent_first_chunk: True
completion_obj: {'content': ' up the'}, model_response.choices[0]: StreamingChoices(finish_reason=None, index=0, delta=Delta(provider_specific_fields=None, content=' up the', role=None, function_call=None, tool_calls=None, audio=None), logprobs=None), response_obj: {'text': ' up the', 'is_finished': False, 'finish_reason': None, 'logprobs': None, 'original_chunk': ModelResponseStream(id='chatcmpl-1e246dec-1357-4ceb-948f-03d49e55b5f9', created=1762261918, model=None, object='chat.completion.chunk', system_fingerprint=None, choices=[StreamingChoices(finish_reason=None, index=0, delta=Delta(provider_specific_fields=None, content=' up the', role=None, function_call=None, tool_calls=None, audio=None), logprobs=None)], provider_specific_fields=None, usage=None), 'usage': None}
choice_json: {'index': 0, 'delta': {'provider_specific_fields': None, 'content': ' up the', 'role': None, 'function_call': None, 'tool_calls': None, 'audio': None}, 'logprobs': None}
choices in streaming: [StreamingChoices(finish_reason=None, index=0, delta=Delta(provider_specific_fields=None, content=' up the', role=None, function_call=None, tool_calls=None, audio=None), logprobs=None)]
final returned processed chunk: ModelResponseStream(id='chatcmpl-1e246dec-1357-4ceb-948f-03d49e55b5f9', created=1762261907, model='claude-sonnet-4-5-20250929', object='chat.completion.chunk', system_fingerprint=None, choices=[StreamingChoices(finish_reason=None, index=0, delta=Delta(provider_specific_fields=None, content=' up the', role=None, function_call=None, tool_calls=None, audio=None), logprobs=None)], provider_specific_fields=None, citations=None)
model_response finish reason 3: None; response_obj={'text': '', 'is_finished': False, 'finish_reason': '', 'usage': None, 'index': 0, 'tool_use': None}
model_response.choices[0].delta: Delta(provider_specific_fields=None, content=None, role=None, function_call=None, tool_calls=None, audio=None); completion_obj: {'content': ''}
self.sent_first_chunk: True
completion_obj: {'content': ''}, model_response.choices[0]: StreamingChoices(finish_reason=None, index=0, delta=Delta(provider_specific_fields=None, content=None, role=None, function_call=None, tool_calls=None, audio=None), logprobs=None), response_obj: {'text': '', 'is_finished': False, 'finish_reason': '', 'usage': None, 'index': 0, 'tool_use': None}
model_response finish reason 3: None; response_obj={'text': '', 'is_finished': False, 'finish_reason': '', 'usage': None, 'index': 0, 'tool_use': None}
model_response.choices[0].delta: Delta(provider_specific_fields=None, content=None, role=None, function_call=None, tool_calls=None, audio=None); completion_obj: {'content': ''}
self.sent_first_chunk: True
completion_obj: {'content': ''}, model_response.choices[0]: StreamingChoices(finish_reason=None, index=0, delta=Delta(provider_specific_fields=None, content=None, role=None, function_call=None, tool_calls=None, audio=None), logprobs=None), response_obj: {'text': '', 'is_finished': False, 'finish_reason': '', 'usage': None, 'index': 0, 'tool_use': None}

Raw OpenAI Chunk
ModelResponseStream(id='chatcmpl-1e246dec-1357-4ceb-948f-03d49e55b5f9', created=1762261918, model=None, object='chat.completion.chunk', system_fingerprint=None, choices=[StreamingChoices(finish_reason=None, index=0, delta=Delta(provider_specific_fields=None, content=' intercept', role=None, function_call=None, tool_calls=None, audio=None), logprobs=None)], provider_specific_fields=None, usage=None)

model_response finish reason 3: None; response_obj={'text': ' intercept', 'is_finished': False, 'finish_reason': None, 'logprobs': None, 'original_chunk': ModelResponseStream(id='chatcmpl-1e246dec-1357-4ceb-948f-03d49e55b5f9', created=1762261918, model=None, object='chat.completion.chunk', system_fingerprint=None, choices=[StreamingChoices(finish_reason=None, index=0, delta=Delta(provider_specific_fields=None, content=' intercept', role=None, function_call=None, tool_calls=None, audio=None), logprobs=None)], provider_specific_fields=None, usage=None), 'usage': None}
original delta: {'provider_specific_fields': None, 'content': ' intercept', 'role': None, 'function_call': None, 'tool_calls': None, 'audio': None}
new delta: Delta(provider_specific_fields=None, content=' intercept', role=None, function_call=None, tool_calls=None, audio=None)
model_response.choices[0].delta: Delta(provider_specific_fields=None, content=' intercept', role=None, function_call=None, tool_calls=None, audio=None); completion_obj: {'content': ' intercept'}
self.sent_first_chunk: True
completion_obj: {'content': ' intercept'}, model_response.choices[0]: StreamingChoices(finish_reason=None, index=0, delta=Delta(provider_specific_fields=None, content=' intercept', role=None, function_call=None, tool_calls=None, audio=None), logprobs=None), response_obj: {'text': ' intercept', 'is_finished': False, 'finish_reason': None, 'logprobs': None, 'original_chunk': ModelResponseStream(id='chatcmpl-1e246dec-1357-4ceb-948f-03d49e55b5f9', created=1762261918, model=None, object='chat.completion.chunk', system_fingerprint=None, choices=[StreamingChoices(finish_reason=None, index=0, delta=Delta(provider_specific_fields=None, content=' intercept', role=None, function_call=None, tool_calls=None, audio=None), logprobs=None)], provider_specific_fields=None, usage=None), 'usage': None}
choice_json: {'index': 0, 'delta': {'provider_specific_fields': None, 'content': ' intercept', 'role': None, 'function_call': None, 'tool_calls': None, 'audio': None}, 'logprobs': None}
choices in streaming: [StreamingChoices(finish_reason=None, index=0, delta=Delta(provider_specific_fields=None, content=' intercept', role=None, function_call=None, tool_calls=None, audio=None), logprobs=None)]
final returned processed chunk: ModelResponseStream(id='chatcmpl-1e246dec-1357-4ceb-948f-03d49e55b5f9', created=1762261907, model='claude-sonnet-4-5-20250929', object='chat.completion.chunk', system_fingerprint=None, choices=[StreamingChoices(finish_reason=None, index=0, delta=Delta(provider_specific_fields=None, content=' intercept', role=None, function_call=None, tool_calls=None, audio=None), logprobs=None)], provider_specific_fields=None, citations=None)
model_response finish reason 3: None; response_obj={'text': '', 'is_finished': False, 'finish_reason': '', 'usage': None, 'index': 0, 'tool_use': None}
model_response.choices[0].delta: Delta(provider_specific_fields=None, content=None, role=None, function_call=None, tool_calls=None, audio=None); completion_obj: {'content': ''}
self.sent_first_chunk: True
completion_obj: {'content': ''}, model_response.choices[0]: StreamingChoices(finish_reason=None, index=0, delta=Delta(provider_specific_fields=None, content=None, role=None, function_call=None, tool_calls=None, audio=None), logprobs=None), response_obj: {'text': '', 'is_finished': False, 'finish_reason': '', 'usage': None, 'index': 0, 'tool_use': None}
model_response finish reason 3: None; response_obj={'text': '', 'is_finished': False, 'finish_reason': '', 'usage': None, 'index': 0, 'tool_use': None}
model_response.choices[0].delta: Delta(provider_specific_fields=None, content=None, role=None, function_call=None, tool_calls=None, audio=None); completion_obj: {'content': ''}
self.sent_first_chunk: True
completion_obj: {'content': ''}, model_response.choices[0]: StreamingChoices(finish_reason=None, index=0, delta=Delta(provider_specific_fields=None, content=None, role=None, function_call=None, tool_calls=None, audio=None), logprobs=None), response_obj: {'text': '', 'is_finished': False, 'finish_reason': '', 'usage': None, 'index': 0, 'tool_use': None}

Raw OpenAI Chunk
ModelResponseStream(id='chatcmpl-1e246dec-1357-4ceb-948f-03d49e55b5f9', created=1762261918, model=None, object='chat.completion.chunk', system_fingerprint=None, choices=[StreamingChoices(finish_reason=None, index=0, delta=Delta(provider_specific_fields=None, content='or proxy', role=None, function_call=None, tool_calls=None, audio=None), logprobs=None)], provider_specific_fields=None, usage=None)

model_response finish reason 3: None; response_obj={'text': 'or proxy', 'is_finished': False, 'finish_reason': None, 'logprobs': None, 'original_chunk': ModelResponseStream(id='chatcmpl-1e246dec-1357-4ceb-948f-03d49e55b5f9', created=1762261918, model=None, object='chat.completion.chunk', system_fingerprint=None, choices=[StreamingChoices(finish_reason=None, index=0, delta=Delta(provider_specific_fields=None, content='or proxy', role=None, function_call=None, tool_calls=None, audio=None), logprobs=None)], provider_specific_fields=None, usage=None), 'usage': None}
original delta: {'provider_specific_fields': None, 'content': 'or proxy', 'role': None, 'function_call': None, 'tool_calls': None, 'audio': None}
new delta: Delta(provider_specific_fields=None, content='or proxy', role=None, function_call=None, tool_calls=None, audio=None)
model_response.choices[0].delta: Delta(provider_specific_fields=None, content='or proxy', role=None, function_call=None, tool_calls=None, audio=None); completion_obj: {'content': 'or proxy'}
self.sent_first_chunk: True
completion_obj: {'content': 'or proxy'}, model_response.choices[0]: StreamingChoices(finish_reason=None, index=0, delta=Delta(provider_specific_fields=None, content='or proxy', role=None, function_call=None, tool_calls=None, audio=None), logprobs=None), response_obj: {'text': 'or proxy', 'is_finished': False, 'finish_reason': None, 'logprobs': None, 'original_chunk': ModelResponseStream(id='chatcmpl-1e246dec-1357-4ceb-948f-03d49e55b5f9', created=1762261918, model=None, object='chat.completion.chunk', system_fingerprint=None, choices=[StreamingChoices(finish_reason=None, index=0, delta=Delta(provider_specific_fields=None, content='or proxy', role=None, function_call=None, tool_calls=None, audio=None), logprobs=None)], provider_specific_fields=None, usage=None), 'usage': None}
choice_json: {'index': 0, 'delta': {'provider_specific_fields': None, 'content': 'or proxy', 'role': None, 'function_call': None, 'tool_calls': None, 'audio': None}, 'logprobs': None}
choices in streaming: [StreamingChoices(finish_reason=None, index=0, delta=Delta(provider_specific_fields=None, content='or proxy', role=None, function_call=None, tool_calls=None, audio=None), logprobs=None)]
final returned processed chunk: ModelResponseStream(id='chatcmpl-1e246dec-1357-4ceb-948f-03d49e55b5f9', created=1762261907, model='claude-sonnet-4-5-20250929', object='chat.completion.chunk', system_fingerprint=None, choices=[StreamingChoices(finish_reason=None, index=0, delta=Delta(provider_specific_fields=None, content='or proxy', role=None, function_call=None, tool_calls=None, audio=None), logprobs=None)], provider_specific_fields=None, citations=None)
model_response finish reason 3: None; response_obj={'text': '', 'is_finished': False, 'finish_reason': '', 'usage': None, 'index': 0, 'tool_use': None}
model_response.choices[0].delta: Delta(provider_specific_fields=None, content=None, role=None, function_call=None, tool_calls=None, audio=None); completion_obj: {'content': ''}
self.sent_first_chunk: True
completion_obj: {'content': ''}, model_response.choices[0]: StreamingChoices(finish_reason=None, index=0, delta=Delta(provider_specific_fields=None, content=None, role=None, function_call=None, tool_calls=None, audio=None), logprobs=None), response_obj: {'text': '', 'is_finished': False, 'finish_reason': '', 'usage': None, 'index': 0, 'tool_use': None}
model_response finish reason 3: None; response_obj={'text': '', 'is_finished': False, 'finish_reason': '', 'usage': None, 'index': 0, 'tool_use': None}
model_response.choices[0].delta: Delta(provider_specific_fields=None, content=None, role=None, function_call=None, tool_calls=None, audio=None); completion_obj: {'content': ''}
self.sent_first_chunk: True
completion_obj: {'content': ''}, model_response.choices[0]: StreamingChoices(finish_reason=None, index=0, delta=Delta(provider_specific_fields=None, content=None, role=None, function_call=None, tool_calls=None, audio=None), logprobs=None), response_obj: {'text': '', 'is_finished': False, 'finish_reason': '', 'usage': None, 'index': 0, 'tool_use': None}

Raw OpenAI Chunk
ModelResponseStream(id='chatcmpl-1e246dec-1357-4ceb-948f-03d49e55b5f9', created=1762261918, model=None, object='chat.completion.chunk', system_fingerprint=None, choices=[StreamingChoices(finish_reason=None, index=0, delta=Delta(provider_specific_fields=None, content='** to properly', role=None, function_call=None, tool_calls=None, audio=None), logprobs=None)], provider_specific_fields=None, usage=None)

model_response finish reason 3: None; response_obj={'text': '** to properly', 'is_finished': False, 'finish_reason': None, 'logprobs': None, 'original_chunk': ModelResponseStream(id='chatcmpl-1e246dec-1357-4ceb-948f-03d49e55b5f9', created=1762261918, model=None, object='chat.completion.chunk', system_fingerprint=None, choices=[StreamingChoices(finish_reason=None, index=0, delta=Delta(provider_specific_fields=None, content='** to properly', role=None, function_call=None, tool_calls=None, audio=None), logprobs=None)], provider_specific_fields=None, usage=None), 'usage': None}
original delta: {'provider_specific_fields': None, 'content': '** to properly', 'role': None, 'function_call': None, 'tool_calls': None, 'audio': None}
new delta: Delta(provider_specific_fields=None, content='** to properly', role=None, function_call=None, tool_calls=None, audio=None)
model_response.choices[0].delta: Delta(provider_specific_fields=None, content='** to properly', role=None, function_call=None, tool_calls=None, audio=None); completion_obj: {'content': '** to properly'}
self.sent_first_chunk: True
completion_obj: {'content': '** to properly'}, model_response.choices[0]: StreamingChoices(finish_reason=None, index=0, delta=Delta(provider_specific_fields=None, content='** to properly', role=None, function_call=None, tool_calls=None, audio=None), logprobs=None), response_obj: {'text': '** to properly', 'is_finished': False, 'finish_reason': None, 'logprobs': None, 'original_chunk': ModelResponseStream(id='chatcmpl-1e246dec-1357-4ceb-948f-03d49e55b5f9', created=1762261918, model=None, object='chat.completion.chunk', system_fingerprint=None, choices=[StreamingChoices(finish_reason=None, index=0, delta=Delta(provider_specific_fields=None, content='** to properly', role=None, function_call=None, tool_calls=None, audio=None), logprobs=None)], provider_specific_fields=None, usage=None), 'usage': None}
choice_json: {'index': 0, 'delta': {'provider_specific_fields': None, 'content': '** to properly', 'role': None, 'function_call': None, 'tool_calls': None, 'audio': None}, 'logprobs': None}
choices in streaming: [StreamingChoices(finish_reason=None, index=0, delta=Delta(provider_specific_fields=None, content='** to properly', role=None, function_call=None, tool_calls=None, audio=None), logprobs=None)]
final returned processed chunk: ModelResponseStream(id='chatcmpl-1e246dec-1357-4ceb-948f-03d49e55b5f9', created=1762261907, model='claude-sonnet-4-5-20250929', object='chat.completion.chunk', system_fingerprint=None, choices=[StreamingChoices(finish_reason=None, index=0, delta=Delta(provider_specific_fields=None, content='** to properly', role=None, function_call=None, tool_calls=None, audio=None), logprobs=None)], provider_specific_fields=None, citations=None)
model_response finish reason 3: None; response_obj={'text': '', 'is_finished': False, 'finish_reason': '', 'usage': None, 'index': 0, 'tool_use': None}
model_response.choices[0].delta: Delta(provider_specific_fields=None, content=None, role=None, function_call=None, tool_calls=None, audio=None); completion_obj: {'content': ''}
self.sent_first_chunk: True
completion_obj: {'content': ''}, model_response.choices[0]: StreamingChoices(finish_reason=None, index=0, delta=Delta(provider_specific_fields=None, content=None, role=None, function_call=None, tool_calls=None, audio=None), logprobs=None), response_obj: {'text': '', 'is_finished': False, 'finish_reason': '', 'usage': None, 'index': 0, 'tool_use': None}
model_response finish reason 3: None; response_obj={'text': '', 'is_finished': False, 'finish_reason': '', 'usage': None, 'index': 0, 'tool_use': None}
model_response.choices[0].delta: Delta(provider_specific_fields=None, content=None, role=None, function_call=None, tool_calls=None, audio=None); completion_obj: {'content': ''}
self.sent_first_chunk: True
completion_obj: {'content': ''}, model_response.choices[0]: StreamingChoices(finish_reason=None, index=0, delta=Delta(provider_specific_fields=None, content=None, role=None, function_call=None, tool_calls=None, audio=None), logprobs=None), response_obj: {'text': '', 'is_finished': False, 'finish_reason': '', 'usage': None, 'index': 0, 'tool_use': None}

Raw OpenAI Chunk
ModelResponseStream(id='chatcmpl-1e246dec-1357-4ceb-948f-03d49e55b5f9', created=1762261918, model=None, object='chat.completion.chunk', system_fingerprint=None, choices=[StreamingChoices(finish_reason=None, index=0, delta=Delta(provider_specific_fields=None, content=' identify', role=None, function_call=None, tool_calls=None, audio=None), logprobs=None)], provider_specific_fields=None, usage=None)

model_response finish reason 3: None; response_obj={'text': ' identify', 'is_finished': False, 'finish_reason': None, 'logprobs': None, 'original_chunk': ModelResponseStream(id='chatcmpl-1e246dec-1357-4ceb-948f-03d49e55b5f9', created=1762261918, model=None, object='chat.completion.chunk', system_fingerprint=None, choices=[StreamingChoices(finish_reason=None, index=0, delta=Delta(provider_specific_fields=None, content=' identify', role=None, function_call=None, tool_calls=None, audio=None), logprobs=None)], provider_specific_fields=None, usage=None), 'usage': None}
original delta: {'provider_specific_fields': None, 'content': ' identify', 'role': None, 'function_call': None, 'tool_calls': None, 'audio': None}
new delta: Delta(provider_specific_fields=None, content=' identify', role=None, function_call=None, tool_calls=None, audio=None)
model_response.choices[0].delta: Delta(provider_specific_fields=None, content=' identify', role=None, function_call=None, tool_calls=None, audio=None); completion_obj: {'content': ' identify'}
self.sent_first_chunk: True
completion_obj: {'content': ' identify'}, model_response.choices[0]: StreamingChoices(finish_reason=None, index=0, delta=Delta(provider_specific_fields=None, content=' identify', role=None, function_call=None, tool_calls=None, audio=None), logprobs=None), response_obj: {'text': ' identify', 'is_finished': False, 'finish_reason': None, 'logprobs': None, 'original_chunk': ModelResponseStream(id='chatcmpl-1e246dec-1357-4ceb-948f-03d49e55b5f9', created=1762261918, model=None, object='chat.completion.chunk', system_fingerprint=None, choices=[StreamingChoices(finish_reason=None, index=0, delta=Delta(provider_specific_fields=None, content=' identify', role=None, function_call=None, tool_calls=None, audio=None), logprobs=None)], provider_specific_fields=None, usage=None), 'usage': None}
choice_json: {'index': 0, 'delta': {'provider_specific_fields': None, 'content': ' identify', 'role': None, 'function_call': None, 'tool_calls': None, 'audio': None}, 'logprobs': None}
choices in streaming: [StreamingChoices(finish_reason=None, index=0, delta=Delta(provider_specific_fields=None, content=' identify', role=None, function_call=None, tool_calls=None, audio=None), logprobs=None)]
final returned processed chunk: ModelResponseStream(id='chatcmpl-1e246dec-1357-4ceb-948f-03d49e55b5f9', created=1762261907, model='claude-sonnet-4-5-20250929', object='chat.completion.chunk', system_fingerprint=None, choices=[StreamingChoices(finish_reason=None, index=0, delta=Delta(provider_specific_fields=None, content=' identify', role=None, function_call=None, tool_calls=None, audio=None), logprobs=None)], provider_specific_fields=None, citations=None)
model_response finish reason 3: None; response_obj={'text': '', 'is_finished': False, 'finish_reason': '', 'usage': None, 'index': 0, 'tool_use': None}
model_response.choices[0].delta: Delta(provider_specific_fields=None, content=None, role=None, function_call=None, tool_calls=None, audio=None); completion_obj: {'content': ''}
self.sent_first_chunk: True
completion_obj: {'content': ''}, model_response.choices[0]: StreamingChoices(finish_reason=None, index=0, delta=Delta(provider_specific_fields=None, content=None, role=None, function_call=None, tool_calls=None, audio=None), logprobs=None), response_obj: {'text': '', 'is_finished': False, 'finish_reason': '', 'usage': None, 'index': 0, 'tool_use': None}
model_response finish reason 3: None; response_obj={'text': '', 'is_finished': False, 'finish_reason': '', 'usage': None, 'index': 0, 'tool_use': None}
model_response.choices[0].delta: Delta(provider_specific_fields=None, content=None, role=None, function_call=None, tool_calls=None, audio=None); completion_obj: {'content': ''}
self.sent_first_chunk: True
completion_obj: {'content': ''}, model_response.choices[0]: StreamingChoices(finish_reason=None, index=0, delta=Delta(provider_specific_fields=None, content=None, role=None, function_call=None, tool_calls=None, audio=None), logprobs=None), response_obj: {'text': '', 'is_finished': False, 'finish_reason': '', 'usage': None, 'index': 0, 'tool_use': None}

Raw OpenAI Chunk
ModelResponseStream(id='chatcmpl-1e246dec-1357-4ceb-948f-03d49e55b5f9', created=1762261918, model=None, object='chat.completion.chunk', system_fingerprint=None, choices=[StreamingChoices(finish_reason=None, index=0, delta=Delta(provider_specific_fields=None, content=' you', role=None, function_call=None, tool_calls=None, audio=None), logprobs=None)], provider_specific_fields=None, usage=None)

model_response finish reason 3: None; response_obj={'text': ' you', 'is_finished': False, 'finish_reason': None, 'logprobs': None, 'original_chunk': ModelResponseStream(id='chatcmpl-1e246dec-1357-4ceb-948f-03d49e55b5f9', created=1762261918, model=None, object='chat.completion.chunk', system_fingerprint=None, choices=[StreamingChoices(finish_reason=None, index=0, delta=Delta(provider_specific_fields=None, content=' you', role=None, function_call=None, tool_calls=None, audio=None), logprobs=None)], provider_specific_fields=None, usage=None), 'usage': None}
original delta: {'provider_specific_fields': None, 'content': ' you', 'role': None, 'function_call': None, 'tool_calls': None, 'audio': None}
new delta: Delta(provider_specific_fields=None, content=' you', role=None, function_call=None, tool_calls=None, audio=None)
model_response.choices[0].delta: Delta(provider_specific_fields=None, content=' you', role=None, function_call=None, tool_calls=None, audio=None); completion_obj: {'content': ' you'}
self.sent_first_chunk: True
completion_obj: {'content': ' you'}, model_response.choices[0]: StreamingChoices(finish_reason=None, index=0, delta=Delta(provider_specific_fields=None, content=' you', role=None, function_call=None, tool_calls=None, audio=None), logprobs=None), response_obj: {'text': ' you', 'is_finished': False, 'finish_reason': None, 'logprobs': None, 'original_chunk': ModelResponseStream(id='chatcmpl-1e246dec-1357-4ceb-948f-03d49e55b5f9', created=1762261918, model=None, object='chat.completion.chunk', system_fingerprint=None, choices=[StreamingChoices(finish_reason=None, index=0, delta=Delta(provider_specific_fields=None, content=' you', role=None, function_call=None, tool_calls=None, audio=None), logprobs=None)], provider_specific_fields=None, usage=None), 'usage': None}
choice_json: {'index': 0, 'delta': {'provider_specific_fields': None, 'content': ' you', 'role': None, 'function_call': None, 'tool_calls': None, 'audio': None}, 'logprobs': None}
choices in streaming: [StreamingChoices(finish_reason=None, index=0, delta=Delta(provider_specific_fields=None, content=' you', role=None, function_call=None, tool_calls=None, audio=None), logprobs=None)]
final returned processed chunk: ModelResponseStream(id='chatcmpl-1e246dec-1357-4ceb-948f-03d49e55b5f9', created=1762261907, model='claude-sonnet-4-5-20250929', object='chat.completion.chunk', system_fingerprint=None, choices=[StreamingChoices(finish_reason=None, index=0, delta=Delta(provider_specific_fields=None, content=' you', role=None, function_call=None, tool_calls=None, audio=None), logprobs=None)], provider_specific_fields=None, citations=None)
model_response finish reason 3: None; response_obj={'text': '', 'is_finished': False, 'finish_reason': '', 'usage': None, 'index': 0, 'tool_use': None}
model_response.choices[0].delta: Delta(provider_specific_fields=None, content=None, role=None, function_call=None, tool_calls=None, audio=None); completion_obj: {'content': ''}
self.sent_first_chunk: True
completion_obj: {'content': ''}, model_response.choices[0]: StreamingChoices(finish_reason=None, index=0, delta=Delta(provider_specific_fields=None, content=None, role=None, function_call=None, tool_calls=None, audio=None), logprobs=None), response_obj: {'text': '', 'is_finished': False, 'finish_reason': '', 'usage': None, 'index': 0, 'tool_use': None}
model_response finish reason 3: None; response_obj={'text': '', 'is_finished': False, 'finish_reason': '', 'usage': None, 'index': 0, 'tool_use': None}
model_response.choices[0].delta: Delta(provider_specific_fields=None, content=None, role=None, function_call=None, tool_calls=None, audio=None); completion_obj: {'content': ''}
self.sent_first_chunk: True
completion_obj: {'content': ''}, model_response.choices[0]: StreamingChoices(finish_reason=None, index=0, delta=Delta(provider_specific_fields=None, content=None, role=None, function_call=None, tool_calls=None, audio=None), logprobs=None), response_obj: {'text': '', 'is_finished': False, 'finish_reason': '', 'usage': None, 'index': 0, 'tool_use': None}

Raw OpenAI Chunk
ModelResponseStream(id='chatcmpl-1e246dec-1357-4ceb-948f-03d49e55b5f9', created=1762261918, model=None, object='chat.completion.chunk', system_fingerprint=None, choices=[StreamingChoices(finish_reason=None, index=0, delta=Delta(provider_specific_fields=None, content=' as a Supermemory user', role=None, function_call=None, tool_calls=None, audio=None), logprobs=None)], provider_specific_fields=None, usage=None)

model_response finish reason 3: None; response_obj={'text': ' as a Supermemory user', 'is_finished': False, 'finish_reason': None, 'logprobs': None, 'original_chunk': ModelResponseStream(id='chatcmpl-1e246dec-1357-4ceb-948f-03d49e55b5f9', created=1762261918, model=None, object='chat.completion.chunk', system_fingerprint=None, choices=[StreamingChoices(finish_reason=None, index=0, delta=Delta(provider_specific_fields=None, content=' as a Supermemory user', role=None, function_call=None, tool_calls=None, audio=None), logprobs=None)], provider_specific_fields=None, usage=None), 'usage': None}
original delta: {'provider_specific_fields': None, 'content': ' as a Supermemory user', 'role': None, 'function_call': None, 'tool_calls': None, 'audio': None}
new delta: Delta(provider_specific_fields=None, content=' as a Supermemory user', role=None, function_call=None, tool_calls=None, audio=None)
model_response.choices[0].delta: Delta(provider_specific_fields=None, content=' as a Supermemory user', role=None, function_call=None, tool_calls=None, audio=None); completion_obj: {'content': ' as a Supermemory user'}
self.sent_first_chunk: True
completion_obj: {'content': ' as a Supermemory user'}, model_response.choices[0]: StreamingChoices(finish_reason=None, index=0, delta=Delta(provider_specific_fields=None, content=' as a Supermemory user', role=None, function_call=None, tool_calls=None, audio=None), logprobs=None), response_obj: {'text': ' as a Supermemory user', 'is_finished': False, 'finish_reason': None, 'logprobs': None, 'original_chunk': ModelResponseStream(id='chatcmpl-1e246dec-1357-4ceb-948f-03d49e55b5f9', created=1762261918, model=None, object='chat.completion.chunk', system_fingerprint=None, choices=[StreamingChoices(finish_reason=None, index=0, delta=Delta(provider_specific_fields=None, content=' as a Supermemory user', role=None, function_call=None, tool_calls=None, audio=None), logprobs=None)], provider_specific_fields=None, usage=None), 'usage': None}
choice_json: {'index': 0, 'delta': {'provider_specific_fields': None, 'content': ' as a Supermemory user', 'role': None, 'function_call': None, 'tool_calls': None, 'audio': None}, 'logprobs': None}
choices in streaming: [StreamingChoices(finish_reason=None, index=0, delta=Delta(provider_specific_fields=None, content=' as a Supermemory user', role=None, function_call=None, tool_calls=None, audio=None), logprobs=None)]
final returned processed chunk: ModelResponseStream(id='chatcmpl-1e246dec-1357-4ceb-948f-03d49e55b5f9', created=1762261907, model='claude-sonnet-4-5-20250929', object='chat.completion.chunk', system_fingerprint=None, choices=[StreamingChoices(finish_reason=None, index=0, delta=Delta(provider_specific_fields=None, content=' as a Supermemory user', role=None, function_call=None, tool_calls=None, audio=None), logprobs=None)], provider_specific_fields=None, citations=None)
model_response finish reason 3: None; response_obj={'text': '', 'is_finished': False, 'finish_reason': '', 'usage': None, 'index': 0, 'tool_use': None}
model_response.choices[0].delta: Delta(provider_specific_fields=None, content=None, role=None, function_call=None, tool_calls=None, audio=None); completion_obj: {'content': ''}
self.sent_first_chunk: True
completion_obj: {'content': ''}, model_response.choices[0]: StreamingChoices(finish_reason=None, index=0, delta=Delta(provider_specific_fields=None, content=None, role=None, function_call=None, tool_calls=None, audio=None), logprobs=None), response_obj: {'text': '', 'is_finished': False, 'finish_reason': '', 'usage': None, 'index': 0, 'tool_use': None}
model_response finish reason 3: None; response_obj={'text': '', 'is_finished': False, 'finish_reason': '', 'usage': None, 'index': 0, 'tool_use': None}
model_response.choices[0].delta: Delta(provider_specific_fields=None, content=None, role=None, function_call=None, tool_calls=None, audio=None); completion_obj: {'content': ''}
self.sent_first_chunk: True
completion_obj: {'content': ''}, model_response.choices[0]: StreamingChoices(finish_reason=None, index=0, delta=Delta(provider_specific_fields=None, content=None, role=None, function_call=None, tool_calls=None, audio=None), logprobs=None), response_obj: {'text': '', 'is_finished': False, 'finish_reason': '', 'usage': None, 'index': 0, 'tool_use': None}

Raw OpenAI Chunk
ModelResponseStream(id='chatcmpl-1e246dec-1357-4ceb-948f-03d49e55b5f9', created=1762261918, model=None, object='chat.completion.chunk', system_fingerprint=None, choices=[StreamingChoices(finish_reason=None, index=0, delta=Delta(provider_specific_fields=None, content=' with', role=None, function_call=None, tool_calls=None, audio=None), logprobs=None)], provider_specific_fields=None, usage=None)

model_response finish reason 3: None; response_obj={'text': ' with', 'is_finished': False, 'finish_reason': None, 'logprobs': None, 'original_chunk': ModelResponseStream(id='chatcmpl-1e246dec-1357-4ceb-948f-03d49e55b5f9', created=1762261918, model=None, object='chat.completion.chunk', system_fingerprint=None, choices=[StreamingChoices(finish_reason=None, index=0, delta=Delta(provider_specific_fields=None, content=' with', role=None, function_call=None, tool_calls=None, audio=None), logprobs=None)], provider_specific_fields=None, usage=None), 'usage': None}
original delta: {'provider_specific_fields': None, 'content': ' with', 'role': None, 'function_call': None, 'tool_calls': None, 'audio': None}
new delta: Delta(provider_specific_fields=None, content=' with', role=None, function_call=None, tool_calls=None, audio=None)
model_response.choices[0].delta: Delta(provider_specific_fields=None, content=' with', role=None, function_call=None, tool_calls=None, audio=None); completion_obj: {'content': ' with'}
self.sent_first_chunk: True
completion_obj: {'content': ' with'}, model_response.choices[0]: StreamingChoices(finish_reason=None, index=0, delta=Delta(provider_specific_fields=None, content=' with', role=None, function_call=None, tool_calls=None, audio=None), logprobs=None), response_obj: {'text': ' with', 'is_finished': False, 'finish_reason': None, 'logprobs': None, 'original_chunk': ModelResponseStream(id='chatcmpl-1e246dec-1357-4ceb-948f-03d49e55b5f9', created=1762261918, model=None, object='chat.completion.chunk', system_fingerprint=None, choices=[StreamingChoices(finish_reason=None, index=0, delta=Delta(provider_specific_fields=None, content=' with', role=None, function_call=None, tool_calls=None, audio=None), logprobs=None)], provider_specific_fields=None, usage=None), 'usage': None}
choice_json: {'index': 0, 'delta': {'provider_specific_fields': None, 'content': ' with', 'role': None, 'function_call': None, 'tool_calls': None, 'audio': None}, 'logprobs': None}
choices in streaming: [StreamingChoices(finish_reason=None, index=0, delta=Delta(provider_specific_fields=None, content=' with', role=None, function_call=None, tool_calls=None, audio=None), logprobs=None)]
final returned processed chunk: ModelResponseStream(id='chatcmpl-1e246dec-1357-4ceb-948f-03d49e55b5f9', created=1762261907, model='claude-sonnet-4-5-20250929', object='chat.completion.chunk', system_fingerprint=None, choices=[StreamingChoices(finish_reason=None, index=0, delta=Delta(provider_specific_fields=None, content=' with', role=None, function_call=None, tool_calls=None, audio=None), logprobs=None)], provider_specific_fields=None, citations=None)
model_response finish reason 3: None; response_obj={'text': '', 'is_finished': False, 'finish_reason': '', 'usage': None, 'index': 0, 'tool_use': None}
model_response.choices[0].delta: Delta(provider_specific_fields=None, content=None, role=None, function_call=None, tool_calls=None, audio=None); completion_obj: {'content': ''}
self.sent_first_chunk: True
completion_obj: {'content': ''}, model_response.choices[0]: StreamingChoices(finish_reason=None, index=0, delta=Delta(provider_specific_fields=None, content=None, role=None, function_call=None, tool_calls=None, audio=None), logprobs=None), response_obj: {'text': '', 'is_finished': False, 'finish_reason': '', 'usage': None, 'index': 0, 'tool_use': None}
model_response finish reason 3: None; response_obj={'text': '', 'is_finished': False, 'finish_reason': '', 'usage': None, 'index': 0, 'tool_use': None}
model_response.choices[0].delta: Delta(provider_specific_fields=None, content=None, role=None, function_call=None, tool_calls=None, audio=None); completion_obj: {'content': ''}
self.sent_first_chunk: True
completion_obj: {'content': ''}, model_response.choices[0]: StreamingChoices(finish_reason=None, index=0, delta=Delta(provider_specific_fields=None, content=None, role=None, function_call=None, tool_calls=None, audio=None), logprobs=None), response_obj: {'text': '', 'is_finished': False, 'finish_reason': '', 'usage': None, 'index': 0, 'tool_use': None}

Raw OpenAI Chunk
ModelResponseStream(id='chatcmpl-1e246dec-1357-4ceb-948f-03d49e55b5f9', created=1762261918, model=None, object='chat.completion.chunk', system_fingerprint=None, choices=[StreamingChoices(finish_reason=None, index=0, delta=Delta(provider_specific_fields=None, content=' your', role=None, function_call=None, tool_calls=None, audio=None), logprobs=None)], provider_specific_fields=None, usage=None)

model_response finish reason 3: None; response_obj={'text': ' your', 'is_finished': False, 'finish_reason': None, 'logprobs': None, 'original_chunk': ModelResponseStream(id='chatcmpl-1e246dec-1357-4ceb-948f-03d49e55b5f9', created=1762261918, model=None, object='chat.completion.chunk', system_fingerprint=None, choices=[StreamingChoices(finish_reason=None, index=0, delta=Delta(provider_specific_fields=None, content=' your', role=None, function_call=None, tool_calls=None, audio=None), logprobs=None)], provider_specific_fields=None, usage=None), 'usage': None}
original delta: {'provider_specific_fields': None, 'content': ' your', 'role': None, 'function_call': None, 'tool_calls': None, 'audio': None}
new delta: Delta(provider_specific_fields=None, content=' your', role=None, function_call=None, tool_calls=None, audio=None)
model_response.choices[0].delta: Delta(provider_specific_fields=None, content=' your', role=None, function_call=None, tool_calls=None, audio=None); completion_obj: {'content': ' your'}
self.sent_first_chunk: True
completion_obj: {'content': ' your'}, model_response.choices[0]: StreamingChoices(finish_reason=None, index=0, delta=Delta(provider_specific_fields=None, content=' your', role=None, function_call=None, tool_calls=None, audio=None), logprobs=None), response_obj: {'text': ' your', 'is_finished': False, 'finish_reason': None, 'logprobs': None, 'original_chunk': ModelResponseStream(id='chatcmpl-1e246dec-1357-4ceb-948f-03d49e55b5f9', created=1762261918, model=None, object='chat.completion.chunk', system_fingerprint=None, choices=[StreamingChoices(finish_reason=None, index=0, delta=Delta(provider_specific_fields=None, content=' your', role=None, function_call=None, tool_calls=None, audio=None), logprobs=None)], provider_specific_fields=None, usage=None), 'usage': None}
choice_json: {'index': 0, 'delta': {'provider_specific_fields': None, 'content': ' your', 'role': None, 'function_call': None, 'tool_calls': None, 'audio': None}, 'logprobs': None}
choices in streaming: [StreamingChoices(finish_reason=None, index=0, delta=Delta(provider_specific_fields=None, content=' your', role=None, function_call=None, tool_calls=None, audio=None), logprobs=None)]
final returned processed chunk: ModelResponseStream(id='chatcmpl-1e246dec-1357-4ceb-948f-03d49e55b5f9', created=1762261907, model='claude-sonnet-4-5-20250929', object='chat.completion.chunk', system_fingerprint=None, choices=[StreamingChoices(finish_reason=None, index=0, delta=Delta(provider_specific_fields=None, content=' your', role=None, function_call=None, tool_calls=None, audio=None), logprobs=None)], provider_specific_fields=None, citations=None)
model_response finish reason 3: None; response_obj={'text': '', 'is_finished': False, 'finish_reason': '', 'usage': None, 'index': 0, 'tool_use': None}
model_response.choices[0].delta: Delta(provider_specific_fields=None, content=None, role=None, function_call=None, tool_calls=None, audio=None); completion_obj: {'content': ''}
self.sent_first_chunk: True
completion_obj: {'content': ''}, model_response.choices[0]: StreamingChoices(finish_reason=None, index=0, delta=Delta(provider_specific_fields=None, content=None, role=None, function_call=None, tool_calls=None, audio=None), logprobs=None), response_obj: {'text': '', 'is_finished': False, 'finish_reason': '', 'usage': None, 'index': 0, 'tool_use': None}
model_response finish reason 3: None; response_obj={'text': '', 'is_finished': False, 'finish_reason': '', 'usage': None, 'index': 0, 'tool_use': None}
model_response.choices[0].delta: Delta(provider_specific_fields=None, content=None, role=None, function_call=None, tool_calls=None, audio=None); completion_obj: {'content': ''}
self.sent_first_chunk: True
completion_obj: {'content': ''}, model_response.choices[0]: StreamingChoices(finish_reason=None, index=0, delta=Delta(provider_specific_fields=None, content=None, role=None, function_call=None, tool_calls=None, audio=None), logprobs=None), response_obj: {'text': '', 'is_finished': False, 'finish_reason': '', 'usage': None, 'index': 0, 'tool_use': None}

Raw OpenAI Chunk
ModelResponseStream(id='chatcmpl-1e246dec-1357-4ceb-948f-03d49e55b5f9', created=1762261918, model=None, object='chat.completion.chunk', system_fingerprint=None, choices=[StreamingChoices(finish_reason=None, index=0, delta=Delta(provider_specific_fields=None, content=' API', role=None, function_call=None, tool_calls=None, audio=None), logprobs=None)], provider_specific_fields=None, usage=None)

model_response finish reason 3: None; response_obj={'text': ' API', 'is_finished': False, 'finish_reason': None, 'logprobs': None, 'original_chunk': ModelResponseStream(id='chatcmpl-1e246dec-1357-4ceb-948f-03d49e55b5f9', created=1762261918, model=None, object='chat.completion.chunk', system_fingerprint=None, choices=[StreamingChoices(finish_reason=None, index=0, delta=Delta(provider_specific_fields=None, content=' API', role=None, function_call=None, tool_calls=None, audio=None), logprobs=None)], provider_specific_fields=None, usage=None), 'usage': None}
original delta: {'provider_specific_fields': None, 'content': ' API', 'role': None, 'function_call': None, 'tool_calls': None, 'audio': None}
new delta: Delta(provider_specific_fields=None, content=' API', role=None, function_call=None, tool_calls=None, audio=None)
model_response.choices[0].delta: Delta(provider_specific_fields=None, content=' API', role=None, function_call=None, tool_calls=None, audio=None); completion_obj: {'content': ' API'}
self.sent_first_chunk: True
completion_obj: {'content': ' API'}, model_response.choices[0]: StreamingChoices(finish_reason=None, index=0, delta=Delta(provider_specific_fields=None, content=' API', role=None, function_call=None, tool_calls=None, audio=None), logprobs=None), response_obj: {'text': ' API', 'is_finished': False, 'finish_reason': None, 'logprobs': None, 'original_chunk': ModelResponseStream(id='chatcmpl-1e246dec-1357-4ceb-948f-03d49e55b5f9', created=1762261918, model=None, object='chat.completion.chunk', system_fingerprint=None, choices=[StreamingChoices(finish_reason=None, index=0, delta=Delta(provider_specific_fields=None, content=' API', role=None, function_call=None, tool_calls=None, audio=None), logprobs=None)], provider_specific_fields=None, usage=None), 'usage': None}
choice_json: {'index': 0, 'delta': {'provider_specific_fields': None, 'content': ' API', 'role': None, 'function_call': None, 'tool_calls': None, 'audio': None}, 'logprobs': None}
choices in streaming: [StreamingChoices(finish_reason=None, index=0, delta=Delta(provider_specific_fields=None, content=' API', role=None, function_call=None, tool_calls=None, audio=None), logprobs=None)]
final returned processed chunk: ModelResponseStream(id='chatcmpl-1e246dec-1357-4ceb-948f-03d49e55b5f9', created=1762261907, model='claude-sonnet-4-5-20250929', object='chat.completion.chunk', system_fingerprint=None, choices=[StreamingChoices(finish_reason=None, index=0, delta=Delta(provider_specific_fields=None, content=' API', role=None, function_call=None, tool_calls=None, audio=None), logprobs=None)], provider_specific_fields=None, citations=None)
model_response finish reason 3: None; response_obj={'text': '', 'is_finished': False, 'finish_reason': '', 'usage': None, 'index': 0, 'tool_use': None}
model_response.choices[0].delta: Delta(provider_specific_fields=None, content=None, role=None, function_call=None, tool_calls=None, audio=None); completion_obj: {'content': ''}
self.sent_first_chunk: True
completion_obj: {'content': ''}, model_response.choices[0]: StreamingChoices(finish_reason=None, index=0, delta=Delta(provider_specific_fields=None, content=None, role=None, function_call=None, tool_calls=None, audio=None), logprobs=None), response_obj: {'text': '', 'is_finished': False, 'finish_reason': '', 'usage': None, 'index': 0, 'tool_use': None}
model_response finish reason 3: None; response_obj={'text': '', 'is_finished': False, 'finish_reason': '', 'usage': None, 'index': 0, 'tool_use': None}
model_response.choices[0].delta: Delta(provider_specific_fields=None, content=None, role=None, function_call=None, tool_calls=None, audio=None); completion_obj: {'content': ''}
self.sent_first_chunk: True
completion_obj: {'content': ''}, model_response.choices[0]: StreamingChoices(finish_reason=None, index=0, delta=Delta(provider_specific_fields=None, content=None, role=None, function_call=None, tool_calls=None, audio=None), logprobs=None), response_obj: {'text': '', 'is_finished': False, 'finish_reason': '', 'usage': None, 'index': 0, 'tool_use': None}

Raw OpenAI Chunk
ModelResponseStream(id='chatcmpl-1e246dec-1357-4ceb-948f-03d49e55b5f9', created=1762261918, model=None, object='chat.completion.chunk', system_fingerprint=None, choices=[StreamingChoices(finish_reason=None, index=0, delta=Delta(provider_specific_fields=None, content=' key?\n3. **Review', role=None, function_call=None, tool_calls=None, audio=None), logprobs=None)], provider_specific_fields=None, usage=None)

model_response finish reason 3: None; response_obj={'text': ' key?\n3. **Review', 'is_finished': False, 'finish_reason': None, 'logprobs': None, 'original_chunk': ModelResponseStream(id='chatcmpl-1e246dec-1357-4ceb-948f-03d49e55b5f9', created=1762261918, model=None, object='chat.completion.chunk', system_fingerprint=None, choices=[StreamingChoices(finish_reason=None, index=0, delta=Delta(provider_specific_fields=None, content=' key?\n3. **Review', role=None, function_call=None, tool_calls=None, audio=None), logprobs=None)], provider_specific_fields=None, usage=None), 'usage': None}
original delta: {'provider_specific_fields': None, 'content': ' key?\n3. **Review', 'role': None, 'function_call': None, 'tool_calls': None, 'audio': None}
new delta: Delta(provider_specific_fields=None, content=' key?\n3. **Review', role=None, function_call=None, tool_calls=None, audio=None)
model_response.choices[0].delta: Delta(provider_specific_fields=None, content=' key?\n3. **Review', role=None, function_call=None, tool_calls=None, audio=None); completion_obj: {'content': ' key?\n3. **Review'}
self.sent_first_chunk: True
completion_obj: {'content': ' key?\n3. **Review'}, model_response.choices[0]: StreamingChoices(finish_reason=None, index=0, delta=Delta(provider_specific_fields=None, content=' key?\n3. **Review', role=None, function_call=None, tool_calls=None, audio=None), logprobs=None), response_obj: {'text': ' key?\n3. **Review', 'is_finished': False, 'finish_reason': None, 'logprobs': None, 'original_chunk': ModelResponseStream(id='chatcmpl-1e246dec-1357-4ceb-948f-03d49e55b5f9', created=1762261918, model=None, object='chat.completion.chunk', system_fingerprint=None, choices=[StreamingChoices(finish_reason=None, index=0, delta=Delta(provider_specific_fields=None, content=' key?\n3. **Review', role=None, function_call=None, tool_calls=None, audio=None), logprobs=None)], provider_specific_fields=None, usage=None), 'usage': None}
choice_json: {'index': 0, 'delta': {'provider_specific_fields': None, 'content': ' key?\n3. **Review', 'role': None, 'function_call': None, 'tool_calls': None, 'audio': None}, 'logprobs': None}
choices in streaming: [StreamingChoices(finish_reason=None, index=0, delta=Delta(provider_specific_fields=None, content=' key?\n3. **Review', role=None, function_call=None, tool_calls=None, audio=None), logprobs=None)]
final returned processed chunk: ModelResponseStream(id='chatcmpl-1e246dec-1357-4ceb-948f-03d49e55b5f9', created=1762261907, model='claude-sonnet-4-5-20250929', object='chat.completion.chunk', system_fingerprint=None, choices=[StreamingChoices(finish_reason=None, index=0, delta=Delta(provider_specific_fields=None, content=' key?\n3. **Review', role=None, function_call=None, tool_calls=None, audio=None), logprobs=None)], provider_specific_fields=None, citations=None)
model_response finish reason 3: None; response_obj={'text': '', 'is_finished': False, 'finish_reason': '', 'usage': None, 'index': 0, 'tool_use': None}
model_response.choices[0].delta: Delta(provider_specific_fields=None, content=None, role=None, function_call=None, tool_calls=None, audio=None); completion_obj: {'content': ''}
self.sent_first_chunk: True
completion_obj: {'content': ''}, model_response.choices[0]: StreamingChoices(finish_reason=None, index=0, delta=Delta(provider_specific_fields=None, content=None, role=None, function_call=None, tool_calls=None, audio=None), logprobs=None), response_obj: {'text': '', 'is_finished': False, 'finish_reason': '', 'usage': None, 'index': 0, 'tool_use': None}
model_response finish reason 3: None; response_obj={'text': '', 'is_finished': False, 'finish_reason': '', 'usage': None, 'index': 0, 'tool_use': None}
model_response.choices[0].delta: Delta(provider_specific_fields=None, content=None, role=None, function_call=None, tool_calls=None, audio=None); completion_obj: {'content': ''}
self.sent_first_chunk: True
completion_obj: {'content': ''}, model_response.choices[0]: StreamingChoices(finish_reason=None, index=0, delta=Delta(provider_specific_fields=None, content=None, role=None, function_call=None, tool_calls=None, audio=None), logprobs=None), response_obj: {'text': '', 'is_finished': False, 'finish_reason': '', 'usage': None, 'index': 0, 'tool_use': None}

Raw OpenAI Chunk
ModelResponseStream(id='chatcmpl-1e246dec-1357-4ceb-948f-03d49e55b5f9', created=1762261919, model=None, object='chat.completion.chunk', system_fingerprint=None, choices=[StreamingChoices(finish_reason=None, index=0, delta=Delta(provider_specific_fields=None, content=' the changes', role=None, function_call=None, tool_calls=None, audio=None), logprobs=None)], provider_specific_fields=None, usage=None)

model_response finish reason 3: None; response_obj={'text': ' the changes', 'is_finished': False, 'finish_reason': None, 'logprobs': None, 'original_chunk': ModelResponseStream(id='chatcmpl-1e246dec-1357-4ceb-948f-03d49e55b5f9', created=1762261919, model=None, object='chat.completion.chunk', system_fingerprint=None, choices=[StreamingChoices(finish_reason=None, index=0, delta=Delta(provider_specific_fields=None, content=' the changes', role=None, function_call=None, tool_calls=None, audio=None), logprobs=None)], provider_specific_fields=None, usage=None), 'usage': None}
original delta: {'provider_specific_fields': None, 'content': ' the changes', 'role': None, 'function_call': None, 'tool_calls': None, 'audio': None}
new delta: Delta(provider_specific_fields=None, content=' the changes', role=None, function_call=None, tool_calls=None, audio=None)
model_response.choices[0].delta: Delta(provider_specific_fields=None, content=' the changes', role=None, function_call=None, tool_calls=None, audio=None); completion_obj: {'content': ' the changes'}
self.sent_first_chunk: True
completion_obj: {'content': ' the changes'}, model_response.choices[0]: StreamingChoices(finish_reason=None, index=0, delta=Delta(provider_specific_fields=None, content=' the changes', role=None, function_call=None, tool_calls=None, audio=None), logprobs=None), response_obj: {'text': ' the changes', 'is_finished': False, 'finish_reason': None, 'logprobs': None, 'original_chunk': ModelResponseStream(id='chatcmpl-1e246dec-1357-4ceb-948f-03d49e55b5f9', created=1762261919, model=None, object='chat.completion.chunk', system_fingerprint=None, choices=[StreamingChoices(finish_reason=None, index=0, delta=Delta(provider_specific_fields=None, content=' the changes', role=None, function_call=None, tool_calls=None, audio=None), logprobs=None)], provider_specific_fields=None, usage=None), 'usage': None}
choice_json: {'index': 0, 'delta': {'provider_specific_fields': None, 'content': ' the changes', 'role': None, 'function_call': None, 'tool_calls': None, 'audio': None}, 'logprobs': None}
choices in streaming: [StreamingChoices(finish_reason=None, index=0, delta=Delta(provider_specific_fields=None, content=' the changes', role=None, function_call=None, tool_calls=None, audio=None), logprobs=None)]
final returned processed chunk: ModelResponseStream(id='chatcmpl-1e246dec-1357-4ceb-948f-03d49e55b5f9', created=1762261907, model='claude-sonnet-4-5-20250929', object='chat.completion.chunk', system_fingerprint=None, choices=[StreamingChoices(finish_reason=None, index=0, delta=Delta(provider_specific_fields=None, content=' the changes', role=None, function_call=None, tool_calls=None, audio=None), logprobs=None)], provider_specific_fields=None, citations=None)
model_response finish reason 3: None; response_obj={'text': '', 'is_finished': False, 'finish_reason': '', 'usage': None, 'index': 0, 'tool_use': None}
model_response.choices[0].delta: Delta(provider_specific_fields=None, content=None, role=None, function_call=None, tool_calls=None, audio=None); completion_obj: {'content': ''}
self.sent_first_chunk: True
completion_obj: {'content': ''}, model_response.choices[0]: StreamingChoices(finish_reason=None, index=0, delta=Delta(provider_specific_fields=None, content=None, role=None, function_call=None, tool_calls=None, audio=None), logprobs=None), response_obj: {'text': '', 'is_finished': False, 'finish_reason': '', 'usage': None, 'index': 0, 'tool_use': None}
model_response finish reason 3: None; response_obj={'text': '', 'is_finished': False, 'finish_reason': '', 'usage': None, 'index': 0, 'tool_use': None}
model_response.choices[0].delta: Delta(provider_specific_fields=None, content=None, role=None, function_call=None, tool_calls=None, audio=None); completion_obj: {'content': ''}
self.sent_first_chunk: True
completion_obj: {'content': ''}, model_response.choices[0]: StreamingChoices(finish_reason=None, index=0, delta=Delta(provider_specific_fields=None, content=None, role=None, function_call=None, tool_calls=None, audio=None), logprobs=None), response_obj: {'text': '', 'is_finished': False, 'finish_reason': '', 'usage': None, 'index': 0, 'tool_use': None}

Raw OpenAI Chunk
ModelResponseStream(id='chatcmpl-1e246dec-1357-4ceb-948f-03d49e55b5f9', created=1762261919, model=None, object='chat.completion.chunk', system_fingerprint=None, choices=[StreamingChoices(finish_reason=None, index=0, delta=Delta(provider_specific_fields=None, content='** you mentione', role=None, function_call=None, tool_calls=None, audio=None), logprobs=None)], provider_specific_fields=None, usage=None)

model_response finish reason 3: None; response_obj={'text': '** you mentione', 'is_finished': False, 'finish_reason': None, 'logprobs': None, 'original_chunk': ModelResponseStream(id='chatcmpl-1e246dec-1357-4ceb-948f-03d49e55b5f9', created=1762261919, model=None, object='chat.completion.chunk', system_fingerprint=None, choices=[StreamingChoices(finish_reason=None, index=0, delta=Delta(provider_specific_fields=None, content='** you mentione', role=None, function_call=None, tool_calls=None, audio=None), logprobs=None)], provider_specific_fields=None, usage=None), 'usage': None}
original delta: {'provider_specific_fields': None, 'content': '** you mentione', 'role': None, 'function_call': None, 'tool_calls': None, 'audio': None}
new delta: Delta(provider_specific_fields=None, content='** you mentione', role=None, function_call=None, tool_calls=None, audio=None)
model_response.choices[0].delta: Delta(provider_specific_fields=None, content='** you mentione', role=None, function_call=None, tool_calls=None, audio=None); completion_obj: {'content': '** you mentione'}
self.sent_first_chunk: True
completion_obj: {'content': '** you mentione'}, model_response.choices[0]: StreamingChoices(finish_reason=None, index=0, delta=Delta(provider_specific_fields=None, content='** you mentione', role=None, function_call=None, tool_calls=None, audio=None), logprobs=None), response_obj: {'text': '** you mentione', 'is_finished': False, 'finish_reason': None, 'logprobs': None, 'original_chunk': ModelResponseStream(id='chatcmpl-1e246dec-1357-4ceb-948f-03d49e55b5f9', created=1762261919, model=None, object='chat.completion.chunk', system_fingerprint=None, choices=[StreamingChoices(finish_reason=None, index=0, delta=Delta(provider_specific_fields=None, content='** you mentione', role=None, function_call=None, tool_calls=None, audio=None), logprobs=None)], provider_specific_fields=None, usage=None), 'usage': None}
choice_json: {'index': 0, 'delta': {'provider_specific_fields': None, 'content': '** you mentione', 'role': None, 'function_call': None, 'tool_calls': None, 'audio': None}, 'logprobs': None}
choices in streaming: [StreamingChoices(finish_reason=None, index=0, delta=Delta(provider_specific_fields=None, content='** you mentione', role=None, function_call=None, tool_calls=None, audio=None), logprobs=None)]
final returned processed chunk: ModelResponseStream(id='chatcmpl-1e246dec-1357-4ceb-948f-03d49e55b5f9', created=1762261907, model='claude-sonnet-4-5-20250929', object='chat.completion.chunk', system_fingerprint=None, choices=[StreamingChoices(finish_reason=None, index=0, delta=Delta(provider_specific_fields=None, content='** you mentione', role=None, function_call=None, tool_calls=None, audio=None), logprobs=None)], provider_specific_fields=None, citations=None)
model_response finish reason 3: None; response_obj={'text': '', 'is_finished': False, 'finish_reason': '', 'usage': None, 'index': 0, 'tool_use': None}
model_response.choices[0].delta: Delta(provider_specific_fields=None, content=None, role=None, function_call=None, tool_calls=None, audio=None); completion_obj: {'content': ''}
self.sent_first_chunk: True
completion_obj: {'content': ''}, model_response.choices[0]: StreamingChoices(finish_reason=None, index=0, delta=Delta(provider_specific_fields=None, content=None, role=None, function_call=None, tool_calls=None, audio=None), logprobs=None), response_obj: {'text': '', 'is_finished': False, 'finish_reason': '', 'usage': None, 'index': 0, 'tool_use': None}
model_response finish reason 3: None; response_obj={'text': '', 'is_finished': False, 'finish_reason': '', 'usage': None, 'index': 0, 'tool_use': None}
model_response.choices[0].delta: Delta(provider_specific_fields=None, content=None, role=None, function_call=None, tool_calls=None, audio=None); completion_obj: {'content': ''}
self.sent_first_chunk: True
completion_obj: {'content': ''}, model_response.choices[0]: StreamingChoices(finish_reason=None, index=0, delta=Delta(provider_specific_fields=None, content=None, role=None, function_call=None, tool_calls=None, audio=None), logprobs=None), response_obj: {'text': '', 'is_finished': False, 'finish_reason': '', 'usage': None, 'index': 0, 'tool_use': None}

Raw OpenAI Chunk
ModelResponseStream(id='chatcmpl-1e246dec-1357-4ceb-948f-03d49e55b5f9', created=1762261919, model=None, object='chat.completion.chunk', system_fingerprint=None, choices=[StreamingChoices(finish_reason=None, index=0, delta=Delta(provider_specific_fields=None, content='d checking', role=None, function_call=None, tool_calls=None, audio=None), logprobs=None)], provider_specific_fields=None, usage=None)

model_response finish reason 3: None; response_obj={'text': 'd checking', 'is_finished': False, 'finish_reason': None, 'logprobs': None, 'original_chunk': ModelResponseStream(id='chatcmpl-1e246dec-1357-4ceb-948f-03d49e55b5f9', created=1762261919, model=None, object='chat.completion.chunk', system_fingerprint=None, choices=[StreamingChoices(finish_reason=None, index=0, delta=Delta(provider_specific_fields=None, content='d checking', role=None, function_call=None, tool_calls=None, audio=None), logprobs=None)], provider_specific_fields=None, usage=None), 'usage': None}
original delta: {'provider_specific_fields': None, 'content': 'd checking', 'role': None, 'function_call': None, 'tool_calls': None, 'audio': None}
new delta: Delta(provider_specific_fields=None, content='d checking', role=None, function_call=None, tool_calls=None, audio=None)
model_response.choices[0].delta: Delta(provider_specific_fields=None, content='d checking', role=None, function_call=None, tool_calls=None, audio=None); completion_obj: {'content': 'd checking'}
self.sent_first_chunk: True
completion_obj: {'content': 'd checking'}, model_response.choices[0]: StreamingChoices(finish_reason=None, index=0, delta=Delta(provider_specific_fields=None, content='d checking', role=None, function_call=None, tool_calls=None, audio=None), logprobs=None), response_obj: {'text': 'd checking', 'is_finished': False, 'finish_reason': None, 'logprobs': None, 'original_chunk': ModelResponseStream(id='chatcmpl-1e246dec-1357-4ceb-948f-03d49e55b5f9', created=1762261919, model=None, object='chat.completion.chunk', system_fingerprint=None, choices=[StreamingChoices(finish_reason=None, index=0, delta=Delta(provider_specific_fields=None, content='d checking', role=None, function_call=None, tool_calls=None, audio=None), logprobs=None)], provider_specific_fields=None, usage=None), 'usage': None}
choice_json: {'index': 0, 'delta': {'provider_specific_fields': None, 'content': 'd checking', 'role': None, 'function_call': None, 'tool_calls': None, 'audio': None}, 'logprobs': None}
choices in streaming: [StreamingChoices(finish_reason=None, index=0, delta=Delta(provider_specific_fields=None, content='d checking', role=None, function_call=None, tool_calls=None, audio=None), logprobs=None)]
final returned processed chunk: ModelResponseStream(id='chatcmpl-1e246dec-1357-4ceb-948f-03d49e55b5f9', created=1762261907, model='claude-sonnet-4-5-20250929', object='chat.completion.chunk', system_fingerprint=None, choices=[StreamingChoices(finish_reason=None, index=0, delta=Delta(provider_specific_fields=None, content='d checking', role=None, function_call=None, tool_calls=None, audio=None), logprobs=None)], provider_specific_fields=None, citations=None)
model_response finish reason 3: None; response_obj={'text': '', 'is_finished': False, 'finish_reason': '', 'usage': None, 'index': 0, 'tool_use': None}
model_response.choices[0].delta: Delta(provider_specific_fields=None, content=None, role=None, function_call=None, tool_calls=None, audio=None); completion_obj: {'content': ''}
self.sent_first_chunk: True
completion_obj: {'content': ''}, model_response.choices[0]: StreamingChoices(finish_reason=None, index=0, delta=Delta(provider_specific_fields=None, content=None, role=None, function_call=None, tool_calls=None, audio=None), logprobs=None), response_obj: {'text': '', 'is_finished': False, 'finish_reason': '', 'usage': None, 'index': 0, 'tool_use': None}
model_response finish reason 3: None; response_obj={'text': '', 'is_finished': False, 'finish_reason': '', 'usage': None, 'index': 0, 'tool_use': None}
model_response.choices[0].delta: Delta(provider_specific_fields=None, content=None, role=None, function_call=None, tool_calls=None, audio=None); completion_obj: {'content': ''}
self.sent_first_chunk: True
completion_obj: {'content': ''}, model_response.choices[0]: StreamingChoices(finish_reason=None, index=0, delta=Delta(provider_specific_fields=None, content=None, role=None, function_call=None, tool_calls=None, audio=None), logprobs=None), response_obj: {'text': '', 'is_finished': False, 'finish_reason': '', 'usage': None, 'index': 0, 'tool_use': None}

Raw OpenAI Chunk
ModelResponseStream(id='chatcmpl-1e246dec-1357-4ceb-948f-03d49e55b5f9', created=1762261919, model=None, object='chat.completion.chunk', system_fingerprint=None, choices=[StreamingChoices(finish_reason=None, index=0, delta=Delta(provider_specific_fields=None, content=' with', role=None, function_call=None, tool_calls=None, audio=None), logprobs=None)], provider_specific_fields=None, usage=None)

model_response finish reason 3: None; response_obj={'text': ' with', 'is_finished': False, 'finish_reason': None, 'logprobs': None, 'original_chunk': ModelResponseStream(id='chatcmpl-1e246dec-1357-4ceb-948f-03d49e55b5f9', created=1762261919, model=None, object='chat.completion.chunk', system_fingerprint=None, choices=[StreamingChoices(finish_reason=None, index=0, delta=Delta(provider_specific_fields=None, content=' with', role=None, function_call=None, tool_calls=None, audio=None), logprobs=None)], provider_specific_fields=None, usage=None), 'usage': None}
original delta: {'provider_specific_fields': None, 'content': ' with', 'role': None, 'function_call': None, 'tool_calls': None, 'audio': None}
new delta: Delta(provider_specific_fields=None, content=' with', role=None, function_call=None, tool_calls=None, audio=None)
model_response.choices[0].delta: Delta(provider_specific_fields=None, content=' with', role=None, function_call=None, tool_calls=None, audio=None); completion_obj: {'content': ' with'}
self.sent_first_chunk: True
completion_obj: {'content': ' with'}, model_response.choices[0]: StreamingChoices(finish_reason=None, index=0, delta=Delta(provider_specific_fields=None, content=' with', role=None, function_call=None, tool_calls=None, audio=None), logprobs=None), response_obj: {'text': ' with', 'is_finished': False, 'finish_reason': None, 'logprobs': None, 'original_chunk': ModelResponseStream(id='chatcmpl-1e246dec-1357-4ceb-948f-03d49e55b5f9', created=1762261919, model=None, object='chat.completion.chunk', system_fingerprint=None, choices=[StreamingChoices(finish_reason=None, index=0, delta=Delta(provider_specific_fields=None, content=' with', role=None, function_call=None, tool_calls=None, audio=None), logprobs=None)], provider_specific_fields=None, usage=None), 'usage': None}
choice_json: {'index': 0, 'delta': {'provider_specific_fields': None, 'content': ' with', 'role': None, 'function_call': None, 'tool_calls': None, 'audio': None}, 'logprobs': None}
choices in streaming: [StreamingChoices(finish_reason=None, index=0, delta=Delta(provider_specific_fields=None, content=' with', role=None, function_call=None, tool_calls=None, audio=None), logprobs=None)]
final returned processed chunk: ModelResponseStream(id='chatcmpl-1e246dec-1357-4ceb-948f-03d49e55b5f9', created=1762261907, model='claude-sonnet-4-5-20250929', object='chat.completion.chunk', system_fingerprint=None, choices=[StreamingChoices(finish_reason=None, index=0, delta=Delta(provider_specific_fields=None, content=' with', role=None, function_call=None, tool_calls=None, audio=None), logprobs=None)], provider_specific_fields=None, citations=None)
model_response finish reason 3: None; response_obj={'text': '', 'is_finished': False, 'finish_reason': '', 'usage': None, 'index': 0, 'tool_use': None}
model_response.choices[0].delta: Delta(provider_specific_fields=None, content=None, role=None, function_call=None, tool_calls=None, audio=None); completion_obj: {'content': ''}
self.sent_first_chunk: True
completion_obj: {'content': ''}, model_response.choices[0]: StreamingChoices(finish_reason=None, index=0, delta=Delta(provider_specific_fields=None, content=None, role=None, function_call=None, tool_calls=None, audio=None), logprobs=None), response_obj: {'text': '', 'is_finished': False, 'finish_reason': '', 'usage': None, 'index': 0, 'tool_use': None}
model_response finish reason 3: None; response_obj={'text': '', 'is_finished': False, 'finish_reason': '', 'usage': None, 'index': 0, 'tool_use': None}
model_response.choices[0].delta: Delta(provider_specific_fields=None, content=None, role=None, function_call=None, tool_calls=None, audio=None); completion_obj: {'content': ''}
self.sent_first_chunk: True
completion_obj: {'content': ''}, model_response.choices[0]: StreamingChoices(finish_reason=None, index=0, delta=Delta(provider_specific_fields=None, content=None, role=None, function_call=None, tool_calls=None, audio=None), logprobs=None), response_obj: {'text': '', 'is_finished': False, 'finish_reason': '', 'usage': None, 'index': 0, 'tool_use': None}

Raw OpenAI Chunk
ModelResponseStream(id='chatcmpl-1e246dec-1357-4ceb-948f-03d49e55b5f9', created=1762261919, model=None, object='chat.completion.chunk', system_fingerprint=None, choices=[StreamingChoices(finish_reason=None, index=0, delta=Delta(provider_specific_fields=None, content=' `jj status`?\n\nLet', role=None, function_call=None, tool_calls=None, audio=None), logprobs=None)], provider_specific_fields=None, usage=None)

model_response finish reason 3: None; response_obj={'text': ' `jj status`?\n\nLet', 'is_finished': False, 'finish_reason': None, 'logprobs': None, 'original_chunk': ModelResponseStream(id='chatcmpl-1e246dec-1357-4ceb-948f-03d49e55b5f9', created=1762261919, model=None, object='chat.completion.chunk', system_fingerprint=None, choices=[StreamingChoices(finish_reason=None, index=0, delta=Delta(provider_specific_fields=None, content=' `jj status`?\n\nLet', role=None, function_call=None, tool_calls=None, audio=None), logprobs=None)], provider_specific_fields=None, usage=None), 'usage': None}
original delta: {'provider_specific_fields': None, 'content': ' `jj status`?\n\nLet', 'role': None, 'function_call': None, 'tool_calls': None, 'audio': None}
new delta: Delta(provider_specific_fields=None, content=' `jj status`?\n\nLet', role=None, function_call=None, tool_calls=None, audio=None)
model_response.choices[0].delta: Delta(provider_specific_fields=None, content=' `jj status`?\n\nLet', role=None, function_call=None, tool_calls=None, audio=None); completion_obj: {'content': ' `jj status`?\n\nLet'}
self.sent_first_chunk: True
completion_obj: {'content': ' `jj status`?\n\nLet'}, model_response.choices[0]: StreamingChoices(finish_reason=None, index=0, delta=Delta(provider_specific_fields=None, content=' `jj status`?\n\nLet', role=None, function_call=None, tool_calls=None, audio=None), logprobs=None), response_obj: {'text': ' `jj status`?\n\nLet', 'is_finished': False, 'finish_reason': None, 'logprobs': None, 'original_chunk': ModelResponseStream(id='chatcmpl-1e246dec-1357-4ceb-948f-03d49e55b5f9', created=1762261919, model=None, object='chat.completion.chunk', system_fingerprint=None, choices=[StreamingChoices(finish_reason=None, index=0, delta=Delta(provider_specific_fields=None, content=' `jj status`?\n\nLet', role=None, function_call=None, tool_calls=None, audio=None), logprobs=None)], provider_specific_fields=None, usage=None), 'usage': None}
choice_json: {'index': 0, 'delta': {'provider_specific_fields': None, 'content': ' `jj status`?\n\nLet', 'role': None, 'function_call': None, 'tool_calls': None, 'audio': None}, 'logprobs': None}
choices in streaming: [StreamingChoices(finish_reason=None, index=0, delta=Delta(provider_specific_fields=None, content=' `jj status`?\n\nLet', role=None, function_call=None, tool_calls=None, audio=None), logprobs=None)]
final returned processed chunk: ModelResponseStream(id='chatcmpl-1e246dec-1357-4ceb-948f-03d49e55b5f9', created=1762261907, model='claude-sonnet-4-5-20250929', object='chat.completion.chunk', system_fingerprint=None, choices=[StreamingChoices(finish_reason=None, index=0, delta=Delta(provider_specific_fields=None, content=' `jj status`?\n\nLet', role=None, function_call=None, tool_calls=None, audio=None), logprobs=None)], provider_specific_fields=None, citations=None)
model_response finish reason 3: None; response_obj={'text': '', 'is_finished': False, 'finish_reason': '', 'usage': None, 'index': 0, 'tool_use': None}
model_response.choices[0].delta: Delta(provider_specific_fields=None, content=None, role=None, function_call=None, tool_calls=None, audio=None); completion_obj: {'content': ''}
self.sent_first_chunk: True
completion_obj: {'content': ''}, model_response.choices[0]: StreamingChoices(finish_reason=None, index=0, delta=Delta(provider_specific_fields=None, content=None, role=None, function_call=None, tool_calls=None, audio=None), logprobs=None), response_obj: {'text': '', 'is_finished': False, 'finish_reason': '', 'usage': None, 'index': 0, 'tool_use': None}
model_response finish reason 3: None; response_obj={'text': '', 'is_finished': False, 'finish_reason': '', 'usage': None, 'index': 0, 'tool_use': None}
model_response.choices[0].delta: Delta(provider_specific_fields=None, content=None, role=None, function_call=None, tool_calls=None, audio=None); completion_obj: {'content': ''}
self.sent_first_chunk: True
completion_obj: {'content': ''}, model_response.choices[0]: StreamingChoices(finish_reason=None, index=0, delta=Delta(provider_specific_fields=None, content=None, role=None, function_call=None, tool_calls=None, audio=None), logprobs=None), response_obj: {'text': '', 'is_finished': False, 'finish_reason': '', 'usage': None, 'index': 0, 'tool_use': None}

Raw OpenAI Chunk
ModelResponseStream(id='chatcmpl-1e246dec-1357-4ceb-948f-03d49e55b5f9', created=1762261919, model=None, object='chat.completion.chunk', system_fingerprint=None, choices=[StreamingChoices(finish_reason=None, index=0, delta=Delta(provider_specific_fields=None, content=' me know how I', role=None, function_call=None, tool_calls=None, audio=None), logprobs=None)], provider_specific_fields=None, usage=None)

model_response finish reason 3: None; response_obj={'text': ' me know how I', 'is_finished': False, 'finish_reason': None, 'logprobs': None, 'original_chunk': ModelResponseStream(id='chatcmpl-1e246dec-1357-4ceb-948f-03d49e55b5f9', created=1762261919, model=None, object='chat.completion.chunk', system_fingerprint=None, choices=[StreamingChoices(finish_reason=None, index=0, delta=Delta(provider_specific_fields=None, content=' me know how I', role=None, function_call=None, tool_calls=None, audio=None), logprobs=None)], provider_specific_fields=None, usage=None), 'usage': None}
original delta: {'provider_specific_fields': None, 'content': ' me know how I', 'role': None, 'function_call': None, 'tool_calls': None, 'audio': None}
new delta: Delta(provider_specific_fields=None, content=' me know how I', role=None, function_call=None, tool_calls=None, audio=None)
model_response.choices[0].delta: Delta(provider_specific_fields=None, content=' me know how I', role=None, function_call=None, tool_calls=None, audio=None); completion_obj: {'content': ' me know how I'}
self.sent_first_chunk: True
completion_obj: {'content': ' me know how I'}, model_response.choices[0]: StreamingChoices(finish_reason=None, index=0, delta=Delta(provider_specific_fields=None, content=' me know how I', role=None, function_call=None, tool_calls=None, audio=None), logprobs=None), response_obj: {'text': ' me know how I', 'is_finished': False, 'finish_reason': None, 'logprobs': None, 'original_chunk': ModelResponseStream(id='chatcmpl-1e246dec-1357-4ceb-948f-03d49e55b5f9', created=1762261919, model=None, object='chat.completion.chunk', system_fingerprint=None, choices=[StreamingChoices(finish_reason=None, index=0, delta=Delta(provider_specific_fields=None, content=' me know how I', role=None, function_call=None, tool_calls=None, audio=None), logprobs=None)], provider_specific_fields=None, usage=None), 'usage': None}
choice_json: {'index': 0, 'delta': {'provider_specific_fields': None, 'content': ' me know how I', 'role': None, 'function_call': None, 'tool_calls': None, 'audio': None}, 'logprobs': None}
choices in streaming: [StreamingChoices(finish_reason=None, index=0, delta=Delta(provider_specific_fields=None, content=' me know how I', role=None, function_call=None, tool_calls=None, audio=None), logprobs=None)]
final returned processed chunk: ModelResponseStream(id='chatcmpl-1e246dec-1357-4ceb-948f-03d49e55b5f9', created=1762261907, model='claude-sonnet-4-5-20250929', object='chat.completion.chunk', system_fingerprint=None, choices=[StreamingChoices(finish_reason=None, index=0, delta=Delta(provider_specific_fields=None, content=' me know how I', role=None, function_call=None, tool_calls=None, audio=None), logprobs=None)], provider_specific_fields=None, citations=None)
model_response finish reason 3: None; response_obj={'text': '', 'is_finished': False, 'finish_reason': '', 'usage': None, 'index': 0, 'tool_use': None}
model_response.choices[0].delta: Delta(provider_specific_fields=None, content=None, role=None, function_call=None, tool_calls=None, audio=None); completion_obj: {'content': ''}
self.sent_first_chunk: True
completion_obj: {'content': ''}, model_response.choices[0]: StreamingChoices(finish_reason=None, index=0, delta=Delta(provider_specific_fields=None, content=None, role=None, function_call=None, tool_calls=None, audio=None), logprobs=None), response_obj: {'text': '', 'is_finished': False, 'finish_reason': '', 'usage': None, 'index': 0, 'tool_use': None}
model_response finish reason 3: None; response_obj={'text': '', 'is_finished': False, 'finish_reason': '', 'usage': None, 'index': 0, 'tool_use': None}
model_response.choices[0].delta: Delta(provider_specific_fields=None, content=None, role=None, function_call=None, tool_calls=None, audio=None); completion_obj: {'content': ''}
self.sent_first_chunk: True
completion_obj: {'content': ''}, model_response.choices[0]: StreamingChoices(finish_reason=None, index=0, delta=Delta(provider_specific_fields=None, content=None, role=None, function_call=None, tool_calls=None, audio=None), logprobs=None), response_obj: {'text': '', 'is_finished': False, 'finish_reason': '', 'usage': None, 'index': 0, 'tool_use': None}

Raw OpenAI Chunk
ModelResponseStream(id='chatcmpl-1e246dec-1357-4ceb-948f-03d49e55b5f9', created=1762261919, model=None, object='chat.completion.chunk', system_fingerprint=None, choices=[StreamingChoices(finish_reason=None, index=0, delta=Delta(provider_specific_fields=None, content=' can help', role=None, function_call=None, tool_calls=None, audio=None), logprobs=None)], provider_specific_fields=None, usage=None)

model_response finish reason 3: None; response_obj={'text': ' can help', 'is_finished': False, 'finish_reason': None, 'logprobs': None, 'original_chunk': ModelResponseStream(id='chatcmpl-1e246dec-1357-4ceb-948f-03d49e55b5f9', created=1762261919, model=None, object='chat.completion.chunk', system_fingerprint=None, choices=[StreamingChoices(finish_reason=None, index=0, delta=Delta(provider_specific_fields=None, content=' can help', role=None, function_call=None, tool_calls=None, audio=None), logprobs=None)], provider_specific_fields=None, usage=None), 'usage': None}
original delta: {'provider_specific_fields': None, 'content': ' can help', 'role': None, 'function_call': None, 'tool_calls': None, 'audio': None}
new delta: Delta(provider_specific_fields=None, content=' can help', role=None, function_call=None, tool_calls=None, audio=None)
model_response.choices[0].delta: Delta(provider_specific_fields=None, content=' can help', role=None, function_call=None, tool_calls=None, audio=None); completion_obj: {'content': ' can help'}
self.sent_first_chunk: True
completion_obj: {'content': ' can help'}, model_response.choices[0]: StreamingChoices(finish_reason=None, index=0, delta=Delta(provider_specific_fields=None, content=' can help', role=None, function_call=None, tool_calls=None, audio=None), logprobs=None), response_obj: {'text': ' can help', 'is_finished': False, 'finish_reason': None, 'logprobs': None, 'original_chunk': ModelResponseStream(id='chatcmpl-1e246dec-1357-4ceb-948f-03d49e55b5f9', created=1762261919, model=None, object='chat.completion.chunk', system_fingerprint=None, choices=[StreamingChoices(finish_reason=None, index=0, delta=Delta(provider_specific_fields=None, content=' can help', role=None, function_call=None, tool_calls=None, audio=None), logprobs=None)], provider_specific_fields=None, usage=None), 'usage': None}
choice_json: {'index': 0, 'delta': {'provider_specific_fields': None, 'content': ' can help', 'role': None, 'function_call': None, 'tool_calls': None, 'audio': None}, 'logprobs': None}
choices in streaming: [StreamingChoices(finish_reason=None, index=0, delta=Delta(provider_specific_fields=None, content=' can help', role=None, function_call=None, tool_calls=None, audio=None), logprobs=None)]
final returned processed chunk: ModelResponseStream(id='chatcmpl-1e246dec-1357-4ceb-948f-03d49e55b5f9', created=1762261907, model='claude-sonnet-4-5-20250929', object='chat.completion.chunk', system_fingerprint=None, choices=[StreamingChoices(finish_reason=None, index=0, delta=Delta(provider_specific_fields=None, content=' can help', role=None, function_call=None, tool_calls=None, audio=None), logprobs=None)], provider_specific_fields=None, citations=None)
model_response finish reason 3: None; response_obj={'text': '', 'is_finished': False, 'finish_reason': '', 'usage': None, 'index': 0, 'tool_use': None}
model_response.choices[0].delta: Delta(provider_specific_fields=None, content=None, role=None, function_call=None, tool_calls=None, audio=None); completion_obj: {'content': ''}
self.sent_first_chunk: True
completion_obj: {'content': ''}, model_response.choices[0]: StreamingChoices(finish_reason=None, index=0, delta=Delta(provider_specific_fields=None, content=None, role=None, function_call=None, tool_calls=None, audio=None), logprobs=None), response_obj: {'text': '', 'is_finished': False, 'finish_reason': '', 'usage': None, 'index': 0, 'tool_use': None}
model_response finish reason 3: None; response_obj={'text': '', 'is_finished': False, 'finish_reason': '', 'usage': None, 'index': 0, 'tool_use': None}
model_response.choices[0].delta: Delta(provider_specific_fields=None, content=None, role=None, function_call=None, tool_calls=None, audio=None); completion_obj: {'content': ''}
self.sent_first_chunk: True
completion_obj: {'content': ''}, model_response.choices[0]: StreamingChoices(finish_reason=None, index=0, delta=Delta(provider_specific_fields=None, content=None, role=None, function_call=None, tool_calls=None, audio=None), logprobs=None), response_obj: {'text': '', 'is_finished': False, 'finish_reason': '', 'usage': None, 'index': 0, 'tool_use': None}

Raw OpenAI Chunk
ModelResponseStream(id='chatcmpl-1e246dec-1357-4ceb-948f-03d49e55b5f9', created=1762261919, model=None, object='chat.completion.chunk', system_fingerprint=None, choices=[StreamingChoices(finish_reason=None, index=0, delta=Delta(provider_specific_fields=None, content='!', role=None, function_call=None, tool_calls=None, audio=None), logprobs=None)], provider_specific_fields=None, usage=None)

model_response finish reason 3: None; response_obj={'text': '!', 'is_finished': False, 'finish_reason': None, 'logprobs': None, 'original_chunk': ModelResponseStream(id='chatcmpl-1e246dec-1357-4ceb-948f-03d49e55b5f9', created=1762261919, model=None, object='chat.completion.chunk', system_fingerprint=None, choices=[StreamingChoices(finish_reason=None, index=0, delta=Delta(provider_specific_fields=None, content='!', role=None, function_call=None, tool_calls=None, audio=None), logprobs=None)], provider_specific_fields=None, usage=None), 'usage': None}
original delta: {'provider_specific_fields': None, 'content': '!', 'role': None, 'function_call': None, 'tool_calls': None, 'audio': None}
new delta: Delta(provider_specific_fields=None, content='!', role=None, function_call=None, tool_calls=None, audio=None)
model_response.choices[0].delta: Delta(provider_specific_fields=None, content='!', role=None, function_call=None, tool_calls=None, audio=None); completion_obj: {'content': '!'}
self.sent_first_chunk: True
completion_obj: {'content': '!'}, model_response.choices[0]: StreamingChoices(finish_reason=None, index=0, delta=Delta(provider_specific_fields=None, content='!', role=None, function_call=None, tool_calls=None, audio=None), logprobs=None), response_obj: {'text': '!', 'is_finished': False, 'finish_reason': None, 'logprobs': None, 'original_chunk': ModelResponseStream(id='chatcmpl-1e246dec-1357-4ceb-948f-03d49e55b5f9', created=1762261919, model=None, object='chat.completion.chunk', system_fingerprint=None, choices=[StreamingChoices(finish_reason=None, index=0, delta=Delta(provider_specific_fields=None, content='!', role=None, function_call=None, tool_calls=None, audio=None), logprobs=None)], provider_specific_fields=None, usage=None), 'usage': None}
choice_json: {'index': 0, 'delta': {'provider_specific_fields': None, 'content': '!', 'role': None, 'function_call': None, 'tool_calls': None, 'audio': None}, 'logprobs': None}
choices in streaming: [StreamingChoices(finish_reason=None, index=0, delta=Delta(provider_specific_fields=None, content='!', role=None, function_call=None, tool_calls=None, audio=None), logprobs=None)]
final returned processed chunk: ModelResponseStream(id='chatcmpl-1e246dec-1357-4ceb-948f-03d49e55b5f9', created=1762261907, model='claude-sonnet-4-5-20250929', object='chat.completion.chunk', system_fingerprint=None, choices=[StreamingChoices(finish_reason=None, index=0, delta=Delta(provider_specific_fields=None, content='!', role=None, function_call=None, tool_calls=None, audio=None), logprobs=None)], provider_specific_fields=None, citations=None)
model_response finish reason 3: None; response_obj={'text': '', 'is_finished': False, 'finish_reason': '', 'usage': None, 'index': 0, 'tool_use': None}
model_response.choices[0].delta: Delta(provider_specific_fields=None, content=None, role=None, function_call=None, tool_calls=None, audio=None); completion_obj: {'content': ''}
self.sent_first_chunk: True
completion_obj: {'content': ''}, model_response.choices[0]: StreamingChoices(finish_reason=None, index=0, delta=Delta(provider_specific_fields=None, content=None, role=None, function_call=None, tool_calls=None, audio=None), logprobs=None), response_obj: {'text': '', 'is_finished': False, 'finish_reason': '', 'usage': None, 'index': 0, 'tool_use': None}
model_response finish reason 3: None; response_obj={'text': '', 'is_finished': False, 'finish_reason': '', 'usage': None, 'index': 0, 'tool_use': None}
model_response.choices[0].delta: Delta(provider_specific_fields=None, content=None, role=None, function_call=None, tool_calls=None, audio=None); completion_obj: {'content': ''}
self.sent_first_chunk: True
completion_obj: {'content': ''}, model_response.choices[0]: StreamingChoices(finish_reason=None, index=0, delta=Delta(provider_specific_fields=None, content=None, role=None, function_call=None, tool_calls=None, audio=None), logprobs=None), response_obj: {'text': '', 'is_finished': False, 'finish_reason': '', 'usage': None, 'index': 0, 'tool_use': None}

Raw OpenAI Chunk
ModelResponseStream(id='chatcmpl-1e246dec-1357-4ceb-948f-03d49e55b5f9', created=1762261919, model=None, object='chat.completion.chunk', system_fingerprint=None, choices=[StreamingChoices(finish_reason=None, index=0, delta=Delta(provider_specific_fields=None, content=' ', role=None, function_call=None, tool_calls=None, audio=None), logprobs=None)], provider_specific_fields=None, usage=None)

model_response finish reason 3: None; response_obj={'text': ' ', 'is_finished': False, 'finish_reason': None, 'logprobs': None, 'original_chunk': ModelResponseStream(id='chatcmpl-1e246dec-1357-4ceb-948f-03d49e55b5f9', created=1762261919, model=None, object='chat.completion.chunk', system_fingerprint=None, choices=[StreamingChoices(finish_reason=None, index=0, delta=Delta(provider_specific_fields=None, content=' ', role=None, function_call=None, tool_calls=None, audio=None), logprobs=None)], provider_specific_fields=None, usage=None), 'usage': None}
original delta: {'provider_specific_fields': None, 'content': ' ', 'role': None, 'function_call': None, 'tool_calls': None, 'audio': None}
new delta: Delta(provider_specific_fields=None, content=' ', role=None, function_call=None, tool_calls=None, audio=None)
model_response.choices[0].delta: Delta(provider_specific_fields=None, content=' ', role=None, function_call=None, tool_calls=None, audio=None); completion_obj: {'content': ' '}
self.sent_first_chunk: True
completion_obj: {'content': ' '}, model_response.choices[0]: StreamingChoices(finish_reason=None, index=0, delta=Delta(provider_specific_fields=None, content=' ', role=None, function_call=None, tool_calls=None, audio=None), logprobs=None), response_obj: {'text': ' ', 'is_finished': False, 'finish_reason': None, 'logprobs': None, 'original_chunk': ModelResponseStream(id='chatcmpl-1e246dec-1357-4ceb-948f-03d49e55b5f9', created=1762261919, model=None, object='chat.completion.chunk', system_fingerprint=None, choices=[StreamingChoices(finish_reason=None, index=0, delta=Delta(provider_specific_fields=None, content=' ', role=None, function_call=None, tool_calls=None, audio=None), logprobs=None)], provider_specific_fields=None, usage=None), 'usage': None}
choice_json: {'index': 0, 'delta': {'provider_specific_fields': None, 'content': ' ', 'role': None, 'function_call': None, 'tool_calls': None, 'audio': None}, 'logprobs': None}
choices in streaming: [StreamingChoices(finish_reason=None, index=0, delta=Delta(provider_specific_fields=None, content=' ', role=None, function_call=None, tool_calls=None, audio=None), logprobs=None)]
final returned processed chunk: ModelResponseStream(id='chatcmpl-1e246dec-1357-4ceb-948f-03d49e55b5f9', created=1762261907, model='claude-sonnet-4-5-20250929', object='chat.completion.chunk', system_fingerprint=None, choices=[StreamingChoices(finish_reason=None, index=0, delta=Delta(provider_specific_fields=None, content=' ', role=None, function_call=None, tool_calls=None, audio=None), logprobs=None)], provider_specific_fields=None, citations=None)
model_response finish reason 3: None; response_obj={'text': '', 'is_finished': False, 'finish_reason': '', 'usage': None, 'index': 0, 'tool_use': None}
model_response.choices[0].delta: Delta(provider_specific_fields=None, content=None, role=None, function_call=None, tool_calls=None, audio=None); completion_obj: {'content': ''}
self.sent_first_chunk: True
completion_obj: {'content': ''}, model_response.choices[0]: StreamingChoices(finish_reason=None, index=0, delta=Delta(provider_specific_fields=None, content=None, role=None, function_call=None, tool_calls=None, audio=None), logprobs=None), response_obj: {'text': '', 'is_finished': False, 'finish_reason': '', 'usage': None, 'index': 0, 'tool_use': None}
model_response finish reason 3: None; response_obj={'text': '', 'is_finished': False, 'finish_reason': '', 'usage': None, 'index': 0, 'tool_use': None}
model_response.choices[0].delta: Delta(provider_specific_fields=None, content=None, role=None, function_call=None, tool_calls=None, audio=None); completion_obj: {'content': ''}
self.sent_first_chunk: True
completion_obj: {'content': ''}, model_response.choices[0]: StreamingChoices(finish_reason=None, index=0, delta=Delta(provider_specific_fields=None, content=None, role=None, function_call=None, tool_calls=None, audio=None), logprobs=None), response_obj: {'text': '', 'is_finished': False, 'finish_reason': '', 'usage': None, 'index': 0, 'tool_use': None}

Raw OpenAI Chunk
ModelResponseStream(id='chatcmpl-1e246dec-1357-4ceb-948f-03d49e55b5f9', created=1762261919, model=None, object='chat.completion.chunk', system_fingerprint=None, choices=[StreamingChoices(finish_reason=None, index=0, delta=Delta(provider_specific_fields=None, content='', role=None, function_call=None, tool_calls=None, audio=None), logprobs=None)], provider_specific_fields=None, usage=None)

model_response finish reason 3: None; response_obj={'text': '', 'is_finished': False, 'finish_reason': None, 'logprobs': None, 'original_chunk': ModelResponseStream(id='chatcmpl-1e246dec-1357-4ceb-948f-03d49e55b5f9', created=1762261919, model=None, object='chat.completion.chunk', system_fingerprint=None, choices=[StreamingChoices(finish_reason=None, index=0, delta=Delta(provider_specific_fields=None, content='', role=None, function_call=None, tool_calls=None, audio=None), logprobs=None)], provider_specific_fields=None, usage=None), 'usage': None}
original delta: {'provider_specific_fields': None, 'content': '', 'role': None, 'function_call': None, 'tool_calls': None, 'audio': None}
new delta: Delta(provider_specific_fields=None, content='', role=None, function_call=None, tool_calls=None, audio=None)
model_response.choices[0].delta: Delta(provider_specific_fields=None, content='', role=None, function_call=None, tool_calls=None, audio=None); completion_obj: {'content': ''}
self.sent_first_chunk: True
completion_obj: {'content': ''}, model_response.choices[0]: StreamingChoices(finish_reason=None, index=0, delta=Delta(provider_specific_fields=None, content='', role=None, function_call=None, tool_calls=None, audio=None), logprobs=None), response_obj: {'text': '', 'is_finished': False, 'finish_reason': None, 'logprobs': None, 'original_chunk': ModelResponseStream(id='chatcmpl-1e246dec-1357-4ceb-948f-03d49e55b5f9', created=1762261919, model=None, object='chat.completion.chunk', system_fingerprint=None, choices=[StreamingChoices(finish_reason=None, index=0, delta=Delta(provider_specific_fields=None, content='', role=None, function_call=None, tool_calls=None, audio=None), logprobs=None)], provider_specific_fields=None, usage=None), 'usage': None}
model_response finish reason 3: None; response_obj={'text': '', 'is_finished': False, 'finish_reason': '', 'usage': None, 'index': 0, 'tool_use': None}
model_response.choices[0].delta: Delta(provider_specific_fields=None, content=None, role=None, function_call=None, tool_calls=None, audio=None); completion_obj: {'content': ''}
self.sent_first_chunk: True
completion_obj: {'content': ''}, model_response.choices[0]: StreamingChoices(finish_reason=None, index=0, delta=Delta(provider_specific_fields=None, content=None, role=None, function_call=None, tool_calls=None, audio=None), logprobs=None), response_obj: {'text': '', 'is_finished': False, 'finish_reason': '', 'usage': None, 'index': 0, 'tool_use': None}
model_response finish reason 3: None; response_obj={'text': '', 'is_finished': False, 'finish_reason': '', 'usage': None, 'index': 0, 'tool_use': None}
model_response.choices[0].delta: Delta(provider_specific_fields=None, content=None, role=None, function_call=None, tool_calls=None, audio=None); completion_obj: {'content': ''}
self.sent_first_chunk: True
completion_obj: {'content': ''}, model_response.choices[0]: StreamingChoices(finish_reason=None, index=0, delta=Delta(provider_specific_fields=None, content=None, role=None, function_call=None, tool_calls=None, audio=None), logprobs=None), response_obj: {'text': '', 'is_finished': False, 'finish_reason': '', 'usage': None, 'index': 0, 'tool_use': None}

Raw OpenAI Chunk
ModelResponseStream(id='chatcmpl-1e246dec-1357-4ceb-948f-03d49e55b5f9', created=1762261919, model=None, object='chat.completion.chunk', system_fingerprint=None, choices=[StreamingChoices(finish_reason='stop', index=0, delta=Delta(provider_specific_fields=None, content='', role=None, function_call=None, tool_calls=None, audio=None), logprobs=None)], provider_specific_fields=None, usage=Usage(completion_tokens=506, prompt_tokens=19880, total_tokens=20386, completion_tokens_details=None, prompt_tokens_details=PromptTokensDetailsWrapper(audio_tokens=None, cached_tokens=0, text_tokens=None, image_tokens=None, cache_creation_tokens=0), cache_creation_input_tokens=0, cache_read_input_tokens=0))

model_response finish reason 3: stop; response_obj={'text': '', 'is_finished': True, 'finish_reason': 'stop', 'logprobs': None, 'original_chunk': ModelResponseStream(id='chatcmpl-1e246dec-1357-4ceb-948f-03d49e55b5f9', created=1762261919, model=None, object='chat.completion.chunk', system_fingerprint=None, choices=[StreamingChoices(finish_reason='stop', index=0, delta=Delta(provider_specific_fields=None, content='', role=None, function_call=None, tool_calls=None, audio=None), logprobs=None)], provider_specific_fields=None, usage=Usage(completion_tokens=506, prompt_tokens=19880, total_tokens=20386, completion_tokens_details=None, prompt_tokens_details=PromptTokensDetailsWrapper(audio_tokens=None, cached_tokens=0, text_tokens=None, image_tokens=None, cache_creation_tokens=0), cache_creation_input_tokens=0, cache_read_input_tokens=0)), 'usage': Usage(completion_tokens=506, prompt_tokens=19880, total_tokens=20386, completion_tokens_details=None, prompt_tokens_details=PromptTokensDetailsWrapper(audio_tokens=None, cached_tokens=0, text_tokens=None, image_tokens=None, cache_creation_tokens=0), cache_creation_input_tokens=0, cache_read_input_tokens=0)}
original delta: {'provider_specific_fields': None, 'content': '', 'role': None, 'function_call': None, 'tool_calls': None, 'audio': None}
new delta: Delta(provider_specific_fields=None, content='', role=None, function_call=None, tool_calls=None, audio=None)
model_response.choices[0].delta: Delta(provider_specific_fields=None, content='', role=None, function_call=None, tool_calls=None, audio=None); completion_obj: {'content': ''}
self.sent_first_chunk: True
completion_obj: {'content': ''}, model_response.choices[0]: StreamingChoices(finish_reason=None, index=0, delta=Delta(provider_specific_fields=None, content='', role=None, function_call=None, tool_calls=None, audio=None), logprobs=None), response_obj: {'text': '', 'is_finished': True, 'finish_reason': 'stop', 'logprobs': None, 'original_chunk': ModelResponseStream(id='chatcmpl-1e246dec-1357-4ceb-948f-03d49e55b5f9', created=1762261919, model=None, object='chat.completion.chunk', system_fingerprint=None, choices=[StreamingChoices(finish_reason='stop', index=0, delta=Delta(provider_specific_fields=None, content='', role=None, function_call=None, tool_calls=None, audio=None), logprobs=None)], provider_specific_fields=None, usage=Usage(completion_tokens=506, prompt_tokens=19880, total_tokens=20386, completion_tokens_details=None, prompt_tokens_details=PromptTokensDetailsWrapper(audio_tokens=None, cached_tokens=0, text_tokens=None, image_tokens=None, cache_creation_tokens=0), cache_creation_input_tokens=0, cache_read_input_tokens=0)), 'usage': Usage(completion_tokens=506, prompt_tokens=19880, total_tokens=20386, completion_tokens_details=None, prompt_tokens_details=PromptTokensDetailsWrapper(audio_tokens=None, cached_tokens=0, text_tokens=None, image_tokens=None, cache_creation_tokens=0), cache_creation_input_tokens=0, cache_read_input_tokens=0)}
final returned processed chunk: ModelResponseStream(id='chatcmpl-1e246dec-1357-4ceb-948f-03d49e55b5f9', created=1762261907, model='claude-sonnet-4-5-20250929', object='chat.completion.chunk', system_fingerprint=None, choices=[StreamingChoices(finish_reason='stop', index=0, delta=Delta(provider_specific_fields=None, content=None, role=None, function_call=None, tool_calls=None, audio=None), logprobs=None)], provider_specific_fields=None)
INFO:     127.0.0.1:53141 - "GET /v1/models HTTP/1.1" 200 OK
INFO:     127.0.0.1:53151 - "GET /v1/models HTTP/1.1" 200 OK
INFO:     127.0.0.1:53215 - "GET /v1/models HTTP/1.1" 200 OK
INFO:     127.0.0.1:53305 - "GET /v1/models HTTP/1.1" 200 OK
INFO:     127.0.0.1:53311 - "GET /v1/models HTTP/1.1" 200 OK
INFO:     127.0.0.1:53313 - "GET /v1/models HTTP/1.1" 200 OK
INFO:     127.0.0.1:53420 - "GET /v1/models HTTP/1.1" 200 OK
INFO:     127.0.0.1:54038 - "GET /v1/models HTTP/1.1" 200 OK
INFO:     127.0.0.1:54294 - "GET /v1/models HTTP/1.1" 200 OK
INFO:     127.0.0.1:54306 - "GET /v1/models HTTP/1.1" 200 OK
INFO:     127.0.0.1:54343 - "GET /v1/models HTTP/1.1" 200 OK
INFO:     127.0.0.1:54347 - "GET /v1/models HTTP/1.1" 200 OK
INFO:     127.0.0.1:54382 - "GET /v1/models HTTP/1.1" 200 OK
INFO:     127.0.0.1:54385 - "GET /v1/models HTTP/1.1" 200 OK
INFO:     127.0.0.1:54386 - "GET /v1/models HTTP/1.1" 200 OK
INFO:     127.0.0.1:54591 - "GET /v1/models HTTP/1.1" 200 OK
INFO:     127.0.0.1:54592 - "GET /v1/models HTTP/1.1" 200 OK
INFO:     127.0.0.1:54685 - "GET /v1/models HTTP/1.1" 200 OK
INFO:     127.0.0.1:54763 - "GET /v1/models HTTP/1.1" 200 OK
INFO:     127.0.0.1:55110 - "GET /v1/models HTTP/1.1" 200 OK
INFO:     127.0.0.1:55628 - "GET /v1/models HTTP/1.1" 200 OK
INFO:     127.0.0.1:55656 - "GET /v1/models HTTP/1.1" 200 OK
INFO:     127.0.0.1:55781 - "GET /v1/models HTTP/1.1" 200 OK
INFO:     127.0.0.1:55834 - "GET /v1/models HTTP/1.1" 200 OK
